{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hd_tp = pd.read_csv('evaluation_set/headline_topic_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Video game content rating system\n",
       "1               Grand Theft Childhood\n",
       "2                     School violence\n",
       "3            Video game controversies\n",
       "4               Nonviolent video game\n",
       "Name: Title, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hd_tp.Title.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input-Token (InputLayer)        (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Segment (InputLayer)      (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token (TokenEmbedding [(None, 20, 25), (28 700         Input-Token[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Segment (Embedding)   (None, 20, 25)       50          Input-Segment[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Token-Segment (Add)   (None, 20, 25)       0           Embedding-Token[0][0]            \n",
      "                                                                 Embedding-Segment[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Position (PositionEmb (None, 20, 25)       500         Embedding-Token-Segment[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Dropout (Dropout)     (None, 20, 25)       0           Embedding-Position[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "Embedding-Norm (LayerNormalizat (None, 20, 25)       50          Embedding-Dropout[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       2600        Embedding-Norm[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-1-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       0           Embedding-Norm[0][0]             \n",
      "                                                                 Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-1-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-1-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-1-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-1-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-1-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-1-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-1-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-2-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-1-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-2-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-2-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-2-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-2-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-2-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-2-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-2-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-3-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-2-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-3-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-3-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-3-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-3-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-3-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-3-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-3-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-4-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-3-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-4-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-4-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-4-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-4-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-4-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-4-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-4-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-5-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-4-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-5-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-5-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-5-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-5-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-5-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-5-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-5-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-6-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-5-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-6-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-6-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-6-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-6-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-6-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-6-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-6-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-7-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-6-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-7-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-7-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-7-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-7-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-7-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-7-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-7-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-8-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-7-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-8-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-8-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-8-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-8-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-8-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-8-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       2600        Encoder-8-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-9-MultiHeadSelfAttention[\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       0           Encoder-8-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-MultiHeadSelfAttentio (None, 20, 25)       50          Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward (FeedForw (None, 20, 25)       5125        Encoder-9-MultiHeadSelfAttention-\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Dropout ( (None, 20, 25)       0           Encoder-9-FeedForward[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Add (Add) (None, 20, 25)       0           Encoder-9-MultiHeadSelfAttention-\n",
      "                                                                 Encoder-9-FeedForward-Dropout[0][\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-9-FeedForward-Norm (Lay (None, 20, 25)       50          Encoder-9-FeedForward-Add[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       2600        Encoder-9-FeedForward-Norm[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-9-FeedForward-Norm[0][0] \n",
      "                                                                 Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-MultiHeadSelfAttenti (None, 20, 25)       50          Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward (FeedFor (None, 20, 25)       5125        Encoder-10-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Dropout  (None, 20, 25)       0           Encoder-10-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Add (Add (None, 20, 25)       0           Encoder-10-MultiHeadSelfAttention\n",
      "                                                                 Encoder-10-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-10-FeedForward-Norm (La (None, 20, 25)       50          Encoder-10-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       2600        Encoder-10-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-10-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-MultiHeadSelfAttenti (None, 20, 25)       50          Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward (FeedFor (None, 20, 25)       5125        Encoder-11-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Dropout  (None, 20, 25)       0           Encoder-11-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Add (Add (None, 20, 25)       0           Encoder-11-MultiHeadSelfAttention\n",
      "                                                                 Encoder-11-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-11-FeedForward-Norm (La (None, 20, 25)       50          Encoder-11-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       2600        Encoder-11-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       0           Encoder-11-FeedForward-Norm[0][0]\n",
      "                                                                 Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-MultiHeadSelfAttenti (None, 20, 25)       50          Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward (FeedFor (None, 20, 25)       5125        Encoder-12-MultiHeadSelfAttention\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Dropout  (None, 20, 25)       0           Encoder-12-FeedForward[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Add (Add (None, 20, 25)       0           Encoder-12-MultiHeadSelfAttention\n",
      "                                                                 Encoder-12-FeedForward-Dropout[0]\n",
      "__________________________________________________________________________________________________\n",
      "Encoder-12-FeedForward-Norm (La (None, 20, 25)       50          Encoder-12-FeedForward-Add[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "MLM-Dense (Dense)               (None, 20, 25)       650         Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Norm (LayerNormalization)   (None, 20, 25)       50          MLM-Dense[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Extract (Extract)               (None, 25)           0           Encoder-12-FeedForward-Norm[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "MLM-Sim (EmbeddingSimilarity)   (None, 20, 28)       28          MLM-Norm[0][0]                   \n",
      "                                                                 Embedding-Token[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "Input-Masked (InputLayer)       (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "NSP-Dense (Dense)               (None, 25)           650         Extract[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "MLM (Masked)                    (None, 20, 28)       0           MLM-Sim[0][0]                    \n",
      "                                                                 Input-Masked[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "NSP (Dense)                     (None, 2)            52          NSP-Dense[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 96,630\n",
      "Trainable params: 96,630\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1000/1000 [==============================] - 64s 64ms/step - loss: 3.9911 - MLM_loss: 3.3370 - NSP_loss: 0.6541 - val_loss: 3.9175 - val_MLM_loss: 3.3191 - val_NSP_loss: 0.5984\n",
      "Epoch 2/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 3.9220 - MLM_loss: 3.2957 - NSP_loss: 0.6263 - val_loss: 3.6933 - val_MLM_loss: 3.2595 - val_NSP_loss: 0.4339\n",
      "Epoch 3/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 3.6267 - MLM_loss: 3.2504 - NSP_loss: 0.3763 - val_loss: 3.3878 - val_MLM_loss: 3.2385 - val_NSP_loss: 0.1492\n",
      "Epoch 4/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 3.3139 - MLM_loss: 3.2057 - NSP_loss: 0.1081 - val_loss: 3.1836 - val_MLM_loss: 3.1629 - val_NSP_loss: 0.0207\n",
      "Epoch 5/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 3.2032 - MLM_loss: 3.1411 - NSP_loss: 0.0621 - val_loss: 3.1280 - val_MLM_loss: 3.0871 - val_NSP_loss: 0.0409\n",
      "Epoch 6/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 3.1099 - MLM_loss: 3.0639 - NSP_loss: 0.0460 - val_loss: 3.0152 - val_MLM_loss: 3.0085 - val_NSP_loss: 0.0067\n",
      "Epoch 7/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 3.0368 - MLM_loss: 2.9848 - NSP_loss: 0.0520 - val_loss: 2.9450 - val_MLM_loss: 2.9243 - val_NSP_loss: 0.0208\n",
      "Epoch 8/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 2.9055 - MLM_loss: 2.8682 - NSP_loss: 0.0373 - val_loss: 2.7469 - val_MLM_loss: 2.7371 - val_NSP_loss: 0.0098\n",
      "Epoch 9/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 2.7216 - MLM_loss: 2.6874 - NSP_loss: 0.0342 - val_loss: 2.5741 - val_MLM_loss: 2.5674 - val_NSP_loss: 0.0067\n",
      "Epoch 10/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 2.5134 - MLM_loss: 2.4833 - NSP_loss: 0.0301 - val_loss: 2.3668 - val_MLM_loss: 2.3364 - val_NSP_loss: 0.0304\n",
      "Epoch 11/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 2.3189 - MLM_loss: 2.2835 - NSP_loss: 0.0354 - val_loss: 2.2464 - val_MLM_loss: 2.2023 - val_NSP_loss: 0.0441\n",
      "Epoch 12/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 2.1180 - MLM_loss: 2.1018 - NSP_loss: 0.0162 - val_loss: 1.9731 - val_MLM_loss: 1.9706 - val_NSP_loss: 0.0025\n",
      "Epoch 13/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.9421 - MLM_loss: 1.9251 - NSP_loss: 0.0170 - val_loss: 1.8335 - val_MLM_loss: 1.8094 - val_NSP_loss: 0.0240\n",
      "Epoch 14/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.7796 - MLM_loss: 1.7633 - NSP_loss: 0.0163 - val_loss: 1.6446 - val_MLM_loss: 1.6404 - val_NSP_loss: 0.0041\n",
      "Epoch 15/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.6389 - MLM_loss: 1.6213 - NSP_loss: 0.0176 - val_loss: 1.6628 - val_MLM_loss: 1.6043 - val_NSP_loss: 0.0586\n",
      "Epoch 16/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.5492 - MLM_loss: 1.5294 - NSP_loss: 0.0198 - val_loss: 1.4889 - val_MLM_loss: 1.4528 - val_NSP_loss: 0.0362\n",
      "Epoch 17/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.4387 - MLM_loss: 1.4212 - NSP_loss: 0.0175 - val_loss: 1.3291 - val_MLM_loss: 1.3269 - val_NSP_loss: 0.0022\n",
      "Epoch 18/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.3256 - MLM_loss: 1.3113 - NSP_loss: 0.0144 - val_loss: 1.1904 - val_MLM_loss: 1.1807 - val_NSP_loss: 0.0098\n",
      "Epoch 19/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.2110 - MLM_loss: 1.1895 - NSP_loss: 0.0215 - val_loss: 1.0586 - val_MLM_loss: 1.0572 - val_NSP_loss: 0.0014\n",
      "Epoch 20/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 1.0899 - MLM_loss: 1.0689 - NSP_loss: 0.0210 - val_loss: 0.9272 - val_MLM_loss: 0.9206 - val_NSP_loss: 0.0067\n",
      "Epoch 21/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.9895 - MLM_loss: 0.9641 - NSP_loss: 0.0255 - val_loss: 0.8365 - val_MLM_loss: 0.8218 - val_NSP_loss: 0.0147\n",
      "Epoch 22/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.8473 - MLM_loss: 0.8337 - NSP_loss: 0.0135 - val_loss: 0.7322 - val_MLM_loss: 0.7182 - val_NSP_loss: 0.0140\n",
      "Epoch 23/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.7262 - MLM_loss: 0.7104 - NSP_loss: 0.0159 - val_loss: 0.5529 - val_MLM_loss: 0.5510 - val_NSP_loss: 0.0018\n",
      "Epoch 24/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.6064 - MLM_loss: 0.5939 - NSP_loss: 0.0125 - val_loss: 0.4402 - val_MLM_loss: 0.4388 - val_NSP_loss: 0.0014\n",
      "Epoch 25/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.5155 - MLM_loss: 0.4938 - NSP_loss: 0.0217 - val_loss: 0.3595 - val_MLM_loss: 0.3450 - val_NSP_loss: 0.0145\n",
      "Epoch 26/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.4215 - MLM_loss: 0.3987 - NSP_loss: 0.0228 - val_loss: 0.2791 - val_MLM_loss: 0.2609 - val_NSP_loss: 0.0182\n",
      "Epoch 27/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.3365 - MLM_loss: 0.3183 - NSP_loss: 0.0182 - val_loss: 0.2007 - val_MLM_loss: 0.1862 - val_NSP_loss: 0.0145\n",
      "Epoch 28/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2679 - MLM_loss: 0.2488 - NSP_loss: 0.0190 - val_loss: 0.1516 - val_MLM_loss: 0.1419 - val_NSP_loss: 0.0097\n",
      "Epoch 29/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.2264 - MLM_loss: 0.2077 - NSP_loss: 0.0187 - val_loss: 0.1318 - val_MLM_loss: 0.1257 - val_NSP_loss: 0.0061\n",
      "Epoch 30/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1948 - MLM_loss: 0.1749 - NSP_loss: 0.0199 - val_loss: 0.0884 - val_MLM_loss: 0.0875 - val_NSP_loss: 9.0370e-04\n",
      "Epoch 31/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1562 - MLM_loss: 0.1415 - NSP_loss: 0.0147 - val_loss: 0.1115 - val_MLM_loss: 0.0881 - val_NSP_loss: 0.0235\n",
      "Epoch 32/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1304 - MLM_loss: 0.1173 - NSP_loss: 0.0131 - val_loss: 0.0534 - val_MLM_loss: 0.0524 - val_NSP_loss: 9.9298e-04\n",
      "Epoch 33/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1266 - MLM_loss: 0.1130 - NSP_loss: 0.0137 - val_loss: 0.0789 - val_MLM_loss: 0.0747 - val_NSP_loss: 0.0042\n",
      "Epoch 34/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.1054 - MLM_loss: 0.0929 - NSP_loss: 0.0126 - val_loss: 0.0353 - val_MLM_loss: 0.0343 - val_NSP_loss: 9.5939e-04\n",
      "Epoch 35/100\n",
      "1000/1000 [==============================] - 45s 45ms/step - loss: 0.1059 - MLM_loss: 0.0904 - NSP_loss: 0.0156 - val_loss: 0.0637 - val_MLM_loss: 0.0428 - val_NSP_loss: 0.0209\n",
      "Epoch 36/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0856 - MLM_loss: 0.0716 - NSP_loss: 0.0140 - val_loss: 0.0844 - val_MLM_loss: 0.0617 - val_NSP_loss: 0.0227\n",
      "Epoch 37/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0921 - MLM_loss: 0.0790 - NSP_loss: 0.0131 - val_loss: 0.0229 - val_MLM_loss: 0.0223 - val_NSP_loss: 6.5389e-04\n",
      "Epoch 38/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0874 - MLM_loss: 0.0699 - NSP_loss: 0.0175 - val_loss: 0.0230 - val_MLM_loss: 0.0210 - val_NSP_loss: 0.0020\n",
      "Epoch 39/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0798 - MLM_loss: 0.0652 - NSP_loss: 0.0146 - val_loss: 0.0272 - val_MLM_loss: 0.0226 - val_NSP_loss: 0.0046\n",
      "Epoch 40/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0773 - MLM_loss: 0.0592 - NSP_loss: 0.0181 - val_loss: 0.1051 - val_MLM_loss: 0.0623 - val_NSP_loss: 0.0429\n",
      "Epoch 41/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0619 - MLM_loss: 0.0528 - NSP_loss: 0.0091 - val_loss: 0.0154 - val_MLM_loss: 0.0150 - val_NSP_loss: 3.5994e-04\n",
      "Epoch 42/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0504 - MLM_loss: 0.0423 - NSP_loss: 0.0081 - val_loss: 0.0196 - val_MLM_loss: 0.0173 - val_NSP_loss: 0.0022\n",
      "Epoch 43/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0496 - MLM_loss: 0.0433 - NSP_loss: 0.0062 - val_loss: 0.0126 - val_MLM_loss: 0.0120 - val_NSP_loss: 6.5907e-04\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0355 - MLM_loss: 0.0314 - NSP_loss: 0.0041 - val_loss: 0.0125 - val_MLM_loss: 0.0117 - val_NSP_loss: 7.5070e-04\n",
      "Epoch 45/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0475 - MLM_loss: 0.0354 - NSP_loss: 0.0121 - val_loss: 0.0121 - val_MLM_loss: 0.0115 - val_NSP_loss: 6.5052e-04\n",
      "Epoch 46/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0656 - MLM_loss: 0.0528 - NSP_loss: 0.0129 - val_loss: 0.0423 - val_MLM_loss: 0.0275 - val_NSP_loss: 0.0148\n",
      "Epoch 47/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0662 - MLM_loss: 0.0526 - NSP_loss: 0.0136 - val_loss: 0.0263 - val_MLM_loss: 0.0206 - val_NSP_loss: 0.0057\n",
      "Epoch 48/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0527 - MLM_loss: 0.0413 - NSP_loss: 0.0114 - val_loss: 0.0204 - val_MLM_loss: 0.0160 - val_NSP_loss: 0.0044\n",
      "Epoch 49/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0372 - MLM_loss: 0.0344 - NSP_loss: 0.0027 - val_loss: 0.0650 - val_MLM_loss: 0.0614 - val_NSP_loss: 0.0036\n",
      "Epoch 50/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0496 - MLM_loss: 0.0373 - NSP_loss: 0.0122 - val_loss: 0.0109 - val_MLM_loss: 0.0086 - val_NSP_loss: 0.0023\n",
      "Epoch 51/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0501 - MLM_loss: 0.0402 - NSP_loss: 0.0099 - val_loss: 0.0334 - val_MLM_loss: 0.0225 - val_NSP_loss: 0.0109\n",
      "Epoch 52/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0474 - MLM_loss: 0.0342 - NSP_loss: 0.0132 - val_loss: 0.0132 - val_MLM_loss: 0.0090 - val_NSP_loss: 0.0042\n",
      "Epoch 53/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0415 - MLM_loss: 0.0340 - NSP_loss: 0.0075 - val_loss: 0.0446 - val_MLM_loss: 0.0387 - val_NSP_loss: 0.0059\n",
      "Epoch 54/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0358 - MLM_loss: 0.0307 - NSP_loss: 0.0050 - val_loss: 0.0111 - val_MLM_loss: 0.0109 - val_NSP_loss: 2.5507e-04\n",
      "Epoch 55/100\n",
      "1000/1000 [==============================] - 44s 44ms/step - loss: 0.0487 - MLM_loss: 0.0389 - NSP_loss: 0.0098 - val_loss: 0.0355 - val_MLM_loss: 0.0225 - val_NSP_loss: 0.0129\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras_bert import get_base_dict, get_model, compile_model, gen_batch_inputs\n",
    "\n",
    "\n",
    "# A toy input example\n",
    "sentence_pairs = [\n",
    "    [['all', 'work', 'and', 'no', 'play'], ['makes', 'jack', 'a', 'dull', 'boy']],\n",
    "    [['from', 'the', 'day', 'forth'], ['my', 'arm', 'changed']],\n",
    "    [['and', 'a', 'voice', 'echoed'], ['power', 'give', 'me', 'more', 'power']],\n",
    "]\n",
    "\n",
    "\n",
    "# Build token dictionary\n",
    "token_dict = get_base_dict()  # A dict that contains some special tokens\n",
    "for pairs in sentence_pairs:\n",
    "    for token in pairs[0] + pairs[1]:\n",
    "        if token not in token_dict:\n",
    "            token_dict[token] = len(token_dict)\n",
    "token_list = list(token_dict.keys())  # Used for selecting a random word\n",
    "\n",
    "\n",
    "# Build & train the model\n",
    "model = get_model(\n",
    "    token_num=len(token_dict),\n",
    "    head_num=5,\n",
    "    transformer_num=12,\n",
    "    embed_dim=25,\n",
    "    feed_forward_dim=100,\n",
    "    seq_len=20,\n",
    "    pos_num=20,\n",
    "    dropout_rate=0.05,\n",
    ")\n",
    "compile_model(model)\n",
    "model.summary()\n",
    "\n",
    "def _generator():\n",
    "    while True:\n",
    "        yield gen_batch_inputs(\n",
    "            sentence_pairs,\n",
    "            token_dict,\n",
    "            token_list,\n",
    "            seq_len=20,\n",
    "            mask_rate=0.3,\n",
    "            swap_sentence_rate=1.0,\n",
    "        )\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=_generator(),\n",
    "    steps_per_epoch=1000,\n",
    "    epochs=100,\n",
    "    validation_data=_generator(),\n",
    "    validation_steps=100,\n",
    "    callbacks=[\n",
    "        keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Use the trained model\n",
    "inputs, output_layer = get_model(\n",
    "    token_num=len(token_dict),\n",
    "    head_num=5,\n",
    "    transformer_num=12,\n",
    "    embed_dim=25,\n",
    "    feed_forward_dim=100,\n",
    "    seq_len=20,\n",
    "    pos_num=20,\n",
    "    dropout_rate=0.05,\n",
    "    training=False,      # The input layers and output layer will be returned if `training` is `False`\n",
    "    trainable=False,     # Whether the model is trainable. The default value is the same with `training`\n",
    "    output_layer_num=4,  # The number of layers whose outputs will be concatenated as a single output.\n",
    "                         # Only available when `training` is `False`.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'Input-Token_1:0' shape=(?, 20) dtype=float32>,\n",
       " <tf.Tensor 'Input-Segment_1:0' shape=(?, 20) dtype=float32>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Encoder-Output/concat:0' shape=(?, 20, 100) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([[ 2,  5,  6,  7,  8,  9,  3,  4, 11, 12, 13, 14,  3,  0,  0,  0,\n",
       "           0,  0,  0,  0],\n",
       "         [ 2,  4,  4, 17, 18,  3,  4, 25,  4, 27, 24,  3,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0],\n",
       "         [ 2,  7,  4,  4, 23,  3, 19,  4, 21,  3,  0,  0,  0,  0,  0,  0,\n",
       "           0,  0,  0,  0]]),\n",
       "  array([[0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]),\n",
       "  array([[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])],\n",
       " [array([[[ 2],\n",
       "          [ 5],\n",
       "          [ 6],\n",
       "          [ 7],\n",
       "          [ 8],\n",
       "          [ 9],\n",
       "          [ 3],\n",
       "          [10],\n",
       "          [11],\n",
       "          [12],\n",
       "          [13],\n",
       "          [14],\n",
       "          [ 3],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0]],\n",
       "  \n",
       "         [[ 2],\n",
       "          [15],\n",
       "          [16],\n",
       "          [17],\n",
       "          [18],\n",
       "          [ 3],\n",
       "          [24],\n",
       "          [25],\n",
       "          [26],\n",
       "          [27],\n",
       "          [24],\n",
       "          [ 3],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0]],\n",
       "  \n",
       "         [[ 2],\n",
       "          [ 7],\n",
       "          [12],\n",
       "          [22],\n",
       "          [23],\n",
       "          [ 3],\n",
       "          [19],\n",
       "          [20],\n",
       "          [21],\n",
       "          [ 3],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0],\n",
       "          [ 0]]]), array([[0.],\n",
       "         [1.],\n",
       "         [1.]])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(_generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0, '[CLS]': 2, '[MASK]': 4, '[SEP]': 3, '[UNK]': 1}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_base_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['all', 'work', 'and', 'no', 'play'], ['makes', 'jack', 'a', 'dull', 'boy']],\n",
       " [['from', 'the', 'day', 'forth'], ['my', 'arm', 'changed']],\n",
       " [['and', 'a', 'voice', 'echoed'], ['power', 'give', 'me', 'more', 'power']]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': 0,\n",
       " '[CLS]': 2,\n",
       " '[MASK]': 4,\n",
       " '[SEP]': 3,\n",
       " '[UNK]': 1,\n",
       " 'a': 12,\n",
       " 'all': 5,\n",
       " 'and': 7,\n",
       " 'arm': 20,\n",
       " 'boy': 14,\n",
       " 'changed': 21,\n",
       " 'day': 17,\n",
       " 'dull': 13,\n",
       " 'echoed': 23,\n",
       " 'forth': 18,\n",
       " 'from': 15,\n",
       " 'give': 25,\n",
       " 'jack': 11,\n",
       " 'makes': 10,\n",
       " 'me': 26,\n",
       " 'more': 27,\n",
       " 'my': 19,\n",
       " 'no': 8,\n",
       " 'play': 9,\n",
       " 'power': 24,\n",
       " 'the': 16,\n",
       " 'voice': 22,\n",
       " 'work': 6}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'no',\n",
       " 'me',\n",
       " 'my',\n",
       " 'power',\n",
       " 'echoed',\n",
       " '[UNK]',\n",
       " '[MASK]',\n",
       " 'work',\n",
       " 'and',\n",
       " 'voice',\n",
       " 'boy',\n",
       " 'more',\n",
       " 'arm',\n",
       " 'dull',\n",
       " '[CLS]',\n",
       " '[SEP]',\n",
       " 'play',\n",
       " 'the',\n",
       " 'a',\n",
       " 'forth',\n",
       " 'jack',\n",
       " 'from',\n",
       " 'day',\n",
       " 'makes',\n",
       " 'give',\n",
       " 'all',\n",
       " 'changed']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all\n",
      "work\n",
      "and\n",
      "no\n",
      "play\n",
      "makes\n",
      "jack\n",
      "a\n",
      "dull\n",
      "boy\n",
      "from\n",
      "the\n",
      "day\n",
      "forth\n",
      "my\n",
      "arm\n",
      "changed\n",
      "and\n",
      "a\n",
      "voice\n",
      "echoed\n",
      "power\n",
      "give\n",
      "me\n",
      "more\n",
      "power\n"
     ]
    }
   ],
   "source": [
    "# Build token dictionary\n",
    "token_dict = get_base_dict()  # A dict that contains some special tokens\n",
    "for pairs in sentence_pairs:\n",
    "    for token in pairs[0] + pairs[1]:\n",
    "        if token not in token_dict:\n",
    "            token_dict[token] = len(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
