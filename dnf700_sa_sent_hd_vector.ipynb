{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import spacy\n",
    "from keras.utils import to_categorical\n",
    "from spacy.lang.en import English\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.layers import BatchNormalization, Lambda, Concatenate, Dropout, Conv1D, MaxPooling1D, Input, TimeDistributed, Dense, LSTM, RepeatVector, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from AttentionModules import SelfAttention,CrossAttention\n",
    "import sys,os\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['authors', 'evidence', 'headline', 'id', 'reason', 'claims', 'type',\n",
       "        'urls'],\n",
       "       dtype='object'),\n",
       " Index(['authors', 'headline', 'id', 'type', 'urls'], dtype='object'),\n",
       " 705,\n",
       " 705)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf700 = pd.read_json('evaluation_set/deepnofakes/dnf_700/initial.json')\n",
    "dnf_eval = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V2.json')\n",
    "dnf_eval.columns = ['authors', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls'] \n",
    "with open('evaluation_set/deepnofakes/dnf_700/dnf700_sent_array_id.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_700/dnf700_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_array_id.p', 'rb') as fp:\n",
    "    articles300 = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors300 = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "dnf_eval.keys(), dnf700.keys(), len(articles.keys()), len(article_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "train_batchsize = 32\n",
    "val_batchsize = 32\n",
    "test_batchsize = 50\n",
    "train_steps_per_epoch = 4\n",
    "val_steps_per_epoch = 1\n",
    "epochs = 2000\n",
    "max_sentences = 0\n",
    "for idx in articles.keys():\n",
    "    num = len(articles[idx])\n",
    "    if num>=max_sentences:\n",
    "        max_sentences = num\n",
    "        \n",
    "max_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [authors, headline, id, type, urls]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdl = \"George Soros: Trump Will Win Popular Vote by a Landslide but Clinton Victory a 'Done Deal'\"\n",
    "hdl = \"Ted Cruz Said 'If Something Happens to Hillary' He'll 'Run as a Democrat Against Trump'\"\n",
    "# hdl = \"If You Thought The Trump Child Rape Case In NY Couldn’t Get Much Worse — You Were Wrong\"\n",
    "# hdl = \"California Set to Let Public Schools Teach Primarily in Spanish\"\n",
    "dnf700[dnf700.headline==hdl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sorted(dnf700.headline.unique())\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(VIDEO) Female College Students Protesting Because ‘Trump is a Rapist’',\n",
       " 'Assange Confirms: WikiLeaks Didn’t Get Emails From Russian Govt',\n",
       " 'BREAKING: Fraudulent Clinton Votes Discovered By The “Tens Of Thousands”',\n",
       " \"Clinton Camp Demands 'Compliant Citizenry' for Master Plan\",\n",
       " 'Clinton Received Debate Questions Week Before Debate',\n",
       " \"DOJ's Loretta Lynch Tried To Squash Comey's Letter To Congress\",\n",
       " 'Department of Homeland Security Chairman Officially Indicts Hillary Clinton of Treason',\n",
       " 'Developing: Obama WH admits that Hillary gave ISIS $400 million on accident',\n",
       " 'Erdoğan: US, the founder of ISIS',\n",
       " \"FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Healthcare Begins With A Bombshell! » 100percentfedUp.com\",\n",
       " 'FBI Agent Suspected in Hillary Email Leaks Found Dead in Apparent Murder-Suicide',\n",
       " 'FBI Director Comey’s ‘Leaked’ Memo Explains Why He’s Reopening the Clinton Email Case',\n",
       " 'FBI director received millions from Clinton Foundation, his brother’s law firm does Clinton’s taxes',\n",
       " 'Former NATO Chief: We Need US as ‘World’s Policeman’',\n",
       " \"George Soros: Trump Will Win Popular Vote by a Landslide but Clinton Victory a 'Done Deal'\",\n",
       " 'HE’S NEVER SOLD AN ORIGINAL PAINTING UNTIL NOW…And This One’s Going In The White House',\n",
       " 'HILLARY’S (Islamic) AMERICA IS ALREADY HERE where ‘Muslim NO-GO ZONES’ are popping up all over Michiganistan',\n",
       " \"Hillary Clinton Cut Her Tax Bill by 'Donating' $1 Million to Herself via the Clinton Foundation?\",\n",
       " 'Hillary Clinton Used Hand Signals to Rig Debate?',\n",
       " \"Hillary Clinton Wore 'Secret Earpiece' During Commander-in-Chief Forum\",\n",
       " 'Hillary Clinton Wore Secret Earpiece During First Presidential Debate?',\n",
       " \"Hillary Clinton in 2013: 'I Would Like to See People Like Donald Trump Run for Office\",\n",
       " \"Hillary Clinton's 'Sudden Move' of $1.8 Billion to Qatar Central Bank Stuns Financial World\",\n",
       " 'Hillary Clinton’s “Sudden Move” Of $1.8 Billion To Qatar Central Bank Stuns Financial World',\n",
       " 'Hillary Friend Bribed FBI Agent and His Wife',\n",
       " 'Hillary Personally Ordered ‘Donald Duck’ Troll Campaign',\n",
       " 'Hillary Sold Weapons To ISIS, Wikileaks Confirms',\n",
       " 'ISIS Leader Calls for American Muslim Voters to Support Hillary Clinton',\n",
       " 'Jill Stein Endorsed Donald Trump',\n",
       " 'Julian Assange Makes VERY Suspect Post Election Announcement, Seeks Pardon From Trump',\n",
       " 'KREMLIN: Putin Congratulates Trump, Hopes to Work Together Major Issues',\n",
       " 'LOL! BRITISH WIFE Of LIB ACTOR Who Said: “There Will Never Be A President Donald Trump”…Warns Americans About President-Elect Trump [VIDEO]',\n",
       " 'Leaked 2013 Trump Tax Return Shows He Paid Over 40 Million in Taxes',\n",
       " 'NSA Whistleblower Says DNC Email Hack Was Not by Russia, but by US Intelligence | Alternative',\n",
       " 'Obama Declares His Family Will Move to Canada If Trump Is Elected',\n",
       " 'Pentagon Officials Furious After Clinton Announces US Response Time for Nuclear Launch During Debate',\n",
       " 'Pentagon Seeks Another $6 Billion for Overseas Troop Deployments',\n",
       " \"Physician Confirms Hillary Clinton Has Parkinson's Disease\",\n",
       " 'President Obama Confirms He Will Refuse to Leave Office If Trump Is Elected',\n",
       " 'Reddit Users Declare War On Hillary’s Paid Internet Trolls',\n",
       " \"Ted Cruz Said 'If Something Happens to Hillary' He'll 'Run as a Democrat Against Trump'\",\n",
       " 'The Clinton Foundation has purchased over $137 million of illegal arms and ammunition',\n",
       " 'Top aide: Hillary ‘still not perfect in her head’, Wikileaks',\n",
       " 'Trump accuses Obama, Hillary Clinton of founding Daesh',\n",
       " 'US Officials See No Link Between Trump and Russia',\n",
       " 'US Officials Try to Scare Voters With Terror Threat',\n",
       " 'US Threatens Military Hacks on Russia’s Electric, Communications Grids Over Election',\n",
       " 'WIKILEAKS: Hillary Got $12 Million for Clinton Charity As Quid Pro Quo For Morocco Meeting',\n",
       " 'WikiLeaks CONFIRMS Hillary Sold Weapons to ISIS... Then Drops Another BOMBSHELL! Breaking News',\n",
       " 'WikiLeaks: Hillary Clinton knew Saudi, Qatar were funding ISIS – but still took their money for Foundation']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_titles = sorted(dnf_eval.headline.unique())\n",
    "len(test_titles)\n",
    "test_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_test_titles = np.array(list(set(titles)-set(test_titles)))\n",
    "len(non_test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, val_index in kf.split(non_test_titles):\n",
    "    indices.append([train_index,val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 260 261 262 263 264 265 266 267 268 269 270 271 272 273\n",
      " 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291\n",
      " 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309\n",
      " 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327\n",
      " 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345\n",
      " 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363\n",
      " 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381\n",
      " 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399\n",
      " 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417\n",
      " 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435\n",
      " 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453\n",
      " 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471\n",
      " 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489\n",
      " 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507\n",
      " 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525\n",
      " 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543\n",
      " 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561\n",
      " 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579\n",
      " 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597\n",
      " 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615\n",
      " 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633\n",
      " 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649] [130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147\n",
      " 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165\n",
      " 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183\n",
      " 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201\n",
      " 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219\n",
      " 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237\n",
      " 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255\n",
      " 256 257 258 259]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(520, 130, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_index, val_index = indices[np.random.randint(0,num_splits)]\n",
    "print(train_index,val_index)\n",
    "val_titles = non_test_titles[val_index]\n",
    "train_titles = non_test_titles[train_index]\n",
    "len(train_titles),len(val_titles),len(test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy():\n",
    "    sentencizer = English()\n",
    "    sentencizer.add_pipe(sentencizer.create_pipe('sentencizer'))\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    return sentencizer, nlp\n",
    "sentencizer, nlp = load_spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf(batchsize,dataframe,mode):\n",
    "    counter=0\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            idx=np.random.choice(train_titles)\n",
    "        elif mode=='val':\n",
    "            idx=np.random.choice(val_titles)\n",
    "        elif mode=='test':\n",
    "            idx=np.random.choice(test_titles)\n",
    "        idx = idx.strip()\n",
    "        \n",
    "            \n",
    "#         cl = dataframe[dataframe.Article==idx]['Claim'].values\n",
    "#         sentences=articles[ar_id]\n",
    "#         print(len(sentences))\n",
    "        if mode=='test':\n",
    "            hd = dnf_eval[dnf_eval.headline==idx]['headline'].values[0].lower()\n",
    "            ar_id = dnf_eval[dnf_eval.headline==idx]['id'].values[0]\n",
    "            cl = dnf_eval[dnf_eval.headline==idx]['claims'].values[0]\n",
    "            ar_claims.append(cl)\n",
    "            sentences = articles300[ar_id]\n",
    "            vectors = article_vectors300[ar_id]\n",
    "        else:\n",
    "            try:\n",
    "                hd = dataframe[dataframe.headline==idx]['headline'].values[0].lower()\n",
    "                ar_id = dataframe[dataframe.headline==idx]['id'].values[0]\n",
    "                ar_claims.append('None')\n",
    "                sentences=articles[ar_id]\n",
    "                vectors = article_vectors[ar_id]\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(idx)\n",
    "            \n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "#         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "        \n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "        counter+=1\n",
    "        if counter==batchsize:\n",
    "            inputs = {\n",
    "                'article_id': np.array(ar_ids)\n",
    "                ,'headline': np.array(hds)\n",
    "                ,'sentence_vectors' : np.array(ar_sents)\n",
    "                ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "                ,'claims':np.array(ar_claims)\n",
    "                ,'sentences':np.array(ar_sentences)\n",
    "            }\n",
    "            outputs = {\n",
    "                'headline_token_classes': np.array(ar_head_classes)\n",
    "                ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "            }\n",
    "            yield inputs,outputs\n",
    "            ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "            counter=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = datagen_dnf(train_batchsize,dnf700,mode='train')\n",
    "vdg = datagen_dnf(val_batchsize,dnf700,mode='val')\n",
    "test_dg = datagen_dnf(test_batchsize,dnf700,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(test_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['sentence_vectors'].shape, x['headline_vector'].shape, y['headline_token_classes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 125, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 125, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 125, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 125, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 125, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 125, 1024)    0           ca1[0][0]                        \n",
      "                                                                 ca2[0][0]                        \n",
      "                                                                 ca3[0][0]                        \n",
      "                                                                 ca4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 125, 1024)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 125, 1024)    4096        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 63, 256)      786688      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 32, 256)      196864      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 16, 256)      196864      conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 8, 256)       196864      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 256)       0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 8, 256)       1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_headline_vector (Dense)  (None, 300)          153900      batch_normalization_6[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 2,465,348\n",
      "Trainable params: 2,460,676\n",
      "Non-trainable params: 4,672\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"2130pt\" viewBox=\"0.00 0.00 1823.50 2130.00\" width=\"1824pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 2126)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-2126 1819.5,-2126 1819.5,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 140287230787824 -->\n",
       "<g class=\"node\" id=\"node1\"><title>140287230787824</title>\n",
       "<polygon fill=\"none\" points=\"870,-2075.5 870,-2121.5 1211,-2121.5 1211,-2075.5 870,-2075.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-2094.8\">sentence_vectors: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1046,-2075.5 1046,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1073.5\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1046,-2098.5 1101,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1073.5\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1101,-2075.5 1101,-2121.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1156\" y=\"-2106.3\">(None, 125, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1101,-2098.5 1211,-2098.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1156\" y=\"-2083.3\">(None, 125, 300)</text>\n",
       "</g>\n",
       "<!-- 140287230788216 -->\n",
       "<g class=\"node\" id=\"node2\"><title>140287230788216</title>\n",
       "<polygon fill=\"none\" points=\"896.5,-1992.5 896.5,-2038.5 1184.5,-2038.5 1184.5,-1992.5 896.5,-1992.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-2011.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1019.5,-1992.5 1019.5,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1047\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1019.5,-2015.5 1074.5,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1047\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1074.5,-1992.5 1074.5,-2038.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1129.5\" y=\"-2023.3\">(None, 125, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1074.5,-2015.5 1184.5,-2015.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1129.5\" y=\"-2000.3\">(None, 125, 16)</text>\n",
       "</g>\n",
       "<!-- 140287230787824&#45;&gt;140287230788216 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>140287230787824-&gt;140287230788216</title>\n",
       "<path d=\"M1040.5,-2075.37C1040.5,-2067.15 1040.5,-2057.66 1040.5,-2048.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1044,-2048.61 1040.5,-2038.61 1037,-2048.61 1044,-2048.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287230788328 -->\n",
       "<g class=\"node\" id=\"node3\"><title>140287230788328</title>\n",
       "<polygon fill=\"none\" points=\"898.5,-1909.5 898.5,-1955.5 1182.5,-1955.5 1182.5,-1909.5 898.5,-1909.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961\" y=\"-1928.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1023.5,-1909.5 1023.5,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1023.5,-1932.5 1078.5,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1078.5,-1909.5 1078.5,-1955.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1130.5\" y=\"-1940.3\">(None, 125, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1078.5,-1932.5 1182.5,-1932.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1130.5\" y=\"-1917.3\">(None, 125, 16)</text>\n",
       "</g>\n",
       "<!-- 140287230788216&#45;&gt;140287230788328 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>140287230788216-&gt;140287230788328</title>\n",
       "<path d=\"M1040.5,-1992.37C1040.5,-1984.15 1040.5,-1974.66 1040.5,-1965.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1044,-1965.61 1040.5,-1955.61 1037,-1965.61 1044,-1965.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287230788384 -->\n",
       "<g class=\"node\" id=\"node4\"><title>140287230788384</title>\n",
       "<polygon fill=\"none\" points=\"899.5,-1826.5 899.5,-1872.5 1181.5,-1872.5 1181.5,-1826.5 899.5,-1826.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961\" y=\"-1845.8\">conv1d_2: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1022.5,-1826.5 1022.5,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1050\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1022.5,-1849.5 1077.5,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1050\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1077.5,-1826.5 1077.5,-1872.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1129.5\" y=\"-1857.3\">(None, 125, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1077.5,-1849.5 1181.5,-1849.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1129.5\" y=\"-1834.3\">(None, 125, 32)</text>\n",
       "</g>\n",
       "<!-- 140287230788328&#45;&gt;140287230788384 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>140287230788328-&gt;140287230788384</title>\n",
       "<path d=\"M1040.5,-1909.37C1040.5,-1901.15 1040.5,-1891.66 1040.5,-1882.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1044,-1882.61 1040.5,-1872.61 1037,-1882.61 1044,-1882.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287230945936 -->\n",
       "<g class=\"node\" id=\"node5\"><title>140287230945936</title>\n",
       "<polygon fill=\"none\" points=\"898.5,-1743.5 898.5,-1789.5 1182.5,-1789.5 1182.5,-1743.5 898.5,-1743.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961\" y=\"-1762.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1023.5,-1743.5 1023.5,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1023.5,-1766.5 1078.5,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1051\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1078.5,-1743.5 1078.5,-1789.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1130.5\" y=\"-1774.3\">(None, 125, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1078.5,-1766.5 1182.5,-1766.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1130.5\" y=\"-1751.3\">(None, 125, 32)</text>\n",
       "</g>\n",
       "<!-- 140287230788384&#45;&gt;140287230945936 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>140287230788384-&gt;140287230945936</title>\n",
       "<path d=\"M1040.5,-1826.37C1040.5,-1818.15 1040.5,-1808.66 1040.5,-1799.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1044,-1799.61 1040.5,-1789.61 1037,-1799.61 1044,-1799.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287230945432 -->\n",
       "<g class=\"node\" id=\"node6\"><title>140287230945432</title>\n",
       "<polygon fill=\"none\" points=\"831,-1660.5 831,-1706.5 1250,-1706.5 1250,-1660.5 831,-1660.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"961\" y=\"-1679.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1091,-1660.5 1091,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1118.5\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1091,-1683.5 1146,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1118.5\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1146,-1660.5 1146,-1706.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1198\" y=\"-1691.3\">(None, 125, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1146,-1683.5 1250,-1683.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1198\" y=\"-1668.3\">(None, 125, 32)</text>\n",
       "</g>\n",
       "<!-- 140287230945936&#45;&gt;140287230945432 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>140287230945936-&gt;140287230945432</title>\n",
       "<path d=\"M1040.5,-1743.37C1040.5,-1735.15 1040.5,-1725.66 1040.5,-1716.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1044,-1716.61 1040.5,-1706.61 1037,-1716.61 1044,-1716.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287220758568 -->\n",
       "<g class=\"node\" id=\"node7\"><title>140287220758568</title>\n",
       "<polygon fill=\"none\" points=\"265.5,-1577.5 265.5,-1623.5 639.5,-1623.5 639.5,-1577.5 265.5,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"323\" y=\"-1596.8\">sa1: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"380.5,-1577.5 380.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"380.5,-1600.5 435.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"408\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"435.5,-1577.5 435.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-1608.3\">(None, 125, 32)</text>\n",
       "<polyline fill=\"none\" points=\"435.5,-1600.5 639.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"537.5\" y=\"-1585.3\">[(None, 125, 32), (125, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287230945432&#45;&gt;140287220758568 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>140287230945432-&gt;140287220758568</title>\n",
       "<path d=\"M880.603,-1660.47C800.702,-1649.47 703.983,-1636.14 622.706,-1624.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"622.749,-1621.42 612.365,-1623.52 621.794,-1628.35 622.749,-1621.42\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287220229792 -->\n",
       "<g class=\"node\" id=\"node8\"><title>140287220229792</title>\n",
       "<polygon fill=\"none\" points=\"657.5,-1577.5 657.5,-1623.5 1031.5,-1623.5 1031.5,-1577.5 657.5,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"715\" y=\"-1596.8\">sa2: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"772.5,-1577.5 772.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"800\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"772.5,-1600.5 827.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"800\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"827.5,-1577.5 827.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"929.5\" y=\"-1608.3\">(None, 125, 32)</text>\n",
       "<polyline fill=\"none\" points=\"827.5,-1600.5 1031.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"929.5\" y=\"-1585.3\">[(None, 125, 32), (125, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287230945432&#45;&gt;140287220229792 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>140287230945432-&gt;140287220229792</title>\n",
       "<path d=\"M987.201,-1660.47C962.466,-1650.25 932.895,-1638.03 907.104,-1627.37\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"908.367,-1624.11 897.788,-1623.52 905.693,-1630.58 908.367,-1624.11\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287219347408 -->\n",
       "<g class=\"node\" id=\"node9\"><title>140287219347408</title>\n",
       "<polygon fill=\"none\" points=\"1049.5,-1577.5 1049.5,-1623.5 1423.5,-1623.5 1423.5,-1577.5 1049.5,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1107\" y=\"-1596.8\">sa3: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1164.5,-1577.5 1164.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1192\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1164.5,-1600.5 1219.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1192\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1219.5,-1577.5 1219.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1321.5\" y=\"-1608.3\">(None, 125, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1219.5,-1600.5 1423.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1321.5\" y=\"-1585.3\">[(None, 125, 32), (125, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287230945432&#45;&gt;140287219347408 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>140287230945432-&gt;140287219347408</title>\n",
       "<path d=\"M1093.8,-1660.47C1118.53,-1650.25 1148.1,-1638.03 1173.9,-1627.37\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1175.31,-1630.58 1183.21,-1623.52 1172.63,-1624.11 1175.31,-1630.58\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287218089376 -->\n",
       "<g class=\"node\" id=\"node10\"><title>140287218089376</title>\n",
       "<polygon fill=\"none\" points=\"1441.5,-1577.5 1441.5,-1623.5 1815.5,-1623.5 1815.5,-1577.5 1441.5,-1577.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1499\" y=\"-1596.8\">sa4: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1556.5,-1577.5 1556.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1584\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1556.5,-1600.5 1611.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1584\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1611.5,-1577.5 1611.5,-1623.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1713.5\" y=\"-1608.3\">(None, 125, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1611.5,-1600.5 1815.5,-1600.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1713.5\" y=\"-1585.3\">[(None, 125, 32), (125, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287230945432&#45;&gt;140287218089376 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>140287230945432-&gt;140287218089376</title>\n",
       "<path d=\"M1200.4,-1660.47C1280.3,-1649.47 1377.02,-1636.14 1458.29,-1624.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1459.21,-1628.35 1468.63,-1623.52 1458.25,-1621.42 1459.21,-1628.35\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287217330720 -->\n",
       "<g class=\"node\" id=\"node12\"><title>140287217330720</title>\n",
       "<polygon fill=\"none\" points=\"731,-1494.5 731,-1540.5 1350,-1540.5 1350,-1494.5 731,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"815\" y=\"-1513.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"899,-1494.5 899,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"926.5\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"899,-1517.5 954,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"926.5\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"954,-1494.5 954,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1152\" y=\"-1525.3\">[(None, 125, 32), (None, 125, 32), (None, 125, 32), (None, 125, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"954,-1517.5 1350,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1152\" y=\"-1502.3\">(None, 125, 128)</text>\n",
       "</g>\n",
       "<!-- 140287220758568&#45;&gt;140287217330720 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>140287220758568-&gt;140287217330720</title>\n",
       "<path d=\"M612.397,-1577.47C692.298,-1566.47 789.017,-1553.14 870.294,-1541.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"871.206,-1545.35 880.635,-1540.52 870.251,-1538.42 871.206,-1545.35\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287220229792&#45;&gt;140287217330720 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>140287220229792-&gt;140287217330720</title>\n",
       "<path d=\"M897.799,-1577.47C922.534,-1567.25 952.105,-1555.03 977.896,-1544.37\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"979.307,-1547.58 987.212,-1540.52 976.633,-1541.11 979.307,-1547.58\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287219347408&#45;&gt;140287217330720 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>140287219347408-&gt;140287217330720</title>\n",
       "<path d=\"M1183.2,-1577.47C1158.47,-1567.25 1128.9,-1555.03 1103.1,-1544.37\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1104.37,-1541.11 1093.79,-1540.52 1101.69,-1547.58 1104.37,-1541.11\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287218089376&#45;&gt;140287217330720 -->\n",
       "<g class=\"edge\" id=\"edge13\"><title>140287218089376-&gt;140287217330720</title>\n",
       "<path d=\"M1468.6,-1577.47C1388.7,-1566.47 1291.98,-1553.14 1210.71,-1541.95\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1210.75,-1538.42 1200.37,-1540.52 1209.79,-1545.35 1210.75,-1538.42\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287230788664 -->\n",
       "<g class=\"node\" id=\"node11\"><title>140287230788664</title>\n",
       "<polygon fill=\"none\" points=\"370,-1494.5 370,-1540.5 713,-1540.5 713,-1494.5 370,-1494.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"472.5\" y=\"-1513.8\">input_headline_vector: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"575,-1494.5 575,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"602.5\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"575,-1517.5 630,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"602.5\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"630,-1494.5 630,-1540.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"671.5\" y=\"-1525.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"630,-1517.5 713,-1517.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"671.5\" y=\"-1502.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140287216616168 -->\n",
       "<g class=\"node\" id=\"node13\"><title>140287216616168</title>\n",
       "<polygon fill=\"none\" points=\"452.5,-1411.5 452.5,-1457.5 692.5,-1457.5 692.5,-1411.5 452.5,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"503.5\" y=\"-1430.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"554.5,-1411.5 554.5,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"582\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"554.5,-1434.5 609.5,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"582\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"609.5,-1411.5 609.5,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"651\" y=\"-1442.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"609.5,-1434.5 692.5,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"651\" y=\"-1419.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140287230788664&#45;&gt;140287216616168 -->\n",
       "<g class=\"edge\" id=\"edge14\"><title>140287230788664-&gt;140287216616168</title>\n",
       "<path d=\"M549.971,-1494.37C553.183,-1485.97 556.906,-1476.24 560.39,-1467.14\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"563.734,-1468.2 564.039,-1457.61 557.196,-1465.7 563.734,-1468.2\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287220507312 -->\n",
       "<g class=\"node\" id=\"node14\"><title>140287220507312</title>\n",
       "<polygon fill=\"none\" points=\"894.5,-1411.5 894.5,-1457.5 1182.5,-1457.5 1182.5,-1411.5 894.5,-1411.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"956\" y=\"-1430.8\">conv1d_3: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1017.5,-1411.5 1017.5,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1045\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1017.5,-1434.5 1072.5,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1045\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1072.5,-1411.5 1072.5,-1457.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1127.5\" y=\"-1442.3\">(None, 125, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1072.5,-1434.5 1182.5,-1434.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1127.5\" y=\"-1419.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 140287217330720&#45;&gt;140287220507312 -->\n",
       "<g class=\"edge\" id=\"edge15\"><title>140287217330720-&gt;140287220507312</title>\n",
       "<path d=\"M1039.95,-1494.37C1039.75,-1486.15 1039.52,-1476.66 1039.3,-1467.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1042.79,-1467.52 1039.05,-1457.61 1035.79,-1467.69 1042.79,-1467.52\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216417592 -->\n",
       "<g class=\"node\" id=\"node15\"><title>140287216417592</title>\n",
       "<polygon fill=\"none\" points=\"443,-1328.5 443,-1374.5 718,-1374.5 718,-1328.5 443,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"504.5\" y=\"-1347.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"566,-1328.5 566,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"593.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"566,-1351.5 621,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"593.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"621,-1328.5 621,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"669.5\" y=\"-1359.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"621,-1351.5 718,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"669.5\" y=\"-1336.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140287216616168&#45;&gt;140287216417592 -->\n",
       "<g class=\"edge\" id=\"edge16\"><title>140287216616168-&gt;140287216417592</title>\n",
       "<path d=\"M574.686,-1411.37C575.497,-1403.15 576.435,-1393.66 577.317,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"580.817,-1384.9 578.317,-1374.61 573.851,-1384.21 580.817,-1384.9\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216618744 -->\n",
       "<g class=\"node\" id=\"node16\"><title>140287216618744</title>\n",
       "<polygon fill=\"none\" points=\"878.5,-1328.5 878.5,-1374.5 1168.5,-1374.5 1168.5,-1328.5 878.5,-1328.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"941\" y=\"-1347.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1003.5,-1328.5 1003.5,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1031\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1003.5,-1351.5 1058.5,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1031\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1058.5,-1328.5 1058.5,-1374.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1113.5\" y=\"-1359.3\">(None, 125, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1058.5,-1351.5 1168.5,-1351.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1113.5\" y=\"-1336.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 140287220507312&#45;&gt;140287216618744 -->\n",
       "<g class=\"edge\" id=\"edge17\"><title>140287220507312-&gt;140287216618744</title>\n",
       "<path d=\"M1034.4,-1411.37C1032.88,-1403.15 1031.12,-1393.66 1029.47,-1384.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1032.86,-1383.8 1027.59,-1374.61 1025.97,-1385.08 1032.86,-1383.8\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216418096 -->\n",
       "<g class=\"node\" id=\"node17\"><title>140287216418096</title>\n",
       "<polygon fill=\"none\" points=\"376.5,-1245.5 376.5,-1291.5 788.5,-1291.5 788.5,-1245.5 376.5,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-1264.8\">batch_normalization_3: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1245.5 636.5,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1268.5 691.5,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1245.5 691.5,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1276.3\">(None, 1, 256)</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1268.5 788.5,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1253.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140287216417592&#45;&gt;140287216418096 -->\n",
       "<g class=\"edge\" id=\"edge18\"><title>140287216417592-&gt;140287216418096</title>\n",
       "<path d=\"M581.047,-1328.37C581.249,-1320.15 581.484,-1310.66 581.704,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"585.206,-1301.69 581.954,-1291.61 578.208,-1301.52 585.206,-1301.69\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216616224 -->\n",
       "<g class=\"node\" id=\"node18\"><title>140287216616224</title>\n",
       "<polygon fill=\"none\" points=\"807,-1245.5 807,-1291.5 1232,-1291.5 1232,-1245.5 807,-1245.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"937\" y=\"-1264.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1245.5 1067,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1268.5 1122,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1245.5 1122,-1291.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1276.3\">(None, 125, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1268.5 1232,-1268.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1253.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 140287216618744&#45;&gt;140287216616224 -->\n",
       "<g class=\"edge\" id=\"edge19\"><title>140287216618744-&gt;140287216616224</title>\n",
       "<path d=\"M1022.41,-1328.37C1022,-1320.15 1021.53,-1310.66 1021.09,-1301.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1024.58,-1301.42 1020.59,-1291.61 1017.59,-1301.77 1024.58,-1301.42\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287215185592 -->\n",
       "<g class=\"node\" id=\"node19\"><title>140287215185592</title>\n",
       "<polygon fill=\"none\" points=\"810,-1162.5 810,-1208.5 1197,-1208.5 1197,-1162.5 810,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872.5\" y=\"-1181.8\">ca1: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"935,-1162.5 935,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"935,-1185.5 990,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"990,-1162.5 990,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1193.3\">[(None, 1, 256), (None, 125, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"990,-1185.5 1197,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1170.3\">[(None, 125, 256), (1, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287216418096&#45;&gt;140287215185592 -->\n",
       "<g class=\"edge\" id=\"edge20\"><title>140287216418096-&gt;140287215185592</title>\n",
       "<path d=\"M696.984,-1245.47C753.376,-1234.62 821.47,-1221.52 879.139,-1210.43\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"879.88,-1213.85 889.039,-1208.52 878.558,-1206.97 879.88,-1213.85\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287215320648 -->\n",
       "<g class=\"node\" id=\"node20\"><title>140287215320648</title>\n",
       "<polygon fill=\"none\" points=\"1215,-1162.5 1215,-1208.5 1602,-1208.5 1602,-1162.5 1215,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277.5\" y=\"-1181.8\">ca2: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1162.5 1340,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1185.5 1395,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1162.5 1395,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1193.3\">[(None, 1, 256), (None, 125, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1185.5 1602,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1170.3\">[(None, 125, 256), (1, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287216418096&#45;&gt;140287215320648 -->\n",
       "<g class=\"edge\" id=\"edge22\"><title>140287216418096-&gt;140287215320648</title>\n",
       "<path d=\"M788.753,-1245.85C791.688,-1245.56 794.605,-1245.28 797.5,-1245 975.858,-1227.82 1023.22,-1227.12 1204.83,-1209.16\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1205.38,-1212.62 1214.99,-1208.15 1204.69,-1205.65 1205.38,-1212.62\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287214735600 -->\n",
       "<g class=\"node\" id=\"node21\"><title>140287214735600</title>\n",
       "<polygon fill=\"none\" points=\"0,-1162.5 0,-1208.5 387,-1208.5 387,-1162.5 0,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-1181.8\">ca3: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"125,-1162.5 125,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-1185.5 180,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-1162.5 180,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1193.3\">[(None, 1, 256), (None, 125, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"180,-1185.5 387,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1170.3\">[(None, 125, 256), (1, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287216418096&#45;&gt;140287214735600 -->\n",
       "<g class=\"edge\" id=\"edge24\"><title>140287216418096-&gt;140287214735600</title>\n",
       "<path d=\"M476.718,-1245.47C424.827,-1234.67 362.214,-1221.63 309.069,-1210.56\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"309.765,-1207.13 299.261,-1208.52 308.338,-1213.99 309.765,-1207.13\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287213772584 -->\n",
       "<g class=\"node\" id=\"node22\"><title>140287213772584</title>\n",
       "<polygon fill=\"none\" points=\"405,-1162.5 405,-1208.5 792,-1208.5 792,-1162.5 405,-1162.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467.5\" y=\"-1181.8\">ca4: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"530,-1162.5 530,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"530,-1185.5 585,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"585,-1162.5 585,-1208.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1193.3\">[(None, 1, 256), (None, 125, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"585,-1185.5 792,-1185.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1170.3\">[(None, 125, 256), (1, 125), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140287216418096&#45;&gt;140287213772584 -->\n",
       "<g class=\"edge\" id=\"edge26\"><title>140287216418096-&gt;140287213772584</title>\n",
       "<path d=\"M586.872,-1245.37C588.512,-1237.06 590.411,-1227.45 592.192,-1218.43\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"595.629,-1219.1 594.133,-1208.61 588.762,-1217.74 595.629,-1219.1\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216616224&#45;&gt;140287215185592 -->\n",
       "<g class=\"edge\" id=\"edge21\"><title>140287216616224-&gt;140287215185592</title>\n",
       "<path d=\"M1015.13,-1245.37C1013.49,-1237.06 1011.59,-1227.45 1009.81,-1218.43\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1013.24,-1217.74 1007.87,-1208.61 1006.37,-1219.1 1013.24,-1217.74\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216616224&#45;&gt;140287215320648 -->\n",
       "<g class=\"edge\" id=\"edge23\"><title>140287216616224-&gt;140287215320648</title>\n",
       "<path d=\"M1125.28,-1245.47C1177.17,-1234.67 1239.79,-1221.63 1292.93,-1210.56\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"1293.66,-1213.99 1302.74,-1208.52 1292.24,-1207.13 1293.66,-1213.99\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216616224&#45;&gt;140287214735600 -->\n",
       "<g class=\"edge\" id=\"edge25\"><title>140287216616224-&gt;140287214735600</title>\n",
       "<path d=\"M806.823,-1245.89C803.694,-1245.59 800.585,-1245.29 797.5,-1245 622.156,-1228.26 575.651,-1226.97 397.009,-1209.14\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"397.312,-1205.66 387.013,-1208.14 396.614,-1212.62 397.312,-1205.66\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287216616224&#45;&gt;140287213772584 -->\n",
       "<g class=\"edge\" id=\"edge27\"><title>140287216616224-&gt;140287213772584</title>\n",
       "<path d=\"M905.016,-1245.47C848.624,-1234.62 780.53,-1221.52 722.861,-1210.43\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"723.442,-1206.97 712.961,-1208.52 722.12,-1213.85 723.442,-1206.97\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287213013592 -->\n",
       "<g class=\"node\" id=\"node23\"><title>140287213013592</title>\n",
       "<polygon fill=\"none\" points=\"477.5,-1079.5 477.5,-1125.5 1123.5,-1125.5 1123.5,-1079.5 477.5,-1079.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-1098.8\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1079.5 645.5,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1102.5 700.5,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1079.5 700.5,-1125.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1110.3\">[(None, 125, 256), (None, 125, 256), (None, 125, 256), (None, 125, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1102.5 1123.5,-1102.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1087.3\">(None, 125, 1024)</text>\n",
       "</g>\n",
       "<!-- 140287215185592&#45;&gt;140287213013592 -->\n",
       "<g class=\"edge\" id=\"edge28\"><title>140287215185592-&gt;140287213013592</title>\n",
       "<path d=\"M948.297,-1162.47C922.567,-1152.21 891.784,-1139.92 864.988,-1129.23\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"866.277,-1125.98 855.692,-1125.52 863.682,-1132.48 866.277,-1125.98\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287215320648&#45;&gt;140287213013592 -->\n",
       "<g class=\"edge\" id=\"edge29\"><title>140287215320648-&gt;140287213013592</title>\n",
       "<path d=\"M1243.16,-1162.47C1160.29,-1151.43 1059.93,-1138.06 975.726,-1126.84\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"976.177,-1123.37 965.803,-1125.52 975.253,-1130.31 976.177,-1123.37\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287214735600&#45;&gt;140287213013592 -->\n",
       "<g class=\"edge\" id=\"edge30\"><title>140287214735600-&gt;140287213013592</title>\n",
       "<path d=\"M358.564,-1162.47C441.214,-1151.44 541.298,-1138.09 625.306,-1126.88\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"626.02,-1130.31 635.469,-1125.52 625.094,-1123.38 626.02,-1130.31\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287213772584&#45;&gt;140287213013592 -->\n",
       "<g class=\"edge\" id=\"edge31\"><title>140287213772584-&gt;140287213013592</title>\n",
       "<path d=\"M653.431,-1162.47C678.923,-1152.25 709.399,-1140.03 735.98,-1129.37\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"737.601,-1132.49 745.58,-1125.52 734.996,-1126 737.601,-1132.49\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140289809237552 -->\n",
       "<g class=\"node\" id=\"node24\"><title>140289809237552</title>\n",
       "<polygon fill=\"none\" points=\"652,-996.5 652,-1042.5 949,-1042.5 949,-996.5 652,-996.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1015.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"777,-996.5 777,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"777,-1019.5 832,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-996.5 832,-1042.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1027.3\">(None, 125, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"832,-1019.5 949,-1019.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1004.3\">(None, 125, 1024)</text>\n",
       "</g>\n",
       "<!-- 140287213013592&#45;&gt;140289809237552 -->\n",
       "<g class=\"edge\" id=\"edge32\"><title>140287213013592-&gt;140289809237552</title>\n",
       "<path d=\"M800.5,-1079.37C800.5,-1071.15 800.5,-1061.66 800.5,-1052.73\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-1052.61 800.5,-1042.61 797,-1052.61 804,-1052.61\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287215425744 -->\n",
       "<g class=\"node\" id=\"node25\"><title>140287215425744</title>\n",
       "<polygon fill=\"none\" points=\"584.5,-913.5 584.5,-959.5 1016.5,-959.5 1016.5,-913.5 584.5,-913.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-932.8\">batch_normalization_4: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-913.5 844.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-936.5 899.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-913.5 899.5,-959.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-944.3\">(None, 125, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-936.5 1016.5,-936.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-921.3\">(None, 125, 1024)</text>\n",
       "</g>\n",
       "<!-- 140289809237552&#45;&gt;140287215425744 -->\n",
       "<g class=\"edge\" id=\"edge33\"><title>140289809237552-&gt;140287215425744</title>\n",
       "<path d=\"M800.5,-996.366C800.5,-988.152 800.5,-978.658 800.5,-969.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-969.607 800.5,-959.607 797,-969.607 804,-969.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287215424288 -->\n",
       "<g class=\"node\" id=\"node26\"><title>140287215424288</title>\n",
       "<polygon fill=\"none\" points=\"653,-830.5 653,-876.5 948,-876.5 948,-830.5 653,-830.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-849.8\">conv1d_4: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-830.5 776,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-853.5 831,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"831,-830.5 831,-876.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-861.3\">(None, 125, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"831,-853.5 948,-853.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-838.3\">(None, 63, 256)</text>\n",
       "</g>\n",
       "<!-- 140287215425744&#45;&gt;140287215424288 -->\n",
       "<g class=\"edge\" id=\"edge34\"><title>140287215425744-&gt;140287215424288</title>\n",
       "<path d=\"M800.5,-913.366C800.5,-905.152 800.5,-895.658 800.5,-886.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-886.607 800.5,-876.607 797,-886.607 804,-886.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287210998360 -->\n",
       "<g class=\"node\" id=\"node27\"><title>140287210998360</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-747.5 659.5,-793.5 941.5,-793.5 941.5,-747.5 659.5,-747.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-766.8\">conv1d_5: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-747.5 782.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-770.5 837.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-747.5 837.5,-793.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-778.3\">(None, 63, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-770.5 941.5,-770.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-755.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140287215424288&#45;&gt;140287210998360 -->\n",
       "<g class=\"edge\" id=\"edge35\"><title>140287215424288-&gt;140287210998360</title>\n",
       "<path d=\"M800.5,-830.366C800.5,-822.152 800.5,-812.658 800.5,-803.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-803.607 800.5,-793.607 797,-803.607 804,-803.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287210360504 -->\n",
       "<g class=\"node\" id=\"node28\"><title>140287210360504</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-664.5 659.5,-710.5 941.5,-710.5 941.5,-664.5 659.5,-664.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-683.8\">conv1d_6: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-664.5 782.5,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-687.5 837.5,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-664.5 837.5,-710.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-695.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-687.5 941.5,-687.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-672.3\">(None, 16, 256)</text>\n",
       "</g>\n",
       "<!-- 140287210998360&#45;&gt;140287210360504 -->\n",
       "<g class=\"edge\" id=\"edge36\"><title>140287210998360-&gt;140287210360504</title>\n",
       "<path d=\"M800.5,-747.366C800.5,-739.152 800.5,-729.658 800.5,-720.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-720.607 800.5,-710.607 797,-720.607 804,-720.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287209760920 -->\n",
       "<g class=\"node\" id=\"node29\"><title>140287209760920</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-581.5 659.5,-627.5 941.5,-627.5 941.5,-581.5 659.5,-581.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-600.8\">conv1d_7: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-581.5 782.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-604.5 837.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-581.5 837.5,-627.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-612.3\">(None, 16, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-604.5 941.5,-604.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-589.3\">(None, 8, 256)</text>\n",
       "</g>\n",
       "<!-- 140287210360504&#45;&gt;140287209760920 -->\n",
       "<g class=\"edge\" id=\"edge37\"><title>140287210360504-&gt;140287209760920</title>\n",
       "<path d=\"M800.5,-664.366C800.5,-656.152 800.5,-646.658 800.5,-637.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-637.607 800.5,-627.607 797,-637.607 804,-637.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287208829392 -->\n",
       "<g class=\"node\" id=\"node30\"><title>140287208829392</title>\n",
       "<polygon fill=\"none\" points=\"662,-498.5 662,-544.5 939,-544.5 939,-498.5 662,-498.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724.5\" y=\"-517.8\">dropout_5: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"787,-498.5 787,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"814.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"787,-521.5 842,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"814.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"842,-498.5 842,-544.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-529.3\">(None, 8, 256)</text>\n",
       "<polyline fill=\"none\" points=\"842,-521.5 939,-521.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-506.3\">(None, 8, 256)</text>\n",
       "</g>\n",
       "<!-- 140287209760920&#45;&gt;140287208829392 -->\n",
       "<g class=\"edge\" id=\"edge38\"><title>140287209760920-&gt;140287208829392</title>\n",
       "<path d=\"M800.5,-581.366C800.5,-573.152 800.5,-563.658 800.5,-554.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-554.607 800.5,-544.607 797,-554.607 804,-554.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287208914168 -->\n",
       "<g class=\"node\" id=\"node31\"><title>140287208914168</title>\n",
       "<polygon fill=\"none\" points=\"594.5,-415.5 594.5,-461.5 1006.5,-461.5 1006.5,-415.5 594.5,-415.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724.5\" y=\"-434.8\">batch_normalization_5: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"854.5,-415.5 854.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"882\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"854.5,-438.5 909.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"882\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"909.5,-415.5 909.5,-461.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-446.3\">(None, 8, 256)</text>\n",
       "<polyline fill=\"none\" points=\"909.5,-438.5 1006.5,-438.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-423.3\">(None, 8, 256)</text>\n",
       "</g>\n",
       "<!-- 140287208829392&#45;&gt;140287208914168 -->\n",
       "<g class=\"edge\" id=\"edge39\"><title>140287208829392-&gt;140287208914168</title>\n",
       "<path d=\"M800.5,-498.366C800.5,-490.152 800.5,-480.658 800.5,-471.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-471.607 800.5,-461.607 797,-471.607 804,-471.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287208832416 -->\n",
       "<g class=\"node\" id=\"node32\"><title>140287208832416</title>\n",
       "<polygon fill=\"none\" points=\"563,-332.5 563,-378.5 1038,-378.5 1038,-332.5 563,-332.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"724.5\" y=\"-351.8\">global_average_pooling1d_1: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"886,-332.5 886,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"886,-355.5 941,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"941,-332.5 941,-378.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-363.3\">(None, 8, 256)</text>\n",
       "<polyline fill=\"none\" points=\"941,-355.5 1038,-355.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-340.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140287208914168&#45;&gt;140287208832416 -->\n",
       "<g class=\"edge\" id=\"edge40\"><title>140287208914168-&gt;140287208832416</title>\n",
       "<path d=\"M800.5,-415.366C800.5,-407.152 800.5,-397.658 800.5,-388.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-388.607 800.5,-378.607 797,-388.607 804,-388.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287209033120 -->\n",
       "<g class=\"node\" id=\"node33\"><title>140287209033120</title>\n",
       "<polygon fill=\"none\" points=\"680.5,-249.5 680.5,-295.5 920.5,-295.5 920.5,-249.5 680.5,-249.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-268.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-249.5 782.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-272.5 837.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-249.5 837.5,-295.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879\" y=\"-280.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-272.5 920.5,-272.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"879\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140287208832416&#45;&gt;140287209033120 -->\n",
       "<g class=\"edge\" id=\"edge41\"><title>140287208832416-&gt;140287209033120</title>\n",
       "<path d=\"M800.5,-332.366C800.5,-324.152 800.5,-314.658 800.5,-305.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-305.607 800.5,-295.607 797,-305.607 804,-305.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287208113432 -->\n",
       "<g class=\"node\" id=\"node34\"><title>140287208113432</title>\n",
       "<polygon fill=\"none\" points=\"669,-166.5 669,-212.5 932,-212.5 932,-166.5 669,-166.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-185.8\">dropout_6: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"794,-166.5 794,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"821.5\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"794,-189.5 849,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"821.5\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"849,-166.5 849,-212.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"849,-189.5 932,-189.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140287209033120&#45;&gt;140287208113432 -->\n",
       "<g class=\"edge\" id=\"edge42\"><title>140287209033120-&gt;140287208113432</title>\n",
       "<path d=\"M800.5,-249.366C800.5,-241.152 800.5,-231.658 800.5,-222.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-222.607 800.5,-212.607 797,-222.607 804,-222.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287208112704 -->\n",
       "<g class=\"node\" id=\"node35\"><title>140287208112704</title>\n",
       "<polygon fill=\"none\" points=\"601.5,-83.5 601.5,-129.5 999.5,-129.5 999.5,-83.5 601.5,-83.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-102.8\">batch_normalization_6: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"861.5,-83.5 861.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"861.5,-106.5 916.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-83.5 916.5,-129.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"916.5,-106.5 999.5,-106.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-91.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140287208113432&#45;&gt;140287208112704 -->\n",
       "<g class=\"edge\" id=\"edge43\"><title>140287208113432-&gt;140287208112704</title>\n",
       "<path d=\"M800.5,-166.366C800.5,-158.152 800.5,-148.658 800.5,-139.725\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-139.607 800.5,-129.607 797,-139.607 804,-139.607\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 140287207814816 -->\n",
       "<g class=\"node\" id=\"node36\"><title>140287207814816</title>\n",
       "<polygon fill=\"none\" points=\"639,-0.5 639,-46.5 962,-46.5 962,-0.5 639,-0.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"731.5\" y=\"-19.8\">output_headline_vector: Dense</text>\n",
       "<polyline fill=\"none\" points=\"824,-0.5 824,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"851.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"824,-23.5 879,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"851.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"879,-0.5 879,-46.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"920.5\" y=\"-31.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"879,-23.5 962,-23.5 \" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"920.5\" y=\"-8.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140287208112704&#45;&gt;140287207814816 -->\n",
       "<g class=\"edge\" id=\"edge44\"><title>140287208112704-&gt;140287207814816</title>\n",
       "<path d=\"M800.5,-83.3664C800.5,-75.1516 800.5,-65.6579 800.5,-56.7252\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"804,-56.6068 800.5,-46.6068 797,-56.6069 804,-56.6068\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    inp_sentence_vectors = Input(shape=(max_sentences, 300), name='sentence_vectors')\n",
    "    inp_headline_vector = Input(shape=(300,), name='input_headline_vector')\n",
    "    conv1 = Conv1D(filters=16,kernel_size=3,strides=1,activation='relu', padding='same')(inp_sentence_vectors)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv2 = Conv1D(filters=32,kernel_size=3,strides=1,activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    sent_sa_feat_1, sent_beta_1, sent_gamma_1 = SelfAttention(int(conv2.shape[-1]), name = 'sa1')(conv2)\n",
    "    sent_sa_feat_2, sent_beta_2, sent_gamma_2 = SelfAttention(int(conv2.shape[-1]), name = 'sa2')(conv2)\n",
    "    sent_sa_feat_3, sent_beta_3, sent_gamma_3 = SelfAttention(int(conv2.shape[-1]), name = 'sa3')(conv2)\n",
    "    sent_sa_feat_4, sent_beta_4, sent_gamma_4 = SelfAttention(int(conv2.shape[-1]), name = 'sa4')(conv2)\n",
    "    concat1 = Concatenate()([sent_sa_feat_1,sent_sa_feat_2,sent_sa_feat_3,sent_sa_feat_4])\n",
    "    conv3 = Conv1D(filters=256,kernel_size=3, strides=1, activation='relu', padding='same')(concat1)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    headline = Dense(256, activation='relu')(inp_headline_vector)\n",
    "    headline = Lambda(lambda x:K.expand_dims(x, axis=1))(headline)\n",
    "    headline = BatchNormalization()(headline)\n",
    "    sent_hd_sa_feat_1, sent_hd_beta_1, sent_hd_gamma_1 = CrossAttention(int(conv3.shape[-1]), name = 'ca1')([headline,conv3])\n",
    "    sent_hd_sa_feat_2, sent_hd_beta_2, sent_hd_gamma_2 = CrossAttention(int(conv3.shape[-1]), name = 'ca2')([headline,conv3])\n",
    "    sent_hd_sa_feat_3, sent_hd_beta_3, sent_hd_gamma_3 = CrossAttention(int(conv3.shape[-1]), name = 'ca3')([headline,conv3])\n",
    "    sent_hd_sa_feat_4, sent_hd_beta_4, sent_hd_gamma_4 = CrossAttention(int(conv3.shape[-1]), name = 'ca4')([headline,conv3])  \n",
    "    concat3 = Concatenate()([sent_hd_sa_feat_1,sent_hd_sa_feat_2,sent_hd_sa_feat_3,sent_hd_sa_feat_4])\n",
    "    concat3 = Dropout(0.5)(concat3)\n",
    "    concat3 = BatchNormalization()(concat3)\n",
    "    conv5 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(concat3)\n",
    "    conv6 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv5)\n",
    "    conv7 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv6)\n",
    "    conv8 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv7)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    gap = GlobalAveragePooling1D()(conv8)\n",
    "#     repeat = RepeatVector(50)(gap)\n",
    "#     lstm = LSTM(256,return_sequences=True)(repeat)\n",
    "    dense1 = Dense(512,activation='relu')(gap)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    gen_hd_vector = Dense(300,activation='linear', name='output_headline_vector')(dense1)\n",
    "    model = Model([inp_sentence_vectors,inp_headline_vector],gen_hd_vector)\n",
    "    return model\n",
    "model = build_model()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001,beta_1=0.0,beta_2=0.99),loss='mse')\n",
    "model.summary()\n",
    "# print('model params:',model.count_params())\n",
    "SVG(model_to_dot(model,show_layer_names=True,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now()\n",
    "mc = ModelCheckpoint('weights/dnf700_sa_sent_hd_vector.hdf5',save_best_only=True,save_weights_only=True)\n",
    "tb = TensorBoard(batch_size=32,log_dir='logs/dnf700_sa_sent_hd_vector/{0}'.format(dt.timestamp()),write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.2458 - val_loss: 0.2802\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 51ms/step - loss: 1.2381 - val_loss: 0.2451\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.2197 - val_loss: 0.2304\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 1s 242ms/step - loss: 1.2212 - val_loss: 0.2102\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 1.2119 - val_loss: 0.1897\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 1.2063 - val_loss: 0.1879\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 2s 394ms/step - loss: 1.2090 - val_loss: 0.1809\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 2s 408ms/step - loss: 1.1747 - val_loss: 0.1796\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 1.1615 - val_loss: 0.1665\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 1.1626 - val_loss: 0.1608\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 2s 408ms/step - loss: 1.1584 - val_loss: 0.1583\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 1.1264 - val_loss: 0.1504\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 1.1137 - val_loss: 0.1455\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 1.1205 - val_loss: 0.1383\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 1.1275 - val_loss: 0.1341\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 1.1198 - val_loss: 0.1330\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 1.1050 - val_loss: 0.1267\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 1.0873 - val_loss: 0.1226\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 1.0712 - val_loss: 0.1223\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 1.0763 - val_loss: 0.1200\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 2s 406ms/step - loss: 1.0630 - val_loss: 0.1219\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 1.0542 - val_loss: 0.1193\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 1.0549 - val_loss: 0.1120\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 1.0368 - val_loss: 0.1112\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 1.0556 - val_loss: 0.1106\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 1.0295 - val_loss: 0.1065\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 1.0293 - val_loss: 0.1038\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 1.0344 - val_loss: 0.1028\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 1.0046 - val_loss: 0.1020\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 1.0199 - val_loss: 0.1114\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 2s 496ms/step - loss: 0.9858 - val_loss: 0.1044\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.9776 - val_loss: 0.1072\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 2s 489ms/step - loss: 0.9868 - val_loss: 0.1037\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 2s 503ms/step - loss: 0.9726 - val_loss: 0.1048\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 2s 514ms/step - loss: 0.9560 - val_loss: 0.0997\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.9469 - val_loss: 0.1043\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 2s 445ms/step - loss: 0.9530 - val_loss: 0.0985\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.9391 - val_loss: 0.0975\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 2s 452ms/step - loss: 0.9443 - val_loss: 0.0937\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 2s 540ms/step - loss: 0.9263 - val_loss: 0.0942\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 2s 472ms/step - loss: 0.9113 - val_loss: 0.0935\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.9095 - val_loss: 0.0921\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 2s 464ms/step - loss: 0.9060 - val_loss: 0.0861\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 0.8974 - val_loss: 0.0860\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 2s 519ms/step - loss: 0.9068 - val_loss: 0.0856\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 2s 452ms/step - loss: 0.9013 - val_loss: 0.0844\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 2s 464ms/step - loss: 0.8873 - val_loss: 0.0810\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.8893 - val_loss: 0.0821\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.8744 - val_loss: 0.0868\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.8618 - val_loss: 0.0810\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.8531 - val_loss: 0.0779\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.8535 - val_loss: 0.0805\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.8597 - val_loss: 0.0792\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.8579 - val_loss: 0.0749\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.8418 - val_loss: 0.0730\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.8264 - val_loss: 0.0713\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.8357 - val_loss: 0.0688\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.7953 - val_loss: 0.0717\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.8169 - val_loss: 0.0713\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.8292 - val_loss: 0.0683\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.8142 - val_loss: 0.0660\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 2s 407ms/step - loss: 0.7845 - val_loss: 0.0643\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 2s 407ms/step - loss: 0.7801 - val_loss: 0.0682\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.7991 - val_loss: 0.0645\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.8047 - val_loss: 0.0643\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.7874 - val_loss: 0.0665\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.7696 - val_loss: 0.0681\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.7771 - val_loss: 0.0639\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.7761 - val_loss: 0.0659\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.7473 - val_loss: 0.0628\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.7831 - val_loss: 0.0580\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.7438 - val_loss: 0.0537\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.7637 - val_loss: 0.0591\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7587 - val_loss: 0.0572\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 2s 440ms/step - loss: 0.7495 - val_loss: 0.0573\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 2s 435ms/step - loss: 0.7428 - val_loss: 0.0598\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7583 - val_loss: 0.0574\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.7296 - val_loss: 0.0538\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.7470 - val_loss: 0.0547\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.7081 - val_loss: 0.0547\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.7120 - val_loss: 0.0510\n",
      "Epoch 82/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 416ms/step - loss: 0.7073 - val_loss: 0.0529\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.7265 - val_loss: 0.0494\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.7075 - val_loss: 0.0507\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.7042 - val_loss: 0.0533\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.7094 - val_loss: 0.0488\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.7054 - val_loss: 0.0507\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.6835 - val_loss: 0.0542\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.6922 - val_loss: 0.0445\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 0.6955 - val_loss: 0.0501\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.6821 - val_loss: 0.0515\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.6695 - val_loss: 0.0448\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 2s 438ms/step - loss: 0.6782 - val_loss: 0.0459\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.6553 - val_loss: 0.0411\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.6584 - val_loss: 0.0443\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.6700 - val_loss: 0.0422\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 2s 407ms/step - loss: 0.6622 - val_loss: 0.0424\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.6610 - val_loss: 0.0375\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.6727 - val_loss: 0.0396\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 0.6597 - val_loss: 0.0404\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 2s 442ms/step - loss: 0.6437 - val_loss: 0.0393\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 2s 435ms/step - loss: 0.6487 - val_loss: 0.0392\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.6535 - val_loss: 0.0350\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.6431 - val_loss: 0.0397\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.6493 - val_loss: 0.0353\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.6372 - val_loss: 0.0374\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 2s 435ms/step - loss: 0.6311 - val_loss: 0.0366\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 2s 465ms/step - loss: 0.6273 - val_loss: 0.0355\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 2s 459ms/step - loss: 0.5957 - val_loss: 0.0376\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 2s 464ms/step - loss: 0.6200 - val_loss: 0.0321\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.6216 - val_loss: 0.0348\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 2s 475ms/step - loss: 0.6163 - val_loss: 0.0336\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 2s 443ms/step - loss: 0.5931 - val_loss: 0.0323\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.6053 - val_loss: 0.0334\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 2s 449ms/step - loss: 0.6011 - val_loss: 0.0295\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.6127 - val_loss: 0.0332\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 2s 444ms/step - loss: 0.6100 - val_loss: 0.0353\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 2s 482ms/step - loss: 0.6077 - val_loss: 0.0335\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.6096 - val_loss: 0.0349\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 2s 476ms/step - loss: 0.5840 - val_loss: 0.0315\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.5880 - val_loss: 0.0328\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 2s 435ms/step - loss: 0.5890 - val_loss: 0.0308\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 2s 438ms/step - loss: 0.5893 - val_loss: 0.0314\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 2s 436ms/step - loss: 0.5816 - val_loss: 0.0317\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.5780 - val_loss: 0.0275\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.5840 - val_loss: 0.0300\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.5628 - val_loss: 0.0296\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.5536 - val_loss: 0.0293\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.5437 - val_loss: 0.0266\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 2s 435ms/step - loss: 0.5722 - val_loss: 0.0295\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.5588 - val_loss: 0.0275\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.5642 - val_loss: 0.0285\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.5762 - val_loss: 0.0247\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.5419 - val_loss: 0.0308\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.5371 - val_loss: 0.0279\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.5507 - val_loss: 0.0280\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 2s 438ms/step - loss: 0.5566 - val_loss: 0.0229\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.5490 - val_loss: 0.0290\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.5508 - val_loss: 0.0269\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.5240 - val_loss: 0.0266\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.5386 - val_loss: 0.0233\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 2s 430ms/step - loss: 0.5373 - val_loss: 0.0286\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.5393 - val_loss: 0.0240\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.5270 - val_loss: 0.0255\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.5127 - val_loss: 0.0238\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 2s 429ms/step - loss: 0.5208 - val_loss: 0.0250\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 2s 434ms/step - loss: 0.5317 - val_loss: 0.0243\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.5218 - val_loss: 0.0258\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.5278 - val_loss: 0.0269\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 0.5154 - val_loss: 0.0264\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.5092 - val_loss: 0.0248\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 2s 438ms/step - loss: 0.5099 - val_loss: 0.0213\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.5128 - val_loss: 0.0253\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 2s 438ms/step - loss: 0.5054 - val_loss: 0.0228\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 0.4919 - val_loss: 0.0238\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.5052 - val_loss: 0.0235\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 2s 470ms/step - loss: 0.4954 - val_loss: 0.0255\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.5002 - val_loss: 0.0227\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 2s 446ms/step - loss: 0.4814 - val_loss: 0.0218\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 0.4840 - val_loss: 0.0223\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 2s 463ms/step - loss: 0.4754 - val_loss: 0.0228\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 511ms/step - loss: 0.4956 - val_loss: 0.0245\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 2s 474ms/step - loss: 0.4864 - val_loss: 0.0211\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.4592 - val_loss: 0.0235\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 2s 432ms/step - loss: 0.4911 - val_loss: 0.0256\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 2s 556ms/step - loss: 0.4785 - val_loss: 0.0235\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 2s 516ms/step - loss: 0.4662 - val_loss: 0.0246\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 2s 439ms/step - loss: 0.4682 - val_loss: 0.0222\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 2s 455ms/step - loss: 0.4748 - val_loss: 0.0222\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 2s 463ms/step - loss: 0.4614 - val_loss: 0.0262\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 2s 441ms/step - loss: 0.4654 - val_loss: 0.0202\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.4414 - val_loss: 0.0231\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 2s 448ms/step - loss: 0.4455 - val_loss: 0.0205\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 2s 499ms/step - loss: 0.4646 - val_loss: 0.0196\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.4516 - val_loss: 0.0242\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 4s 971ms/step - loss: 0.4575 - val_loss: 0.0198\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 4s 951ms/step - loss: 0.4615 - val_loss: 0.0204\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.4613 - val_loss: 0.0208\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 4s 946ms/step - loss: 0.4432 - val_loss: 0.0209\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.4477 - val_loss: 0.0218\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 3s 872ms/step - loss: 0.4490 - val_loss: 0.0204\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.4072 - val_loss: 0.0223\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.4336 - val_loss: 0.0201\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.4218 - val_loss: 0.0209\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.4240 - val_loss: 0.0182\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.4232 - val_loss: 0.0197\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.4283 - val_loss: 0.0194\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.4219 - val_loss: 0.0211\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.4226 - val_loss: 0.0200\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.4132 - val_loss: 0.0202\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 3s 787ms/step - loss: 0.4206 - val_loss: 0.0216\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.4012 - val_loss: 0.0201\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.4087 - val_loss: 0.0175\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.3893 - val_loss: 0.0205\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 3s 834ms/step - loss: 0.4111 - val_loss: 0.0180\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.4011 - val_loss: 0.0184\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.3966 - val_loss: 0.0185\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.3937 - val_loss: 0.0184\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.3914 - val_loss: 0.0180\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.3853 - val_loss: 0.0206\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.3708 - val_loss: 0.0184\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.3954 - val_loss: 0.0204\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.4031 - val_loss: 0.0177\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.3710 - val_loss: 0.0188\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.3746 - val_loss: 0.0193\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.3764 - val_loss: 0.0190\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.3879 - val_loss: 0.0186\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.3776 - val_loss: 0.0197\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.3810 - val_loss: 0.0181\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.3728 - val_loss: 0.0170\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.3734 - val_loss: 0.0169\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.3589 - val_loss: 0.0159\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.3522 - val_loss: 0.0187\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.3375 - val_loss: 0.0180\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.3626 - val_loss: 0.0190\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.3256 - val_loss: 0.0195\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.3397 - val_loss: 0.0172\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.3390 - val_loss: 0.0212\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 2s 563ms/step - loss: 0.3229 - val_loss: 0.0238\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.3183 - val_loss: 0.0191\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.3186 - val_loss: 0.0184\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.3309 - val_loss: 0.0211\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.3071 - val_loss: 0.0190\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.2920 - val_loss: 0.0207\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.2970 - val_loss: 0.0182\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.2798 - val_loss: 0.0167\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.2848 - val_loss: 0.0193\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.2887 - val_loss: 0.0208\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.2841 - val_loss: 0.0164\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.2572 - val_loss: 0.0155\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.2632 - val_loss: 0.0174\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.2756 - val_loss: 0.0144\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.2758 - val_loss: 0.0146\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.2455 - val_loss: 0.0139\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.2638 - val_loss: 0.0159\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.2586 - val_loss: 0.0166\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.2571 - val_loss: 0.0159\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.2431 - val_loss: 0.0176\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.2490 - val_loss: 0.0140\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.2545 - val_loss: 0.0149\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.2448 - val_loss: 0.0148\n",
      "Epoch 242/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 778ms/step - loss: 0.2234 - val_loss: 0.0136\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.2413 - val_loss: 0.0144\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.2135 - val_loss: 0.0155\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.2057 - val_loss: 0.0201\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.2139 - val_loss: 0.0140\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.2100 - val_loss: 0.0174\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.2001 - val_loss: 0.0129\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.1808 - val_loss: 0.0134\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.1890 - val_loss: 0.0132\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 3s 779ms/step - loss: 0.1914 - val_loss: 0.0132\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.1993 - val_loss: 0.0130\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.1754 - val_loss: 0.0131\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.1842 - val_loss: 0.0126\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.1720 - val_loss: 0.0150\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.1525 - val_loss: 0.0144\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.1840 - val_loss: 0.0138\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.1561 - val_loss: 0.0133\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.1844 - val_loss: 0.0147\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.1432 - val_loss: 0.0135\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 3s 811ms/step - loss: 0.1451 - val_loss: 0.0126\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 3s 854ms/step - loss: 0.1537 - val_loss: 0.0132\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.1384 - val_loss: 0.0139\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.1354 - val_loss: 0.0134\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 3s 823ms/step - loss: 0.1426 - val_loss: 0.0120\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.1353 - val_loss: 0.0159\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 0.1398 - val_loss: 0.0138\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.1042 - val_loss: 0.0163\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.1133 - val_loss: 0.0124\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.1222 - val_loss: 0.0127\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.1001 - val_loss: 0.0182\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 3s 787ms/step - loss: 0.1081 - val_loss: 0.0116\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.1120 - val_loss: 0.0144\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.1069 - val_loss: 0.0125\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.1004 - val_loss: 0.0111\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.1076 - val_loss: 0.0116\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0855 - val_loss: 0.0138\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0902 - val_loss: 0.0150\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0932 - val_loss: 0.0110\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0678 - val_loss: 0.0133\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0715 - val_loss: 0.0126\n",
      "Epoch 282/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0727 - val_loss: 0.0128\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 2s 550ms/step - loss: 0.0679 - val_loss: 0.0097\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0732 - val_loss: 0.0119\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0583 - val_loss: 0.0105\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0627 - val_loss: 0.0120\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0446 - val_loss: 0.0111\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0422 - val_loss: 0.0133\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 3s 789ms/step - loss: 0.0437 - val_loss: 0.0149\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0476 - val_loss: 0.0119\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0429 - val_loss: 0.0111\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0445 - val_loss: 0.0130\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0349 - val_loss: 0.0107\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0409 - val_loss: 0.0125\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0360 - val_loss: 0.0105\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0362 - val_loss: 0.0142\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0314 - val_loss: 0.0125\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0304 - val_loss: 0.0102\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0241 - val_loss: 0.0114\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0212 - val_loss: 0.0110\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0306 - val_loss: 0.0115\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 3s 807ms/step - loss: 0.0323 - val_loss: 0.0122\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0258 - val_loss: 0.0095\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0284 - val_loss: 0.0104\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0207 - val_loss: 0.0116\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0197 - val_loss: 0.0142\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0230 - val_loss: 0.0114\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0195 - val_loss: 0.0142\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0193 - val_loss: 0.0120\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0232 - val_loss: 0.0115\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0194 - val_loss: 0.0116\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0146 - val_loss: 0.0145\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0153 - val_loss: 0.0099\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0145 - val_loss: 0.0117\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0142 - val_loss: 0.0120\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 4s 878ms/step - loss: 0.0156 - val_loss: 0.0116\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0151 - val_loss: 0.0108\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0143 - val_loss: 0.0103\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0143 - val_loss: 0.0118\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0134 - val_loss: 0.0125\n",
      "Epoch 322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0134 - val_loss: 0.0114\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0178 - val_loss: 0.0119\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0132 - val_loss: 0.0118\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0136 - val_loss: 0.0138\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0136 - val_loss: 0.0106\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0165 - val_loss: 0.0099\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0126 - val_loss: 0.0108\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0141 - val_loss: 0.0098\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0140 - val_loss: 0.0103\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0128 - val_loss: 0.0108\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0122 - val_loss: 0.0107\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0120 - val_loss: 0.0104\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 2s 584ms/step - loss: 0.0113 - val_loss: 0.0101\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0118 - val_loss: 0.0087\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0131 - val_loss: 0.0110\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0142 - val_loss: 0.0115\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 344/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0135 - val_loss: 0.0113\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0125 - val_loss: 0.0108\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0130 - val_loss: 0.0097\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0127 - val_loss: 0.0108\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0106 - val_loss: 0.0139\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0126 - val_loss: 0.0109\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0153 - val_loss: 0.0119\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0124 - val_loss: 0.0112\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0120 - val_loss: 0.0106\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0125 - val_loss: 0.0110\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0112 - val_loss: 0.0080\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0118 - val_loss: 0.0113\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.0151 - val_loss: 0.0101\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 3s 787ms/step - loss: 0.0107 - val_loss: 0.0135\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0118 - val_loss: 0.0097\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0110 - val_loss: 0.0137\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0121 - val_loss: 0.0102\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0132 - val_loss: 0.0099\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0117 - val_loss: 0.0570\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0111 - val_loss: 0.1016\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0109 - val_loss: 0.0147\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0109 - val_loss: 0.0192\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 402/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0124 - val_loss: 0.0097\n",
      "Epoch 406/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0108 - val_loss: 0.0128\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0128 - val_loss: 0.0114\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0120 - val_loss: 0.0120\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0106 - val_loss: 0.0135\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 3s 807ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0130 - val_loss: 0.0100\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 3s 850ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0099 - val_loss: 0.0123\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 3s 807ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0104 - val_loss: 0.0093\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0133 - val_loss: 0.0125\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0125 - val_loss: 0.0097\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 468/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0107 - val_loss: 0.0126\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0104 - val_loss: 0.0124\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0122 - val_loss: 0.0110\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0118 - val_loss: 0.0115\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0122 - val_loss: 0.0135\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0115 - val_loss: 0.0092\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0097 - val_loss: 0.0108\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0102 - val_loss: 0.0133\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 530/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0096 - val_loss: 0.0121\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0100 - val_loss: 0.0121\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.0096 - val_loss: 0.0138\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0135 - val_loss: 0.0108\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0114 - val_loss: 0.0089\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0123 - val_loss: 0.0137\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 562/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 3s 805ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0119 - val_loss: 0.0114\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 3s 811ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 3s 796ms/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0103 - val_loss: 0.0121\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0102 - val_loss: 0.0144\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0097 - val_loss: 0.0128\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0115 - val_loss: 0.0106\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0099 - val_loss: 0.0114\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0117 - val_loss: 0.0123\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0102 - val_loss: 0.0091\n",
      "Epoch 592/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0102 - val_loss: 0.0138\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0116 - val_loss: 0.0127\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0112 - val_loss: 0.0125\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0114 - val_loss: 0.0131\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0113 - val_loss: 0.0144\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 3s 868ms/step - loss: 0.0125 - val_loss: 0.0119\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 3s 796ms/step - loss: 0.0114 - val_loss: 0.0099\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0120 - val_loss: 0.0109\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0104 - val_loss: 0.0092\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 2s 557ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0107 - val_loss: 0.0221\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0117 - val_loss: 0.0114\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 654/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0116 - val_loss: 15.5372\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0103 - val_loss: 0.5859\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0122 - val_loss: 0.0122\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0108 - val_loss: 0.0136\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0107 - val_loss: 0.0289\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0120 - val_loss: 1.7334\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0103 - val_loss: 0.1892\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0103 - val_loss: 0.0357\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0130 - val_loss: 0.0116\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0121 - val_loss: 0.0328\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.0121 - val_loss: 0.0114\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0118 - val_loss: 0.0102\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0118 - val_loss: 0.0140\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 3s 787ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 716/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0113 - val_loss: 0.0127\n",
      "Epoch 722/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0115 - val_loss: 0.0095\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 3s 803ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0113 - val_loss: 0.0130\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0104 - val_loss: 0.4819\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0106 - val_loss: 0.3878\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0123 - val_loss: 0.0130\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.0120 - val_loss: 0.0133\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0117 - val_loss: 0.0130\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.0111 - val_loss: 0.0131\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 3s 792ms/step - loss: 0.0097 - val_loss: 0.0117\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0102 - val_loss: 0.0120\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 3s 816ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0121 - val_loss: 0.0121\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 778/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0117 - val_loss: 0.0099\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 3s 773ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0119 - val_loss: 0.0092\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0121 - val_loss: 0.0109\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 802/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0100 - val_loss: 0.0132\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0119 - val_loss: 0.0096\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 3s 779ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 3s 831ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0118 - val_loss: 0.0120\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0111 - val_loss: 0.0145\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 4s 897ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0128 - val_loss: 0.0130\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 3s 828ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 3s 819ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0120 - val_loss: 0.0114\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 3s 818ms/step - loss: 0.0114 - val_loss: 0.0124\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0104 - val_loss: 0.0149\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.0102 - val_loss: 0.0137\n",
      "Epoch 840/2000\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0111 - val_loss: 0.0143\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0104 - val_loss: 0.0123\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0115 - val_loss: 0.0129\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 3s 805ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0104 - val_loss: 0.0091\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0098 - val_loss: 0.0124\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0105 - val_loss: 2.1283\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 3s 874ms/step - loss: 0.0115 - val_loss: 0.1147\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 3s 826ms/step - loss: 0.0118 - val_loss: 36.0591\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0111 - val_loss: 51.1501\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.0112 - val_loss: 45.3363\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0113 - val_loss: 22.5968\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0107 - val_loss: 13.9473\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.0106 - val_loss: 2.6009\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0105 - val_loss: 0.6824\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0102 - val_loss: 1.4590\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0109 - val_loss: 3.7178\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0121 - val_loss: 1.8178\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0110 - val_loss: 0.3214\n",
      "Epoch 882/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0108 - val_loss: 1.2415\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0113 - val_loss: 0.1179\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0132 - val_loss: 0.0587\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0123 - val_loss: 0.0940\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0114 - val_loss: 0.0320\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0103 - val_loss: 0.0227\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0114 - val_loss: 0.0162\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 902/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0114 - val_loss: 0.0198\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0109 - val_loss: 4.6619\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0105 - val_loss: 0.2146\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0112 - val_loss: 0.0137\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0114 - val_loss: 0.0112\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0103 - val_loss: 0.0093\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0126 - val_loss: 0.0236\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0108 - val_loss: 0.0142\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0120 - val_loss: 0.0108\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0122 - val_loss: 0.0093\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 3s 804ms/step - loss: 0.0119 - val_loss: 0.0135\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0117 - val_loss: 0.0120\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0112 - val_loss: 0.0129\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0101 - val_loss: 0.0121\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0112 - val_loss: 0.0147\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0107 - val_loss: 0.0144\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 3s 827ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.0117 - val_loss: 0.0109\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 962/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 964/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0116 - val_loss: 0.0105\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 4s 895ms/step - loss: 0.0109 - val_loss: 0.0092\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 3s 815ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0112 - val_loss: 0.0118\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0104 - val_loss: 0.0131\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.0109 - val_loss: 0.0136\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 3s 815ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0134 - val_loss: 0.0110\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 3s 848ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0118 - val_loss: 0.0132\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 3s 773ms/step - loss: 0.0118 - val_loss: 0.0142\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.0121 - val_loss: 0.0104\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 1026/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0115 - val_loss: 0.0122\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0117 - val_loss: 0.0124\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 3s 842ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0115 - val_loss: 0.0130\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 1042/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0143 - val_loss: 3.2309\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0124 - val_loss: 0.1843\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0101 - val_loss: 0.4936\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0115 - val_loss: 0.0830\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0106 - val_loss: 0.0314\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0112 - val_loss: 181.5221\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0112 - val_loss: 3.1630\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0109 - val_loss: 3.9891\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 3s 803ms/step - loss: 0.0105 - val_loss: 2.0475\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0109 - val_loss: 0.5324\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0107 - val_loss: 10.7003\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 3s 808ms/step - loss: 0.0121 - val_loss: 7.5135\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.0100 - val_loss: 3.0180\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.0107 - val_loss: 0.8408\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 3s 817ms/step - loss: 0.0099 - val_loss: 0.5276\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0108 - val_loss: 0.1974\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0101 - val_loss: 0.1229\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0105 - val_loss: 0.0504\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0105 - val_loss: 0.0275\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0109 - val_loss: 0.0255\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0098 - val_loss: 0.0169\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0111 - val_loss: 0.0142\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0108 - val_loss: 1.5611\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0114 - val_loss: 22.1340\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0114 - val_loss: 8.4211\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0103 - val_loss: 0.6422\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0109 - val_loss: 0.4719\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0106 - val_loss: 3.3955\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.0104 - val_loss: 2.1377\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0102 - val_loss: 0.6902\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0103 - val_loss: 0.3197\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0115 - val_loss: 0.0719\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0108 - val_loss: 0.0185\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0105 - val_loss: 0.0139\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0099 - val_loss: 0.0133\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0118 - val_loss: 0.0098\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 3s 865ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0123 - val_loss: 11.3294\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0107 - val_loss: 11.0462\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0112 - val_loss: 0.1322\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0101 - val_loss: 0.0943\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 0.0112 - val_loss: 0.0389\n",
      "Epoch 1088/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0102 - val_loss: 0.0182\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0108 - val_loss: 0.0141\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 3s 792ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0112 - val_loss: 0.0119\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0117 - val_loss: 0.0138\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 3s 817ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0113 - val_loss: 0.0134\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0107 - val_loss: 0.0155\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0116 - val_loss: 0.0117\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 3s 785ms/step - loss: 0.0109 - val_loss: 1.2795\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0112 - val_loss: 0.0919\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0102 - val_loss: 0.0147\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0115 - val_loss: 0.0141\n",
      "Epoch 1121/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0104 - val_loss: 0.0172\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0123 - val_loss: 0.0128\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0124 - val_loss: 0.0118\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0124 - val_loss: 0.0123\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0128 - val_loss: 0.0111\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0125 - val_loss: 0.0109\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0128 - val_loss: 0.0104\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1150/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 3s 824ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 4s 877ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0116 - val_loss: 0.0124\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0099 - val_loss: 0.0127\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.0124 - val_loss: 0.0105\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0121 - val_loss: 0.0112\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0111 - val_loss: 0.0143\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0100 - val_loss: 0.0131\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0105 - val_loss: 0.0136\n",
      "Epoch 1200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0105 - val_loss: 0.0092\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0114 - val_loss: 0.0136\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0121 - val_loss: 0.0117\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0111 - val_loss: 0.0094\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1212/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 3s 834ms/step - loss: 0.0115 - val_loss: 0.0128\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0114 - val_loss: 0.0123\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0130 - val_loss: 0.0109\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0123 - val_loss: 0.0112\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 2s 565ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0099 - val_loss: 0.0116\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 3s 773ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0117 - val_loss: 0.0118\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0102 - val_loss: 0.5349\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0107 - val_loss: 0.1894\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.0117 - val_loss: 0.0092\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 2s 535ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0125 - val_loss: 0.0142\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 3s 798ms/step - loss: 0.0105 - val_loss: 0.2711\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0122 - val_loss: 0.0910\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0129 - val_loss: 0.0101\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0102 - val_loss: 0.0132\n",
      "Epoch 1274/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0111 - val_loss: 0.0099\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 1279/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 3s 811ms/step - loss: 0.0114 - val_loss: 1024.5396\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0105 - val_loss: 0.0355\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0111 - val_loss: 0.0129\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0120 - val_loss: 0.0119\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0107 - val_loss: 0.0128\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0119 - val_loss: 0.0126\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0109 - val_loss: 0.0161\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0101 - val_loss: 0.0124\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 3s 846ms/step - loss: 0.0116 - val_loss: 0.0128\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0126 - val_loss: 0.0110\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0110 - val_loss: 0.0117\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 3s 785ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 4s 932ms/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0118 - val_loss: 0.0096\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 3s 863ms/step - loss: 0.0123 - val_loss: 0.0104\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 4s 903ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1336/2000\n",
      "4/4 [==============================] - 3s 820ms/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0112 - val_loss: 0.0130\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 3s 826ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 3s 817ms/step - loss: 0.0113 - val_loss: 0.0095\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0103 - val_loss: 0.0135\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0125 - val_loss: 0.0125\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 1358/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0123 - val_loss: 0.0088\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 3s 864ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0121 - val_loss: 0.0094\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0122 - val_loss: 0.0109\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 3s 806ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 3s 824ms/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0113 - val_loss: 0.0110\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 3s 816ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 3s 832ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.0111 - val_loss: 1.5337\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0108 - val_loss: 0.0133\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0105 - val_loss: 5.0510\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0104 - val_loss: 0.0326\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0114 - val_loss: 0.0652\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0114 - val_loss: 0.0102\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0103 - val_loss: 0.0117\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 1398/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0111 - val_loss: 0.8083\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0119 - val_loss: 0.0113\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0114 - val_loss: 128.4930\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0107 - val_loss: 0.1089\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0103 - val_loss: 0.0245\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.0116 - val_loss: 0.0215\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0122 - val_loss: 0.0113\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0107 - val_loss: 201.8917\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0109 - val_loss: 0.1666\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0103 - val_loss: 0.0208\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 3s 826ms/step - loss: 0.0102 - val_loss: 0.0131\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0107 - val_loss: 0.0133\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0116 - val_loss: 0.0120\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0117 - val_loss: 0.0144\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0107 - val_loss: 0.0153\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 1437/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 3s 810ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 3s 798ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 3s 809ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0109 - val_loss: 0.0130\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0112 - val_loss: 0.0123\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0110 - val_loss: 0.0128\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 1460/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0114 - val_loss: 0.0120\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0118 - val_loss: 0.0118\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 4s 881ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0138 - val_loss: 0.0145\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0110 - val_loss: 0.0142\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0122 - val_loss: 0.0103\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 3s 839ms/step - loss: 0.0104 - val_loss: 0.0134\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 3s 815ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0107 - val_loss: 0.0143\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0113 - val_loss: 0.0093\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 3s 778ms/step - loss: 0.0109 - val_loss: 0.0124\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0102 - val_loss: 0.0092\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0107 - val_loss: 0.0093\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0098 - val_loss: 0.0124\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0116 - val_loss: 0.0093\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0114 - val_loss: 0.0090\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0096 - val_loss: 0.0118\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 3s 825ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 1516/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 837ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0119 - val_loss: 0.0101\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1522/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0132 - val_loss: 0.0104\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.0112 - val_loss: 0.0124\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 3s 789ms/step - loss: 0.0123 - val_loss: 0.0110\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0115 - val_loss: 0.0120\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0109 - val_loss: 0.0096\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0105 - val_loss: 0.0138\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0124 - val_loss: 0.0132\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0103 - val_loss: 0.0128\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0118 - val_loss: 0.0112\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0096 - val_loss: 0.0091\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0122 - val_loss: 0.0120\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0124 - val_loss: 0.0117\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0091 - val_loss: 0.0127\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0123 - val_loss: 0.0111\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0119 - val_loss: 0.0108\n",
      "Epoch 1584/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 3s 857ms/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0121 - val_loss: 0.0107\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 1595/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0103 - val_loss: 0.0136\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0105 - val_loss: 0.0084\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 2s 584ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 2s 571ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0131 - val_loss: 0.0109\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0123 - val_loss: 0.0098\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0113 - val_loss: 0.0112\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0112 - val_loss: 0.0103\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0117 - val_loss: 0.0108\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0111 - val_loss: 0.0126\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0118 - val_loss: 0.0127\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0109 - val_loss: 0.0113\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0121 - val_loss: 0.0128\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0104 - val_loss: 0.0128\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0105 - val_loss: 0.0141\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0119 - val_loss: 0.0116\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 1646/2000\n",
      "4/4 [==============================] - 3s 828ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0117 - val_loss: 0.0131\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0119 - val_loss: 0.0118\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0110 - val_loss: 0.0106\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 3s 857ms/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0107 - val_loss: 0.0128\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0122 - val_loss: 0.0123\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0126 - val_loss: 0.0104\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0114 - val_loss: 0.0114\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 1674/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0100 - val_loss: 0.0120\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0113 - val_loss: 0.0123\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 3s 792ms/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0100 - val_loss: 0.0095\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0122 - val_loss: 0.0102\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0099 - val_loss: 0.0119\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0111 - val_loss: 0.0136\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0118 - val_loss: 0.0103\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0120 - val_loss: 0.0105\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1708/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0106 - val_loss: 0.0146\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0114 - val_loss: 0.0130\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0109 - val_loss: 0.0145\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 3s 788ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0113 - val_loss: 0.0090\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0110 - val_loss: 0.0125\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0102 - val_loss: 0.0129\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0122 - val_loss: 0.0096\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0107 - val_loss: 0.0145\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0106 - val_loss: 0.0129\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0104 - val_loss: 0.0158\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0112 - val_loss: 0.0098\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0124 - val_loss: 0.0100\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 3s 792ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0114 - val_loss: 0.0126\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0117 - val_loss: 0.0093\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0100 - val_loss: 0.0129\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0108 - val_loss: 0.0103\n",
      "Epoch 1753/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0124 - val_loss: 0.0124\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0114 - val_loss: 0.0095\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0106 - val_loss: 0.0132\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0116 - val_loss: 0.0108\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 3s 798ms/step - loss: 0.0104 - val_loss: 0.0120\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0113 - val_loss: 0.0113\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0111 - val_loss: 0.0105\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0104 - val_loss: 0.0139\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0118 - val_loss: 0.0100\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1770/2000\n",
      "4/4 [==============================] - 3s 857ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0115 - val_loss: 0.0094\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0102 - val_loss: 0.0142\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0125 - val_loss: 0.0121\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0109 - val_loss: 0.0126\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0103 - val_loss: 0.0096\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0097 - val_loss: 0.0118\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0111 - val_loss: 0.0137\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0105 - val_loss: 0.0143\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0124 - val_loss: 0.0141\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0108 - val_loss: 0.0086\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 3s 817ms/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0104 - val_loss: 0.0129\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 3s 788ms/step - loss: 0.0114 - val_loss: 0.0092\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 3s 804ms/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 3s 826ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 3s 824ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0097 - val_loss: 0.0103\n",
      "Epoch 1832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.0121 - val_loss: 0.0135\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0120 - val_loss: 0.0128\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0111 - val_loss: 0.0130\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0108 - val_loss: 0.0132\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0123 - val_loss: 0.0126\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0108 - val_loss: 0.0163\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0122 - val_loss: 0.0101\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0118 - val_loss: 0.0122\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 3s 831ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0116 - val_loss: 0.0127\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0117 - val_loss: 0.0100\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 3s 851ms/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0124 - val_loss: 0.0120\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0101 - val_loss: 0.0133\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0107 - val_loss: 0.0132\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0109 - val_loss: 0.1079\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.0107 - val_loss: 0.0125\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0122 - val_loss: 0.0108\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0116 - val_loss: 0.0082\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0119 - val_loss: 0.0120\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 1894/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0128 - val_loss: 0.0126\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0118 - val_loss: 0.0133\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0116 - val_loss: 0.0134\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 3s 861ms/step - loss: 0.0129 - val_loss: 0.0116\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.0110 - val_loss: 0.0131\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0122 - val_loss: 0.0092\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0106 - val_loss: 0.0124\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0114 - val_loss: 0.0122\n",
      "Epoch 1911/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0109 - val_loss: 0.0087\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 3s 791ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0112 - val_loss: 0.0088\n",
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0114 - val_loss: 0.0091\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0115 - val_loss: 0.0103\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0116 - val_loss: 0.0115\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.0111 - val_loss: 0.0103\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 3s 788ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.0123 - val_loss: 0.0118\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 3s 801ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.0098 - val_loss: 0.0126\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0130 - val_loss: 0.0117\n",
      "Epoch 1956/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0111 - val_loss: 0.0123\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 1958/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.0117 - val_loss: 0.0115\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0121 - val_loss: 0.0113\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0114 - val_loss: 0.0108\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0118 - val_loss: 0.0124\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0104 - val_loss: 0.0796\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0104 - val_loss: 0.0143\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 3s 803ms/step - loss: 0.0113 - val_loss: 0.0109\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0120 - val_loss: 0.0096\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0116 - val_loss: 0.0129\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0105 - val_loss: 0.0135\n",
      "Epoch 1989/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 3s 854ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0111 - val_loss: 0.0132\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0114 - val_loss: 0.0103\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(tdg, callbacks=[mc,tb], initial_epoch=0\n",
    "                           ,steps_per_epoch=train_steps_per_epoch\n",
    "                           ,validation_data=vdg\n",
    "                           ,validation_steps=val_steps_per_epoch\n",
    "                           ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# acc = hist.history['acc']\n",
    "# loss = hist.history['loss']\n",
    "\n",
    "# # Create count of the number of epochs\n",
    "# epoch_count = range(1, len(acc) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# # plt.plot(epoch_count, acc, 'b-')\n",
    "# fig, ax = plt.subplots(ncols=2,sharex=True)\n",
    "# ax[0].plot(epoch_count, loss, 'r--')\n",
    "# ax[0].legend(['Loss'])\n",
    "# ax[0].set_xlabel('Epoch')\n",
    "# ax[0].set_ylabel('Loss')\n",
    "# ax[1].plot(epoch_count, acc, 'b-')\n",
    "# ax[1].legend(['Accuracy'])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_xlabel('Accuracy')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.DataFrame(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_res[['acc','val_acc']].plot()\n",
    "# hd_nlp = nlp(\"What is you name my name is Anthony Gonsalves What is you name my name is Anthony GonsalvesWhat is you name my name is Anthony GonsalvesWhat is you name my name is Anthony GonsalvesWhat is you name my name is Anthony GonsalvesWhat is you name my name is Anthony Gonsalves!\".lower())\n",
    "# len(hd_nlp[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `evaluate_generator` call to the Keras 2 API: `evaluate_generator(<generator..., steps=5, use_multiprocessing=True)`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.010693317279219627"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('weights/dnf700_sa_sent_hd_vector.hdf5')\n",
    "model.evaluate_generator(test_dg,steps=5,pickle_safe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_dg)\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['reddit users declare war on hillary’s paid internet trolls',\n",
       "       'lol! british wife of lib actor who said: “there will never be a president donald trump”…warns americans about president-elect trump [video]',\n",
       "       'he’s never sold an original painting until now…and this one’s going in the white house',\n",
       "       'erdoğan: us, the founder of isis',\n",
       "       '(video) female college students protesting because ‘trump is a rapist’',\n",
       "       \"fantastic! trump's 7 point plan to reform healthcare begins with a bombshell! » 100percentfedup.com\",\n",
       "       '(video) female college students protesting because ‘trump is a rapist’',\n",
       "       'obama declares his family will move to canada if trump is elected',\n",
       "       'jill stein endorsed donald trump',\n",
       "       'fbi director comey’s ‘leaked’ memo explains why he’s reopening the clinton email case',\n",
       "       'reddit users declare war on hillary’s paid internet trolls',\n",
       "       \"clinton camp demands 'compliant citizenry' for master plan\",\n",
       "       'breaking: fraudulent clinton votes discovered by the “tens of thousands”',\n",
       "       'isis leader calls for american muslim voters to support hillary clinton',\n",
       "       'president obama confirms he will refuse to leave office if trump is elected',\n",
       "       'hillary personally ordered ‘donald duck’ troll campaign',\n",
       "       'the clinton foundation has purchased over $137 million of illegal arms and ammunition',\n",
       "       '(video) female college students protesting because ‘trump is a rapist’',\n",
       "       'top aide: hillary ‘still not perfect in her head’, wikileaks',\n",
       "       'reddit users declare war on hillary’s paid internet trolls',\n",
       "       'wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting',\n",
       "       'breaking: fraudulent clinton votes discovered by the “tens of thousands”',\n",
       "       'fbi agent suspected in hillary email leaks found dead in apparent murder-suicide',\n",
       "       'nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative',\n",
       "       \"clinton camp demands 'compliant citizenry' for master plan\",\n",
       "       'wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting',\n",
       "       'hillary sold weapons to isis, wikileaks confirms',\n",
       "       'leaked 2013 trump tax return shows he paid over 40 million in taxes',\n",
       "       'hillary personally ordered ‘donald duck’ troll campaign',\n",
       "       'hillary’s (islamic) america is already here where ‘muslim no-go zones’ are popping up all over michiganistan',\n",
       "       'isis leader calls for american muslim voters to support hillary clinton',\n",
       "       \"hillary clinton in 2013: 'i would like to see people like donald trump run for office\",\n",
       "       'fbi director comey’s ‘leaked’ memo explains why he’s reopening the clinton email case',\n",
       "       'hillary clinton’s “sudden move” of $1.8 billion to qatar central bank stuns financial world',\n",
       "       'trump accuses obama, hillary clinton of founding daesh',\n",
       "       'hillary clinton used hand signals to rig debate?',\n",
       "       'hillary personally ordered ‘donald duck’ troll campaign',\n",
       "       \"hillary clinton cut her tax bill by 'donating' $1 million to herself via the clinton foundation?\",\n",
       "       'former nato chief: we need us as ‘world’s policeman’',\n",
       "       'kremlin: putin congratulates trump, hopes to work together major issues',\n",
       "       'erdoğan: us, the founder of isis',\n",
       "       \"fantastic! trump's 7 point plan to reform healthcare begins with a bombshell! » 100percentfedup.com\",\n",
       "       'us officials try to scare voters with terror threat',\n",
       "       'pentagon officials furious after clinton announces us response time for nuclear launch during debate',\n",
       "       \"doj's loretta lynch tried to squash comey's letter to congress\",\n",
       "       'lol! british wife of lib actor who said: “there will never be a president donald trump”…warns americans about president-elect trump [video]',\n",
       "       \"clinton camp demands 'compliant citizenry' for master plan\",\n",
       "       'nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative',\n",
       "       \"physician confirms hillary clinton has parkinson's disease\",\n",
       "       \"george soros: trump will win popular vote by a landslide but clinton victory a 'done deal'\"],\n",
       "      dtype='<U139')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hillary clinton in 2013: 'i would like to see people like donald trump run for office\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx = np.random.randint(0,50)\n",
    "display(x['headline'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before running against billionaire real estate mogul Donald Trump for the presidency, Secretary of State Hillary Clinton told an audience at a private, paid speech she wanted to see more successful businessmen and women run for office because they can’t be bought.',\n",
       " 'In a speech made public by Wikileaks – which released an email from Hillary for America Research Director Tony Caark containing three attached speeches given at a private Goldman Sachs events – Clinton spoke and took audience questions at the “Builders and Innovators Summit” hosted by Goldman Sachs on October 29, 2013.',\n",
       " 'Answering a question about businessmen in politics, Clinton said that they are “most often the people that look over the horizon,” and therefore share a vision that many politicians of today lack. “',\n",
       " 'And that’s a very good question and thank you for asking it.',\n",
       " 'Yes, I would love to see more businessmen go into politics because I believe they would bring in an entirely different mindset and strategies than what we’re used to seeing traditionally,” she opined.',\n",
       " 'And then she just had to go on. “',\n",
       " 'In fact, when you say businessmen and women, I can’t help but think of a particular one that I would just love to see running for the presidency at some point in the future,” Clinton added. “',\n",
       " 'I don’t know what it is exactly about him, I can’t quite put my finger on it, but my instinct is almost never wrong.',\n",
       " 'And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.”',\n",
       " 'Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “',\n",
       " 'And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.',\n",
       " 'I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['sentences'][test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 125, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 125, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 125, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 125, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 125, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 125, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 125, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 125, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 125, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 125, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 125, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 125, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 125, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 125, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 125, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 125, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 125, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 125, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 125, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 125, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 125, 32), (1 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 125, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 125, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 125, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 125, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 125, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(model.inputs,model.get_layer(name='ca1').output)\n",
    "model_2 = Model(model.inputs,model.get_layer(name='ca2').output)\n",
    "model_3 = Model(model.inputs,model.get_layer(name='ca3').output)\n",
    "model_4 = Model(model.inputs,model.get_layer(name='ca4').output)\n",
    "model_1.summary()\n",
    "model_2.summary()\n",
    "model_3.summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, b1, g1 = model_1.predict(x)\n",
    "_, b2, g2 = model_2.predict(x)\n",
    "_, b3, g3 = model_3.predict(x)\n",
    "_, b4, g4 = model_4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b1+b2+b3+b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 10,  7,  6,  5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_N = 5\n",
    "t = b[test_idx][0][:len(x['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-30.300713"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "b[test_idx][0][:len(x['sentences'][test_idx])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hillary clinton in 2013: 'i would like to see people like donald trump run for office\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Before running against billionaire real estate mogul Donald Trump for the presidency, Secretary of State Hillary Clinton told an audience at a private, paid speech she wanted to see more successful businessmen and women run for office because they can’t be bought.',\n",
       " 'And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.” Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.',\n",
       " 'I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x['headline'][test_idx])\n",
    "display(x['claims'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 : I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.\n",
      "10 : And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.\n",
      "7 : I don’t know what it is exactly about him, I can’t quite put my finger on it, but my instinct is almost never wrong.\n",
      "6 : In fact, when you say businessmen and women, I can’t help but think of a particular one that I would just love to see running for the presidency at some point in the future,” Clinton added. “\n",
      "5 : And then she just had to go on. “\n"
     ]
    }
   ],
   "source": [
    "for s in t:\n",
    "    if s>=len(x['sentences'][test_idx]):continue\n",
    "    print(s,':',x['sentences'][test_idx][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-30.300713"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "h_s_attended_vector = b[test_idx][0][:len(x['sentences'][test_idx])]\n",
    "h_s_attended_vector.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h_s_attended_vector = pd.DataFrame(h_s_attended_vector)\n",
    "\n",
    "\n",
    "xw = df_h_s_attended_vector.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xw_scaled = min_max_scaler.fit_transform(xw)\n",
    "df_h_s_attended_vector = pd.DataFrame(xw_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f9715b3ada0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(2.0,7.0)})\n",
    "sns.heatmap(df_h_s_attended_vector, annot=True, cmap='YlGnBu', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 125, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 125, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 125, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 125, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa1 (SelfAttention)          [(None, 125, 32), (125, 1 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 125, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 125, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 125, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 125, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa2 (SelfAttention)          [(None, 125, 32), (125, 1 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 125, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 125, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 125, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 125, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa3 (SelfAttention)          [(None, 125, 32), (125, 1 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 125, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 125, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 125, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 125, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 125, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 125, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa4 (SelfAttention)          [(None, 125, 32), (125, 1 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s1 = Model(model.inputs,model.get_layer(name='sa1').output)\n",
    "model_s2 = Model(model.inputs,model.get_layer(name='sa2').output)\n",
    "model_s3 = Model(model.inputs,model.get_layer(name='sa3').output)\n",
    "model_s4 = Model(model.inputs,model.get_layer(name='sa4').output)\n",
    "model_s1.summary()\n",
    "model_s2.summary()\n",
    "model_s3.summary()\n",
    "model_s4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sb1, sg1 = model_s1.predict([x['sentence_vectors'],x['input_headline_vector']])\n",
    "_, sb2, sg2 = model_s2.predict(x)\n",
    "_, sb3, sg3 = model_s3.predict(x)\n",
    "_, sb4, sg4 = model_s4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 12)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = sb1[test_idx]#+sb2[test_idx]+sb3[test_idx]+sb4[test_idx]\n",
    "sb = sb[:len(x['sentences'][test_idx]),:len(x['sentences'][test_idx])]\n",
    "\n",
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb = pd.DataFrame(sb)\n",
    "\n",
    "\n",
    "# zx = df_sb.values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# zx_scaled = min_max_scaler.fit_transform(zx)\n",
    "# df_sb = pd.DataFrame(zx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f970a29f2b0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14.0,12.0)})\n",
    "sns.heatmap(pd.DataFrame(df_sb),annot=True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Before running against billionaire real estate mogul Donald Trump for the presidency, Secretary of State Hillary Clinton told an audience at a private, paid speech she wanted to see more successful businessmen and women run for office because they can’t be bought.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a speech made public by Wikileaks – which released an email from Hillary for America Research Director Tony Caark containing three attached speeches given at a private Goldman Sachs events – Clinton spoke and took audience questions at the “Builders and Innovators Summit” hosted by Goldman Sachs on October 29, 2013.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Answering a question about businessmen in politics, Clinton said that they are “most often the people that look over the horizon,” and therefore share a vision that many politicians of today lack. “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And that’s a very good question and thank you for asking it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes, I would love to see more businessmen go into politics because I believe they would bring in an entirely different mindset and strategies than what we’re used to seeing traditionally,” she opined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And then she just had to go on. “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In fact, when you say businessmen and women, I can’t help but think of a particular one that I would just love to see running for the presidency at some point in the future,” Clinton added. “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I don’t know what it is exactly about him, I can’t quite put my finger on it, but my instinct is almost never wrong.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                   0\n",
       "0   Before running against billionaire real estate mogul Donald Trump for the presidency, Secretary of State Hillary Clinton told an audience at a private, paid speech she wanted to see more successful businessmen and women run for office because they can’t be bought.                                                        \n",
       "1   In a speech made public by Wikileaks – which released an email from Hillary for America Research Director Tony Caark containing three attached speeches given at a private Goldman Sachs events – Clinton spoke and took audience questions at the “Builders and Innovators Summit” hosted by Goldman Sachs on October 29, 2013.\n",
       "2   Answering a question about businessmen in politics, Clinton said that they are “most often the people that look over the horizon,” and therefore share a vision that many politicians of today lack. “                                                                                                                          \n",
       "3   And that’s a very good question and thank you for asking it.                                                                                                                                                                                                                                                                    \n",
       "4   Yes, I would love to see more businessmen go into politics because I believe they would bring in an entirely different mindset and strategies than what we’re used to seeing traditionally,” she opined.                                                                                                                        \n",
       "5   And then she just had to go on. “                                                                                                                                                                                                                                                                                               \n",
       "6   In fact, when you say businessmen and women, I can’t help but think of a particular one that I would just love to see running for the presidency at some point in the future,” Clinton added. “                                                                                                                                 \n",
       "7   I don’t know what it is exactly about him, I can’t quite put my finger on it, but my instinct is almost never wrong.                                                                                                                                                                                                            \n",
       "8   And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.”                                                                                                                                                                                                              \n",
       "9   Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “                                                                                                                                                                  \n",
       "10  And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.                                                                                                                                \n",
       "11  I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.                                                                                                                                                "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x['sentences'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
