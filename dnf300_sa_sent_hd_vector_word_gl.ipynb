{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import spacy\n",
    "from keras.utils import to_categorical\n",
    "from spacy.lang.en import English\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.layers import BatchNormalization, Lambda, Concatenate, Dropout, Conv1D, MaxPooling1D, Input, TimeDistributed, Dense, LSTM, RepeatVector, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from AttentionModules import SelfAttention, CrossAttention\n",
    "import sys,os\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['authors', 'claim_ids', 'evidence', 'headline', 'id', 'reason',\n",
       "        'claims', 'type', 'urls'],\n",
       "       dtype='object'),\n",
       " Index(['authors', 'evidence', 'headline', 'id', 'reason', 'type', 'urls'], dtype='object'),\n",
       " 300,\n",
       " 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf300 = pd.read_json('evaluation_set/deepnofakes/dnf_300/combined_300.json').T\n",
    "dnf_eval = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "# display(dnf_eval.head(2))\n",
    "dnf_eval.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls'] \n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_array_id.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "dnf_eval.keys(), dnf300.keys(), len(articles.keys()), len(article_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "train_batchsize = 32\n",
    "val_batchsize = 32\n",
    "test_batchsize = 50\n",
    "train_steps_per_epoch = 4\n",
    "val_steps_per_epoch = 1\n",
    "epochs = 2000\n",
    "max_sentences = 500\n",
    "# for idx in articles.keys():\n",
    "#     num = len(articles[idx])\n",
    "#     if num>=max_sentences:\n",
    "#         max_sentences = num\n",
    "        \n",
    "max_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = sorted(dnf_eval.headline.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "non_test_titles = np.array(list(set(titles)-set(test_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, val_index in kf.split(non_test_titles):\n",
    "    indices.append([train_index,val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68\n",
      "  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86\n",
      "  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104\n",
      " 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122\n",
      " 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158\n",
      " 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176\n",
      " 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194\n",
      " 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212\n",
      " 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230\n",
      " 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248\n",
      " 249 250 251 252] [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(202, 51, 50)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_index, val_index = indices[np.random.randint(0,num_splits)]\n",
    "print(train_index,val_index)\n",
    "val_titles = non_test_titles[val_index]\n",
    "train_titles = non_test_titles[train_index]\n",
    "len(train_titles),len(val_titles),len(test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy():\n",
    "    sentencizer = English()\n",
    "    sentencizer.add_pipe(sentencizer.create_pipe('sentencizer'))\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    return sentencizer, nlp\n",
    "sentencizer, nlp = load_spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf(batchsize,dataframe,mode):\n",
    "    counter=0\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            idx=np.random.choice(train_titles)\n",
    "        elif mode=='val':\n",
    "            idx=np.random.choice(val_titles)\n",
    "        elif mode=='test':\n",
    "            idx=np.random.choice(test_titles)\n",
    "        idx = idx.strip()\n",
    "        \n",
    "            \n",
    "#         cl = dataframe[dataframe.Article==idx]['Claim'].values\n",
    "#         sentences=articles[ar_id]\n",
    "#         print(len(sentences))\n",
    "        if mode=='test':\n",
    "            hd = dnf_eval[dnf_eval.headline==idx]['headline'].values[0].lower()\n",
    "            ar_id = dnf_eval[dnf_eval.headline==idx]['id'].values[0]\n",
    "            cl = dnf_eval[dnf_eval.headline==idx]['claim_ids'].values[0]\n",
    "            ar_claims.append(cl)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                hd = dataframe[dataframe.headline==idx]['headline'].values[0].lower()\n",
    "                ar_id = dataframe[dataframe.headline==idx]['id'].values[0]\n",
    "                ar_claims.append('None')\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(idx)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "#         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "        \n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "        counter+=1\n",
    "        if counter==batchsize:\n",
    "            inputs = {\n",
    "                'article_id': np.array(ar_ids)\n",
    "                ,'headline': np.array(hds)\n",
    "                ,'sentence_vectors' : np.array(ar_sents)\n",
    "                ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "                ,'claims':np.array(ar_claims)\n",
    "                ,'sentences':np.array(ar_sentences)\n",
    "            }\n",
    "            outputs = {\n",
    "                'headline_token_classes': np.array(ar_head_classes)\n",
    "                ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "            }\n",
    "            yield inputs,outputs\n",
    "            ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "            counter=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = datagen_dnf(train_batchsize,dnf300,mode='train')\n",
    "vdg = datagen_dnf(val_batchsize,dnf300,mode='val')\n",
    "test_dg = datagen_dnf(test_batchsize,dnf300,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(test_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['sentence_vectors'].shape, x['headline_vector'].shape, y['headline_token_classes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 500, 1024)    0           ca1[0][0]                        \n",
      "                                                                 ca2[0][0]                        \n",
      "                                                                 ca3[0][0]                        \n",
      "                                                                 ca4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 1024)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 500, 1024)    4096        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 250, 256)     786688      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 125, 256)     196864      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 63, 256)      196864      conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 32, 256)      196864      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 256)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 256)      1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 50, 256)      0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50, 256)      525312      repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 256)      1024        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_headline_vector (Dense)  (None, 300)          153900      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "headline_token_classes (TimeDis (None, 50, 20000)    5140000     batch_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 8,131,684\n",
      "Trainable params: 8,126,500\n",
      "Non-trainable params: 5,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"2213pt\" viewBox=\"0.00 0.00 1810.50 2213.00\" width=\"1811pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 2209)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-2209 1806.5,-2209 1806.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 139760157921232 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>139760157921232</title>\n",
       "<polygon fill=\"none\" points=\"857,-2158.5 857,-2204.5 1198,-2204.5 1198,-2158.5 857,-2158.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2177.8\">sentence_vectors: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2158.5 1033,-2204.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2189.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2181.5 1088,-2181.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2166.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2158.5 1088,-2204.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2189.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2181.5 1198,-2181.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2166.3\">(None, 500, 300)</text>\n",
       "</g>\n",
       "<!-- 139760157938240 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>139760157938240</title>\n",
       "<polygon fill=\"none\" points=\"883.5,-2075.5 883.5,-2121.5 1171.5,-2121.5 1171.5,-2075.5 883.5,-2075.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2094.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2075.5 1006.5,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2098.5 1061.5,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2075.5 1061.5,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2106.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2098.5 1171.5,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2083.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 139760157921232&#45;&gt;139760157938240 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>139760157921232-&gt;139760157938240</title>\n",
       "<path d=\"M1027.5,-2158.3799C1027.5,-2150.1745 1027.5,-2140.7679 1027.5,-2131.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2131.784 1027.5,-2121.784 1024.0001,-2131.784 1031.0001,-2131.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760157938352 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>139760157938352</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1992.5 885.5,-2038.5 1169.5,-2038.5 1169.5,-1992.5 885.5,-1992.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-2011.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1992.5 1010.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-2015.5 1065.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1992.5 1065.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-2023.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-2015.5 1169.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-2000.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 139760157938240&#45;&gt;139760157938352 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>139760157938240-&gt;139760157938352</title>\n",
       "<path d=\"M1027.5,-2075.3799C1027.5,-2067.1745 1027.5,-2057.7679 1027.5,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2048.784 1027.5,-2038.784 1024.0001,-2048.784 1031.0001,-2048.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760157938408 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>139760157938408</title>\n",
       "<polygon fill=\"none\" points=\"886.5,-1909.5 886.5,-1955.5 1168.5,-1955.5 1168.5,-1909.5 886.5,-1909.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1928.8\">conv1d_2: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1909.5 1009.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1932.5 1064.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1909.5 1064.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1940.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1932.5 1168.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1917.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 139760157938352&#45;&gt;139760157938408 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>139760157938352-&gt;139760157938408</title>\n",
       "<path d=\"M1027.5,-1992.3799C1027.5,-1984.1745 1027.5,-1974.7679 1027.5,-1965.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1965.784 1027.5,-1955.784 1024.0001,-1965.784 1031.0001,-1965.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760152335696 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>139760152335696</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1826.5 885.5,-1872.5 1169.5,-1872.5 1169.5,-1826.5 885.5,-1826.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1845.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1826.5 1010.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1849.5 1065.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1826.5 1065.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1857.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1849.5 1169.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1834.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 139760157938408&#45;&gt;139760152335696 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>139760157938408-&gt;139760152335696</title>\n",
       "<path d=\"M1027.5,-1909.3799C1027.5,-1901.1745 1027.5,-1891.7679 1027.5,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1882.784 1027.5,-1872.784 1024.0001,-1882.784 1031.0001,-1882.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760152189584 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>139760152189584</title>\n",
       "<polygon fill=\"none\" points=\"818,-1743.5 818,-1789.5 1237,-1789.5 1237,-1743.5 818,-1743.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1762.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1743.5 1078,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1766.5 1133,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1743.5 1133,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1774.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1766.5 1237,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1751.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 139760152335696&#45;&gt;139760152189584 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>139760152335696-&gt;139760152189584</title>\n",
       "<path d=\"M1027.5,-1826.3799C1027.5,-1818.1745 1027.5,-1808.7679 1027.5,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1799.784 1027.5,-1789.784 1024.0001,-1799.784 1031.0001,-1799.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760152083200 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>139760152083200</title>\n",
       "<polygon fill=\"none\" points=\"252.5,-1660.5 252.5,-1706.5 626.5,-1706.5 626.5,-1660.5 252.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-1679.8\">sa1: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1660.5 367.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1683.5 422.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1660.5 422.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1683.5 626.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760152189584&#45;&gt;139760152083200 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>139760152189584-&gt;139760152083200</title>\n",
       "<path d=\"M864.4901,-1743.4901C786.1844,-1732.4367 692.2952,-1719.1837 612.7036,-1707.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"612.9631,-1704.4508 602.572,-1706.5187 611.9847,-1711.3821 612.9631,-1704.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760151298400 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>139760151298400</title>\n",
       "<polygon fill=\"none\" points=\"644.5,-1660.5 644.5,-1706.5 1018.5,-1706.5 1018.5,-1660.5 644.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"702\" y=\"-1679.8\">sa2: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1660.5 759.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1683.5 814.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1660.5 814.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1683.5 1018.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760152189584&#45;&gt;139760151298400 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>139760152189584-&gt;139760151298400</title>\n",
       "<path d=\"M973.1634,-1743.4901C949.0535,-1733.2803 920.5118,-1721.1938 895.3877,-1710.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"896.5156,-1707.2313 885.9423,-1706.5547 893.7859,-1713.6771 896.5156,-1707.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760150262784 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>139760150262784</title>\n",
       "<polygon fill=\"none\" points=\"1036.5,-1660.5 1036.5,-1706.5 1410.5,-1706.5 1410.5,-1660.5 1036.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094\" y=\"-1679.8\">sa3: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1660.5 1151.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1683.5 1206.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1660.5 1206.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1683.5 1410.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760152189584&#45;&gt;139760150262784 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>139760152189584-&gt;139760150262784</title>\n",
       "<path d=\"M1081.8366,-1743.4901C1105.9465,-1733.2803 1134.4882,-1721.1938 1159.6123,-1710.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1161.2141,-1713.6771 1169.0577,-1706.5547 1158.4844,-1707.2313 1161.2141,-1713.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760149437856 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>139760149437856</title>\n",
       "<polygon fill=\"none\" points=\"1428.5,-1660.5 1428.5,-1706.5 1802.5,-1706.5 1802.5,-1660.5 1428.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1486\" y=\"-1679.8\">sa4: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1660.5 1543.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1683.5 1598.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1660.5 1598.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1683.5 1802.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760152189584&#45;&gt;139760149437856 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>139760152189584-&gt;139760149437856</title>\n",
       "<path d=\"M1190.5099,-1743.4901C1268.8156,-1732.4367 1362.7048,-1719.1837 1442.2964,-1707.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1443.0153,-1711.3821 1452.428,-1706.5187 1442.0369,-1704.4508 1443.0153,-1711.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760148687504 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>139760148687504</title>\n",
       "<polygon fill=\"none\" points=\"718,-1577.5 718,-1623.5 1337,-1623.5 1337,-1577.5 718,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-1596.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"886,-1577.5 886,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"886,-1600.5 941,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"941,-1577.5 941,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1608.3\">[(None, 500, 32), (None, 500, 32), (None, 500, 32), (None, 500, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"941,-1600.5 1337,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1585.3\">(None, 500, 128)</text>\n",
       "</g>\n",
       "<!-- 139760152083200&#45;&gt;139760148687504 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>139760152083200-&gt;139760148687504</title>\n",
       "<path d=\"M602.5099,-1660.4901C680.8156,-1649.4367 774.7048,-1636.1837 854.2964,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"855.0153,-1628.3821 864.428,-1623.5187 854.0369,-1621.4508 855.0153,-1628.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760151298400&#45;&gt;139760148687504 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>139760151298400-&gt;139760148687504</title>\n",
       "<path d=\"M885.8366,-1660.4901C909.9465,-1650.2803 938.4882,-1638.1938 963.6123,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"965.2141,-1630.6771 973.0577,-1623.5547 962.4844,-1624.2313 965.2141,-1630.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760150262784&#45;&gt;139760148687504 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>139760150262784-&gt;139760148687504</title>\n",
       "<path d=\"M1169.1634,-1660.4901C1145.0535,-1650.2803 1116.5118,-1638.1938 1091.3877,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1092.5156,-1624.2313 1081.9423,-1623.5547 1089.7859,-1630.6771 1092.5156,-1624.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760149437856&#45;&gt;139760148687504 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>139760149437856-&gt;139760148687504</title>\n",
       "<path d=\"M1452.4901,-1660.4901C1374.1844,-1649.4367 1280.2952,-1636.1837 1200.7036,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1200.9631,-1621.4508 1190.572,-1623.5187 1199.9847,-1628.3821 1200.9631,-1621.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760157938688 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>139760157938688</title>\n",
       "<polygon fill=\"none\" points=\"357,-1577.5 357,-1623.5 700,-1623.5 700,-1577.5 357,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-1596.8\">input_headline_vector: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"562,-1577.5 562,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"562,-1600.5 617,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"617,-1577.5 617,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1608.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"617,-1600.5 700,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1585.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 139760147460784 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>139760147460784</title>\n",
       "<polygon fill=\"none\" points=\"439.5,-1494.5 439.5,-1540.5 679.5,-1540.5 679.5,-1494.5 439.5,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-1513.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1494.5 541.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1517.5 596.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1494.5 596.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1525.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1517.5 679.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1502.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 139760157938688&#45;&gt;139760147460784 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>139760157938688-&gt;139760147460784</title>\n",
       "<path d=\"M537.1352,-1577.3799C540.2665,-1568.9962 543.8662,-1559.3584 547.2495,-1550.2996\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"550.5834,-1551.3766 550.8036,-1540.784 544.0259,-1548.9273 550.5834,-1551.3766\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760151839408 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>139760151839408</title>\n",
       "<polygon fill=\"none\" points=\"881.5,-1494.5 881.5,-1540.5 1169.5,-1540.5 1169.5,-1494.5 881.5,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"943\" y=\"-1513.8\">conv1d_3: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1494.5 1004.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1517.5 1059.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1494.5 1059.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1525.3\">(None, 500, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1517.5 1169.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1502.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 139760148687504&#45;&gt;139760151839408 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>139760148687504-&gt;139760151839408</title>\n",
       "<path d=\"M1026.9429,-1577.3799C1026.7452,-1569.1745 1026.5185,-1559.7679 1026.3043,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1029.801,-1550.6968 1026.0611,-1540.784 1022.8031,-1550.8655 1029.801,-1550.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147258952 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>139760147258952</title>\n",
       "<polygon fill=\"none\" points=\"437,-1411.5 437,-1457.5 712,-1457.5 712,-1411.5 437,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-1430.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"560,-1411.5 560,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"560,-1434.5 615,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"615,-1411.5 615,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1442.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"615,-1434.5 712,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1419.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 139760147460784&#45;&gt;139760147258952 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>139760147460784-&gt;139760147258952</title>\n",
       "<path d=\"M563.6783,-1494.3799C565.1612,-1486.1745 566.8612,-1476.7679 568.4677,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"571.9578,-1468.2471 570.292,-1457.784 565.0693,-1467.0021 571.9578,-1468.2471\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147463528 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>139760147463528</title>\n",
       "<polygon fill=\"none\" points=\"876.5,-1411.5 876.5,-1457.5 1166.5,-1457.5 1166.5,-1411.5 876.5,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"939\" y=\"-1430.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1411.5 1001.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1434.5 1056.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1411.5 1056.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1442.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1434.5 1166.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1419.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 139760151839408&#45;&gt;139760147463528 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>139760151839408-&gt;139760147463528</title>\n",
       "<path d=\"M1024.3858,-1494.3799C1023.9903,-1486.1745 1023.537,-1476.7679 1023.1086,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1026.5995,-1467.6039 1022.6221,-1457.784 1019.6076,-1467.9409 1026.5995,-1467.6039\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147258896 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>139760147258896</title>\n",
       "<polygon fill=\"none\" points=\"376.5,-1328.5 376.5,-1374.5 788.5,-1374.5 788.5,-1328.5 376.5,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-1347.8\">batch_normalization_3: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1328.5 636.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1351.5 691.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1328.5 691.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1359.3\">(None, 1, 256)</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1351.5 788.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1336.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 139760147258952&#45;&gt;139760147258896 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>139760147258952-&gt;139760147258896</title>\n",
       "<path d=\"M576.7284,-1411.3799C577.5193,-1403.1745 578.426,-1393.7679 579.2828,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"582.7801,-1385.0737 580.2558,-1374.784 575.8124,-1384.4021 582.7801,-1385.0737\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147460840 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>139760147460840</title>\n",
       "<polygon fill=\"none\" points=\"807,-1328.5 807,-1374.5 1232,-1374.5 1232,-1328.5 807,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"937\" y=\"-1347.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1328.5 1067,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1351.5 1122,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1328.5 1122,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1359.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1351.5 1232,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1336.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 139760147463528&#45;&gt;139760147460840 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>139760147463528-&gt;139760147460840</title>\n",
       "<path d=\"M1020.9429,-1411.3799C1020.7452,-1403.1745 1020.5185,-1393.7679 1020.3043,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1023.801,-1384.6968 1020.0611,-1374.784 1016.8031,-1384.8655 1023.801,-1384.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760146554608 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>139760146554608</title>\n",
       "<polygon fill=\"none\" points=\"810,-1245.5 810,-1291.5 1197,-1291.5 1197,-1245.5 810,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872.5\" y=\"-1264.8\">ca1: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"935,-1245.5 935,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"935,-1268.5 990,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"990,-1245.5 990,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"990,-1268.5 1197,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760147258896&#45;&gt;139760146554608 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>139760147258896-&gt;139760146554608</title>\n",
       "<path d=\"M699.2129,-1328.4901C754.3078,-1317.6282 820.1773,-1304.642 876.519,-1293.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"877.4259,-1296.9229 886.5601,-1291.5547 876.0719,-1290.0551 877.4259,-1296.9229\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760146169472 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>139760146169472</title>\n",
       "<polygon fill=\"none\" points=\"1215,-1245.5 1215,-1291.5 1602,-1291.5 1602,-1245.5 1215,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277.5\" y=\"-1264.8\">ca2: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1245.5 1340,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1268.5 1395,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1245.5 1395,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1268.5 1602,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760147258896&#45;&gt;139760146169472 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>139760147258896-&gt;139760146169472</title>\n",
       "<path d=\"M788.5682,-1328.986C791.9028,-1328.6525 795.2153,-1328.3236 798.5,-1328 976.3881,-1310.477 1023.7095,-1310.5124 1204.8542,-1292.1557\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1205.3964,-1295.6187 1214.9903,-1291.1236 1204.6872,-1288.6547 1205.3964,-1295.6187\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760145584424 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>139760145584424</title>\n",
       "<polygon fill=\"none\" points=\"0,-1245.5 0,-1291.5 387,-1291.5 387,-1245.5 0,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-1264.8\">ca3: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"125,-1245.5 125,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-1268.5 180,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-1245.5 180,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"180,-1268.5 387,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760147258896&#45;&gt;139760145584424 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>139760147258896-&gt;139760145584424</title>\n",
       "<path d=\"M474.6584,-1328.4901C423.962,-1317.6731 363.3923,-1304.7495 311.4764,-1293.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"312.0616,-1290.2185 301.5514,-1291.5547 310.6009,-1297.0644 312.0616,-1290.2185\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760144613160 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>139760144613160</title>\n",
       "<polygon fill=\"none\" points=\"405,-1245.5 405,-1291.5 792,-1291.5 792,-1245.5 405,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467.5\" y=\"-1264.8\">ca4: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"530,-1245.5 530,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"530,-1268.5 585,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"585,-1245.5 585,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"585,-1268.5 792,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 139760147258896&#45;&gt;139760144613160 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>139760147258896-&gt;139760144613160</title>\n",
       "<path d=\"M586.9569,-1328.3799C588.5386,-1320.1745 590.352,-1310.7679 592.0656,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"595.5553,-1302.2658 594.0115,-1291.784 588.6818,-1300.9407 595.5553,-1302.2658\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147460840&#45;&gt;139760146554608 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>139760147460840-&gt;139760146554608</title>\n",
       "<path d=\"M1015.0431,-1328.3799C1013.4614,-1320.1745 1011.648,-1310.7679 1009.9344,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1013.3182,-1300.9407 1007.9885,-1291.784 1006.4447,-1302.2658 1013.3182,-1300.9407\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147460840&#45;&gt;139760146169472 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>139760147460840-&gt;139760146169472</title>\n",
       "<path d=\"M1127.3416,-1328.4901C1178.038,-1317.6731 1238.6077,-1304.7495 1290.5236,-1293.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1291.3991,-1297.0644 1300.4486,-1291.5547 1289.9384,-1290.2185 1291.3991,-1297.0644\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147460840&#45;&gt;139760145584424 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>139760147460840-&gt;139760145584424</title>\n",
       "<path d=\"M806.8249,-1328.9162C803.6957,-1328.6071 800.5859,-1328.3015 797.5,-1328 622.1938,-1310.873 575.6096,-1310.3786 397.0043,-1292.1432\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"397.3151,-1288.6568 387.0102,-1291.1184 396.601,-1295.6203 397.3151,-1288.6568\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760147460840&#45;&gt;139760144613160 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>139760147460840-&gt;139760144613160</title>\n",
       "<path d=\"M902.7871,-1328.4901C847.6922,-1317.6282 781.8227,-1304.642 725.481,-1293.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"725.9281,-1290.0551 715.4399,-1291.5547 724.5741,-1296.9229 725.9281,-1290.0551\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760143862360 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>139760143862360</title>\n",
       "<polygon fill=\"none\" points=\"477.5,-1162.5 477.5,-1208.5 1123.5,-1208.5 1123.5,-1162.5 477.5,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-1181.8\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1162.5 645.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1185.5 700.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1162.5 700.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1193.3\">[(None, 500, 256), (None, 500, 256), (None, 500, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1185.5 1123.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1170.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 139760146554608&#45;&gt;139760143862360 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>139760146554608-&gt;139760143862360</title>\n",
       "<path d=\"M947.2228,-1245.4901C922.1419,-1235.2353 892.4302,-1223.0872 866.3257,-1212.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"867.4675,-1209.0996 856.8867,-1208.5547 864.8183,-1215.579 867.4675,-1209.0996\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760146169472&#45;&gt;139760143862360 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>139760146169472-&gt;139760143862360</title>\n",
       "<path d=\"M1239.9455,-1245.4901C1158.8115,-1234.4142 1061.4981,-1221.1297 979.0922,-1209.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"979.5002,-1206.4035 969.1187,-1208.5187 978.5534,-1213.3392 979.5002,-1206.4035\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760145584424&#45;&gt;139760143862360 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>139760145584424-&gt;139760143862360</title>\n",
       "<path d=\"M361.7773,-1245.4901C442.7778,-1234.4142 539.9312,-1221.1297 622.2015,-1209.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"622.725,-1213.3413 632.1586,-1208.5187 621.7766,-1206.4058 622.725,-1213.3413\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760144613160&#45;&gt;139760143862360 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>139760144613160-&gt;139760143862360</title>\n",
       "<path d=\"M654.5,-1245.4901C679.4573,-1235.2353 709.0226,-1223.0872 734.9986,-1212.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"736.4717,-1215.5927 744.3911,-1208.5547 733.8112,-1209.1179 736.4717,-1215.5927\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760143164528 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>139760143164528</title>\n",
       "<polygon fill=\"none\" points=\"652,-1079.5 652,-1125.5 949,-1125.5 949,-1079.5 652,-1079.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1098.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"777,-1079.5 777,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"777,-1102.5 832,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-1079.5 832,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1110.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"832,-1102.5 949,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1087.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 139760143862360&#45;&gt;139760143164528 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>139760143862360-&gt;139760143164528</title>\n",
       "<path d=\"M800.5,-1162.3799C800.5,-1154.1745 800.5,-1144.7679 800.5,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1135.784 800.5,-1125.784 797.0001,-1135.784 804.0001,-1135.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760146268456 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>139760146268456</title>\n",
       "<polygon fill=\"none\" points=\"584.5,-996.5 584.5,-1042.5 1016.5,-1042.5 1016.5,-996.5 584.5,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1015.8\">batch_normalization_4: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-996.5 844.5,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-1019.5 899.5,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-996.5 899.5,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-1027.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-1019.5 1016.5,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-1004.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 139760143164528&#45;&gt;139760146268456 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>139760143164528-&gt;139760146268456</title>\n",
       "<path d=\"M800.5,-1079.3799C800.5,-1071.1745 800.5,-1061.7679 800.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1052.784 800.5,-1042.784 797.0001,-1052.784 804.0001,-1052.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760146268512 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>139760146268512</title>\n",
       "<polygon fill=\"none\" points=\"653,-913.5 653,-959.5 948,-959.5 948,-913.5 653,-913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-932.8\">conv1d_4: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-913.5 776,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-936.5 831,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"831,-913.5 831,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-944.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"831,-936.5 948,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-921.3\">(None, 250, 256)</text>\n",
       "</g>\n",
       "<!-- 139760146268456&#45;&gt;139760146268512 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>139760146268456-&gt;139760146268512</title>\n",
       "<path d=\"M800.5,-996.3799C800.5,-988.1745 800.5,-978.7679 800.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-969.784 800.5,-959.784 797.0001,-969.784 804.0001,-969.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760141987120 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>139760141987120</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-830.5 656.5,-876.5 944.5,-876.5 944.5,-830.5 656.5,-830.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-849.8\">conv1d_5: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-830.5 779.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-853.5 834.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-830.5 834.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-861.3\">(None, 250, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-853.5 944.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-838.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 139760146268512&#45;&gt;139760141987120 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>139760146268512-&gt;139760141987120</title>\n",
       "<path d=\"M800.5,-913.3799C800.5,-905.1745 800.5,-895.7679 800.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-886.784 800.5,-876.784 797.0001,-886.784 804.0001,-886.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760141307240 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>139760141307240</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-747.5 656.5,-793.5 944.5,-793.5 944.5,-747.5 656.5,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-766.8\">conv1d_6: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-747.5 779.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-770.5 834.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-747.5 834.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-778.3\">(None, 125, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-770.5 944.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-755.3\">(None, 63, 256)</text>\n",
       "</g>\n",
       "<!-- 139760141987120&#45;&gt;139760141307240 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>139760141987120-&gt;139760141307240</title>\n",
       "<path d=\"M800.5,-830.3799C800.5,-822.1745 800.5,-812.7679 800.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-803.784 800.5,-793.784 797.0001,-803.784 804.0001,-803.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760140895288 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>139760140895288</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-664.5 659.5,-710.5 941.5,-710.5 941.5,-664.5 659.5,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-683.8\">conv1d_7: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-664.5 782.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-687.5 837.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-664.5 837.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-695.3\">(None, 63, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-687.5 941.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-672.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 139760141307240&#45;&gt;139760140895288 -->\n",
       "<g class=\"edge\" id=\"edge37\">\n",
       "<title>139760141307240-&gt;139760140895288</title>\n",
       "<path d=\"M800.5,-747.3799C800.5,-739.1745 800.5,-729.7679 800.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-720.784 800.5,-710.784 797.0001,-720.784 804.0001,-720.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760140025752 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>139760140025752</title>\n",
       "<polygon fill=\"none\" points=\"658.5,-581.5 658.5,-627.5 942.5,-627.5 942.5,-581.5 658.5,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-600.8\">dropout_5: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-581.5 783.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-604.5 838.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-581.5 838.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-612.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-604.5 942.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-589.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 139760140895288&#45;&gt;139760140025752 -->\n",
       "<g class=\"edge\" id=\"edge38\">\n",
       "<title>139760140895288-&gt;139760140025752</title>\n",
       "<path d=\"M800.5,-664.3799C800.5,-656.1745 800.5,-646.7679 800.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-637.784 800.5,-627.784 797.0001,-637.784 804.0001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760140101896 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>139760140101896</title>\n",
       "<polygon fill=\"none\" points=\"591,-498.5 591,-544.5 1010,-544.5 1010,-498.5 591,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-517.8\">batch_normalization_5: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"851,-498.5 851,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"851,-521.5 906,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"906,-498.5 906,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-529.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"906,-521.5 1010,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-506.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 139760140025752&#45;&gt;139760140101896 -->\n",
       "<g class=\"edge\" id=\"edge39\">\n",
       "<title>139760140025752-&gt;139760140101896</title>\n",
       "<path d=\"M800.5,-581.3799C800.5,-573.1745 800.5,-563.7679 800.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-554.784 800.5,-544.784 797.0001,-554.784 804.0001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760140022392 -->\n",
       "<g class=\"node\" id=\"node32\">\n",
       "<title>139760140022392</title>\n",
       "<polygon fill=\"none\" points=\"559.5,-415.5 559.5,-461.5 1041.5,-461.5 1041.5,-415.5 559.5,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-434.8\">global_average_pooling1d_1: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-415.5 882.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-438.5 937.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-415.5 937.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-446.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-438.5 1041.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-423.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 139760140101896&#45;&gt;139760140022392 -->\n",
       "<g class=\"edge\" id=\"edge40\">\n",
       "<title>139760140101896-&gt;139760140022392</title>\n",
       "<path d=\"M800.5,-498.3799C800.5,-490.1745 800.5,-480.7679 800.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-471.784 800.5,-461.784 797.0001,-471.784 804.0001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760138165496 -->\n",
       "<g class=\"node\" id=\"node33\">\n",
       "<title>139760138165496</title>\n",
       "<polygon fill=\"none\" points=\"473.5,-332.5 473.5,-378.5 817.5,-378.5 817.5,-332.5 473.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566\" y=\"-351.8\">repeat_vector_1: RepeatVector</text>\n",
       "<polyline fill=\"none\" points=\"658.5,-332.5 658.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"686\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"658.5,-355.5 713.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"686\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-332.5 713.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"765.5\" y=\"-363.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-355.5 817.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"765.5\" y=\"-340.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 139760140022392&#45;&gt;139760138165496 -->\n",
       "<g class=\"edge\" id=\"edge41\">\n",
       "<title>139760140022392-&gt;139760138165496</title>\n",
       "<path d=\"M757.3239,-415.3799C738.842,-405.4832 717.0966,-393.8388 697.7191,-383.4625\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"699.1811,-380.2752 688.7132,-378.6399 695.8766,-386.4461 699.1811,-380.2752\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760140224160 -->\n",
       "<g class=\"node\" id=\"node34\">\n",
       "<title>139760140224160</title>\n",
       "<polygon fill=\"none\" points=\"845.5,-332.5 845.5,-378.5 1085.5,-378.5 1085.5,-332.5 845.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"896.5\" y=\"-351.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"947.5,-332.5 947.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"975\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"947.5,-355.5 1002.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"975\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1002.5,-332.5 1002.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1044\" y=\"-363.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1002.5,-355.5 1085.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1044\" y=\"-340.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139760140022392&#45;&gt;139760140224160 -->\n",
       "<g class=\"edge\" id=\"edge42\">\n",
       "<title>139760140022392-&gt;139760140224160</title>\n",
       "<path d=\"M846.4617,-415.3799C866.314,-405.3936 889.7036,-393.6279 910.4713,-383.1811\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"912.1383,-386.2605 919.4989,-378.6399 908.9926,-380.0071 912.1383,-386.2605\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760138431176 -->\n",
       "<g class=\"node\" id=\"node35\">\n",
       "<title>139760138431176</title>\n",
       "<polygon fill=\"none\" points=\"493,-249.5 493,-295.5 750,-295.5 750,-249.5 493,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"542\" y=\"-268.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"591,-249.5 591,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"591,-272.5 646,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"646,-249.5 646,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-280.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"646,-272.5 750,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-257.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 139760138165496&#45;&gt;139760138431176 -->\n",
       "<g class=\"edge\" id=\"edge43\">\n",
       "<title>139760138165496-&gt;139760138431176</title>\n",
       "<path d=\"M638.8147,-332.3799C636.4162,-324.0854 633.6629,-314.5633 631.0679,-305.5889\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"634.3728,-304.4182 628.2327,-295.784 627.6483,-306.3627 634.3728,-304.4182\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760139701888 -->\n",
       "<g class=\"node\" id=\"node36\">\n",
       "<title>139760139701888</title>\n",
       "<polygon fill=\"none\" points=\"839,-249.5 839,-295.5 1102,-295.5 1102,-249.5 839,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"901.5\" y=\"-268.8\">dropout_6: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"964,-249.5 964,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"991.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"964,-272.5 1019,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"991.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1019,-249.5 1019,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-280.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1019,-272.5 1102,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139760140224160&#45;&gt;139760139701888 -->\n",
       "<g class=\"edge\" id=\"edge44\">\n",
       "<title>139760140224160-&gt;139760139701888</title>\n",
       "<path d=\"M966.8928,-332.3799C967.3871,-324.1745 967.9537,-314.7679 968.4892,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"971.9896,-305.9764 969.0973,-295.784 965.0023,-305.5554 971.9896,-305.9764\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760137689016 -->\n",
       "<g class=\"node\" id=\"node37\">\n",
       "<title>139760137689016</title>\n",
       "<polygon fill=\"none\" points=\"467.5,-166.5 467.5,-212.5 751.5,-212.5 751.5,-166.5 467.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530\" y=\"-185.8\">dropout_7: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"592.5,-166.5 592.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"592.5,-189.5 647.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"647.5,-166.5 647.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699.5\" y=\"-197.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"647.5,-189.5 751.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699.5\" y=\"-174.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 139760138431176&#45;&gt;139760137689016 -->\n",
       "<g class=\"edge\" id=\"edge45\">\n",
       "<title>139760138431176-&gt;139760137689016</title>\n",
       "<path d=\"M618.1573,-249.3799C616.971,-241.1745 615.611,-231.7679 614.3258,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"617.7613,-222.1803 612.8664,-212.784 610.8334,-223.1819 617.7613,-222.1803\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760139701832 -->\n",
       "<g class=\"node\" id=\"node38\">\n",
       "<title>139760139701832</title>\n",
       "<polygon fill=\"none\" points=\"776.5,-166.5 776.5,-212.5 1174.5,-212.5 1174.5,-166.5 776.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"906.5\" y=\"-185.8\">batch_normalization_6: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1036.5,-166.5 1036.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1036.5,-189.5 1091.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1091.5,-166.5 1091.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1133\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1091.5,-189.5 1174.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1133\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 139760139701888&#45;&gt;139760139701832 -->\n",
       "<g class=\"edge\" id=\"edge46\">\n",
       "<title>139760139701888-&gt;139760139701832</title>\n",
       "<path d=\"M971.8928,-249.3799C972.3871,-241.1745 972.9537,-231.7679 973.4892,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"976.9896,-222.9764 974.0973,-212.784 970.0023,-222.5554 976.9896,-222.9764\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760136666976 -->\n",
       "<g class=\"node\" id=\"node39\">\n",
       "<title>139760136666976</title>\n",
       "<polygon fill=\"none\" points=\"385,-83.5 385,-129.5 804,-129.5 804,-83.5 385,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-102.8\">batch_normalization_7: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"645,-83.5 645,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"672.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645,-106.5 700,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"672.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700,-83.5 700,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"752\" y=\"-114.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"700,-106.5 804,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"752\" y=\"-91.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 139760137689016&#45;&gt;139760136666976 -->\n",
       "<g class=\"edge\" id=\"edge47\">\n",
       "<title>139760137689016-&gt;139760136666976</title>\n",
       "<path d=\"M605.3217,-166.3799C603.8388,-158.1745 602.1388,-148.7679 600.5323,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"603.9307,-139.0021 598.708,-129.784 597.0422,-140.2471 603.9307,-139.0021\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760139063480 -->\n",
       "<g class=\"node\" id=\"node40\">\n",
       "<title>139760139063480</title>\n",
       "<polygon fill=\"none\" points=\"822,-83.5 822,-129.5 1145,-129.5 1145,-83.5 822,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"914.5\" y=\"-102.8\">output_headline_vector: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1007,-83.5 1007,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1007,-106.5 1062,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1062,-83.5 1062,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1103.5\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1062,-106.5 1145,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1103.5\" y=\"-91.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 139760139701832&#45;&gt;139760139063480 -->\n",
       "<g class=\"edge\" id=\"edge48\">\n",
       "<title>139760139701832-&gt;139760139063480</title>\n",
       "<path d=\"M977.7284,-166.3799C978.5193,-158.1745 979.426,-148.7679 980.2828,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"983.7801,-140.0737 981.2558,-129.784 976.8124,-139.4021 983.7801,-140.0737\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 139760135727872 -->\n",
       "<g class=\"node\" id=\"node41\">\n",
       "<title>139760135727872</title>\n",
       "<polygon fill=\"none\" points=\"340,-.5 340,-46.5 849,-46.5 849,-.5 340,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508.5\" y=\"-19.8\">headline_token_classes(dense_3): TimeDistributed(Dense)</text>\n",
       "<polyline fill=\"none\" points=\"677,-.5 677,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"677,-23.5 732,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"732,-.5 732,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-31.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"732,-23.5 849,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-8.3\">(None, 50, 20000)</text>\n",
       "</g>\n",
       "<!-- 139760136666976&#45;&gt;139760135727872 -->\n",
       "<g class=\"edge\" id=\"edge49\">\n",
       "<title>139760136666976-&gt;139760135727872</title>\n",
       "<path d=\"M594.5,-83.3799C594.5,-75.1745 594.5,-65.7679 594.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"598.0001,-56.784 594.5,-46.784 591.0001,-56.784 598.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    inp_sentence_vectors = Input(shape=(max_sentences, 300), name='sentence_vectors')\n",
    "    inp_headline_vector = Input(shape=(300,), name='input_headline_vector')\n",
    "    conv1 = Conv1D(filters=16,kernel_size=3,strides=1,activation='relu', padding='same')(inp_sentence_vectors)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv2 = Conv1D(filters=32,kernel_size=3,strides=1,activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    sent_sa_feat_1, sent_beta_1, sent_gamma_1 = SelfAttention(int(conv2.shape[-1]), name = 'sa1')(conv2)\n",
    "    sent_sa_feat_2, sent_beta_2, sent_gamma_2 = SelfAttention(int(conv2.shape[-1]), name = 'sa2')(conv2)\n",
    "    sent_sa_feat_3, sent_beta_3, sent_gamma_3 = SelfAttention(int(conv2.shape[-1]), name = 'sa3')(conv2)\n",
    "    sent_sa_feat_4, sent_beta_4, sent_gamma_4 = SelfAttention(int(conv2.shape[-1]), name = 'sa4')(conv2)\n",
    "    concat1 = Concatenate()([sent_sa_feat_1,sent_sa_feat_2,sent_sa_feat_3,sent_sa_feat_4])\n",
    "    conv3 = Conv1D(filters=256,kernel_size=3, strides=1, activation='relu', padding='same')(concat1)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    headline = Dense(256, activation='relu')(inp_headline_vector)\n",
    "    headline = Lambda(lambda x:K.expand_dims(x, axis=1))(headline)\n",
    "    headline = BatchNormalization()(headline)\n",
    "    sent_hd_sa_feat_1, sent_hd_beta_1, sent_hd_gamma_1 = CrossAttention(int(conv3.shape[-1]), name = 'ca1')([headline,conv3])\n",
    "    sent_hd_sa_feat_2, sent_hd_beta_2, sent_hd_gamma_2 = CrossAttention(int(conv3.shape[-1]), name = 'ca2')([headline,conv3])\n",
    "    sent_hd_sa_feat_3, sent_hd_beta_3, sent_hd_gamma_3 = CrossAttention(int(conv3.shape[-1]), name = 'ca3')([headline,conv3])\n",
    "    sent_hd_sa_feat_4, sent_hd_beta_4, sent_hd_gamma_4 = CrossAttention(int(conv3.shape[-1]), name = 'ca4')([headline,conv3])  \n",
    "    concat3 = Concatenate()([sent_hd_sa_feat_1,sent_hd_sa_feat_2,sent_hd_sa_feat_3,sent_hd_sa_feat_4])\n",
    "    concat3 = Dropout(0.5)(concat3)\n",
    "    concat3 = BatchNormalization()(concat3)\n",
    "    conv5 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(concat3)\n",
    "    conv6 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv5)\n",
    "    conv7 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv6)\n",
    "    conv8 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv7)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    gap = GlobalAveragePooling1D()(conv8)\n",
    "#     repeat = RepeatVector(50)(gap)\n",
    "#     lstm = LSTM(256,return_sequences=True)(repeat)\n",
    "    dense1 = Dense(512,activation='relu')(gap)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    gen_hd_vector = Dense(300,activation='linear', name='output_headline_vector')(dense1)\n",
    "    repeat = RepeatVector(50)(gap)\n",
    "    lstm1 = LSTM(256,return_sequences=True, activation='relu')(repeat)\n",
    "    lstm1 = Dropout(0.5)(lstm1)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    gen_hd_word = TimeDistributed(Dense(20000,activation='softmax'), name='headline_token_classes')(lstm1)\n",
    "    model = Model([inp_sentence_vectors,inp_headline_vector],[gen_hd_vector,gen_hd_word])\n",
    "    return model\n",
    "model = build_model()\n",
    "losses = {\n",
    "    'output_headline_vector':'mse'\n",
    "    ,'headline_token_classes':'categorical_crossentropy'\n",
    "}\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001,beta_1=0.0,beta_2=0.99),loss=losses)\n",
    "model.summary()\n",
    "# print('model params:',model.count_params())\n",
    "SVG(model_to_dot(model,show_layer_names=True,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now()\n",
    "mc = ModelCheckpoint('weights/dnf300_sa_sent_hd_vector_word_gl.hdf5',save_best_only=True,save_weights_only=True)\n",
    "tb = TensorBoard(batch_size=32,log_dir='logs/dnf300_sa_sent_hd_vector_word_gl/{0}'.format(dt.timestamp()),write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 47s 12s/step - loss: 11.0781 - output_headline_vector_loss: 1.1668 - headline_token_classes_loss: 9.9113 - val_loss: 10.3346 - val_output_headline_vector_loss: 0.5212 - val_headline_token_classes_loss: 9.8134\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 11.0577 - output_headline_vector_loss: 1.1555 - headline_token_classes_loss: 9.9023 - val_loss: 10.2278 - val_output_headline_vector_loss: 0.4715 - val_headline_token_classes_loss: 9.7563\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 2s 516ms/step - loss: 11.0432 - output_headline_vector_loss: 1.1483 - headline_token_classes_loss: 9.8949 - val_loss: 10.1277 - val_output_headline_vector_loss: 0.4173 - val_headline_token_classes_loss: 9.7103\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 11.0333 - output_headline_vector_loss: 1.1427 - headline_token_classes_loss: 9.8906 - val_loss: 10.0846 - val_output_headline_vector_loss: 0.3946 - val_headline_token_classes_loss: 9.6901\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 11.0118 - output_headline_vector_loss: 1.1304 - headline_token_classes_loss: 9.8814 - val_loss: 9.9927 - val_output_headline_vector_loss: 0.3708 - val_headline_token_classes_loss: 9.6219\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.9844 - output_headline_vector_loss: 1.1125 - headline_token_classes_loss: 9.8719 - val_loss: 9.8711 - val_output_headline_vector_loss: 0.3596 - val_headline_token_classes_loss: 9.5115\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.9719 - output_headline_vector_loss: 1.1158 - headline_token_classes_loss: 9.8560 - val_loss: 9.7172 - val_output_headline_vector_loss: 0.3497 - val_headline_token_classes_loss: 9.3675\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.9279 - output_headline_vector_loss: 1.0981 - headline_token_classes_loss: 9.8297 - val_loss: 9.2460 - val_output_headline_vector_loss: 0.3345 - val_headline_token_classes_loss: 8.9115\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.9385 - output_headline_vector_loss: 1.1063 - headline_token_classes_loss: 9.8323 - val_loss: 9.7299 - val_output_headline_vector_loss: 0.3047 - val_headline_token_classes_loss: 9.4251\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.8757 - output_headline_vector_loss: 1.0818 - headline_token_classes_loss: 9.7939 - val_loss: 7.2452 - val_output_headline_vector_loss: 0.2797 - val_headline_token_classes_loss: 6.9656\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.8331 - output_headline_vector_loss: 1.0711 - headline_token_classes_loss: 9.7620 - val_loss: 8.8929 - val_output_headline_vector_loss: 0.2760 - val_headline_token_classes_loss: 8.6169\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.8887 - output_headline_vector_loss: 1.0695 - headline_token_classes_loss: 9.8192 - val_loss: 8.2870 - val_output_headline_vector_loss: 0.2704 - val_headline_token_classes_loss: 8.0166\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.7965 - output_headline_vector_loss: 1.0635 - headline_token_classes_loss: 9.7330 - val_loss: 9.1345 - val_output_headline_vector_loss: 0.2598 - val_headline_token_classes_loss: 8.8747\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.7677 - output_headline_vector_loss: 1.0399 - headline_token_classes_loss: 9.7278 - val_loss: 9.3979 - val_output_headline_vector_loss: 0.2676 - val_headline_token_classes_loss: 9.1303\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.7475 - output_headline_vector_loss: 1.0447 - headline_token_classes_loss: 9.7028 - val_loss: 8.0674 - val_output_headline_vector_loss: 0.2550 - val_headline_token_classes_loss: 7.8124\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.7056 - output_headline_vector_loss: 1.0266 - headline_token_classes_loss: 9.6791 - val_loss: 9.5772 - val_output_headline_vector_loss: 0.2385 - val_headline_token_classes_loss: 9.3388\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.6746 - output_headline_vector_loss: 1.0031 - headline_token_classes_loss: 9.6715 - val_loss: 8.4151 - val_output_headline_vector_loss: 0.2345 - val_headline_token_classes_loss: 8.1806\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.6569 - output_headline_vector_loss: 1.0224 - headline_token_classes_loss: 9.6345 - val_loss: 7.9316 - val_output_headline_vector_loss: 0.2465 - val_headline_token_classes_loss: 7.6851\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.6068 - output_headline_vector_loss: 1.0073 - headline_token_classes_loss: 9.5996 - val_loss: 8.1198 - val_output_headline_vector_loss: 0.2360 - val_headline_token_classes_loss: 7.8838\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.6071 - output_headline_vector_loss: 1.0065 - headline_token_classes_loss: 9.6006 - val_loss: 9.3636 - val_output_headline_vector_loss: 0.2367 - val_headline_token_classes_loss: 9.1269\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.5771 - output_headline_vector_loss: 0.9842 - headline_token_classes_loss: 9.5929 - val_loss: 8.0328 - val_output_headline_vector_loss: 0.2333 - val_headline_token_classes_loss: 7.7995\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.5447 - output_headline_vector_loss: 0.9982 - headline_token_classes_loss: 9.5466 - val_loss: 6.7684 - val_output_headline_vector_loss: 0.2218 - val_headline_token_classes_loss: 6.5466\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.5187 - output_headline_vector_loss: 0.9676 - headline_token_classes_loss: 9.5511 - val_loss: 9.0363 - val_output_headline_vector_loss: 0.2281 - val_headline_token_classes_loss: 8.8082\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.4797 - output_headline_vector_loss: 0.9657 - headline_token_classes_loss: 9.5140 - val_loss: 7.4949 - val_output_headline_vector_loss: 0.2141 - val_headline_token_classes_loss: 7.2808\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.4675 - output_headline_vector_loss: 0.9658 - headline_token_classes_loss: 9.5017 - val_loss: 9.1089 - val_output_headline_vector_loss: 0.2210 - val_headline_token_classes_loss: 8.8879\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.4593 - output_headline_vector_loss: 0.9592 - headline_token_classes_loss: 9.5001 - val_loss: 8.5798 - val_output_headline_vector_loss: 0.2138 - val_headline_token_classes_loss: 8.3660\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.3792 - output_headline_vector_loss: 0.9659 - headline_token_classes_loss: 9.4133 - val_loss: 7.4530 - val_output_headline_vector_loss: 0.2195 - val_headline_token_classes_loss: 7.2335\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.3144 - output_headline_vector_loss: 0.9452 - headline_token_classes_loss: 9.3692 - val_loss: 7.6018 - val_output_headline_vector_loss: 0.2151 - val_headline_token_classes_loss: 7.3867\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.2989 - output_headline_vector_loss: 0.9423 - headline_token_classes_loss: 9.3566 - val_loss: 7.5018 - val_output_headline_vector_loss: 0.2075 - val_headline_token_classes_loss: 7.2943\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.2815 - output_headline_vector_loss: 0.9336 - headline_token_classes_loss: 9.3478 - val_loss: 8.6396 - val_output_headline_vector_loss: 0.2015 - val_headline_token_classes_loss: 8.4381\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.1523 - output_headline_vector_loss: 0.9216 - headline_token_classes_loss: 9.2308 - val_loss: 7.1462 - val_output_headline_vector_loss: 0.1920 - val_headline_token_classes_loss: 6.9542\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 10.1527 - output_headline_vector_loss: 0.9193 - headline_token_classes_loss: 9.2334 - val_loss: 7.0586 - val_output_headline_vector_loss: 0.2043 - val_headline_token_classes_loss: 6.8543\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.0549 - output_headline_vector_loss: 0.8977 - headline_token_classes_loss: 9.1571 - val_loss: 7.0665 - val_output_headline_vector_loss: 0.1783 - val_headline_token_classes_loss: 6.8882\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 10.0146 - output_headline_vector_loss: 0.9025 - headline_token_classes_loss: 9.1121 - val_loss: 6.9350 - val_output_headline_vector_loss: 0.1804 - val_headline_token_classes_loss: 6.7545\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.9972 - output_headline_vector_loss: 0.9117 - headline_token_classes_loss: 9.0854 - val_loss: 6.4215 - val_output_headline_vector_loss: 0.1987 - val_headline_token_classes_loss: 6.2228\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 9.9172 - output_headline_vector_loss: 0.9021 - headline_token_classes_loss: 9.0151 - val_loss: 6.9435 - val_output_headline_vector_loss: 0.1810 - val_headline_token_classes_loss: 6.7624\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 9.8578 - output_headline_vector_loss: 0.8815 - headline_token_classes_loss: 8.9763 - val_loss: 6.8545 - val_output_headline_vector_loss: 0.1846 - val_headline_token_classes_loss: 6.6700\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.7670 - output_headline_vector_loss: 0.8695 - headline_token_classes_loss: 8.8975 - val_loss: 6.2777 - val_output_headline_vector_loss: 0.1877 - val_headline_token_classes_loss: 6.0900\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.7066 - output_headline_vector_loss: 0.8703 - headline_token_classes_loss: 8.8362 - val_loss: 6.4130 - val_output_headline_vector_loss: 0.1697 - val_headline_token_classes_loss: 6.2433\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 9.5640 - output_headline_vector_loss: 0.8679 - headline_token_classes_loss: 8.6962 - val_loss: 6.0852 - val_output_headline_vector_loss: 0.1673 - val_headline_token_classes_loss: 5.9179\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.5372 - output_headline_vector_loss: 0.8662 - headline_token_classes_loss: 8.6710 - val_loss: 5.9424 - val_output_headline_vector_loss: 0.1816 - val_headline_token_classes_loss: 5.7608\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.5166 - output_headline_vector_loss: 0.8493 - headline_token_classes_loss: 8.6673 - val_loss: 5.8845 - val_output_headline_vector_loss: 0.1600 - val_headline_token_classes_loss: 5.7245\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.4078 - output_headline_vector_loss: 0.8551 - headline_token_classes_loss: 8.5526 - val_loss: 5.4207 - val_output_headline_vector_loss: 0.1741 - val_headline_token_classes_loss: 5.2467\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.3634 - output_headline_vector_loss: 0.8431 - headline_token_classes_loss: 8.5203 - val_loss: 5.2030 - val_output_headline_vector_loss: 0.1578 - val_headline_token_classes_loss: 5.0452\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.2416 - output_headline_vector_loss: 0.8234 - headline_token_classes_loss: 8.4182 - val_loss: 5.5603 - val_output_headline_vector_loss: 0.1622 - val_headline_token_classes_loss: 5.3981\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.1588 - output_headline_vector_loss: 0.8181 - headline_token_classes_loss: 8.3407 - val_loss: 4.6452 - val_output_headline_vector_loss: 0.1608 - val_headline_token_classes_loss: 4.4845\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 9.1318 - output_headline_vector_loss: 0.8366 - headline_token_classes_loss: 8.2953 - val_loss: 4.8456 - val_output_headline_vector_loss: 0.1581 - val_headline_token_classes_loss: 4.6875\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 9.0137 - output_headline_vector_loss: 0.8228 - headline_token_classes_loss: 8.1909 - val_loss: 4.2962 - val_output_headline_vector_loss: 0.1497 - val_headline_token_classes_loss: 4.1465\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 8.9585 - output_headline_vector_loss: 0.7933 - headline_token_classes_loss: 8.1652 - val_loss: 5.0913 - val_output_headline_vector_loss: 0.1440 - val_headline_token_classes_loss: 4.9473\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.8425 - output_headline_vector_loss: 0.7920 - headline_token_classes_loss: 8.0506 - val_loss: 4.5209 - val_output_headline_vector_loss: 0.1562 - val_headline_token_classes_loss: 4.3647\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.7914 - output_headline_vector_loss: 0.7871 - headline_token_classes_loss: 8.0044 - val_loss: 4.6374 - val_output_headline_vector_loss: 0.1469 - val_headline_token_classes_loss: 4.4905\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.7318 - output_headline_vector_loss: 0.7811 - headline_token_classes_loss: 7.9507 - val_loss: 4.4115 - val_output_headline_vector_loss: 0.1449 - val_headline_token_classes_loss: 4.2666\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.6668 - output_headline_vector_loss: 0.7828 - headline_token_classes_loss: 7.8840 - val_loss: 5.3866 - val_output_headline_vector_loss: 0.1436 - val_headline_token_classes_loss: 5.2430\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.6219 - output_headline_vector_loss: 0.7777 - headline_token_classes_loss: 7.8442 - val_loss: 4.7086 - val_output_headline_vector_loss: 0.1310 - val_headline_token_classes_loss: 4.5775\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.4912 - output_headline_vector_loss: 0.7688 - headline_token_classes_loss: 7.7224 - val_loss: 4.5302 - val_output_headline_vector_loss: 0.1335 - val_headline_token_classes_loss: 4.3967\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.4291 - output_headline_vector_loss: 0.7697 - headline_token_classes_loss: 7.6594 - val_loss: 4.5484 - val_output_headline_vector_loss: 0.1378 - val_headline_token_classes_loss: 4.4106\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.3494 - output_headline_vector_loss: 0.7571 - headline_token_classes_loss: 7.5923 - val_loss: 6.1542 - val_output_headline_vector_loss: 0.1303 - val_headline_token_classes_loss: 6.0239\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.2958 - output_headline_vector_loss: 0.7512 - headline_token_classes_loss: 7.5447 - val_loss: 5.4727 - val_output_headline_vector_loss: 0.1238 - val_headline_token_classes_loss: 5.3489\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1705 - output_headline_vector_loss: 0.7452 - headline_token_classes_loss: 7.4253 - val_loss: 4.6997 - val_output_headline_vector_loss: 0.1169 - val_headline_token_classes_loss: 4.5829\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1167 - output_headline_vector_loss: 0.7343 - headline_token_classes_loss: 7.3823 - val_loss: 4.8681 - val_output_headline_vector_loss: 0.1279 - val_headline_token_classes_loss: 4.7403\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.0559 - output_headline_vector_loss: 0.7318 - headline_token_classes_loss: 7.3242 - val_loss: 4.3107 - val_output_headline_vector_loss: 0.1128 - val_headline_token_classes_loss: 4.1978\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.8547 - output_headline_vector_loss: 0.7178 - headline_token_classes_loss: 8.1369 - val_loss: 9.5172 - val_output_headline_vector_loss: 0.2521 - val_headline_token_classes_loss: 9.2651\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.3625 - output_headline_vector_loss: 0.7269 - headline_token_classes_loss: 7.6356 - val_loss: 9.4842 - val_output_headline_vector_loss: 0.2041 - val_headline_token_classes_loss: 9.2801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.2881 - output_headline_vector_loss: 0.7223 - headline_token_classes_loss: 7.5658 - val_loss: 9.3542 - val_output_headline_vector_loss: 0.2036 - val_headline_token_classes_loss: 9.1506\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.2570 - output_headline_vector_loss: 0.7272 - headline_token_classes_loss: 7.5298 - val_loss: 9.3197 - val_output_headline_vector_loss: 0.2019 - val_headline_token_classes_loss: 9.1178\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1876 - output_headline_vector_loss: 0.7133 - headline_token_classes_loss: 7.4743 - val_loss: 9.3581 - val_output_headline_vector_loss: 0.1833 - val_headline_token_classes_loss: 9.1748\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.1810 - output_headline_vector_loss: 0.7189 - headline_token_classes_loss: 7.4621 - val_loss: 9.2433 - val_output_headline_vector_loss: 0.1778 - val_headline_token_classes_loss: 9.0655\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1268 - output_headline_vector_loss: 0.7085 - headline_token_classes_loss: 7.4184 - val_loss: 9.2204 - val_output_headline_vector_loss: 0.1821 - val_headline_token_classes_loss: 9.0384\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.0337 - output_headline_vector_loss: 0.6960 - headline_token_classes_loss: 7.3376 - val_loss: 9.2652 - val_output_headline_vector_loss: 0.1764 - val_headline_token_classes_loss: 9.0889\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.9894 - output_headline_vector_loss: 0.6979 - headline_token_classes_loss: 7.2915 - val_loss: 9.2042 - val_output_headline_vector_loss: 0.1741 - val_headline_token_classes_loss: 9.0301\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.0174 - output_headline_vector_loss: 0.7118 - headline_token_classes_loss: 7.3056 - val_loss: 9.2260 - val_output_headline_vector_loss: 0.1571 - val_headline_token_classes_loss: 9.0690\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.9195 - output_headline_vector_loss: 0.6956 - headline_token_classes_loss: 7.2240 - val_loss: 9.1737 - val_output_headline_vector_loss: 0.1583 - val_headline_token_classes_loss: 9.0155\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8224 - output_headline_vector_loss: 0.6913 - headline_token_classes_loss: 7.1310 - val_loss: 8.9579 - val_output_headline_vector_loss: 0.1524 - val_headline_token_classes_loss: 8.8055\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8339 - output_headline_vector_loss: 0.6749 - headline_token_classes_loss: 7.1590 - val_loss: 8.9307 - val_output_headline_vector_loss: 0.1445 - val_headline_token_classes_loss: 8.7861\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.7633 - output_headline_vector_loss: 0.6826 - headline_token_classes_loss: 7.0808 - val_loss: 8.8798 - val_output_headline_vector_loss: 0.1484 - val_headline_token_classes_loss: 8.7314\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.7648 - output_headline_vector_loss: 0.6825 - headline_token_classes_loss: 7.0823 - val_loss: 8.8542 - val_output_headline_vector_loss: 0.1473 - val_headline_token_classes_loss: 8.7070\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.6739 - output_headline_vector_loss: 0.6655 - headline_token_classes_loss: 7.0084 - val_loss: 8.7788 - val_output_headline_vector_loss: 0.1507 - val_headline_token_classes_loss: 8.6281\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.6261 - output_headline_vector_loss: 0.6566 - headline_token_classes_loss: 6.9695 - val_loss: 8.7944 - val_output_headline_vector_loss: 0.1269 - val_headline_token_classes_loss: 8.6675\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.6144 - output_headline_vector_loss: 0.6638 - headline_token_classes_loss: 6.9506 - val_loss: 8.7264 - val_output_headline_vector_loss: 0.1241 - val_headline_token_classes_loss: 8.6024\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5194 - output_headline_vector_loss: 0.6520 - headline_token_classes_loss: 6.8674 - val_loss: 8.5631 - val_output_headline_vector_loss: 0.1309 - val_headline_token_classes_loss: 8.4322\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.4997 - output_headline_vector_loss: 0.6517 - headline_token_classes_loss: 6.8480 - val_loss: 8.5706 - val_output_headline_vector_loss: 0.1212 - val_headline_token_classes_loss: 8.4494\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.4262 - output_headline_vector_loss: 0.6479 - headline_token_classes_loss: 6.7784 - val_loss: 8.5846 - val_output_headline_vector_loss: 0.1179 - val_headline_token_classes_loss: 8.4667\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.4498 - output_headline_vector_loss: 0.6455 - headline_token_classes_loss: 6.8043 - val_loss: 8.4603 - val_output_headline_vector_loss: 0.1212 - val_headline_token_classes_loss: 8.3391\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.4250 - output_headline_vector_loss: 0.6531 - headline_token_classes_loss: 6.7719 - val_loss: 8.4958 - val_output_headline_vector_loss: 0.1155 - val_headline_token_classes_loss: 8.3803\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.3232 - output_headline_vector_loss: 0.6271 - headline_token_classes_loss: 6.6961 - val_loss: 8.4001 - val_output_headline_vector_loss: 0.1075 - val_headline_token_classes_loss: 8.2925\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.2807 - output_headline_vector_loss: 0.6238 - headline_token_classes_loss: 6.6569 - val_loss: 8.4597 - val_output_headline_vector_loss: 0.1142 - val_headline_token_classes_loss: 8.3455\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.2343 - output_headline_vector_loss: 0.6242 - headline_token_classes_loss: 6.6100 - val_loss: 8.2894 - val_output_headline_vector_loss: 0.0982 - val_headline_token_classes_loss: 8.1912\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.1696 - output_headline_vector_loss: 0.6335 - headline_token_classes_loss: 6.5361 - val_loss: 8.3087 - val_output_headline_vector_loss: 0.1037 - val_headline_token_classes_loss: 8.2050\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.1543 - output_headline_vector_loss: 0.6205 - headline_token_classes_loss: 6.5339 - val_loss: 8.2544 - val_output_headline_vector_loss: 0.1050 - val_headline_token_classes_loss: 8.1493\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.1731 - output_headline_vector_loss: 0.6214 - headline_token_classes_loss: 6.5517 - val_loss: 8.2134 - val_output_headline_vector_loss: 0.1118 - val_headline_token_classes_loss: 8.1016\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.0670 - output_headline_vector_loss: 0.6149 - headline_token_classes_loss: 6.4521 - val_loss: 8.0663 - val_output_headline_vector_loss: 0.0970 - val_headline_token_classes_loss: 7.9693\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.0480 - output_headline_vector_loss: 0.6048 - headline_token_classes_loss: 6.4432 - val_loss: 8.1779 - val_output_headline_vector_loss: 0.1065 - val_headline_token_classes_loss: 8.0714\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.9437 - output_headline_vector_loss: 0.6038 - headline_token_classes_loss: 6.3399 - val_loss: 8.0520 - val_output_headline_vector_loss: 0.0938 - val_headline_token_classes_loss: 7.9582\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.0061 - output_headline_vector_loss: 0.5967 - headline_token_classes_loss: 6.4094 - val_loss: 8.0273 - val_output_headline_vector_loss: 0.0988 - val_headline_token_classes_loss: 7.9284\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.9557 - output_headline_vector_loss: 0.6037 - headline_token_classes_loss: 6.3520 - val_loss: 7.9677 - val_output_headline_vector_loss: 0.0940 - val_headline_token_classes_loss: 7.8737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.8968 - output_headline_vector_loss: 0.6042 - headline_token_classes_loss: 6.2925 - val_loss: 7.8967 - val_output_headline_vector_loss: 0.0891 - val_headline_token_classes_loss: 7.8077\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 6.8888 - output_headline_vector_loss: 0.5926 - headline_token_classes_loss: 6.2962 - val_loss: 7.9121 - val_output_headline_vector_loss: 0.0897 - val_headline_token_classes_loss: 7.8224\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.7605 - output_headline_vector_loss: 0.5857 - headline_token_classes_loss: 6.1749 - val_loss: 7.7220 - val_output_headline_vector_loss: 0.0877 - val_headline_token_classes_loss: 7.6343\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.7042 - output_headline_vector_loss: 0.5969 - headline_token_classes_loss: 6.1072 - val_loss: 7.8295 - val_output_headline_vector_loss: 0.0864 - val_headline_token_classes_loss: 7.7431\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.7158 - output_headline_vector_loss: 0.5823 - headline_token_classes_loss: 6.1335 - val_loss: 7.7862 - val_output_headline_vector_loss: 0.0800 - val_headline_token_classes_loss: 7.7062\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.6485 - output_headline_vector_loss: 0.5739 - headline_token_classes_loss: 6.0745 - val_loss: 7.6134 - val_output_headline_vector_loss: 0.0786 - val_headline_token_classes_loss: 7.5347\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.5870 - output_headline_vector_loss: 0.5678 - headline_token_classes_loss: 6.0191 - val_loss: 7.7008 - val_output_headline_vector_loss: 0.0802 - val_headline_token_classes_loss: 7.6206\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 6.6558 - output_headline_vector_loss: 0.5643 - headline_token_classes_loss: 6.0915 - val_loss: 7.5741 - val_output_headline_vector_loss: 0.0798 - val_headline_token_classes_loss: 7.4944\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.6116 - output_headline_vector_loss: 0.5735 - headline_token_classes_loss: 6.0381 - val_loss: 7.4669 - val_output_headline_vector_loss: 0.0806 - val_headline_token_classes_loss: 7.3863\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.6137 - output_headline_vector_loss: 0.5828 - headline_token_classes_loss: 6.0309 - val_loss: 7.4260 - val_output_headline_vector_loss: 0.0800 - val_headline_token_classes_loss: 7.3460\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 6.4908 - output_headline_vector_loss: 0.5658 - headline_token_classes_loss: 5.9250 - val_loss: 7.4990 - val_output_headline_vector_loss: 0.0775 - val_headline_token_classes_loss: 7.4214\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.4189 - output_headline_vector_loss: 0.5551 - headline_token_classes_loss: 5.8639 - val_loss: 7.2672 - val_output_headline_vector_loss: 0.0825 - val_headline_token_classes_loss: 7.1848\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.3398 - output_headline_vector_loss: 0.5552 - headline_token_classes_loss: 5.7846 - val_loss: 7.3955 - val_output_headline_vector_loss: 0.0754 - val_headline_token_classes_loss: 7.3201\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.3749 - output_headline_vector_loss: 0.5618 - headline_token_classes_loss: 5.8131 - val_loss: 7.2946 - val_output_headline_vector_loss: 0.0759 - val_headline_token_classes_loss: 7.2187\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.2987 - output_headline_vector_loss: 0.5348 - headline_token_classes_loss: 5.7639 - val_loss: 7.1570 - val_output_headline_vector_loss: 0.0756 - val_headline_token_classes_loss: 7.0814\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.2641 - output_headline_vector_loss: 0.5336 - headline_token_classes_loss: 5.7306 - val_loss: 7.1990 - val_output_headline_vector_loss: 0.0773 - val_headline_token_classes_loss: 7.1217\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.3217 - output_headline_vector_loss: 0.5468 - headline_token_classes_loss: 5.7749 - val_loss: 7.0821 - val_output_headline_vector_loss: 0.0662 - val_headline_token_classes_loss: 7.0159\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 6.2428 - output_headline_vector_loss: 0.5298 - headline_token_classes_loss: 5.7130 - val_loss: 7.0477 - val_output_headline_vector_loss: 0.0656 - val_headline_token_classes_loss: 6.9821\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.1285 - output_headline_vector_loss: 0.5317 - headline_token_classes_loss: 5.5968 - val_loss: 6.9155 - val_output_headline_vector_loss: 0.0621 - val_headline_token_classes_loss: 6.8534\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.1639 - output_headline_vector_loss: 0.5294 - headline_token_classes_loss: 5.6345 - val_loss: 6.8549 - val_output_headline_vector_loss: 0.0642 - val_headline_token_classes_loss: 6.7907\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.1347 - output_headline_vector_loss: 0.5208 - headline_token_classes_loss: 5.6139 - val_loss: 6.8143 - val_output_headline_vector_loss: 0.0608 - val_headline_token_classes_loss: 6.7536\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.1372 - output_headline_vector_loss: 0.5213 - headline_token_classes_loss: 5.6159 - val_loss: 6.8602 - val_output_headline_vector_loss: 0.0608 - val_headline_token_classes_loss: 6.7994\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.1020 - output_headline_vector_loss: 0.5171 - headline_token_classes_loss: 5.5849 - val_loss: 6.6772 - val_output_headline_vector_loss: 0.0644 - val_headline_token_classes_loss: 6.6128\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.0928 - output_headline_vector_loss: 0.5152 - headline_token_classes_loss: 5.5776 - val_loss: 6.6272 - val_output_headline_vector_loss: 0.0637 - val_headline_token_classes_loss: 6.5635\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.0648 - output_headline_vector_loss: 0.5131 - headline_token_classes_loss: 5.5518 - val_loss: 6.7911 - val_output_headline_vector_loss: 0.0615 - val_headline_token_classes_loss: 6.7297\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 6.0151 - output_headline_vector_loss: 0.5121 - headline_token_classes_loss: 5.5030 - val_loss: 6.4894 - val_output_headline_vector_loss: 0.0589 - val_headline_token_classes_loss: 6.4305\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.8991 - output_headline_vector_loss: 0.5047 - headline_token_classes_loss: 5.3945 - val_loss: 6.5143 - val_output_headline_vector_loss: 0.0588 - val_headline_token_classes_loss: 6.4555\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.9280 - output_headline_vector_loss: 0.4925 - headline_token_classes_loss: 5.4354 - val_loss: 6.5685 - val_output_headline_vector_loss: 0.0608 - val_headline_token_classes_loss: 6.5077\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.8808 - output_headline_vector_loss: 0.5029 - headline_token_classes_loss: 5.3780 - val_loss: 6.4942 - val_output_headline_vector_loss: 0.0590 - val_headline_token_classes_loss: 6.4352\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.8269 - output_headline_vector_loss: 0.5001 - headline_token_classes_loss: 5.3268 - val_loss: 6.3213 - val_output_headline_vector_loss: 0.0512 - val_headline_token_classes_loss: 6.2702\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.8571 - output_headline_vector_loss: 0.4969 - headline_token_classes_loss: 5.3602 - val_loss: 6.2003 - val_output_headline_vector_loss: 0.0579 - val_headline_token_classes_loss: 6.1424\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6971 - output_headline_vector_loss: 0.4931 - headline_token_classes_loss: 5.2039 - val_loss: 6.1971 - val_output_headline_vector_loss: 0.0531 - val_headline_token_classes_loss: 6.1440\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5.6757 - output_headline_vector_loss: 0.4779 - headline_token_classes_loss: 5.1978 - val_loss: 6.4420 - val_output_headline_vector_loss: 0.0549 - val_headline_token_classes_loss: 6.3871\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6579 - output_headline_vector_loss: 0.4788 - headline_token_classes_loss: 5.1791 - val_loss: 6.2431 - val_output_headline_vector_loss: 0.0575 - val_headline_token_classes_loss: 6.1856\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.6398 - output_headline_vector_loss: 0.4815 - headline_token_classes_loss: 5.1583 - val_loss: 6.1772 - val_output_headline_vector_loss: 0.0528 - val_headline_token_classes_loss: 6.1245\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5778 - output_headline_vector_loss: 0.4734 - headline_token_classes_loss: 5.1044 - val_loss: 5.9641 - val_output_headline_vector_loss: 0.0549 - val_headline_token_classes_loss: 5.9092\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6431 - output_headline_vector_loss: 0.4686 - headline_token_classes_loss: 5.1745 - val_loss: 5.9870 - val_output_headline_vector_loss: 0.0537 - val_headline_token_classes_loss: 5.9334\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5279 - output_headline_vector_loss: 0.4644 - headline_token_classes_loss: 5.0634 - val_loss: 6.0183 - val_output_headline_vector_loss: 0.0544 - val_headline_token_classes_loss: 5.9638\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.4823 - output_headline_vector_loss: 0.4632 - headline_token_classes_loss: 5.0192 - val_loss: 5.8657 - val_output_headline_vector_loss: 0.0507 - val_headline_token_classes_loss: 5.8150\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3764 - output_headline_vector_loss: 0.4470 - headline_token_classes_loss: 4.9294 - val_loss: 5.9019 - val_output_headline_vector_loss: 0.0515 - val_headline_token_classes_loss: 5.8504\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5334 - output_headline_vector_loss: 0.4609 - headline_token_classes_loss: 5.0726 - val_loss: 5.7622 - val_output_headline_vector_loss: 0.0506 - val_headline_token_classes_loss: 5.7116\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.4906 - output_headline_vector_loss: 0.4546 - headline_token_classes_loss: 5.0360 - val_loss: 5.7458 - val_output_headline_vector_loss: 0.0529 - val_headline_token_classes_loss: 5.6930\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5.3890 - output_headline_vector_loss: 0.4532 - headline_token_classes_loss: 4.9358 - val_loss: 5.8067 - val_output_headline_vector_loss: 0.0501 - val_headline_token_classes_loss: 5.7566\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.2741 - output_headline_vector_loss: 0.4352 - headline_token_classes_loss: 4.8389 - val_loss: 5.6918 - val_output_headline_vector_loss: 0.0500 - val_headline_token_classes_loss: 5.6418\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.3217 - output_headline_vector_loss: 0.4432 - headline_token_classes_loss: 4.8785 - val_loss: 5.5546 - val_output_headline_vector_loss: 0.0454 - val_headline_token_classes_loss: 5.5092\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3823 - output_headline_vector_loss: 0.4412 - headline_token_classes_loss: 4.9411 - val_loss: 5.5041 - val_output_headline_vector_loss: 0.0494 - val_headline_token_classes_loss: 5.4547\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3442 - output_headline_vector_loss: 0.4466 - headline_token_classes_loss: 4.8977 - val_loss: 5.6390 - val_output_headline_vector_loss: 0.0452 - val_headline_token_classes_loss: 5.5938\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1851 - output_headline_vector_loss: 0.4165 - headline_token_classes_loss: 4.7686 - val_loss: 5.4655 - val_output_headline_vector_loss: 0.0422 - val_headline_token_classes_loss: 5.4233\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1941 - output_headline_vector_loss: 0.4259 - headline_token_classes_loss: 4.7682 - val_loss: 5.4573 - val_output_headline_vector_loss: 0.0453 - val_headline_token_classes_loss: 5.4120\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1697 - output_headline_vector_loss: 0.4319 - headline_token_classes_loss: 4.7378 - val_loss: 5.4276 - val_output_headline_vector_loss: 0.0427 - val_headline_token_classes_loss: 5.3849\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1727 - output_headline_vector_loss: 0.4284 - headline_token_classes_loss: 4.7444 - val_loss: 5.3374 - val_output_headline_vector_loss: 0.0402 - val_headline_token_classes_loss: 5.2973\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1707 - output_headline_vector_loss: 0.4197 - headline_token_classes_loss: 4.7510 - val_loss: 5.2884 - val_output_headline_vector_loss: 0.0435 - val_headline_token_classes_loss: 5.2449\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 5.2139 - output_headline_vector_loss: 0.4161 - headline_token_classes_loss: 4.7978 - val_loss: 5.1510 - val_output_headline_vector_loss: 0.0432 - val_headline_token_classes_loss: 5.1078\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.1438 - output_headline_vector_loss: 0.4123 - headline_token_classes_loss: 4.7315 - val_loss: 5.1937 - val_output_headline_vector_loss: 0.0378 - val_headline_token_classes_loss: 5.1559\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0963 - output_headline_vector_loss: 0.4056 - headline_token_classes_loss: 4.6907 - val_loss: 5.1763 - val_output_headline_vector_loss: 0.0395 - val_headline_token_classes_loss: 5.1368\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9609 - output_headline_vector_loss: 0.4124 - headline_token_classes_loss: 4.5485 - val_loss: 5.1132 - val_output_headline_vector_loss: 0.0380 - val_headline_token_classes_loss: 5.0752\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9215 - output_headline_vector_loss: 0.4066 - headline_token_classes_loss: 4.5149 - val_loss: 4.8174 - val_output_headline_vector_loss: 0.0381 - val_headline_token_classes_loss: 4.7793\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0465 - output_headline_vector_loss: 0.3933 - headline_token_classes_loss: 4.6532 - val_loss: 5.1150 - val_output_headline_vector_loss: 0.0369 - val_headline_token_classes_loss: 5.0782\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9303 - output_headline_vector_loss: 0.4029 - headline_token_classes_loss: 4.5275 - val_loss: 4.8141 - val_output_headline_vector_loss: 0.0350 - val_headline_token_classes_loss: 4.7790\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.8396 - output_headline_vector_loss: 0.3879 - headline_token_classes_loss: 4.4517 - val_loss: 4.9388 - val_output_headline_vector_loss: 0.0348 - val_headline_token_classes_loss: 4.9040\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8582 - output_headline_vector_loss: 0.3893 - headline_token_classes_loss: 4.4689 - val_loss: 4.6900 - val_output_headline_vector_loss: 0.0375 - val_headline_token_classes_loss: 4.6526\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9686 - output_headline_vector_loss: 0.3937 - headline_token_classes_loss: 4.5749 - val_loss: 4.6212 - val_output_headline_vector_loss: 0.0338 - val_headline_token_classes_loss: 4.5873\n",
      "Epoch 158/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 3s/step - loss: 4.8777 - output_headline_vector_loss: 0.3886 - headline_token_classes_loss: 4.4891 - val_loss: 4.6437 - val_output_headline_vector_loss: 0.0338 - val_headline_token_classes_loss: 4.6100\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7401 - output_headline_vector_loss: 0.3757 - headline_token_classes_loss: 4.3644 - val_loss: 4.8773 - val_output_headline_vector_loss: 0.0341 - val_headline_token_classes_loss: 4.8432\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7124 - output_headline_vector_loss: 0.3739 - headline_token_classes_loss: 4.3385 - val_loss: 4.7734 - val_output_headline_vector_loss: 0.0323 - val_headline_token_classes_loss: 4.7411\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6526 - output_headline_vector_loss: 0.3717 - headline_token_classes_loss: 4.2809 - val_loss: 4.8632 - val_output_headline_vector_loss: 0.0317 - val_headline_token_classes_loss: 4.8314\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6733 - output_headline_vector_loss: 0.3652 - headline_token_classes_loss: 4.3080 - val_loss: 4.5267 - val_output_headline_vector_loss: 0.0312 - val_headline_token_classes_loss: 4.4955\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.6204 - output_headline_vector_loss: 0.3685 - headline_token_classes_loss: 4.2519 - val_loss: 4.4344 - val_output_headline_vector_loss: 0.0315 - val_headline_token_classes_loss: 4.4029\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7054 - output_headline_vector_loss: 0.3682 - headline_token_classes_loss: 4.3372 - val_loss: 4.5675 - val_output_headline_vector_loss: 0.0317 - val_headline_token_classes_loss: 4.5358\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6782 - output_headline_vector_loss: 0.3689 - headline_token_classes_loss: 4.3093 - val_loss: 4.5760 - val_output_headline_vector_loss: 0.0303 - val_headline_token_classes_loss: 4.5457\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.5323 - output_headline_vector_loss: 0.3562 - headline_token_classes_loss: 4.1761 - val_loss: 4.2986 - val_output_headline_vector_loss: 0.0285 - val_headline_token_classes_loss: 4.2701\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.5613 - output_headline_vector_loss: 0.3582 - headline_token_classes_loss: 4.2031 - val_loss: 4.5412 - val_output_headline_vector_loss: 0.0310 - val_headline_token_classes_loss: 4.5102\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.5642 - output_headline_vector_loss: 0.3499 - headline_token_classes_loss: 4.2143 - val_loss: 4.1902 - val_output_headline_vector_loss: 0.0283 - val_headline_token_classes_loss: 4.1619\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.5830 - output_headline_vector_loss: 0.3566 - headline_token_classes_loss: 4.2264 - val_loss: 4.3665 - val_output_headline_vector_loss: 0.0296 - val_headline_token_classes_loss: 4.3369\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4532 - output_headline_vector_loss: 0.3488 - headline_token_classes_loss: 4.1044 - val_loss: 4.3708 - val_output_headline_vector_loss: 0.0290 - val_headline_token_classes_loss: 4.3418\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.4532 - output_headline_vector_loss: 0.3445 - headline_token_classes_loss: 4.1087 - val_loss: 4.3927 - val_output_headline_vector_loss: 0.0272 - val_headline_token_classes_loss: 4.3655\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4673 - output_headline_vector_loss: 0.3427 - headline_token_classes_loss: 4.1247 - val_loss: 4.1128 - val_output_headline_vector_loss: 0.0285 - val_headline_token_classes_loss: 4.0844\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3525 - output_headline_vector_loss: 0.3394 - headline_token_classes_loss: 4.0131 - val_loss: 4.1412 - val_output_headline_vector_loss: 0.0260 - val_headline_token_classes_loss: 4.1152\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4527 - output_headline_vector_loss: 0.3259 - headline_token_classes_loss: 4.1268 - val_loss: 4.1557 - val_output_headline_vector_loss: 0.0279 - val_headline_token_classes_loss: 4.1278\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4822 - output_headline_vector_loss: 0.3267 - headline_token_classes_loss: 4.1555 - val_loss: 4.0404 - val_output_headline_vector_loss: 0.0257 - val_headline_token_classes_loss: 4.0147\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.3705 - output_headline_vector_loss: 0.3225 - headline_token_classes_loss: 4.0480 - val_loss: 4.0123 - val_output_headline_vector_loss: 0.0262 - val_headline_token_classes_loss: 3.9861\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3358 - output_headline_vector_loss: 0.3292 - headline_token_classes_loss: 4.0066 - val_loss: 4.0267 - val_output_headline_vector_loss: 0.0258 - val_headline_token_classes_loss: 4.0009\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3313 - output_headline_vector_loss: 0.3229 - headline_token_classes_loss: 4.0084 - val_loss: 4.1742 - val_output_headline_vector_loss: 0.0283 - val_headline_token_classes_loss: 4.1459\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.2122 - output_headline_vector_loss: 0.3211 - headline_token_classes_loss: 3.8911 - val_loss: 3.9151 - val_output_headline_vector_loss: 0.0230 - val_headline_token_classes_loss: 3.8920\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3212 - output_headline_vector_loss: 0.3200 - headline_token_classes_loss: 4.0012 - val_loss: 4.1281 - val_output_headline_vector_loss: 0.0229 - val_headline_token_classes_loss: 4.1052\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2936 - output_headline_vector_loss: 0.3204 - headline_token_classes_loss: 3.9732 - val_loss: 3.7686 - val_output_headline_vector_loss: 0.0248 - val_headline_token_classes_loss: 3.7438\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2443 - output_headline_vector_loss: 0.3173 - headline_token_classes_loss: 3.9270 - val_loss: 4.0013 - val_output_headline_vector_loss: 0.0233 - val_headline_token_classes_loss: 3.9780\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2455 - output_headline_vector_loss: 0.3140 - headline_token_classes_loss: 3.9315 - val_loss: 3.9514 - val_output_headline_vector_loss: 0.0223 - val_headline_token_classes_loss: 3.9291\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.1233 - output_headline_vector_loss: 0.2967 - headline_token_classes_loss: 3.8266 - val_loss: 3.8919 - val_output_headline_vector_loss: 0.0238 - val_headline_token_classes_loss: 3.8681\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.1540 - output_headline_vector_loss: 0.3081 - headline_token_classes_loss: 3.8459 - val_loss: 4.0221 - val_output_headline_vector_loss: 0.0252 - val_headline_token_classes_loss: 3.9968\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.1977 - output_headline_vector_loss: 0.3005 - headline_token_classes_loss: 3.8972 - val_loss: 3.7519 - val_output_headline_vector_loss: 0.0230 - val_headline_token_classes_loss: 3.7289\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 4.2034 - output_headline_vector_loss: 0.3034 - headline_token_classes_loss: 3.9000 - val_loss: 3.8271 - val_output_headline_vector_loss: 0.0237 - val_headline_token_classes_loss: 3.8034\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0859 - output_headline_vector_loss: 0.2901 - headline_token_classes_loss: 3.7958 - val_loss: 3.6667 - val_output_headline_vector_loss: 0.0210 - val_headline_token_classes_loss: 3.6457\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.0980 - output_headline_vector_loss: 0.2842 - headline_token_classes_loss: 3.8138 - val_loss: 3.9450 - val_output_headline_vector_loss: 0.0222 - val_headline_token_classes_loss: 3.9228\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.0949 - output_headline_vector_loss: 0.2774 - headline_token_classes_loss: 3.8174 - val_loss: 3.6313 - val_output_headline_vector_loss: 0.0224 - val_headline_token_classes_loss: 3.6090\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.9298 - output_headline_vector_loss: 0.2772 - headline_token_classes_loss: 3.6526 - val_loss: 3.8129 - val_output_headline_vector_loss: 0.0224 - val_headline_token_classes_loss: 3.7905\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0076 - output_headline_vector_loss: 0.2731 - headline_token_classes_loss: 3.7345 - val_loss: 3.6750 - val_output_headline_vector_loss: 0.0222 - val_headline_token_classes_loss: 3.6528\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0044 - output_headline_vector_loss: 0.2848 - headline_token_classes_loss: 3.7196 - val_loss: 3.6715 - val_output_headline_vector_loss: 0.0215 - val_headline_token_classes_loss: 3.6499\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.9416 - output_headline_vector_loss: 0.2725 - headline_token_classes_loss: 3.6691 - val_loss: 3.7517 - val_output_headline_vector_loss: 0.0237 - val_headline_token_classes_loss: 3.7280\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8910 - output_headline_vector_loss: 0.2649 - headline_token_classes_loss: 3.6262 - val_loss: 3.6662 - val_output_headline_vector_loss: 0.0225 - val_headline_token_classes_loss: 3.6436\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9152 - output_headline_vector_loss: 0.2652 - headline_token_classes_loss: 3.6500 - val_loss: 3.6724 - val_output_headline_vector_loss: 0.0206 - val_headline_token_classes_loss: 3.6518\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.8606 - output_headline_vector_loss: 0.2680 - headline_token_classes_loss: 3.5926 - val_loss: 3.5792 - val_output_headline_vector_loss: 0.0228 - val_headline_token_classes_loss: 3.5564\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 3.8879 - output_headline_vector_loss: 0.2683 - headline_token_classes_loss: 3.6196 - val_loss: 3.4747 - val_output_headline_vector_loss: 0.0223 - val_headline_token_classes_loss: 3.4524\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.9065 - output_headline_vector_loss: 0.2650 - headline_token_classes_loss: 3.6415 - val_loss: 3.5075 - val_output_headline_vector_loss: 0.0226 - val_headline_token_classes_loss: 3.4849\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7579 - output_headline_vector_loss: 0.2561 - headline_token_classes_loss: 3.5018 - val_loss: 3.2875 - val_output_headline_vector_loss: 0.0201 - val_headline_token_classes_loss: 3.2674\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.8084 - output_headline_vector_loss: 0.2534 - headline_token_classes_loss: 3.5551 - val_loss: 3.4304 - val_output_headline_vector_loss: 0.0214 - val_headline_token_classes_loss: 3.4090\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7331 - output_headline_vector_loss: 0.2505 - headline_token_classes_loss: 3.4826 - val_loss: 3.3198 - val_output_headline_vector_loss: 0.0185 - val_headline_token_classes_loss: 3.3013\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.7829 - output_headline_vector_loss: 0.2431 - headline_token_classes_loss: 3.5398 - val_loss: 3.7963 - val_output_headline_vector_loss: 0.0206 - val_headline_token_classes_loss: 3.7757\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7092 - output_headline_vector_loss: 0.2443 - headline_token_classes_loss: 3.4649 - val_loss: 3.4295 - val_output_headline_vector_loss: 0.0240 - val_headline_token_classes_loss: 3.4055\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7088 - output_headline_vector_loss: 0.2414 - headline_token_classes_loss: 3.4674 - val_loss: 3.3405 - val_output_headline_vector_loss: 0.0210 - val_headline_token_classes_loss: 3.3194\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7197 - output_headline_vector_loss: 0.2427 - headline_token_classes_loss: 3.4770 - val_loss: 3.4519 - val_output_headline_vector_loss: 0.0202 - val_headline_token_classes_loss: 3.4317\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6691 - output_headline_vector_loss: 0.2438 - headline_token_classes_loss: 3.4253 - val_loss: 3.5145 - val_output_headline_vector_loss: 0.0215 - val_headline_token_classes_loss: 3.4930\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6333 - output_headline_vector_loss: 0.2282 - headline_token_classes_loss: 3.4051 - val_loss: 3.5655 - val_output_headline_vector_loss: 0.0199 - val_headline_token_classes_loss: 3.5456\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5882 - output_headline_vector_loss: 0.2253 - headline_token_classes_loss: 3.3629 - val_loss: 3.2202 - val_output_headline_vector_loss: 0.0196 - val_headline_token_classes_loss: 3.2006\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.5906 - output_headline_vector_loss: 0.2257 - headline_token_classes_loss: 3.3649 - val_loss: 3.2769 - val_output_headline_vector_loss: 0.0221 - val_headline_token_classes_loss: 3.2548\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5751 - output_headline_vector_loss: 0.2206 - headline_token_classes_loss: 3.3545 - val_loss: 3.2494 - val_output_headline_vector_loss: 0.0200 - val_headline_token_classes_loss: 3.2294\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6122 - output_headline_vector_loss: 0.2262 - headline_token_classes_loss: 3.3860 - val_loss: 3.2243 - val_output_headline_vector_loss: 0.0205 - val_headline_token_classes_loss: 3.2038\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5790 - output_headline_vector_loss: 0.2127 - headline_token_classes_loss: 3.3663 - val_loss: 3.4932 - val_output_headline_vector_loss: 0.0207 - val_headline_token_classes_loss: 3.4725\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4612 - output_headline_vector_loss: 0.2237 - headline_token_classes_loss: 3.2375 - val_loss: 3.1043 - val_output_headline_vector_loss: 0.0194 - val_headline_token_classes_loss: 3.0849\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.5421 - output_headline_vector_loss: 0.2156 - headline_token_classes_loss: 3.3264 - val_loss: 3.3591 - val_output_headline_vector_loss: 0.0190 - val_headline_token_classes_loss: 3.3401\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5206 - output_headline_vector_loss: 0.2046 - headline_token_classes_loss: 3.3160 - val_loss: 3.4455 - val_output_headline_vector_loss: 0.0181 - val_headline_token_classes_loss: 3.4274\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.5058 - output_headline_vector_loss: 0.2089 - headline_token_classes_loss: 3.2968 - val_loss: 3.2542 - val_output_headline_vector_loss: 0.0217 - val_headline_token_classes_loss: 3.2325\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4683 - output_headline_vector_loss: 0.2108 - headline_token_classes_loss: 3.2576 - val_loss: 2.8873 - val_output_headline_vector_loss: 0.0199 - val_headline_token_classes_loss: 2.8674\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4213 - output_headline_vector_loss: 0.2006 - headline_token_classes_loss: 3.2207 - val_loss: 3.5083 - val_output_headline_vector_loss: 0.0187 - val_headline_token_classes_loss: 3.4896\n",
      "Epoch 220/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 3.4088 - output_headline_vector_loss: 0.1983 - headline_token_classes_loss: 3.2105 - val_loss: 3.2393 - val_output_headline_vector_loss: 0.0215 - val_headline_token_classes_loss: 3.2177\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4267 - output_headline_vector_loss: 0.1954 - headline_token_classes_loss: 3.2314 - val_loss: 3.2168 - val_output_headline_vector_loss: 0.0187 - val_headline_token_classes_loss: 3.1981\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4584 - output_headline_vector_loss: 0.1975 - headline_token_classes_loss: 3.2609 - val_loss: 2.8625 - val_output_headline_vector_loss: 0.0192 - val_headline_token_classes_loss: 2.8433\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 3.4431 - output_headline_vector_loss: 0.1987 - headline_token_classes_loss: 3.2445 - val_loss: 3.4999 - val_output_headline_vector_loss: 0.0196 - val_headline_token_classes_loss: 3.4803\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3377 - output_headline_vector_loss: 0.1893 - headline_token_classes_loss: 3.1484 - val_loss: 3.1342 - val_output_headline_vector_loss: 0.0200 - val_headline_token_classes_loss: 3.1142\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3786 - output_headline_vector_loss: 0.1896 - headline_token_classes_loss: 3.1890 - val_loss: 3.2131 - val_output_headline_vector_loss: 0.0168 - val_headline_token_classes_loss: 3.1963\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3444 - output_headline_vector_loss: 0.1879 - headline_token_classes_loss: 3.1566 - val_loss: 3.0419 - val_output_headline_vector_loss: 0.0191 - val_headline_token_classes_loss: 3.0228\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3684 - output_headline_vector_loss: 0.1814 - headline_token_classes_loss: 3.1870 - val_loss: 3.0773 - val_output_headline_vector_loss: 0.0190 - val_headline_token_classes_loss: 3.0583\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4595 - output_headline_vector_loss: 0.1845 - headline_token_classes_loss: 3.2750 - val_loss: 3.3274 - val_output_headline_vector_loss: 0.0186 - val_headline_token_classes_loss: 3.3088\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.3681 - output_headline_vector_loss: 0.1888 - headline_token_classes_loss: 3.1793 - val_loss: 2.9437 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 2.9266\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1989 - output_headline_vector_loss: 0.1781 - headline_token_classes_loss: 3.0207 - val_loss: 3.1892 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 3.1709\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2679 - output_headline_vector_loss: 0.1755 - headline_token_classes_loss: 3.0924 - val_loss: 3.0583 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 3.0411\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2400 - output_headline_vector_loss: 0.1742 - headline_token_classes_loss: 3.0658 - val_loss: 3.4258 - val_output_headline_vector_loss: 0.0184 - val_headline_token_classes_loss: 3.4074\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.2532 - output_headline_vector_loss: 0.1624 - headline_token_classes_loss: 3.0908 - val_loss: 2.9516 - val_output_headline_vector_loss: 0.0169 - val_headline_token_classes_loss: 2.9346\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.1517 - output_headline_vector_loss: 0.1661 - headline_token_classes_loss: 2.9856 - val_loss: 3.0043 - val_output_headline_vector_loss: 0.0173 - val_headline_token_classes_loss: 2.9870\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2418 - output_headline_vector_loss: 0.1660 - headline_token_classes_loss: 3.0758 - val_loss: 3.1910 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 3.1763\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.1819 - output_headline_vector_loss: 0.1666 - headline_token_classes_loss: 3.0152 - val_loss: 3.2901 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 3.2729\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1409 - output_headline_vector_loss: 0.1593 - headline_token_classes_loss: 2.9817 - val_loss: 2.9622 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 2.9459\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.1602 - output_headline_vector_loss: 0.1610 - headline_token_classes_loss: 2.9991 - val_loss: 3.0991 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 3.0821\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1275 - output_headline_vector_loss: 0.1556 - headline_token_classes_loss: 2.9719 - val_loss: 3.1385 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 3.1223\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 3.1133 - output_headline_vector_loss: 0.1478 - headline_token_classes_loss: 2.9654 - val_loss: 3.1292 - val_output_headline_vector_loss: 0.0181 - val_headline_token_classes_loss: 3.1111\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1483 - output_headline_vector_loss: 0.1556 - headline_token_classes_loss: 2.9927 - val_loss: 3.0250 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 3.0095\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1099 - output_headline_vector_loss: 0.1541 - headline_token_classes_loss: 2.9558 - val_loss: 3.2265 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 3.2103\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1653 - output_headline_vector_loss: 0.1460 - headline_token_classes_loss: 3.0193 - val_loss: 3.0458 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 3.0307\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.0013 - output_headline_vector_loss: 0.1515 - headline_token_classes_loss: 2.8498 - val_loss: 2.9543 - val_output_headline_vector_loss: 0.0166 - val_headline_token_classes_loss: 2.9378\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.0380 - output_headline_vector_loss: 0.1491 - headline_token_classes_loss: 2.8890 - val_loss: 3.0523 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 3.0371\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.9437 - output_headline_vector_loss: 0.1402 - headline_token_classes_loss: 2.8035 - val_loss: 2.8487 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.8343\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.0011 - output_headline_vector_loss: 0.1381 - headline_token_classes_loss: 2.8630 - val_loss: 3.0460 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 3.0308\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.9502 - output_headline_vector_loss: 0.1345 - headline_token_classes_loss: 2.8157 - val_loss: 2.9750 - val_output_headline_vector_loss: 0.0161 - val_headline_token_classes_loss: 2.9588\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.0303 - output_headline_vector_loss: 0.1410 - headline_token_classes_loss: 2.8893 - val_loss: 3.0007 - val_output_headline_vector_loss: 0.0169 - val_headline_token_classes_loss: 2.9838\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.9728 - output_headline_vector_loss: 0.1375 - headline_token_classes_loss: 2.8352 - val_loss: 2.8987 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.8844\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8632 - output_headline_vector_loss: 0.1308 - headline_token_classes_loss: 2.7324 - val_loss: 2.7526 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.7377\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.9649 - output_headline_vector_loss: 0.1310 - headline_token_classes_loss: 2.8340 - val_loss: 2.8237 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.8088\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.9806 - output_headline_vector_loss: 0.1284 - headline_token_classes_loss: 2.8522 - val_loss: 2.9667 - val_output_headline_vector_loss: 0.0156 - val_headline_token_classes_loss: 2.9511\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8786 - output_headline_vector_loss: 0.1222 - headline_token_classes_loss: 2.7564 - val_loss: 3.3354 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 3.3208\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8594 - output_headline_vector_loss: 0.1283 - headline_token_classes_loss: 2.7311 - val_loss: 2.9221 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.9083\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8223 - output_headline_vector_loss: 0.1250 - headline_token_classes_loss: 2.6973 - val_loss: 2.5730 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.5596\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.7796 - output_headline_vector_loss: 0.1233 - headline_token_classes_loss: 2.6563 - val_loss: 3.0185 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 3.0026\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8388 - output_headline_vector_loss: 0.1198 - headline_token_classes_loss: 2.7191 - val_loss: 3.0961 - val_output_headline_vector_loss: 0.0166 - val_headline_token_classes_loss: 3.0796\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8515 - output_headline_vector_loss: 0.1172 - headline_token_classes_loss: 2.7342 - val_loss: 2.9371 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 2.9212\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7745 - output_headline_vector_loss: 0.1142 - headline_token_classes_loss: 2.6603 - val_loss: 2.8128 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.7984\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7937 - output_headline_vector_loss: 0.1162 - headline_token_classes_loss: 2.6775 - val_loss: 2.9479 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.9326\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7002 - output_headline_vector_loss: 0.1099 - headline_token_classes_loss: 2.5902 - val_loss: 3.0287 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 3.0135\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7143 - output_headline_vector_loss: 0.1068 - headline_token_classes_loss: 2.6076 - val_loss: 2.6595 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.6448\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7081 - output_headline_vector_loss: 0.1068 - headline_token_classes_loss: 2.6013 - val_loss: 3.1600 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 3.1454\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.7116 - output_headline_vector_loss: 0.1012 - headline_token_classes_loss: 2.6105 - val_loss: 2.7990 - val_output_headline_vector_loss: 0.0173 - val_headline_token_classes_loss: 2.7817\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7470 - output_headline_vector_loss: 0.1002 - headline_token_classes_loss: 2.6468 - val_loss: 2.7581 - val_output_headline_vector_loss: 0.0161 - val_headline_token_classes_loss: 2.7420\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6355 - output_headline_vector_loss: 0.1066 - headline_token_classes_loss: 2.5289 - val_loss: 2.8200 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.8042\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.7696 - output_headline_vector_loss: 0.1031 - headline_token_classes_loss: 2.6664 - val_loss: 2.8552 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.8415\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.6702 - output_headline_vector_loss: 0.0985 - headline_token_classes_loss: 2.5716 - val_loss: 2.8909 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.8757\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.7044 - output_headline_vector_loss: 0.1008 - headline_token_classes_loss: 2.6037 - val_loss: 2.5011 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 2.4849\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.7070 - output_headline_vector_loss: 0.0951 - headline_token_classes_loss: 2.6119 - val_loss: 2.7838 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.7685\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7530 - output_headline_vector_loss: 0.0998 - headline_token_classes_loss: 2.6532 - val_loss: 2.8370 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 2.8212\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5789 - output_headline_vector_loss: 0.0949 - headline_token_classes_loss: 2.4840 - val_loss: 2.7499 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 2.7327\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.6127 - output_headline_vector_loss: 0.0977 - headline_token_classes_loss: 2.5150 - val_loss: 2.4185 - val_output_headline_vector_loss: 0.0157 - val_headline_token_classes_loss: 2.4028\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.6874 - output_headline_vector_loss: 0.0901 - headline_token_classes_loss: 2.5974 - val_loss: 2.6593 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.6453\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6746 - output_headline_vector_loss: 0.0870 - headline_token_classes_loss: 2.5875 - val_loss: 2.7647 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.7495\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6617 - output_headline_vector_loss: 0.0861 - headline_token_classes_loss: 2.5755 - val_loss: 2.5553 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5434\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6378 - output_headline_vector_loss: 0.0869 - headline_token_classes_loss: 2.5509 - val_loss: 2.5407 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.5260\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5965 - output_headline_vector_loss: 0.0888 - headline_token_classes_loss: 2.5077 - val_loss: 2.8896 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.8756\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5738 - output_headline_vector_loss: 0.0862 - headline_token_classes_loss: 2.4876 - val_loss: 3.0680 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 3.0541\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5275 - output_headline_vector_loss: 0.0836 - headline_token_classes_loss: 2.4439 - val_loss: 2.7138 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.6998\n",
      "Epoch 282/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.4987 - output_headline_vector_loss: 0.0833 - headline_token_classes_loss: 2.4154 - val_loss: 2.6405 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.6260\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5909 - output_headline_vector_loss: 0.0834 - headline_token_classes_loss: 2.5075 - val_loss: 3.0248 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 3.0110\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5638 - output_headline_vector_loss: 0.0764 - headline_token_classes_loss: 2.4873 - val_loss: 2.7707 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.7581\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5522 - output_headline_vector_loss: 0.0826 - headline_token_classes_loss: 2.4697 - val_loss: 2.6057 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.5930\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6139 - output_headline_vector_loss: 0.0729 - headline_token_classes_loss: 2.5409 - val_loss: 2.7532 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.7397\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5068 - output_headline_vector_loss: 0.0758 - headline_token_classes_loss: 2.4309 - val_loss: 2.9705 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.9583\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6167 - output_headline_vector_loss: 0.0775 - headline_token_classes_loss: 2.5392 - val_loss: 3.0121 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 3.0001\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5168 - output_headline_vector_loss: 0.0738 - headline_token_classes_loss: 2.4430 - val_loss: 2.9003 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.8870\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4668 - output_headline_vector_loss: 0.0751 - headline_token_classes_loss: 2.3917 - val_loss: 2.6009 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.5869\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4880 - output_headline_vector_loss: 0.0677 - headline_token_classes_loss: 2.4203 - val_loss: 2.5941 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.5803\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5214 - output_headline_vector_loss: 0.0731 - headline_token_classes_loss: 2.4483 - val_loss: 2.8561 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.8428\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5205 - output_headline_vector_loss: 0.0700 - headline_token_classes_loss: 2.4505 - val_loss: 2.8431 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.8298\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5035 - output_headline_vector_loss: 0.0719 - headline_token_classes_loss: 2.4315 - val_loss: 2.5159 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.5019\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4205 - output_headline_vector_loss: 0.0750 - headline_token_classes_loss: 2.3455 - val_loss: 2.5581 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5462\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4464 - output_headline_vector_loss: 0.0688 - headline_token_classes_loss: 2.3776 - val_loss: 2.7361 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.7212\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3839 - output_headline_vector_loss: 0.0638 - headline_token_classes_loss: 2.3201 - val_loss: 2.5705 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.5573\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4141 - output_headline_vector_loss: 0.0667 - headline_token_classes_loss: 2.3475 - val_loss: 2.8561 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.8442\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4976 - output_headline_vector_loss: 0.0683 - headline_token_classes_loss: 2.4293 - val_loss: 2.8519 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.8382\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4832 - output_headline_vector_loss: 0.0597 - headline_token_classes_loss: 2.4235 - val_loss: 2.7240 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7127\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3802 - output_headline_vector_loss: 0.0635 - headline_token_classes_loss: 2.3168 - val_loss: 2.6655 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6539\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4400 - output_headline_vector_loss: 0.0588 - headline_token_classes_loss: 2.3812 - val_loss: 2.8056 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.7932\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3661 - output_headline_vector_loss: 0.0570 - headline_token_classes_loss: 2.3091 - val_loss: 2.5413 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.5269\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3040 - output_headline_vector_loss: 0.0587 - headline_token_classes_loss: 2.2453 - val_loss: 2.5209 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5095\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3300 - output_headline_vector_loss: 0.0563 - headline_token_classes_loss: 2.2738 - val_loss: 2.8099 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7981\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3375 - output_headline_vector_loss: 0.0592 - headline_token_classes_loss: 2.2783 - val_loss: 2.4531 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4410\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3527 - output_headline_vector_loss: 0.0564 - headline_token_classes_loss: 2.2963 - val_loss: 2.7456 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.7339\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3378 - output_headline_vector_loss: 0.0542 - headline_token_classes_loss: 2.2836 - val_loss: 2.8270 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.8151\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3482 - output_headline_vector_loss: 0.0571 - headline_token_classes_loss: 2.2911 - val_loss: 2.5492 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.5379\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3033 - output_headline_vector_loss: 0.0575 - headline_token_classes_loss: 2.2458 - val_loss: 2.5866 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.5729\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3571 - output_headline_vector_loss: 0.0552 - headline_token_classes_loss: 2.3019 - val_loss: 2.7932 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7821\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3230 - output_headline_vector_loss: 0.0529 - headline_token_classes_loss: 2.2701 - val_loss: 2.6423 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.6291\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2639 - output_headline_vector_loss: 0.0534 - headline_token_classes_loss: 2.2106 - val_loss: 3.1985 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 3.1884\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3168 - output_headline_vector_loss: 0.0512 - headline_token_classes_loss: 2.2657 - val_loss: 2.7556 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.7436\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2684 - output_headline_vector_loss: 0.0509 - headline_token_classes_loss: 2.2176 - val_loss: 2.4749 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.4609\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2826 - output_headline_vector_loss: 0.0501 - headline_token_classes_loss: 2.2326 - val_loss: 2.3122 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3005\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3237 - output_headline_vector_loss: 0.0525 - headline_token_classes_loss: 2.2713 - val_loss: 2.6359 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6252\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2586 - output_headline_vector_loss: 0.0494 - headline_token_classes_loss: 2.2092 - val_loss: 2.7704 - val_output_headline_vector_loss: 0.0225 - val_headline_token_classes_loss: 2.7479\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1852 - output_headline_vector_loss: 0.0476 - headline_token_classes_loss: 2.1377 - val_loss: 2.5560 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.5435\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3289 - output_headline_vector_loss: 0.0505 - headline_token_classes_loss: 2.2784 - val_loss: 2.7505 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7395\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.2933 - output_headline_vector_loss: 0.0449 - headline_token_classes_loss: 2.2484 - val_loss: 2.9151 - val_output_headline_vector_loss: 0.0509 - val_headline_token_classes_loss: 2.8642\n",
      "Epoch 322/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1748 - output_headline_vector_loss: 0.0476 - headline_token_classes_loss: 2.1272 - val_loss: 3.0221 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 3.0086\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1756 - output_headline_vector_loss: 0.0435 - headline_token_classes_loss: 2.1322 - val_loss: 2.9510 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.9395\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1166 - output_headline_vector_loss: 0.0443 - headline_token_classes_loss: 2.0723 - val_loss: 2.7744 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7638\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2016 - output_headline_vector_loss: 0.0480 - headline_token_classes_loss: 2.1536 - val_loss: 2.7155 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.7017\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2005 - output_headline_vector_loss: 0.0415 - headline_token_classes_loss: 2.1591 - val_loss: 2.9758 - val_output_headline_vector_loss: 0.0214 - val_headline_token_classes_loss: 2.9544\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1991 - output_headline_vector_loss: 0.0430 - headline_token_classes_loss: 2.1562 - val_loss: 2.4265 - val_output_headline_vector_loss: 0.0299 - val_headline_token_classes_loss: 2.3966\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2696 - output_headline_vector_loss: 0.0432 - headline_token_classes_loss: 2.2264 - val_loss: 2.7551 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 2.7389\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3390 - output_headline_vector_loss: 0.0443 - headline_token_classes_loss: 2.2947 - val_loss: 2.3513 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.3388\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1937 - output_headline_vector_loss: 0.0408 - headline_token_classes_loss: 2.1529 - val_loss: 2.9710 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 2.9622\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1646 - output_headline_vector_loss: 0.0404 - headline_token_classes_loss: 2.1242 - val_loss: 2.5824 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.5684\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1268 - output_headline_vector_loss: 0.0419 - headline_token_classes_loss: 2.0849 - val_loss: 2.6200 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6104\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1594 - output_headline_vector_loss: 0.0409 - headline_token_classes_loss: 2.1185 - val_loss: 3.2249 - val_output_headline_vector_loss: 0.0084 - val_headline_token_classes_loss: 3.2166\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1864 - output_headline_vector_loss: 0.0389 - headline_token_classes_loss: 2.1475 - val_loss: 2.3030 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2914\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1289 - output_headline_vector_loss: 0.0371 - headline_token_classes_loss: 2.0918 - val_loss: 2.5561 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5443\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2453 - output_headline_vector_loss: 0.0398 - headline_token_classes_loss: 2.2056 - val_loss: 2.3068 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.2937\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2587 - output_headline_vector_loss: 0.0382 - headline_token_classes_loss: 2.2205 - val_loss: 3.0487 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 3.0349\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2034 - output_headline_vector_loss: 0.0411 - headline_token_classes_loss: 2.1623 - val_loss: 2.3122 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3007\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2375 - output_headline_vector_loss: 0.0367 - headline_token_classes_loss: 2.2008 - val_loss: 2.9306 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.9213\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1702 - output_headline_vector_loss: 0.0347 - headline_token_classes_loss: 2.1355 - val_loss: 2.8386 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.8277\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1673 - output_headline_vector_loss: 0.0370 - headline_token_classes_loss: 2.1303 - val_loss: 2.9820 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9717\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2188 - output_headline_vector_loss: 0.0381 - headline_token_classes_loss: 2.1806 - val_loss: 2.5281 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.5147\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2122 - output_headline_vector_loss: 0.0368 - headline_token_classes_loss: 2.1754 - val_loss: 2.5486 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5364\n",
      "Epoch 344/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 2.2114 - output_headline_vector_loss: 0.0384 - headline_token_classes_loss: 2.1730 - val_loss: 2.6523 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.6391\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1175 - output_headline_vector_loss: 0.0351 - headline_token_classes_loss: 2.0825 - val_loss: 2.4602 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.4481\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1350 - output_headline_vector_loss: 0.0345 - headline_token_classes_loss: 2.1005 - val_loss: 2.7020 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 2.6858\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0990 - output_headline_vector_loss: 0.0373 - headline_token_classes_loss: 2.0617 - val_loss: 2.4611 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4508\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1124 - output_headline_vector_loss: 0.0333 - headline_token_classes_loss: 2.0791 - val_loss: 2.7635 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7529\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0747 - output_headline_vector_loss: 0.0330 - headline_token_classes_loss: 2.0417 - val_loss: 2.8059 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7953\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0210 - output_headline_vector_loss: 0.0357 - headline_token_classes_loss: 1.9854 - val_loss: 2.7532 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7426\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0610 - output_headline_vector_loss: 0.0327 - headline_token_classes_loss: 2.0283 - val_loss: 2.5673 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5565\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1029 - output_headline_vector_loss: 0.0335 - headline_token_classes_loss: 2.0695 - val_loss: 2.7669 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7558\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0120 - output_headline_vector_loss: 0.0322 - headline_token_classes_loss: 1.9798 - val_loss: 2.6684 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6570\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0928 - output_headline_vector_loss: 0.0327 - headline_token_classes_loss: 2.0601 - val_loss: 2.6982 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6869\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0917 - output_headline_vector_loss: 0.0338 - headline_token_classes_loss: 2.0580 - val_loss: 2.4789 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.4671\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0582 - output_headline_vector_loss: 0.0320 - headline_token_classes_loss: 2.0262 - val_loss: 2.9011 - val_output_headline_vector_loss: 0.1559 - val_headline_token_classes_loss: 2.7451\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0168 - output_headline_vector_loss: 0.0311 - headline_token_classes_loss: 1.9857 - val_loss: 2.6980 - val_output_headline_vector_loss: 0.1759 - val_headline_token_classes_loss: 2.5221\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0220 - output_headline_vector_loss: 0.0314 - headline_token_classes_loss: 1.9906 - val_loss: 2.7844 - val_output_headline_vector_loss: 0.2237 - val_headline_token_classes_loss: 2.5607\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1080 - output_headline_vector_loss: 0.0335 - headline_token_classes_loss: 2.0745 - val_loss: 2.9539 - val_output_headline_vector_loss: 0.1322 - val_headline_token_classes_loss: 2.8217\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1175 - output_headline_vector_loss: 0.0317 - headline_token_classes_loss: 2.0858 - val_loss: 2.7828 - val_output_headline_vector_loss: 0.1589 - val_headline_token_classes_loss: 2.6239\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0920 - output_headline_vector_loss: 0.0315 - headline_token_classes_loss: 2.0605 - val_loss: 2.7583 - val_output_headline_vector_loss: 0.4575 - val_headline_token_classes_loss: 2.3008\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0573 - output_headline_vector_loss: 0.0314 - headline_token_classes_loss: 2.0259 - val_loss: 3.8353 - val_output_headline_vector_loss: 1.2852 - val_headline_token_classes_loss: 2.5501\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0670 - output_headline_vector_loss: 0.0304 - headline_token_classes_loss: 2.0366 - val_loss: 3.2843 - val_output_headline_vector_loss: 0.3275 - val_headline_token_classes_loss: 2.9568\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0318 - output_headline_vector_loss: 0.0305 - headline_token_classes_loss: 2.0013 - val_loss: 2.4834 - val_output_headline_vector_loss: 0.1596 - val_headline_token_classes_loss: 2.3238\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9527 - output_headline_vector_loss: 0.0304 - headline_token_classes_loss: 1.9223 - val_loss: 2.7481 - val_output_headline_vector_loss: 0.1890 - val_headline_token_classes_loss: 2.5591\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9839 - output_headline_vector_loss: 0.0283 - headline_token_classes_loss: 1.9556 - val_loss: 2.6120 - val_output_headline_vector_loss: 0.0618 - val_headline_token_classes_loss: 2.5502\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1068 - output_headline_vector_loss: 0.0292 - headline_token_classes_loss: 2.0776 - val_loss: 2.5030 - val_output_headline_vector_loss: 0.0700 - val_headline_token_classes_loss: 2.4330\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0943 - output_headline_vector_loss: 0.0285 - headline_token_classes_loss: 2.0658 - val_loss: 2.3904 - val_output_headline_vector_loss: 0.0526 - val_headline_token_classes_loss: 2.3378\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9531 - output_headline_vector_loss: 0.0324 - headline_token_classes_loss: 1.9207 - val_loss: 2.9772 - val_output_headline_vector_loss: 0.0414 - val_headline_token_classes_loss: 2.9358\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0664 - output_headline_vector_loss: 0.0334 - headline_token_classes_loss: 2.0331 - val_loss: 2.8345 - val_output_headline_vector_loss: 0.1183 - val_headline_token_classes_loss: 2.7162\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0406 - output_headline_vector_loss: 0.0315 - headline_token_classes_loss: 2.0091 - val_loss: 2.6761 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.6607\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0223 - output_headline_vector_loss: 0.0303 - headline_token_classes_loss: 1.9921 - val_loss: 2.3935 - val_output_headline_vector_loss: 0.0206 - val_headline_token_classes_loss: 2.3729\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9560 - output_headline_vector_loss: 0.0271 - headline_token_classes_loss: 1.9289 - val_loss: 2.8906 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.8794\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0461 - output_headline_vector_loss: 0.0275 - headline_token_classes_loss: 2.0186 - val_loss: 2.6746 - val_output_headline_vector_loss: 0.0184 - val_headline_token_classes_loss: 2.6562\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9686 - output_headline_vector_loss: 0.0291 - headline_token_classes_loss: 1.9395 - val_loss: 2.5796 - val_output_headline_vector_loss: 0.0171 - val_headline_token_classes_loss: 2.5625\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9141 - output_headline_vector_loss: 0.0259 - headline_token_classes_loss: 1.8881 - val_loss: 2.3580 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 2.3421\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9427 - output_headline_vector_loss: 0.0282 - headline_token_classes_loss: 1.9146 - val_loss: 2.5950 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5839\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9274 - output_headline_vector_loss: 0.0277 - headline_token_classes_loss: 1.8997 - val_loss: 2.2010 - val_output_headline_vector_loss: 0.0201 - val_headline_token_classes_loss: 2.1809\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9534 - output_headline_vector_loss: 0.0284 - headline_token_classes_loss: 1.9251 - val_loss: 2.4521 - val_output_headline_vector_loss: 0.0476 - val_headline_token_classes_loss: 2.4045\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9559 - output_headline_vector_loss: 0.0281 - headline_token_classes_loss: 1.9278 - val_loss: 2.5163 - val_output_headline_vector_loss: 0.0193 - val_headline_token_classes_loss: 2.4970\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9347 - output_headline_vector_loss: 0.0284 - headline_token_classes_loss: 1.9063 - val_loss: 2.4608 - val_output_headline_vector_loss: 0.0230 - val_headline_token_classes_loss: 2.4378\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9541 - output_headline_vector_loss: 0.0267 - headline_token_classes_loss: 1.9274 - val_loss: 2.3422 - val_output_headline_vector_loss: 0.0178 - val_headline_token_classes_loss: 2.3244\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8809 - output_headline_vector_loss: 0.0295 - headline_token_classes_loss: 1.8513 - val_loss: 2.1421 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.1290\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9753 - output_headline_vector_loss: 0.0307 - headline_token_classes_loss: 1.9445 - val_loss: 2.3720 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3618\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9278 - output_headline_vector_loss: 0.0267 - headline_token_classes_loss: 1.9011 - val_loss: 2.4812 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4712\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8715 - output_headline_vector_loss: 0.0263 - headline_token_classes_loss: 1.8452 - val_loss: 2.9091 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8983\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9029 - output_headline_vector_loss: 0.0241 - headline_token_classes_loss: 1.8788 - val_loss: 2.5250 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.5121\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8538 - output_headline_vector_loss: 0.0261 - headline_token_classes_loss: 1.8278 - val_loss: 2.4137 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.4000\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8749 - output_headline_vector_loss: 0.0269 - headline_token_classes_loss: 1.8480 - val_loss: 2.4803 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.4660\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9184 - output_headline_vector_loss: 0.0240 - headline_token_classes_loss: 1.8944 - val_loss: 2.4004 - val_output_headline_vector_loss: 0.0272 - val_headline_token_classes_loss: 2.3732\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8885 - output_headline_vector_loss: 0.0256 - headline_token_classes_loss: 1.8629 - val_loss: 2.4035 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 2.3855\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8770 - output_headline_vector_loss: 0.0259 - headline_token_classes_loss: 1.8511 - val_loss: 2.4200 - val_output_headline_vector_loss: 0.0164 - val_headline_token_classes_loss: 2.4036\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0485 - output_headline_vector_loss: 0.0263 - headline_token_classes_loss: 2.0221 - val_loss: 2.4946 - val_output_headline_vector_loss: 0.0715 - val_headline_token_classes_loss: 2.4231\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8786 - output_headline_vector_loss: 0.0237 - headline_token_classes_loss: 1.8549 - val_loss: 2.5239 - val_output_headline_vector_loss: 0.0250 - val_headline_token_classes_loss: 2.4989\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8851 - output_headline_vector_loss: 0.0231 - headline_token_classes_loss: 1.8620 - val_loss: 2.5256 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.5107\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8776 - output_headline_vector_loss: 0.0231 - headline_token_classes_loss: 1.8545 - val_loss: 2.4557 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.4439\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8479 - output_headline_vector_loss: 0.0223 - headline_token_classes_loss: 1.8256 - val_loss: 2.5122 - val_output_headline_vector_loss: 0.0182 - val_headline_token_classes_loss: 2.4939\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8358 - output_headline_vector_loss: 0.0252 - headline_token_classes_loss: 1.8106 - val_loss: 2.7593 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.7463\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9837 - output_headline_vector_loss: 0.0224 - headline_token_classes_loss: 1.9613 - val_loss: 2.3473 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3354\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8093 - output_headline_vector_loss: 0.0252 - headline_token_classes_loss: 1.7841 - val_loss: 2.3048 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.2917\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8233 - output_headline_vector_loss: 0.0267 - headline_token_classes_loss: 1.7966 - val_loss: 2.6612 - val_output_headline_vector_loss: 0.0167 - val_headline_token_classes_loss: 2.6445\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8687 - output_headline_vector_loss: 0.0231 - headline_token_classes_loss: 1.8456 - val_loss: 2.4482 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.4367\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8318 - output_headline_vector_loss: 0.0232 - headline_token_classes_loss: 1.8086 - val_loss: 2.5715 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.5620\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0023 - output_headline_vector_loss: 0.0238 - headline_token_classes_loss: 1.9785 - val_loss: 2.3914 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3812\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9041 - output_headline_vector_loss: 0.0234 - headline_token_classes_loss: 1.8806 - val_loss: 2.6041 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5921\n",
      "Epoch 406/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.8160 - output_headline_vector_loss: 0.0229 - headline_token_classes_loss: 1.7931 - val_loss: 2.5165 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.5042\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9003 - output_headline_vector_loss: 0.0226 - headline_token_classes_loss: 1.8776 - val_loss: 2.2767 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.2652\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8335 - output_headline_vector_loss: 0.0229 - headline_token_classes_loss: 1.8106 - val_loss: 2.5497 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.5372\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9393 - output_headline_vector_loss: 0.0217 - headline_token_classes_loss: 1.9176 - val_loss: 2.3644 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.3516\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9942 - output_headline_vector_loss: 0.0209 - headline_token_classes_loss: 1.9733 - val_loss: 2.7427 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7324\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9442 - output_headline_vector_loss: 0.0220 - headline_token_classes_loss: 1.9222 - val_loss: 2.5004 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4901\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8972 - output_headline_vector_loss: 0.0198 - headline_token_classes_loss: 1.8774 - val_loss: 2.6383 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.6259\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8941 - output_headline_vector_loss: 0.0231 - headline_token_classes_loss: 1.8710 - val_loss: 2.2693 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2579\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7789 - output_headline_vector_loss: 0.0202 - headline_token_classes_loss: 1.7587 - val_loss: 2.7150 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7043\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7482 - output_headline_vector_loss: 0.0233 - headline_token_classes_loss: 1.7249 - val_loss: 2.4795 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.4677\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8350 - output_headline_vector_loss: 0.0206 - headline_token_classes_loss: 1.8144 - val_loss: 2.4726 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4616\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8849 - output_headline_vector_loss: 0.0218 - headline_token_classes_loss: 1.8631 - val_loss: 2.3366 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3257\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8568 - output_headline_vector_loss: 0.0205 - headline_token_classes_loss: 1.8363 - val_loss: 2.3117 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.2998\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7802 - output_headline_vector_loss: 0.0206 - headline_token_classes_loss: 1.7596 - val_loss: 2.4496 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4388\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9074 - output_headline_vector_loss: 0.0215 - headline_token_classes_loss: 1.8860 - val_loss: 2.8152 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.8033\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8965 - output_headline_vector_loss: 0.0204 - headline_token_classes_loss: 1.8761 - val_loss: 2.6947 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6841\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7314 - output_headline_vector_loss: 0.0220 - headline_token_classes_loss: 1.7095 - val_loss: 2.4695 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4589\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8517 - output_headline_vector_loss: 0.0201 - headline_token_classes_loss: 1.8316 - val_loss: 2.6961 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.6868\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8355 - output_headline_vector_loss: 0.0190 - headline_token_classes_loss: 1.8165 - val_loss: 2.3581 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3473\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7963 - output_headline_vector_loss: 0.0188 - headline_token_classes_loss: 1.7775 - val_loss: 2.5850 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5752\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7578 - output_headline_vector_loss: 0.0187 - headline_token_classes_loss: 1.7390 - val_loss: 2.5802 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5710\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7669 - output_headline_vector_loss: 0.0195 - headline_token_classes_loss: 1.7474 - val_loss: 2.3580 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3480\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8020 - output_headline_vector_loss: 0.0205 - headline_token_classes_loss: 1.7815 - val_loss: 2.8870 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8763\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8217 - output_headline_vector_loss: 0.0209 - headline_token_classes_loss: 1.8008 - val_loss: 2.5728 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.5615\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9285 - output_headline_vector_loss: 0.0184 - headline_token_classes_loss: 1.9100 - val_loss: 2.5363 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5265\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8569 - output_headline_vector_loss: 0.0206 - headline_token_classes_loss: 1.8363 - val_loss: 2.1741 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.1637\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8933 - output_headline_vector_loss: 0.0180 - headline_token_classes_loss: 1.8753 - val_loss: 2.1815 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.1690\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8041 - output_headline_vector_loss: 0.0191 - headline_token_classes_loss: 1.7850 - val_loss: 2.8038 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7926\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6575 - output_headline_vector_loss: 0.0205 - headline_token_classes_loss: 1.6370 - val_loss: 2.7220 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7123\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7160 - output_headline_vector_loss: 0.0200 - headline_token_classes_loss: 1.6960 - val_loss: 2.5859 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5758\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7204 - output_headline_vector_loss: 0.0205 - headline_token_classes_loss: 1.6999 - val_loss: 2.5620 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5512\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7048 - output_headline_vector_loss: 0.0190 - headline_token_classes_loss: 1.6858 - val_loss: 2.5577 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5460\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8288 - output_headline_vector_loss: 0.0187 - headline_token_classes_loss: 1.8101 - val_loss: 2.2777 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.2675\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7097 - output_headline_vector_loss: 0.0191 - headline_token_classes_loss: 1.6906 - val_loss: 2.3237 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3131\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8619 - output_headline_vector_loss: 0.0191 - headline_token_classes_loss: 1.8428 - val_loss: 2.6442 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.6350\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6757 - output_headline_vector_loss: 0.0187 - headline_token_classes_loss: 1.6570 - val_loss: 2.3406 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3304\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8220 - output_headline_vector_loss: 0.0176 - headline_token_classes_loss: 1.8044 - val_loss: 2.7472 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7377\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6706 - output_headline_vector_loss: 0.0181 - headline_token_classes_loss: 1.6526 - val_loss: 2.3854 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3749\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6842 - output_headline_vector_loss: 0.0177 - headline_token_classes_loss: 1.6665 - val_loss: 2.4245 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.4148\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9031 - output_headline_vector_loss: 0.0169 - headline_token_classes_loss: 1.8861 - val_loss: 2.8193 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.8093\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5755 - output_headline_vector_loss: 0.0169 - headline_token_classes_loss: 2.5586 - val_loss: 3.6101 - val_output_headline_vector_loss: 0.0468 - val_headline_token_classes_loss: 3.5633\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.1951 - output_headline_vector_loss: 0.0197 - headline_token_classes_loss: 3.1754 - val_loss: 3.4577 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 3.4444\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2531 - output_headline_vector_loss: 0.0183 - headline_token_classes_loss: 3.2348 - val_loss: 3.4044 - val_output_headline_vector_loss: 0.1224 - val_headline_token_classes_loss: 3.2821\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.1489 - output_headline_vector_loss: 0.0189 - headline_token_classes_loss: 3.1300 - val_loss: 8.2354 - val_output_headline_vector_loss: 5.0673 - val_headline_token_classes_loss: 3.1681\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.0108 - output_headline_vector_loss: 0.0170 - headline_token_classes_loss: 2.9937 - val_loss: 5.2243 - val_output_headline_vector_loss: 2.0668 - val_headline_token_classes_loss: 3.1574\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8527 - output_headline_vector_loss: 0.0180 - headline_token_classes_loss: 2.8347 - val_loss: 4.1046 - val_output_headline_vector_loss: 0.8108 - val_headline_token_classes_loss: 3.2938\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8067 - output_headline_vector_loss: 0.0176 - headline_token_classes_loss: 2.7890 - val_loss: 3.9078 - val_output_headline_vector_loss: 0.4351 - val_headline_token_classes_loss: 3.4727\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7368 - output_headline_vector_loss: 0.0172 - headline_token_classes_loss: 2.7196 - val_loss: 3.1442 - val_output_headline_vector_loss: 0.1082 - val_headline_token_classes_loss: 3.0361\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8024 - output_headline_vector_loss: 0.0180 - headline_token_classes_loss: 2.7844 - val_loss: 3.1085 - val_output_headline_vector_loss: 0.1204 - val_headline_token_classes_loss: 2.9880\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8891 - output_headline_vector_loss: 0.0172 - headline_token_classes_loss: 2.8719 - val_loss: 3.1985 - val_output_headline_vector_loss: 0.0533 - val_headline_token_classes_loss: 3.1452\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8057 - output_headline_vector_loss: 0.0172 - headline_token_classes_loss: 2.7885 - val_loss: 2.9359 - val_output_headline_vector_loss: 0.0382 - val_headline_token_classes_loss: 2.8977\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7862 - output_headline_vector_loss: 0.0168 - headline_token_classes_loss: 2.7694 - val_loss: 3.2324 - val_output_headline_vector_loss: 0.1009 - val_headline_token_classes_loss: 3.1315\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8941 - output_headline_vector_loss: 0.0174 - headline_token_classes_loss: 2.8767 - val_loss: 3.4061 - val_output_headline_vector_loss: 0.0914 - val_headline_token_classes_loss: 3.3147\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.7366 - output_headline_vector_loss: 0.0179 - headline_token_classes_loss: 2.7187 - val_loss: 3.2709 - val_output_headline_vector_loss: 0.0837 - val_headline_token_classes_loss: 3.1872\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7426 - output_headline_vector_loss: 0.0163 - headline_token_classes_loss: 2.7263 - val_loss: 3.1703 - val_output_headline_vector_loss: 0.0512 - val_headline_token_classes_loss: 3.1191\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6257 - output_headline_vector_loss: 0.0174 - headline_token_classes_loss: 2.6084 - val_loss: 3.1818 - val_output_headline_vector_loss: 0.0391 - val_headline_token_classes_loss: 3.1427\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8218 - output_headline_vector_loss: 0.0175 - headline_token_classes_loss: 2.8043 - val_loss: 3.0454 - val_output_headline_vector_loss: 0.0169 - val_headline_token_classes_loss: 3.0285\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.6382 - output_headline_vector_loss: 0.0165 - headline_token_classes_loss: 2.6218 - val_loss: 3.2630 - val_output_headline_vector_loss: 0.0181 - val_headline_token_classes_loss: 3.2450\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8651 - output_headline_vector_loss: 0.0165 - headline_token_classes_loss: 2.8486 - val_loss: 3.2499 - val_output_headline_vector_loss: 0.0550 - val_headline_token_classes_loss: 3.1949\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7986 - output_headline_vector_loss: 0.0161 - headline_token_classes_loss: 2.7826 - val_loss: 3.3106 - val_output_headline_vector_loss: 0.0248 - val_headline_token_classes_loss: 3.2858\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8178 - output_headline_vector_loss: 0.0157 - headline_token_classes_loss: 2.8021 - val_loss: 3.1557 - val_output_headline_vector_loss: 0.0235 - val_headline_token_classes_loss: 3.1323\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7171 - output_headline_vector_loss: 0.0163 - headline_token_classes_loss: 2.7008 - val_loss: 3.3620 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 3.3469\n",
      "Epoch 468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 2.7336 - output_headline_vector_loss: 0.0167 - headline_token_classes_loss: 2.7170 - val_loss: 3.2860 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 3.2738\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.6562 - output_headline_vector_loss: 0.0174 - headline_token_classes_loss: 2.6388 - val_loss: 3.2783 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.2680\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7105 - output_headline_vector_loss: 0.0162 - headline_token_classes_loss: 2.6943 - val_loss: 3.0878 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 3.0749\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6030 - output_headline_vector_loss: 0.0171 - headline_token_classes_loss: 2.5859 - val_loss: 3.2940 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 3.2848\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.8199 - output_headline_vector_loss: 0.0157 - headline_token_classes_loss: 2.8043 - val_loss: 3.1636 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.1524\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7198 - output_headline_vector_loss: 0.0173 - headline_token_classes_loss: 2.7026 - val_loss: 2.9748 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.9623\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6405 - output_headline_vector_loss: 0.0160 - headline_token_classes_loss: 2.6244 - val_loss: 3.3366 - val_output_headline_vector_loss: 0.0078 - val_headline_token_classes_loss: 3.3287\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5415 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.5265 - val_loss: 3.0067 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.9955\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6089 - output_headline_vector_loss: 0.0168 - headline_token_classes_loss: 2.5920 - val_loss: 2.8864 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.8754\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5658 - output_headline_vector_loss: 0.0163 - headline_token_classes_loss: 2.5494 - val_loss: 3.1260 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.1157\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7835 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.7693 - val_loss: 3.0054 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.9951\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7216 - output_headline_vector_loss: 0.0154 - headline_token_classes_loss: 2.7062 - val_loss: 2.9150 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.9037\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5688 - output_headline_vector_loss: 0.0160 - headline_token_classes_loss: 2.5528 - val_loss: 2.8775 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8676\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6427 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.6278 - val_loss: 3.1220 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 3.1095\n",
      "Epoch 482/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6040 - output_headline_vector_loss: 0.0153 - headline_token_classes_loss: 2.5887 - val_loss: 3.0497 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.0389\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.4886 - output_headline_vector_loss: 0.0154 - headline_token_classes_loss: 2.4732 - val_loss: 3.0540 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.0427\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5043 - output_headline_vector_loss: 0.0152 - headline_token_classes_loss: 2.4891 - val_loss: 2.9277 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.9164\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4955 - output_headline_vector_loss: 0.0152 - headline_token_classes_loss: 2.4803 - val_loss: 3.1825 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 3.1728\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3987 - output_headline_vector_loss: 0.0152 - headline_token_classes_loss: 2.3834 - val_loss: 2.8172 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8072\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4379 - output_headline_vector_loss: 0.0159 - headline_token_classes_loss: 2.4220 - val_loss: 2.9186 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9078\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5155 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.5003 - val_loss: 3.0732 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.0627\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4692 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.4541 - val_loss: 2.8620 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.8474\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4258 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.4108 - val_loss: 2.9251 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.9142\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3995 - output_headline_vector_loss: 0.0149 - headline_token_classes_loss: 2.3846 - val_loss: 2.7087 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.6962\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4582 - output_headline_vector_loss: 0.0145 - headline_token_classes_loss: 2.4438 - val_loss: 2.8053 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7955\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3097 - output_headline_vector_loss: 0.0147 - headline_token_classes_loss: 2.2950 - val_loss: 2.8311 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.8219\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3878 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.3727 - val_loss: 3.2441 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.2328\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4367 - output_headline_vector_loss: 0.0143 - headline_token_classes_loss: 2.4224 - val_loss: 2.7061 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6951\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2719 - output_headline_vector_loss: 0.0148 - headline_token_classes_loss: 2.2571 - val_loss: 2.6745 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6637\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3691 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.3552 - val_loss: 2.9688 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.9590\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4828 - output_headline_vector_loss: 0.0146 - headline_token_classes_loss: 2.4681 - val_loss: 2.9573 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.9468\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4115 - output_headline_vector_loss: 0.0147 - headline_token_classes_loss: 2.3968 - val_loss: 2.9237 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.9143\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3495 - output_headline_vector_loss: 0.0148 - headline_token_classes_loss: 2.3346 - val_loss: 2.7753 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7650\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3415 - output_headline_vector_loss: 0.0145 - headline_token_classes_loss: 2.3270 - val_loss: 2.7862 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7751\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5629 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.5487 - val_loss: 2.9372 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.9257\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2238 - output_headline_vector_loss: 0.0149 - headline_token_classes_loss: 2.2089 - val_loss: 2.8736 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8623\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3477 - output_headline_vector_loss: 0.0132 - headline_token_classes_loss: 2.3345 - val_loss: 2.6198 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6104\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3335 - output_headline_vector_loss: 0.0141 - headline_token_classes_loss: 2.3194 - val_loss: 2.5957 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5856\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4164 - output_headline_vector_loss: 0.0136 - headline_token_classes_loss: 2.4028 - val_loss: 2.7959 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7847\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.2862 - output_headline_vector_loss: 0.0144 - headline_token_classes_loss: 2.2718 - val_loss: 2.8167 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.8069\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3195 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.3056 - val_loss: 2.8996 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.8862\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3408 - output_headline_vector_loss: 0.0140 - headline_token_classes_loss: 2.3269 - val_loss: 2.7106 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6991\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3714 - output_headline_vector_loss: 0.0141 - headline_token_classes_loss: 2.3573 - val_loss: 2.9136 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.9042\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4420 - output_headline_vector_loss: 0.0141 - headline_token_classes_loss: 2.4280 - val_loss: 2.7104 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6996\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3551 - output_headline_vector_loss: 0.0137 - headline_token_classes_loss: 2.3414 - val_loss: 2.7265 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7168\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3329 - output_headline_vector_loss: 0.0144 - headline_token_classes_loss: 2.3185 - val_loss: 2.7123 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7012\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2557 - output_headline_vector_loss: 0.0143 - headline_token_classes_loss: 2.2414 - val_loss: 2.7914 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7820\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2993 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.2858 - val_loss: 2.5289 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5186\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2991 - output_headline_vector_loss: 0.0136 - headline_token_classes_loss: 2.2855 - val_loss: 2.6949 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.6862\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3283 - output_headline_vector_loss: 0.0133 - headline_token_classes_loss: 2.3150 - val_loss: 2.7055 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6961\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3648 - output_headline_vector_loss: 0.0137 - headline_token_classes_loss: 2.3511 - val_loss: 2.4394 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.4273\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2000 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.1858 - val_loss: 2.6877 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6780\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1235 - output_headline_vector_loss: 0.0141 - headline_token_classes_loss: 2.1094 - val_loss: 2.7093 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.7001\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2739 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.2612 - val_loss: 2.7701 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.7608\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3933 - output_headline_vector_loss: 0.0138 - headline_token_classes_loss: 2.3795 - val_loss: 2.4353 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.4257\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.2676 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.2541 - val_loss: 2.8136 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8028\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2017 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.1882 - val_loss: 2.7986 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.7899\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1604 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.1464 - val_loss: 2.6706 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6592\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2803 - output_headline_vector_loss: 0.0134 - headline_token_classes_loss: 2.2669 - val_loss: 2.7405 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.7312\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3219 - output_headline_vector_loss: 0.0133 - headline_token_classes_loss: 2.3086 - val_loss: 2.5374 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5282\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4871 - output_headline_vector_loss: 0.0134 - headline_token_classes_loss: 2.4737 - val_loss: 2.4752 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4655\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2889 - output_headline_vector_loss: 0.0133 - headline_token_classes_loss: 2.2756 - val_loss: 2.7418 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7307\n",
      "Epoch 530/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.3100 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.2971 - val_loss: 2.5794 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5695\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4174 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.4050 - val_loss: 2.5567 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5460\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3221 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.3094 - val_loss: 2.8739 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.8642\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1366 - output_headline_vector_loss: 0.0136 - headline_token_classes_loss: 2.1230 - val_loss: 2.6134 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6026\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2454 - output_headline_vector_loss: 0.0134 - headline_token_classes_loss: 2.2320 - val_loss: 2.8126 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8022\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3315 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 2.3184 - val_loss: 2.5666 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5555\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2449 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.2324 - val_loss: 2.7177 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7056\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3291 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.3164 - val_loss: 2.7946 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7844\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3037 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.2914 - val_loss: 2.5508 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.5382\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1549 - output_headline_vector_loss: 0.0137 - headline_token_classes_loss: 2.1411 - val_loss: 2.7102 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.6984\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2542 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.2407 - val_loss: 2.5633 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5534\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3316 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.3180 - val_loss: 2.5930 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5818\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1969 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.1830 - val_loss: 2.7951 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7846\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1545 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 2.1415 - val_loss: 2.6989 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6882\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1839 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.1710 - val_loss: 2.5761 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5654\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1995 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.1866 - val_loss: 2.7256 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7153\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1679 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1558 - val_loss: 2.7411 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.7287\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2074 - output_headline_vector_loss: 0.0132 - headline_token_classes_loss: 2.1942 - val_loss: 2.7751 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.7626\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0564 - output_headline_vector_loss: 0.0136 - headline_token_classes_loss: 2.0428 - val_loss: 2.6238 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6130\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2417 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 2.2286 - val_loss: 2.7955 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7849\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1684 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 2.1554 - val_loss: 2.3635 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.3499\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.2968 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.2854 - val_loss: 2.5375 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5271\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2128 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 2.1997 - val_loss: 2.6186 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.6090\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2856 - output_headline_vector_loss: 0.0134 - headline_token_classes_loss: 2.2722 - val_loss: 2.8010 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7908\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0575 - output_headline_vector_loss: 0.0134 - headline_token_classes_loss: 2.0441 - val_loss: 2.5849 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.5718\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0992 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.0864 - val_loss: 2.5120 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5020\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3112 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.2989 - val_loss: 2.9643 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.9536\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0860 - output_headline_vector_loss: 0.0137 - headline_token_classes_loss: 2.0723 - val_loss: 2.5302 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.5160\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2235 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.2114 - val_loss: 2.4671 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.4545\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1903 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1782 - val_loss: 2.6495 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6379\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2061 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.1951 - val_loss: 2.6180 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6080\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0732 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.0607 - val_loss: 2.4111 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.3990\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0961 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.0837 - val_loss: 2.5669 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5560\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1984 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.1862 - val_loss: 2.6403 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6305\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1905 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.1790 - val_loss: 2.5692 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5574\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.0831 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.0704 - val_loss: 2.6563 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.6472\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0491 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.0370 - val_loss: 2.7581 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.7486\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1438 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1317 - val_loss: 2.7041 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.6949\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0774 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.0639 - val_loss: 2.5461 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5351\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2599 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.2476 - val_loss: 2.7346 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.7247\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1625 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.1506 - val_loss: 2.5452 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5347\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0314 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.0190 - val_loss: 2.6163 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6065\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1282 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.1153 - val_loss: 2.4691 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4585\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1344 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.1225 - val_loss: 2.4951 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.4835\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2319 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.2201 - val_loss: 2.6131 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.6042\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0974 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.0851 - val_loss: 2.4497 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4397\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1448 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.1331 - val_loss: 2.5573 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5475\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.1937 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1823 - val_loss: 2.5012 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4905\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2636 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.2524 - val_loss: 2.5185 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5063\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.2506 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2397 - val_loss: 2.4486 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.4391\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0385 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0268 - val_loss: 2.4352 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4230\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0739 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.0619 - val_loss: 2.5657 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5555\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1322 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1211 - val_loss: 2.6450 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6353\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0355 - output_headline_vector_loss: 0.0132 - headline_token_classes_loss: 2.0224 - val_loss: 2.5380 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5274\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2531 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.2410 - val_loss: 2.2752 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2644\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2005 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.1887 - val_loss: 2.4750 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4652\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1824 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.1708 - val_loss: 2.6134 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6032\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0722 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.0596 - val_loss: 2.4369 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.4242\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0097 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 1.9968 - val_loss: 2.6697 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6603\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1787 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.1664 - val_loss: 2.6142 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6029\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2972 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.2857 - val_loss: 3.1337 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.1235\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1746 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.1620 - val_loss: 2.9320 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9212\n",
      "Epoch 592/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.3589 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.3479 - val_loss: 2.8082 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7981\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3640 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.3528 - val_loss: 2.7945 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7831\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2533 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.2415 - val_loss: 2.6998 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.6867\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4101 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.3987 - val_loss: 2.3003 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.2879\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.1530 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.1413 - val_loss: 2.5700 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5601\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2413 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.2304 - val_loss: 2.3419 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.3290\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4747 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.4640 - val_loss: 2.4563 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.4446\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.8651 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.8537 - val_loss: 2.5752 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.5637\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7473 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.7355 - val_loss: 2.3199 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3090\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.9638 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.9528 - val_loss: 2.6732 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6627\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7164 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.7037 - val_loss: 2.4587 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4479\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.9315 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.9192 - val_loss: 2.7665 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7568\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.9187 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.9074 - val_loss: 2.3108 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2998\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7733 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.7619 - val_loss: 2.7921 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7814\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7555 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.7437 - val_loss: 2.4757 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4646\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.7593 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.7479 - val_loss: 2.6548 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.6419\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4761 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.4637 - val_loss: 2.4634 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.4511\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7445 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.7328 - val_loss: 2.5719 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5613\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6654 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.6536 - val_loss: 2.7158 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7049\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8647 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.8538 - val_loss: 2.2613 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.2488\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.6172 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.6059 - val_loss: 2.5341 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5226\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6633 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.6516 - val_loss: 2.4302 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4202\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6742 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.6631 - val_loss: 2.2840 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.2722\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7018 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.6906 - val_loss: 2.1060 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.0931\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.6283 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.6165 - val_loss: 2.5226 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5116\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8703 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.8598 - val_loss: 2.3116 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3016\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5844 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.5731 - val_loss: 2.2749 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2636\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.4580 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.4467 - val_loss: 2.7040 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6930\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6748 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.6635 - val_loss: 2.7862 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7758\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6548 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.6435 - val_loss: 2.7679 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7583\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4137 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.4012 - val_loss: 2.4954 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4847\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5228 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.5110 - val_loss: 2.5096 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4990\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4366 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.4250 - val_loss: 2.8265 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.8169\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5521 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.5400 - val_loss: 2.4983 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.4890\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5735 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.5619 - val_loss: 2.8046 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.7951\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5235 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.5123 - val_loss: 2.6573 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6462\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.8013 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.7900 - val_loss: 2.8471 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.8375\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3338 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.3217 - val_loss: 2.5589 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5478\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5847 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.5733 - val_loss: 2.6047 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5939\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7982 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.7872 - val_loss: 2.6255 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6141\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5544 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.5425 - val_loss: 2.3576 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3463\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4709 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.4585 - val_loss: 2.3276 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3172\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5173 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.5056 - val_loss: 2.4749 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4636\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5824 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.5718 - val_loss: 3.1441 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 3.1344\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6536 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.6422 - val_loss: 2.5959 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.5839\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3980 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.3861 - val_loss: 2.4819 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4719\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5989 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.5874 - val_loss: 2.6121 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.6015\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.5155 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.5045 - val_loss: 2.4769 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4670\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5929 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.5821 - val_loss: 2.5692 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5589\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4087 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.3975 - val_loss: 2.5040 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4934\n",
      "Epoch 642/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5330 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.5227 - val_loss: 2.5952 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.5836\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4247 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.4134 - val_loss: 2.4246 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4140\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4529 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.4419 - val_loss: 2.6774 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6671\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4728 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.4607 - val_loss: 2.8455 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8352\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5166 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.5050 - val_loss: 2.5865 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5758\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4819 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.4703 - val_loss: 2.4437 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4326\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5281 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.5167 - val_loss: 2.5140 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.5046\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5431 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.5315 - val_loss: 2.4498 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4387\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5515 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.5403 - val_loss: 2.5465 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.5335\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6207 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.6097 - val_loss: 2.2497 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.2362\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6078 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.5962 - val_loss: 2.7620 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.7527\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5319 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.5210 - val_loss: 2.6717 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.6624\n",
      "Epoch 654/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 2.4227 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.4114 - val_loss: 2.7917 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7812\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2470 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.2354 - val_loss: 2.7087 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6969\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3778 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.3655 - val_loss: 2.5730 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5639\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2986 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.2867 - val_loss: 2.6887 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6792\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.4774 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.4654 - val_loss: 2.4682 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4572\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5053 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.4946 - val_loss: 2.7387 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.7268\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2775 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.2655 - val_loss: 3.0085 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.9998\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4816 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.4711 - val_loss: 2.5988 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5872\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3975 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.3861 - val_loss: 2.6302 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6195\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4336 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.4220 - val_loss: 2.6144 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6047\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4751 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.4636 - val_loss: 2.4404 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4296\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3428 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.3312 - val_loss: 2.4374 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.4255\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4343 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.4229 - val_loss: 2.2665 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.2539\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4103 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.3987 - val_loss: 2.7721 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7607\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5664 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.5561 - val_loss: 2.7320 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7221\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3577 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.3464 - val_loss: 2.6686 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.6595\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2672 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.2553 - val_loss: 2.3018 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2908\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3619 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.3496 - val_loss: 2.4322 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4217\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4039 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.3932 - val_loss: 2.6649 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6548\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3281 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.3156 - val_loss: 2.3341 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3223\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6035 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.5931 - val_loss: 3.0471 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.0368\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3673 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.3557 - val_loss: 2.6344 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6232\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4747 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.4632 - val_loss: 2.8077 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7976\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4905 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.4791 - val_loss: 2.7969 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7866\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3465 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.3355 - val_loss: 2.3978 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3864\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5971 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.5863 - val_loss: 2.7117 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.7022\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3831 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.3717 - val_loss: 2.7812 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.7726\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2385 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.2266 - val_loss: 2.8139 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8042\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4380 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.4269 - val_loss: 2.6202 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.6075\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2772 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.2655 - val_loss: 2.8318 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8218\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4610 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.4498 - val_loss: 2.6935 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6830\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2809 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.2693 - val_loss: 2.8057 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7951\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1363 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.1240 - val_loss: 2.4700 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.4585\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3651 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.3532 - val_loss: 2.6580 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6483\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3128 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.3016 - val_loss: 2.6158 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6049\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2786 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.2677 - val_loss: 3.0786 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 3.0694\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2686 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.2567 - val_loss: 2.5558 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5449\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4048 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.3943 - val_loss: 2.5330 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5228\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5303 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.5198 - val_loss: 2.3974 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3864\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2488 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.2366 - val_loss: 2.6299 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6195\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2848 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.2732 - val_loss: 3.0446 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.0344\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4115 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.3996 - val_loss: 2.6140 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6041\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3894 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.3785 - val_loss: 2.6603 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6499\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6041 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.5932 - val_loss: 2.6471 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6369\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5026 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.4919 - val_loss: 2.2630 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2517\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3200 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.3086 - val_loss: 2.7313 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.7192\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5093 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.4986 - val_loss: 2.6657 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.6562\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4480 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.4376 - val_loss: 2.7225 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7109\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2820 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.2714 - val_loss: 2.8581 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.8481\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2998 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.2885 - val_loss: 2.3877 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3772\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2390 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.2277 - val_loss: 2.8706 - val_output_headline_vector_loss: 0.0086 - val_headline_token_classes_loss: 2.8620\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3587 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.3467 - val_loss: 2.7351 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.7220\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5297 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 2.5196 - val_loss: 2.5642 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5520\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2588 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.2479 - val_loss: 2.3865 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3750\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2766 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.2645 - val_loss: 2.4372 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4268\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2111 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.1993 - val_loss: 2.5058 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4953\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3888 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.3781 - val_loss: 2.7183 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.7083\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.3353 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.3233 - val_loss: 2.5891 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.5766\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3516 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.3402 - val_loss: 2.6296 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6194\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4717 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.4610 - val_loss: 2.7491 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7394\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2921 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.2812 - val_loss: 2.7535 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7430\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3060 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.2948 - val_loss: 2.5057 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.4942\n",
      "Epoch 716/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.2743 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.2632 - val_loss: 2.6740 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6633\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3285 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.3173 - val_loss: 2.5401 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5286\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3416 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.3307 - val_loss: 3.0336 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.0231\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3025 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2915 - val_loss: 2.5746 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.5626\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2111 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.2006 - val_loss: 2.6415 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6308\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3710 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.3607 - val_loss: 2.4407 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4303\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4186 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.4077 - val_loss: 2.6245 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6138\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2108 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1987 - val_loss: 2.5139 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5029\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5098 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.4997 - val_loss: 2.8286 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.8167\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2564 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.2449 - val_loss: 2.6515 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6397\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1886 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.1771 - val_loss: 2.5261 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5152\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2875 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.2768 - val_loss: 2.5262 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5163\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2828 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.2715 - val_loss: 2.7594 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.7472\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2167 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.2049 - val_loss: 2.2716 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2605\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2597 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.2474 - val_loss: 2.9339 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.9229\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3056 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.2949 - val_loss: 2.4802 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4694\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2831 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.2718 - val_loss: 2.5957 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5850\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2869 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2758 - val_loss: 2.6820 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6716\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3653 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.3545 - val_loss: 2.3941 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3828\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2180 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.2073 - val_loss: 2.2711 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2599\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3336 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.3230 - val_loss: 2.6113 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5997\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2885 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2775 - val_loss: 2.5130 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.5006\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3110 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.3006 - val_loss: 2.7480 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.7386\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2216 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.2100 - val_loss: 2.5397 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5298\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3565 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.3455 - val_loss: 2.5117 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5002\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3073 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.2969 - val_loss: 2.4447 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4343\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3876 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.3764 - val_loss: 2.5868 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5754\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2119 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.1999 - val_loss: 2.3899 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.3778\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3490 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.3381 - val_loss: 2.3126 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3018\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2606 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.2497 - val_loss: 2.6323 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6225\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3097 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2988 - val_loss: 2.4995 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4893\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2368 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.2248 - val_loss: 2.6473 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6376\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3307 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.3196 - val_loss: 2.6373 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6262\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2794 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.2691 - val_loss: 2.7266 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7164\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.2942 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.2828 - val_loss: 2.4514 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4417\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1463 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.1348 - val_loss: 2.6427 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6318\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2879 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.2761 - val_loss: 2.7843 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7739\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.2987 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.2879 - val_loss: 2.5543 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.5419\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1501 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1390 - val_loss: 2.6257 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6150\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1529 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.1420 - val_loss: 2.4737 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4626\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1768 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.1656 - val_loss: 2.4846 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.4728\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0839 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.0724 - val_loss: 2.4008 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3907\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1807 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1695 - val_loss: 2.4483 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4377\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2641 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.2532 - val_loss: 2.5657 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5552\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2156 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.2041 - val_loss: 2.4789 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4691\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0952 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.0832 - val_loss: 2.6438 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6329\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3463 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.3361 - val_loss: 2.5634 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5538\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3353 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.3248 - val_loss: 2.3548 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3444\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1216 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.1098 - val_loss: 2.6152 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6054\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2155 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.2044 - val_loss: 2.5191 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.5066\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3181 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.3063 - val_loss: 2.7180 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7062\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1326 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.1218 - val_loss: 2.6014 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5909\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3440 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.3333 - val_loss: 2.3571 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3452\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2260 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.2152 - val_loss: 2.4465 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.4340\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2359 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 2.2260 - val_loss: 2.9064 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8963\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.2419 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.2311 - val_loss: 2.7039 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6927\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.1710 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1599 - val_loss: 2.7661 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7551\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.2328 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2218 - val_loss: 2.4857 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.4742\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1215 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.1105 - val_loss: 2.3772 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3672\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2037 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1927 - val_loss: 2.5661 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5559\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0492 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0381 - val_loss: 2.4810 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.4678\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1440 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1329 - val_loss: 2.5495 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5384\n",
      "Epoch 778/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step - loss: 2.1912 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1799 - val_loss: 2.6536 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.6446\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2435 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.2327 - val_loss: 2.3900 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3775\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.2077 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1972 - val_loss: 2.3816 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3705\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2013 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.1910 - val_loss: 2.3850 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.3753\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0954 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0846 - val_loss: 2.4405 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4302\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1717 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.1610 - val_loss: 2.3364 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3245\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1039 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0928 - val_loss: 2.4413 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4307\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2077 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1966 - val_loss: 2.2506 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2395\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0171 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.0058 - val_loss: 2.3978 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.3843\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2373 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.2264 - val_loss: 2.5512 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5408\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1706 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.1599 - val_loss: 2.7930 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.7813\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1581 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.1473 - val_loss: 2.4028 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3913\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0227 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.0110 - val_loss: 2.5768 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5667\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1855 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1750 - val_loss: 2.5586 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5483\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0958 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0851 - val_loss: 2.8949 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.8853\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0279 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0168 - val_loss: 2.1875 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.1747\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1177 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.1071 - val_loss: 2.5557 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5452\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0226 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0112 - val_loss: 2.3454 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3354\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1944 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.1840 - val_loss: 2.8467 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.8375\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1602 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.1490 - val_loss: 2.7199 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7084\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1033 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.0918 - val_loss: 2.6142 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6032\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0433 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0316 - val_loss: 2.3254 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.3135\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1262 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1151 - val_loss: 2.6676 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6558\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1242 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1130 - val_loss: 2.4892 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4784\n",
      "Epoch 802/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2101 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.1994 - val_loss: 2.5645 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5553\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0594 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0482 - val_loss: 2.5908 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5806\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1589 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.1486 - val_loss: 2.7885 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.7765\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0562 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0452 - val_loss: 2.2160 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2051\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0134 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0022 - val_loss: 2.5106 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4996\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1117 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.1006 - val_loss: 2.6751 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6647\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0534 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0427 - val_loss: 2.5348 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.5224\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1567 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1462 - val_loss: 2.5906 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5808\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.1315 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.1205 - val_loss: 2.5588 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5491\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2495 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.2391 - val_loss: 2.5310 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5203\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0060 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9951 - val_loss: 2.7066 - val_output_headline_vector_loss: 0.0086 - val_headline_token_classes_loss: 2.6981\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0851 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0744 - val_loss: 2.5295 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5192\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0165 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0057 - val_loss: 2.4482 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4376\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0946 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.0827 - val_loss: 2.5952 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.5817\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9896 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9792 - val_loss: 2.3986 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.3893\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0707 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0605 - val_loss: 2.7371 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.7275\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1739 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.1622 - val_loss: 2.5119 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.5003\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2566 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.2461 - val_loss: 2.5991 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.5902\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0335 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0218 - val_loss: 2.7984 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.7891\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9864 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.9765 - val_loss: 2.7844 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7742\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0963 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0853 - val_loss: 2.4676 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4567\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1332 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.1229 - val_loss: 2.4193 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4081\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1517 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1411 - val_loss: 2.5555 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.5442\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1069 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.0966 - val_loss: 2.9074 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.8984\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0092 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9981 - val_loss: 2.5595 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5490\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1282 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.1172 - val_loss: 2.3680 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3572\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0199 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0091 - val_loss: 2.5589 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5492\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9241 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9125 - val_loss: 2.6403 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6293\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9216 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9106 - val_loss: 2.5234 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5125\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0998 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0890 - val_loss: 2.5537 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5437\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0004 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9897 - val_loss: 2.7443 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7321\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0126 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0018 - val_loss: 2.5397 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5288\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0374 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0267 - val_loss: 2.5357 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5257\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8714 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8601 - val_loss: 2.7825 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7715\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0299 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0187 - val_loss: 2.2692 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2588\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9837 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9733 - val_loss: 2.3575 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3472\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0566 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0457 - val_loss: 2.7072 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.6983\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0324 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.0210 - val_loss: 2.4245 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4141\n",
      "Epoch 840/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 3s/step - loss: 1.9444 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9331 - val_loss: 2.3650 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3551\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0058 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9955 - val_loss: 2.5090 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.4995\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0740 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0630 - val_loss: 2.7322 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7209\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0270 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0165 - val_loss: 2.7078 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6980\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0053 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9942 - val_loss: 2.6709 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6615\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9839 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9728 - val_loss: 2.6725 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6610\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9721 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9609 - val_loss: 2.4451 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.4338\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9643 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9542 - val_loss: 2.3833 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3735\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9052 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8937 - val_loss: 2.3787 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3687\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9794 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9682 - val_loss: 2.5795 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5699\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9837 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9733 - val_loss: 2.6486 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.6380\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0158 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.0043 - val_loss: 2.7228 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.7127\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0617 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0506 - val_loss: 2.3592 - val_output_headline_vector_loss: 0.0272 - val_headline_token_classes_loss: 2.3320\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0932 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0829 - val_loss: 2.4034 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.3901\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9822 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9718 - val_loss: 2.3448 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.3328\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1246 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.1139 - val_loss: 2.4791 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.4672\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0386 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0274 - val_loss: 2.8236 - val_output_headline_vector_loss: 0.0083 - val_headline_token_classes_loss: 2.8153\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8650 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8539 - val_loss: 2.3671 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3546\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9447 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.9331 - val_loss: 2.4439 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.4325\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.1374 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1263 - val_loss: 2.5865 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5749\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.1057 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0947 - val_loss: 2.6370 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6256\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9527 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9418 - val_loss: 2.3995 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3887\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0168 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0058 - val_loss: 2.5613 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5517\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9991 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9883 - val_loss: 2.3267 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3157\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9622 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9511 - val_loss: 2.4762 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.4614\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9766 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9653 - val_loss: 2.5148 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5041\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0540 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.0436 - val_loss: 2.6874 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6767\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0476 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0364 - val_loss: 2.4754 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.4633\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0241 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0139 - val_loss: 2.6014 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.5922\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9917 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9812 - val_loss: 2.6584 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.6492\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8110 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7994 - val_loss: 2.6205 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6093\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0088 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9987 - val_loss: 2.5916 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5797\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9040 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8932 - val_loss: 2.8013 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.7892\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0709 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0604 - val_loss: 2.7593 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7482\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9678 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9567 - val_loss: 2.5455 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5338\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0205 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0098 - val_loss: 2.6226 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6129\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9945 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9839 - val_loss: 2.6363 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6262\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9946 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.9828 - val_loss: 2.7515 - val_output_headline_vector_loss: 0.0085 - val_headline_token_classes_loss: 2.7430\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8848 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8741 - val_loss: 2.3864 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3755\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9962 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9852 - val_loss: 2.4777 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.4650\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9362 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9250 - val_loss: 2.6340 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6245\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0448 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0345 - val_loss: 2.7096 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.6976\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1301 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.1199 - val_loss: 2.2952 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2836\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1127 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1022 - val_loss: 2.5964 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.5871\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0335 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0220 - val_loss: 2.6663 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6555\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9888 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9771 - val_loss: 2.5616 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5518\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9627 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9524 - val_loss: 2.4683 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4571\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9225 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9119 - val_loss: 2.5649 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5548\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9880 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.9757 - val_loss: 2.7235 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7133\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0403 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0292 - val_loss: 2.7276 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.7183\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0868 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0765 - val_loss: 2.5825 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5729\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8843 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8728 - val_loss: 2.4233 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4126\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7982 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.7861 - val_loss: 2.5332 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5212\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9316 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9209 - val_loss: 2.6657 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6547\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9767 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9656 - val_loss: 2.6807 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6706\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0775 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 2.0678 - val_loss: 2.6228 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6113\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8082 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.7962 - val_loss: 2.5541 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.5410\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0164 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 2.0063 - val_loss: 2.8446 - val_output_headline_vector_loss: 0.0086 - val_headline_token_classes_loss: 2.8360\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9744 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9642 - val_loss: 2.9455 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9347\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9772 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9667 - val_loss: 2.3938 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.3816\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0428 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0323 - val_loss: 2.6127 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6030\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1410 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.1307 - val_loss: 2.4712 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.4620\n",
      "Epoch 902/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.9066 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8958 - val_loss: 2.7015 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6909\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9594 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9485 - val_loss: 2.6439 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6330\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8979 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8868 - val_loss: 2.5497 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5400\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8575 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.8456 - val_loss: 2.4470 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4372\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1495 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.1395 - val_loss: 2.6705 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6606\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9476 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9366 - val_loss: 2.5279 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5162\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0663 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.0550 - val_loss: 2.7136 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7018\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0183 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.0070 - val_loss: 2.7957 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.7839\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8442 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.8322 - val_loss: 2.4825 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.4689\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8725 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 1.8600 - val_loss: 2.4215 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4105\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9563 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9450 - val_loss: 2.6964 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6864\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9310 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9201 - val_loss: 2.6270 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.6164\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9776 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9663 - val_loss: 2.5570 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5461\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9578 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9467 - val_loss: 2.5924 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5819\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8759 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8644 - val_loss: 2.5860 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5768\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8571 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.8454 - val_loss: 2.9434 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.9330\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9266 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9157 - val_loss: 2.5377 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.5264\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9906 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9791 - val_loss: 2.6110 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.6014\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9359 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9242 - val_loss: 2.6568 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6455\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8536 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8425 - val_loss: 2.3836 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.3745\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9544 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9434 - val_loss: 2.3552 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.3460\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8633 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8525 - val_loss: 2.4766 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4643\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0433 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.0333 - val_loss: 2.9452 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.9359\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9889 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9780 - val_loss: 2.4201 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4095\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8455 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8344 - val_loss: 2.4274 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.4158\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8705 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8590 - val_loss: 2.5467 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5349\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8972 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8866 - val_loss: 2.6566 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6468\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9373 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9263 - val_loss: 2.5622 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.5531\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9021 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8911 - val_loss: 2.5483 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5374\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8104 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7993 - val_loss: 2.5466 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.5331\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8497 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8391 - val_loss: 2.5924 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5821\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9301 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9197 - val_loss: 2.3151 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.3031\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8962 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8849 - val_loss: 2.7333 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.7207\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9792 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9680 - val_loss: 2.6264 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6145\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9220 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9112 - val_loss: 2.6724 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6615\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9206 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9102 - val_loss: 2.6255 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6146\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8702 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8599 - val_loss: 2.2832 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2711\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8575 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8470 - val_loss: 2.5382 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5274\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9654 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9541 - val_loss: 2.6914 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6814\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9655 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9546 - val_loss: 2.6270 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.6145\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8381 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8266 - val_loss: 2.6585 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6484\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8601 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.8482 - val_loss: 2.3991 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3887\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9344 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9239 - val_loss: 2.4789 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.4696\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8511 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8405 - val_loss: 2.3682 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3578\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8281 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8168 - val_loss: 2.9049 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.8962\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9236 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9128 - val_loss: 2.9569 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.9469\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8775 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8672 - val_loss: 2.5515 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5411\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7807 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7696 - val_loss: 2.4571 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4449\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8830 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8716 - val_loss: 2.7129 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7025\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7855 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7743 - val_loss: 2.6942 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6842\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7756 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7645 - val_loss: 2.7046 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6945\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8365 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8250 - val_loss: 2.6340 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6223\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8262 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.8142 - val_loss: 2.9438 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9330\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8028 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7914 - val_loss: 2.5439 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.5318\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8337 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8228 - val_loss: 2.5441 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.5317\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8733 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8619 - val_loss: 2.6699 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6586\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7561 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7447 - val_loss: 2.5842 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5736\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7918 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7807 - val_loss: 2.5922 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5804\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8217 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8111 - val_loss: 2.9122 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.9016\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9937 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.9821 - val_loss: 2.5326 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5223\n",
      "Epoch 962/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8416 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8306 - val_loss: 2.4559 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4442\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8639 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8529 - val_loss: 2.6920 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6813\n",
      "Epoch 964/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 1.7783 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7674 - val_loss: 2.7133 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7011\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9686 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9585 - val_loss: 2.6716 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6605\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9939 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9828 - val_loss: 2.6892 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6774\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9411 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9306 - val_loss: 2.4441 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4331\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8031 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7920 - val_loss: 2.7427 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7317\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8399 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8296 - val_loss: 2.6234 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6131\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8083 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7972 - val_loss: 2.6805 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6708\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7851 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7744 - val_loss: 2.5258 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.5168\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8199 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.8082 - val_loss: 2.8885 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.8770\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8000 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7896 - val_loss: 2.7257 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.7162\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8779 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8675 - val_loss: 2.5371 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5260\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8029 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7921 - val_loss: 2.7627 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7505\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8023 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7920 - val_loss: 2.5470 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5371\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8067 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7968 - val_loss: 2.4997 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.4904\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7641 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7536 - val_loss: 2.6752 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6645\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7232 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7120 - val_loss: 2.6391 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6280\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7996 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7882 - val_loss: 2.5601 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.5473\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7727 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7616 - val_loss: 2.9351 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9243\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8339 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8230 - val_loss: 2.9633 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 2.9545\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7716 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7611 - val_loss: 2.5166 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.5032\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7920 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7815 - val_loss: 2.5070 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4969\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7583 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7472 - val_loss: 2.6560 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.6431\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7797 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7684 - val_loss: 2.8366 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8261\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7883 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7775 - val_loss: 2.3509 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3403\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6912 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6807 - val_loss: 2.4993 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.4866\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8036 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7923 - val_loss: 2.8715 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8602\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7815 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7706 - val_loss: 2.8484 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.8380\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9023 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8920 - val_loss: 2.5281 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5184\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8196 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8087 - val_loss: 2.3320 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3220\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7422 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7307 - val_loss: 2.5964 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5856\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8219 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8117 - val_loss: 2.5986 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5880\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8888 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8781 - val_loss: 2.5544 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5422\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0113 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 2.0015 - val_loss: 2.9464 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.9355\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9483 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9381 - val_loss: 2.8736 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8629\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8174 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8069 - val_loss: 2.7423 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7309\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8506 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.8387 - val_loss: 2.8436 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.8343\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7563 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7448 - val_loss: 2.5956 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5856\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7610 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7497 - val_loss: 2.4963 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4853\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8104 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8003 - val_loss: 2.7404 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7293\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7996 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7890 - val_loss: 2.6945 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6835\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7711 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7596 - val_loss: 2.6909 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6810\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7759 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7647 - val_loss: 2.8279 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8174\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7367 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7262 - val_loss: 2.9184 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.9089\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7483 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7379 - val_loss: 2.6567 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.6448\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7780 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.7659 - val_loss: 2.7354 - val_output_headline_vector_loss: 0.0082 - val_headline_token_classes_loss: 2.7271\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7629 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7520 - val_loss: 2.7853 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.7761\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7875 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7769 - val_loss: 2.8109 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7991\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7510 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7401 - val_loss: 2.7425 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7317\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8095 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7984 - val_loss: 2.4297 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4185\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7751 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7646 - val_loss: 2.9291 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.9184\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9081 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8980 - val_loss: 2.8519 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.8428\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7648 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7543 - val_loss: 2.8887 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.8777\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7223 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7120 - val_loss: 2.8963 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8868\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8238 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8123 - val_loss: 2.7979 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7866\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7421 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7316 - val_loss: 2.5806 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5694\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9570 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9467 - val_loss: 2.3677 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3567\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7899 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7787 - val_loss: 2.5914 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5802\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8088 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7987 - val_loss: 2.7726 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7629\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7304 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7191 - val_loss: 2.7811 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7706\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8074 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7966 - val_loss: 2.7285 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7190\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7740 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7632 - val_loss: 2.6449 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6341\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6740 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6631 - val_loss: 2.6767 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6661\n",
      "Epoch 1026/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.8310 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8208 - val_loss: 2.2938 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2825\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8103 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7991 - val_loss: 2.7478 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.7388\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8359 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8245 - val_loss: 3.0859 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 3.0770\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7429 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7320 - val_loss: 2.4602 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4494\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7839 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7734 - val_loss: 2.3191 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3078\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8200 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8089 - val_loss: 2.5978 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5860\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7625 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7510 - val_loss: 2.7061 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6960\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8267 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8158 - val_loss: 2.5319 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5212\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8540 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8432 - val_loss: 2.5484 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5366\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7921 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7812 - val_loss: 2.4809 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4698\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8880 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8781 - val_loss: 2.5902 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.5775\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7980 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7866 - val_loss: 2.4776 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4673\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8291 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.8171 - val_loss: 2.6111 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6007\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7384 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7275 - val_loss: 2.7860 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7751\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7482 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7368 - val_loss: 2.4279 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4178\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6893 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6783 - val_loss: 2.4819 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4722\n",
      "Epoch 1042/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8072 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7966 - val_loss: 2.7282 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7181\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8034 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7932 - val_loss: 2.6084 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.5994\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8078 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7973 - val_loss: 2.5405 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5314\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8016 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7909 - val_loss: 2.7367 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7253\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7852 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7746 - val_loss: 2.5369 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5264\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7614 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.7492 - val_loss: 2.6601 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6485\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7903 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7789 - val_loss: 2.8429 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.8312\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7137 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7024 - val_loss: 2.7655 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7544\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9198 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9094 - val_loss: 2.5802 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5694\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8771 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8672 - val_loss: 2.8451 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8344\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8178 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8068 - val_loss: 2.7239 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.7141\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7439 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7329 - val_loss: 2.3850 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3734\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7264 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7160 - val_loss: 2.7863 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7754\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8775 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8661 - val_loss: 2.7400 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7300\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8449 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8345 - val_loss: 2.4880 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4776\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8105 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7991 - val_loss: 2.6948 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6840\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7935 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7835 - val_loss: 2.6265 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6166\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8275 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8168 - val_loss: 2.8338 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.8219\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7734 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7625 - val_loss: 2.7358 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7254\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8057 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7950 - val_loss: 2.9015 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.8922\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8869 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8764 - val_loss: 2.5770 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5675\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8030 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7917 - val_loss: 2.6255 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6138\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8225 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8113 - val_loss: 2.8154 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.8051\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7791 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7677 - val_loss: 2.4640 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.4520\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7545 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7439 - val_loss: 2.9284 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9177\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8379 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8271 - val_loss: 2.6613 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6504\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7679 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7575 - val_loss: 2.7989 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7892\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7240 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7127 - val_loss: 2.9487 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.9396\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6565 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.6441 - val_loss: 2.7073 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.6949\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7271 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7165 - val_loss: 2.7487 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7376\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7346 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7236 - val_loss: 2.5396 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5290\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7201 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7092 - val_loss: 2.8247 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.8142\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7792 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7676 - val_loss: 2.4692 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.4572\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6992 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6881 - val_loss: 2.5385 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5278\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7465 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7363 - val_loss: 2.6000 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.5880\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7816 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7711 - val_loss: 2.8981 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8883\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7732 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7625 - val_loss: 2.7735 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7625\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7287 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7185 - val_loss: 2.8616 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.8505\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7345 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7242 - val_loss: 2.5087 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.4973\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7859 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7752 - val_loss: 2.5219 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.5087\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7431 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.7310 - val_loss: 2.7515 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.7426\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6844 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6733 - val_loss: 2.6284 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6181\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8187 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8074 - val_loss: 2.4767 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4658\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7944 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7843 - val_loss: 2.8046 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.7954\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8677 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8573 - val_loss: 2.8891 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8785\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7420 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7307 - val_loss: 2.5378 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.5256\n",
      "Epoch 1088/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7036 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6921 - val_loss: 2.7461 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7354\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7807 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7699 - val_loss: 2.4439 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4325\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7084 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6974 - val_loss: 2.5702 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5602\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7337 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7233 - val_loss: 2.8338 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.8214\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7962 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7852 - val_loss: 2.6873 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6770\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8137 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8022 - val_loss: 2.5438 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5321\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7908 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7801 - val_loss: 2.7720 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7607\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7084 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6976 - val_loss: 2.7041 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6925\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8102 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7998 - val_loss: 2.8906 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8807\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7661 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7551 - val_loss: 2.4820 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4712\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8719 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8610 - val_loss: 2.8081 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7979\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7200 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7086 - val_loss: 2.6303 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6189\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8313 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8213 - val_loss: 2.8964 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8858\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8056 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7940 - val_loss: 2.5969 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5855\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7585 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7476 - val_loss: 2.7094 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6989\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7844 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7726 - val_loss: 2.6904 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6804\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7850 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7747 - val_loss: 2.5418 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5314\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7642 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7529 - val_loss: 2.4945 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.4832\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7348 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7243 - val_loss: 2.6663 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6564\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6661 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6548 - val_loss: 2.7109 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.6987\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8946 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8845 - val_loss: 2.9547 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.9450\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8174 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8055 - val_loss: 2.6638 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6537\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7623 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7517 - val_loss: 2.5724 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5621\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7269 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7159 - val_loss: 2.6745 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6641\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7814 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7710 - val_loss: 2.4475 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4371\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7994 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7878 - val_loss: 2.6367 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6271\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7970 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7868 - val_loss: 2.5974 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5877\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7881 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7777 - val_loss: 2.6416 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6316\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7989 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7874 - val_loss: 2.8617 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8509\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7621 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.7497 - val_loss: 2.8875 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8767\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7369 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7266 - val_loss: 2.5067 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4950\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8966 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8861 - val_loss: 2.6302 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.6163\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9222 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.9126 - val_loss: 2.7329 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7214\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7650 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7545 - val_loss: 2.6602 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6494\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7718 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7607 - val_loss: 3.1057 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.0951\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7853 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.7756 - val_loss: 2.9826 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.9723\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7624 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7514 - val_loss: 2.9829 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.9722\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7233 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7126 - val_loss: 2.6061 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5952\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8007 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7901 - val_loss: 2.5536 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5424\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7217 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7117 - val_loss: 2.3899 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3790\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7826 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7710 - val_loss: 2.6531 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6429\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7394 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7283 - val_loss: 2.5622 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.5490\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7191 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7085 - val_loss: 2.4727 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4620\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7916 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7806 - val_loss: 2.4720 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4618\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8492 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8384 - val_loss: 2.4542 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4430\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8296 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8184 - val_loss: 2.7359 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.7265\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7908 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7805 - val_loss: 2.6420 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.6300\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8953 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8855 - val_loss: 2.5346 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5237\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8179 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8076 - val_loss: 2.6832 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6736\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7470 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7357 - val_loss: 2.9121 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.9026\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7694 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7586 - val_loss: 2.5863 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5761\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8868 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8764 - val_loss: 2.7123 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7013\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8167 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8056 - val_loss: 2.4939 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4837\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7995 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7890 - val_loss: 2.8210 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.8106\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7339 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7230 - val_loss: 3.0557 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 3.0457\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8741 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8643 - val_loss: 2.5577 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5477\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7581 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7472 - val_loss: 3.0176 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 3.0078\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7587 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7479 - val_loss: 2.7863 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.7746\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7399 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7294 - val_loss: 2.8474 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8369\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8530 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8415 - val_loss: 2.8522 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8419\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7468 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7365 - val_loss: 2.4723 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4610\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8167 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8060 - val_loss: 2.5219 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 2.5131\n",
      "Epoch 1150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 1.8333 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8227 - val_loss: 2.7430 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7320\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8722 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8619 - val_loss: 2.7987 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.7896\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7883 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7776 - val_loss: 2.5684 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5569\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8418 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8305 - val_loss: 2.8276 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.8174\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8313 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8208 - val_loss: 2.8047 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7939\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9384 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9275 - val_loss: 3.0396 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.0284\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8145 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8035 - val_loss: 2.6149 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6047\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8346 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8239 - val_loss: 2.6801 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6692\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8277 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 1.8152 - val_loss: 2.8462 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.8343\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7962 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.7865 - val_loss: 2.5062 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.4974\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9394 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9284 - val_loss: 2.6702 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6585\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8852 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8746 - val_loss: 2.4619 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4506\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7659 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7554 - val_loss: 2.7179 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7070\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7310 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7195 - val_loss: 2.6823 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.6734\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7600 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7481 - val_loss: 3.1085 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 3.0993\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7963 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7852 - val_loss: 2.9428 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.9314\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8776 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8670 - val_loss: 2.5199 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5094\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8464 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8352 - val_loss: 2.9374 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.9275\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7751 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7643 - val_loss: 2.8308 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8201\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8024 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7917 - val_loss: 2.6207 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6103\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7406 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7299 - val_loss: 2.7342 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7237\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7990 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7879 - val_loss: 2.8018 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7920\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8212 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8108 - val_loss: 2.7515 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7410\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8752 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8649 - val_loss: 2.6697 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.6603\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7817 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7708 - val_loss: 2.7908 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.7809\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8420 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8310 - val_loss: 2.8270 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8170\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7515 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7401 - val_loss: 2.8107 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8001\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7362 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7248 - val_loss: 2.7488 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7392\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8038 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7928 - val_loss: 2.7819 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7710\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6910 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6798 - val_loss: 2.5814 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5716\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8801 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8692 - val_loss: 2.5915 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5806\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8943 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8839 - val_loss: 2.7031 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6926\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6955 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6841 - val_loss: 2.8472 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8370\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9869 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9754 - val_loss: 2.8787 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.8666\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9885 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9775 - val_loss: 2.9536 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.9439\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0858 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0755 - val_loss: 2.5972 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5859\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9980 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.9883 - val_loss: 2.8314 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8215\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.1390 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.1289 - val_loss: 2.6168 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6059\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9577 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9467 - val_loss: 2.6855 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.6732\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9048 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8938 - val_loss: 2.9679 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.9569\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9362 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9252 - val_loss: 2.6719 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6605\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9964 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9863 - val_loss: 2.8560 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.8458\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.9395 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9288 - val_loss: 2.8257 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8150\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9829 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.9712 - val_loss: 2.7020 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6926\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.0371 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0266 - val_loss: 2.6258 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6158\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8306 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8199 - val_loss: 2.7171 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7074\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9054 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8946 - val_loss: 2.7973 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7869\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9680 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9576 - val_loss: 2.7339 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7231\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9200 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9095 - val_loss: 2.6086 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5977\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9455 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9347 - val_loss: 2.6424 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.6299\n",
      "Epoch 1200/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8990 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8879 - val_loss: 2.6604 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.6479\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9034 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8929 - val_loss: 2.7035 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6917\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9375 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9265 - val_loss: 2.6424 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6318\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9223 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9118 - val_loss: 2.8674 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8579\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9100 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8984 - val_loss: 2.9592 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.9489\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8546 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8437 - val_loss: 2.6931 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.6812\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8980 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8879 - val_loss: 2.8409 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8303\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9807 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.9709 - val_loss: 2.7172 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7058\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9150 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9041 - val_loss: 3.0062 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.9964\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9651 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9539 - val_loss: 2.7503 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.7379\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8539 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8433 - val_loss: 2.6214 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6100\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8730 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8627 - val_loss: 2.8062 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7960\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.7914 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7804 - val_loss: 2.6264 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6155\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8030 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7911 - val_loss: 2.6559 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.6439\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9668 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9565 - val_loss: 2.6821 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.6695\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7586 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7467 - val_loss: 2.9811 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.9694\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8396 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8287 - val_loss: 2.8206 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8093\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8971 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8865 - val_loss: 2.8945 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.8824\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9100 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8995 - val_loss: 2.7600 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7496\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8599 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8493 - val_loss: 2.9182 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.9067\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8130 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8021 - val_loss: 2.8405 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.8287\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9175 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9070 - val_loss: 2.5583 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.5463\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8541 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8431 - val_loss: 2.4653 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.4529\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8623 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8514 - val_loss: 2.7892 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7782\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8982 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8871 - val_loss: 3.0057 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.9935\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8363 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.8266 - val_loss: 2.6765 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.6643\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8813 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8709 - val_loss: 2.9175 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.9028\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8454 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8344 - val_loss: 2.5747 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.5619\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9598 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9496 - val_loss: 2.5977 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5860\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9104 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8998 - val_loss: 2.9446 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.9324\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9462 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9360 - val_loss: 2.8150 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8042\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8875 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8776 - val_loss: 2.9725 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.9592\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8807 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8697 - val_loss: 3.1276 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.1163\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9523 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.9424 - val_loss: 2.8500 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.8371\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9250 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9145 - val_loss: 2.8172 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.8053\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8319 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8223 - val_loss: 2.6999 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.6880\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9266 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9165 - val_loss: 3.0284 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 3.0150\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8433 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8323 - val_loss: 3.0181 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.0066\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8681 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8576 - val_loss: 2.9943 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.9819\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8364 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8259 - val_loss: 2.9370 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.9255\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7765 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7648 - val_loss: 3.0062 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.9951\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9194 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9092 - val_loss: 2.9322 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.9204\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8093 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7990 - val_loss: 2.7802 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.7653\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0192 - output_headline_vector_loss: 0.0094 - headline_token_classes_loss: 2.0098 - val_loss: 2.7983 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7861\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8960 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8852 - val_loss: 2.6507 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.6381\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7940 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7838 - val_loss: 2.8175 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.8058\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8535 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8427 - val_loss: 2.8337 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8231\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7940 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7833 - val_loss: 2.9639 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.9500\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7731 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7631 - val_loss: 2.9173 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.9057\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8524 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8423 - val_loss: 2.8498 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.8369\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9319 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9212 - val_loss: 2.7020 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.6881\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9144 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9042 - val_loss: 2.8220 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.8088\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8000 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7894 - val_loss: 2.8961 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.8838\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8978 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8872 - val_loss: 2.8495 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.8358\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8955 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8854 - val_loss: 2.6968 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6853\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8254 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8145 - val_loss: 2.9856 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.9710\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8056 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7952 - val_loss: 2.9459 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.9323\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8641 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8529 - val_loss: 2.7178 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.7051\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8778 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8676 - val_loss: 2.7062 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.6934\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8377 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8265 - val_loss: 2.5898 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5788\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8524 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8421 - val_loss: 2.6914 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.6783\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8169 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8054 - val_loss: 3.0326 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 3.0191\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9241 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9133 - val_loss: 2.7723 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7613\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9361 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9252 - val_loss: 2.8625 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.8502\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7895 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7795 - val_loss: 2.9158 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.9025\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8875 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8770 - val_loss: 2.8589 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.8465\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7936 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7829 - val_loss: 2.6989 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.6857\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8029 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7922 - val_loss: 2.7629 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7514\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7518 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7408 - val_loss: 2.7141 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7030\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8313 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8208 - val_loss: 2.7993 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7887\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8217 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8115 - val_loss: 2.8491 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.8368\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8756 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8654 - val_loss: 2.8748 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.8621\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7276 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7170 - val_loss: 2.6390 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.6259\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8220 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8105 - val_loss: 2.8349 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.8235\n",
      "Epoch 1274/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.8687 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8584 - val_loss: 2.9843 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.9715\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8281 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8175 - val_loss: 2.8051 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.7931\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8507 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8400 - val_loss: 2.6784 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6673\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7968 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7860 - val_loss: 2.6479 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6382\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7885 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7770 - val_loss: 2.8349 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.8226\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7569 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7457 - val_loss: 2.6646 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6531\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8487 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8375 - val_loss: 2.5999 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5882\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7279 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7168 - val_loss: 3.0065 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.9947\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8094 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7985 - val_loss: 2.9242 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.9132\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9405 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.9309 - val_loss: 2.9880 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.9774\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9828 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9726 - val_loss: 2.6904 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6803\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7258 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7150 - val_loss: 3.0432 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 3.0292\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9071 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8966 - val_loss: 2.6543 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6431\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8379 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8271 - val_loss: 2.9072 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.8936\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9154 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.9058 - val_loss: 2.6489 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6376\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7728 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7618 - val_loss: 2.9430 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.9333\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7973 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7869 - val_loss: 2.8738 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.8606\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7936 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7825 - val_loss: 2.6890 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6779\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9449 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9347 - val_loss: 2.7166 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7052\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9041 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8941 - val_loss: 2.6837 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6722\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8191 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8085 - val_loss: 2.8456 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.8343\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9229 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9129 - val_loss: 2.8222 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.8100\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8005 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7896 - val_loss: 2.6728 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6620\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7267 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7154 - val_loss: 2.9811 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.9681\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8149 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8041 - val_loss: 2.8316 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.8179\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8227 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8121 - val_loss: 2.7643 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7538\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7449 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7344 - val_loss: 2.9803 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.9684\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8124 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8027 - val_loss: 2.6656 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.6532\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8309 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8209 - val_loss: 2.9670 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.9555\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7346 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7236 - val_loss: 2.7533 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7429\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8467 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8359 - val_loss: 2.7692 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7584\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7139 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7034 - val_loss: 2.7755 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.7624\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7016 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6905 - val_loss: 3.0215 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.0103\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7757 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7657 - val_loss: 2.6396 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.6280\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8591 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8486 - val_loss: 2.7465 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.7338\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7792 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7688 - val_loss: 3.0500 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 3.0367\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7951 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7842 - val_loss: 2.9845 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9743\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8437 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8333 - val_loss: 2.8961 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8853\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7929 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7812 - val_loss: 2.6375 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.6254\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7505 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7404 - val_loss: 2.8384 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.8273\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8891 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8783 - val_loss: 2.8730 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.8609\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8145 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8043 - val_loss: 2.8237 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8131\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7840 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7731 - val_loss: 2.7159 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.7027\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7444 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7337 - val_loss: 2.8421 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.8293\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6721 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6608 - val_loss: 2.8036 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7932\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8523 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8424 - val_loss: 2.8190 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.8074\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8426 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8327 - val_loss: 2.7817 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7694\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7600 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7488 - val_loss: 2.9021 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8922\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8337 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8232 - val_loss: 2.6581 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.6460\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7629 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7523 - val_loss: 2.7044 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6939\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8237 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8133 - val_loss: 2.8860 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.8750\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7304 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7199 - val_loss: 2.9169 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.9075\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7948 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7838 - val_loss: 2.7056 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6944\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7555 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7440 - val_loss: 2.9107 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.8988\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7984 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7870 - val_loss: 3.1026 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.0913\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7609 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7498 - val_loss: 2.9062 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.8973\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8570 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8471 - val_loss: 3.1223 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.1110\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8010 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7900 - val_loss: 2.8649 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.8516\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9004 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8900 - val_loss: 2.5766 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5664\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7115 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7011 - val_loss: 2.8832 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8726\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8926 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8818 - val_loss: 2.5869 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5758\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7871 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7763 - val_loss: 2.6099 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5988\n",
      "Epoch 1336/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.8278 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8178 - val_loss: 2.7162 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7060\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7763 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7654 - val_loss: 2.8918 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.8807\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6819 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6706 - val_loss: 2.6873 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.6750\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8566 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8457 - val_loss: 2.8428 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8330\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7528 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7428 - val_loss: 2.7596 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.7475\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8898 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8800 - val_loss: 2.8707 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.8597\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6881 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6773 - val_loss: 2.6770 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6663\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8488 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8387 - val_loss: 2.8102 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8006\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8188 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8089 - val_loss: 2.9152 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9050\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8379 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8275 - val_loss: 2.8623 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.8521\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6957 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6845 - val_loss: 3.1664 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.1552\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8617 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8516 - val_loss: 2.7291 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.7192\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7383 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7277 - val_loss: 2.5540 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5418\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7153 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7040 - val_loss: 2.8289 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8186\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7728 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7617 - val_loss: 2.5128 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5028\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6737 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6631 - val_loss: 2.9544 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.9454\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7565 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7464 - val_loss: 2.7679 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7573\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6846 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6735 - val_loss: 2.8530 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8424\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7179 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7069 - val_loss: 3.2359 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 3.2258\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8384 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8282 - val_loss: 2.5702 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.5569\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7578 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7470 - val_loss: 2.8072 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7963\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8232 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8124 - val_loss: 2.7659 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7537\n",
      "Epoch 1358/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8058 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7955 - val_loss: 2.6707 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.6580\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8232 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8126 - val_loss: 2.8846 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.8727\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7439 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7324 - val_loss: 2.8918 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8813\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7904 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7798 - val_loss: 2.8436 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8323\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7692 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7590 - val_loss: 2.8328 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.8215\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7472 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7360 - val_loss: 2.9447 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.9342\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7666 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7562 - val_loss: 2.5869 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5755\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8183 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8075 - val_loss: 2.7943 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.7813\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7423 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7310 - val_loss: 2.8281 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8179\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7824 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7715 - val_loss: 2.6441 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6336\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7455 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7347 - val_loss: 2.7569 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.7439\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8000 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7888 - val_loss: 2.7594 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7489\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7502 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7391 - val_loss: 2.8778 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.8669\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7682 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7577 - val_loss: 2.8437 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8337\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7335 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7232 - val_loss: 2.7562 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.7445\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7611 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7508 - val_loss: 2.6038 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5925\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8081 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7976 - val_loss: 2.6462 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.6342\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6840 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6725 - val_loss: 2.8081 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7978\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6686 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6576 - val_loss: 2.9043 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.8949\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7439 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7330 - val_loss: 2.7495 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.7371\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7334 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7230 - val_loss: 2.7277 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.7157\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7182 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7071 - val_loss: 2.7179 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.7060\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7103 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6987 - val_loss: 2.7940 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7830\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7746 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7638 - val_loss: 2.7024 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6907\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8088 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7990 - val_loss: 2.9303 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.9189\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7199 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7090 - val_loss: 2.7182 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7076\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7814 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7712 - val_loss: 2.9970 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9867\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8471 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8371 - val_loss: 2.9921 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.9803\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6740 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6635 - val_loss: 2.8611 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8498\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6738 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6627 - val_loss: 2.7559 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7452\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6642 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6533 - val_loss: 2.9776 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.9647\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7190 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7089 - val_loss: 3.0904 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 3.0813\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6722 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6609 - val_loss: 2.5861 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5739\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7307 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7203 - val_loss: 2.6482 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6364\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7807 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7702 - val_loss: 2.7222 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7099\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7381 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7271 - val_loss: 2.7468 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 2.7381\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7988 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7883 - val_loss: 2.7378 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.7243\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7296 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7197 - val_loss: 2.7099 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6989\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6602 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6496 - val_loss: 3.0915 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 3.0820\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7553 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7447 - val_loss: 2.9575 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.9459\n",
      "Epoch 1398/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7846 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7742 - val_loss: 2.7716 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7595\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6970 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6862 - val_loss: 2.6344 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6233\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7078 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6977 - val_loss: 2.8222 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8119\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8081 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7980 - val_loss: 2.9840 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.9735\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7105 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7001 - val_loss: 2.9097 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.8986\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6699 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6583 - val_loss: 2.8449 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8354\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7104 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6999 - val_loss: 2.9085 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8982\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8164 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8060 - val_loss: 2.6841 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6725\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7106 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6995 - val_loss: 2.8287 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.8196\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7382 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7282 - val_loss: 2.8095 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7981\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7798 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7692 - val_loss: 2.6641 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6529\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7473 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7369 - val_loss: 2.6826 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6720\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7916 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7811 - val_loss: 2.9165 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.9056\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7525 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.7427 - val_loss: 2.7040 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6923\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7579 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7461 - val_loss: 2.7322 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7213\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8163 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8064 - val_loss: 2.9571 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.9472\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7508 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7398 - val_loss: 2.6757 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6652\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6788 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6682 - val_loss: 2.9670 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.9555\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7216 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7106 - val_loss: 2.7256 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.7127\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6898 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6796 - val_loss: 2.7687 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.7568\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7506 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7399 - val_loss: 2.8124 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.7988\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7877 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7776 - val_loss: 2.6784 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.6691\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7372 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7266 - val_loss: 3.0190 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.0075\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7474 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7367 - val_loss: 2.7791 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7672\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8093 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.7998 - val_loss: 2.8496 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8390\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7473 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7358 - val_loss: 2.6098 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.5970\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7320 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7212 - val_loss: 2.9297 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.9177\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7842 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7741 - val_loss: 2.8376 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.8279\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6767 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6656 - val_loss: 2.7098 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6991\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6832 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6729 - val_loss: 2.6980 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6866\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7619 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7517 - val_loss: 2.7945 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7822\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7405 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7298 - val_loss: 2.6156 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.6022\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6936 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6826 - val_loss: 2.7911 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.7781\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7670 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7563 - val_loss: 2.9818 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.9700\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8216 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8115 - val_loss: 2.7951 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7848\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7692 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7584 - val_loss: 2.8024 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.7888\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7510 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7404 - val_loss: 2.7908 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7797\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7762 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7662 - val_loss: 2.7322 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7205\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6811 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6695 - val_loss: 2.8405 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.8293\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7375 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7266 - val_loss: 2.9653 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.9512\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7999 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7893 - val_loss: 2.6992 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6896\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7311 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7207 - val_loss: 2.7422 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7328\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7809 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7690 - val_loss: 2.7753 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7643\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8304 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8208 - val_loss: 2.7644 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7531\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8494 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8393 - val_loss: 2.7371 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7258\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7891 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7791 - val_loss: 2.6010 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.5876\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7244 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7134 - val_loss: 2.7963 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7857\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8141 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8037 - val_loss: 2.8708 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8613\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7873 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7766 - val_loss: 2.6785 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6674\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7532 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7416 - val_loss: 2.7046 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6928\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6856 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6748 - val_loss: 2.5626 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.5504\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7416 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7305 - val_loss: 2.8769 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8668\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7800 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7695 - val_loss: 2.6762 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6652\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7182 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7074 - val_loss: 2.8318 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.8193\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8148 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8047 - val_loss: 2.7543 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.7443\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8634 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8536 - val_loss: 2.7003 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6888\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7819 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7719 - val_loss: 2.7260 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.7141\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7690 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7587 - val_loss: 2.9398 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.9280\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7041 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6934 - val_loss: 2.9268 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 2.9098\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8315 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8205 - val_loss: 2.7926 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 2.7743\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7927 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7825 - val_loss: 2.6916 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.6773\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8576 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8480 - val_loss: 2.9022 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.8891\n",
      "Epoch 1460/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.8446 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8340 - val_loss: 2.8662 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.8535\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8354 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8249 - val_loss: 2.7666 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.7538\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8906 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8805 - val_loss: 2.5359 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.5219\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7856 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7750 - val_loss: 2.6233 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6126\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8023 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.7926 - val_loss: 2.8808 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.8691\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7064 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6955 - val_loss: 2.8409 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.8293\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7014 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6908 - val_loss: 2.7614 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.7498\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8140 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8036 - val_loss: 2.9562 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.9426\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7374 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7263 - val_loss: 2.6158 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.6016\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7814 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7705 - val_loss: 2.6214 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.6074\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7992 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7890 - val_loss: 2.6074 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.5931\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7603 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7496 - val_loss: 2.8961 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.8835\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7655 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7538 - val_loss: 2.9097 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8992\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8332 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8233 - val_loss: 2.7646 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.7522\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8429 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8319 - val_loss: 2.8738 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.8608\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7018 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6905 - val_loss: 2.7719 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.7604\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7531 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7423 - val_loss: 2.4493 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4386\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9028 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8919 - val_loss: 2.6852 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6747\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7679 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7568 - val_loss: 2.4435 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.4320\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8065 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 1.7939 - val_loss: 2.4981 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4871\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7768 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7653 - val_loss: 2.7823 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7705\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7712 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7593 - val_loss: 2.6443 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6334\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7789 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.7669 - val_loss: 3.0053 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.9958\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8350 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8232 - val_loss: 2.6236 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.6110\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8944 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8840 - val_loss: 2.8127 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.8004\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7967 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7853 - val_loss: 2.4559 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4450\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9153 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9044 - val_loss: 2.5999 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5899\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7873 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7761 - val_loss: 2.7456 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7333\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7772 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 1.7647 - val_loss: 2.7955 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7840\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8177 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8076 - val_loss: 2.6235 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6140\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8132 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8020 - val_loss: 2.7954 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.7835\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9092 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8988 - val_loss: 2.5499 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5381\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7681 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7573 - val_loss: 2.6299 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6191\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8151 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8038 - val_loss: 2.7089 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6985\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7929 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7822 - val_loss: 2.5261 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.5168\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7897 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7780 - val_loss: 2.7128 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7006\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8328 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.8208 - val_loss: 2.8487 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.8369\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6816 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6701 - val_loss: 2.6194 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6082\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9400 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9292 - val_loss: 2.5325 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5208\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7172 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7062 - val_loss: 2.7786 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7684\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8782 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8676 - val_loss: 2.6815 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.6689\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8942 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.8848 - val_loss: 2.7703 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.7591\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7553 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 1.7427 - val_loss: 2.9063 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.8938\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8042 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7936 - val_loss: 2.7865 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7742\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9435 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.9338 - val_loss: 2.7510 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7409\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8034 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7930 - val_loss: 2.7263 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7154\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7892 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7789 - val_loss: 2.6345 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6229\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7795 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7696 - val_loss: 2.6114 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.5981\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8079 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7961 - val_loss: 2.5853 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.5706\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8203 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8093 - val_loss: 2.6316 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.6183\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8707 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8592 - val_loss: 2.6554 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.6403\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8096 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7983 - val_loss: 2.6560 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.6414\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7695 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7581 - val_loss: 2.5528 - val_output_headline_vector_loss: 0.0161 - val_headline_token_classes_loss: 2.5367\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8197 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8081 - val_loss: 2.6413 - val_output_headline_vector_loss: 0.0192 - val_headline_token_classes_loss: 2.6221\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7722 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7612 - val_loss: 2.8106 - val_output_headline_vector_loss: 0.0209 - val_headline_token_classes_loss: 2.7896\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8345 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8234 - val_loss: 2.5655 - val_output_headline_vector_loss: 0.0210 - val_headline_token_classes_loss: 2.5445\n",
      "Epoch 1516/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8463 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8361 - val_loss: 2.7046 - val_output_headline_vector_loss: 0.0207 - val_headline_token_classes_loss: 2.6839\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8022 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7918 - val_loss: 2.9629 - val_output_headline_vector_loss: 0.0230 - val_headline_token_classes_loss: 2.9399\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7724 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7606 - val_loss: 2.7763 - val_output_headline_vector_loss: 0.0220 - val_headline_token_classes_loss: 2.7543\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7490 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7378 - val_loss: 2.7200 - val_output_headline_vector_loss: 0.0298 - val_headline_token_classes_loss: 2.6902\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8890 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8779 - val_loss: 2.8439 - val_output_headline_vector_loss: 0.0316 - val_headline_token_classes_loss: 2.8123\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8001 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7896 - val_loss: 3.0166 - val_output_headline_vector_loss: 0.0342 - val_headline_token_classes_loss: 2.9824\n",
      "Epoch 1522/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.8936 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8835 - val_loss: 2.7783 - val_output_headline_vector_loss: 0.0368 - val_headline_token_classes_loss: 2.7415\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7158 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7050 - val_loss: 2.8466 - val_output_headline_vector_loss: 0.0420 - val_headline_token_classes_loss: 2.8047\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9255 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9150 - val_loss: 2.8762 - val_output_headline_vector_loss: 0.0306 - val_headline_token_classes_loss: 2.8456\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8152 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8056 - val_loss: 2.8210 - val_output_headline_vector_loss: 0.0462 - val_headline_token_classes_loss: 2.7748\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8810 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8704 - val_loss: 2.8270 - val_output_headline_vector_loss: 0.0500 - val_headline_token_classes_loss: 2.7770\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7735 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7630 - val_loss: 2.7987 - val_output_headline_vector_loss: 0.0576 - val_headline_token_classes_loss: 2.7410\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7941 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7834 - val_loss: 2.7998 - val_output_headline_vector_loss: 0.0579 - val_headline_token_classes_loss: 2.7419\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8277 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8174 - val_loss: 2.8224 - val_output_headline_vector_loss: 0.0666 - val_headline_token_classes_loss: 2.7558\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8940 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8840 - val_loss: 2.7431 - val_output_headline_vector_loss: 0.0580 - val_headline_token_classes_loss: 2.6851\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8333 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8224 - val_loss: 3.0211 - val_output_headline_vector_loss: 0.0589 - val_headline_token_classes_loss: 2.9622\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8389 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8279 - val_loss: 2.8897 - val_output_headline_vector_loss: 0.0913 - val_headline_token_classes_loss: 2.7984\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8640 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8532 - val_loss: 3.0313 - val_output_headline_vector_loss: 0.0846 - val_headline_token_classes_loss: 2.9466\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8951 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8841 - val_loss: 2.8146 - val_output_headline_vector_loss: 0.0713 - val_headline_token_classes_loss: 2.7434\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9390 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9288 - val_loss: 2.9952 - val_output_headline_vector_loss: 0.0915 - val_headline_token_classes_loss: 2.9037\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8349 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8242 - val_loss: 2.8623 - val_output_headline_vector_loss: 0.1193 - val_headline_token_classes_loss: 2.7430\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8850 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8740 - val_loss: 3.0889 - val_output_headline_vector_loss: 0.1210 - val_headline_token_classes_loss: 2.9679\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9374 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9261 - val_loss: 2.8263 - val_output_headline_vector_loss: 0.1116 - val_headline_token_classes_loss: 2.7147\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9252 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9143 - val_loss: 3.2727 - val_output_headline_vector_loss: 0.1117 - val_headline_token_classes_loss: 3.1610\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8087 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7977 - val_loss: 3.1455 - val_output_headline_vector_loss: 0.1278 - val_headline_token_classes_loss: 3.0177\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8873 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8764 - val_loss: 3.0560 - val_output_headline_vector_loss: 0.1281 - val_headline_token_classes_loss: 2.9279\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8356 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8244 - val_loss: 3.0357 - val_output_headline_vector_loss: 0.1168 - val_headline_token_classes_loss: 2.9189\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8852 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8740 - val_loss: 3.0377 - val_output_headline_vector_loss: 0.1433 - val_headline_token_classes_loss: 2.8944\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9000 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8896 - val_loss: 2.8928 - val_output_headline_vector_loss: 0.1647 - val_headline_token_classes_loss: 2.7281\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9259 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9151 - val_loss: 3.2296 - val_output_headline_vector_loss: 0.1722 - val_headline_token_classes_loss: 3.0573\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8215 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8100 - val_loss: 2.8908 - val_output_headline_vector_loss: 0.1767 - val_headline_token_classes_loss: 2.7141\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8851 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8737 - val_loss: 3.2387 - val_output_headline_vector_loss: 0.1917 - val_headline_token_classes_loss: 3.0470\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7518 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7409 - val_loss: 2.8778 - val_output_headline_vector_loss: 0.1815 - val_headline_token_classes_loss: 2.6963\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8407 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8304 - val_loss: 2.9852 - val_output_headline_vector_loss: 0.2054 - val_headline_token_classes_loss: 2.7798\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9209 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.9111 - val_loss: 2.9893 - val_output_headline_vector_loss: 0.2261 - val_headline_token_classes_loss: 2.7632\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7482 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7379 - val_loss: 2.9523 - val_output_headline_vector_loss: 0.1898 - val_headline_token_classes_loss: 2.7624\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9192 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9085 - val_loss: 3.1096 - val_output_headline_vector_loss: 0.2162 - val_headline_token_classes_loss: 2.8934\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8613 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8505 - val_loss: 2.9107 - val_output_headline_vector_loss: 0.1922 - val_headline_token_classes_loss: 2.7185\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8584 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8480 - val_loss: 3.3095 - val_output_headline_vector_loss: 0.2605 - val_headline_token_classes_loss: 3.0491\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8686 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8581 - val_loss: 2.9686 - val_output_headline_vector_loss: 0.2081 - val_headline_token_classes_loss: 2.7605\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8236 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8125 - val_loss: 3.0596 - val_output_headline_vector_loss: 0.2768 - val_headline_token_classes_loss: 2.7828\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7866 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7749 - val_loss: 3.1075 - val_output_headline_vector_loss: 0.3019 - val_headline_token_classes_loss: 2.8055\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8671 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8566 - val_loss: 3.0756 - val_output_headline_vector_loss: 0.3053 - val_headline_token_classes_loss: 2.7703\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8903 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8798 - val_loss: 3.2276 - val_output_headline_vector_loss: 0.2587 - val_headline_token_classes_loss: 2.9689\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7122 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7012 - val_loss: 2.9641 - val_output_headline_vector_loss: 0.3031 - val_headline_token_classes_loss: 2.6610\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7994 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7886 - val_loss: 3.2143 - val_output_headline_vector_loss: 0.2385 - val_headline_token_classes_loss: 2.9758\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8391 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8288 - val_loss: 3.0731 - val_output_headline_vector_loss: 0.3043 - val_headline_token_classes_loss: 2.7688\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8075 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7967 - val_loss: 3.1108 - val_output_headline_vector_loss: 0.3158 - val_headline_token_classes_loss: 2.7950\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7628 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7513 - val_loss: 2.9886 - val_output_headline_vector_loss: 0.3265 - val_headline_token_classes_loss: 2.6621\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7794 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7686 - val_loss: 3.2728 - val_output_headline_vector_loss: 0.3465 - val_headline_token_classes_loss: 2.9262\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8802 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8699 - val_loss: 2.9496 - val_output_headline_vector_loss: 0.3417 - val_headline_token_classes_loss: 2.6079\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7509 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7396 - val_loss: 2.9059 - val_output_headline_vector_loss: 0.3202 - val_headline_token_classes_loss: 2.5857\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8029 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7919 - val_loss: 3.1408 - val_output_headline_vector_loss: 0.4113 - val_headline_token_classes_loss: 2.7294\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8435 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8327 - val_loss: 3.0274 - val_output_headline_vector_loss: 0.3628 - val_headline_token_classes_loss: 2.6646\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7481 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7381 - val_loss: 3.0612 - val_output_headline_vector_loss: 0.4314 - val_headline_token_classes_loss: 2.6298\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9485 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.9388 - val_loss: 3.1608 - val_output_headline_vector_loss: 0.4688 - val_headline_token_classes_loss: 2.6920\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8761 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.8639 - val_loss: 3.1819 - val_output_headline_vector_loss: 0.4066 - val_headline_token_classes_loss: 2.7753\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8485 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8384 - val_loss: 3.3571 - val_output_headline_vector_loss: 0.4241 - val_headline_token_classes_loss: 2.9330\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8042 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7930 - val_loss: 3.5149 - val_output_headline_vector_loss: 0.4849 - val_headline_token_classes_loss: 3.0300\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7971 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7870 - val_loss: 3.1676 - val_output_headline_vector_loss: 0.3765 - val_headline_token_classes_loss: 2.7911\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7720 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7613 - val_loss: 3.0797 - val_output_headline_vector_loss: 0.4132 - val_headline_token_classes_loss: 2.6665\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7483 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7370 - val_loss: 3.2682 - val_output_headline_vector_loss: 0.4611 - val_headline_token_classes_loss: 2.8071\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7986 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7881 - val_loss: 3.6495 - val_output_headline_vector_loss: 0.5313 - val_headline_token_classes_loss: 3.1183\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8087 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7974 - val_loss: 3.4472 - val_output_headline_vector_loss: 0.5524 - val_headline_token_classes_loss: 2.8948\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8241 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8129 - val_loss: 3.4625 - val_output_headline_vector_loss: 0.5642 - val_headline_token_classes_loss: 2.8983\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7346 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7239 - val_loss: 3.1565 - val_output_headline_vector_loss: 0.5090 - val_headline_token_classes_loss: 2.6475\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6762 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6657 - val_loss: 3.2056 - val_output_headline_vector_loss: 0.5160 - val_headline_token_classes_loss: 2.6897\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7998 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7887 - val_loss: 3.4287 - val_output_headline_vector_loss: 0.5763 - val_headline_token_classes_loss: 2.8523\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7705 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7601 - val_loss: 3.1335 - val_output_headline_vector_loss: 0.5644 - val_headline_token_classes_loss: 2.5692\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8888 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8785 - val_loss: 3.1514 - val_output_headline_vector_loss: 0.5462 - val_headline_token_classes_loss: 2.6052\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8589 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8477 - val_loss: 3.2145 - val_output_headline_vector_loss: 0.4245 - val_headline_token_classes_loss: 2.7900\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7812 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7705 - val_loss: 3.3142 - val_output_headline_vector_loss: 0.6478 - val_headline_token_classes_loss: 2.6664\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8013 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7898 - val_loss: 3.5053 - val_output_headline_vector_loss: 0.7064 - val_headline_token_classes_loss: 2.7989\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8147 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8032 - val_loss: 3.3252 - val_output_headline_vector_loss: 0.6418 - val_headline_token_classes_loss: 2.6833\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8587 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8475 - val_loss: 3.3747 - val_output_headline_vector_loss: 0.6621 - val_headline_token_classes_loss: 2.7126\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7907 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7803 - val_loss: 3.4983 - val_output_headline_vector_loss: 0.7162 - val_headline_token_classes_loss: 2.7821\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9334 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9230 - val_loss: 3.1134 - val_output_headline_vector_loss: 0.6480 - val_headline_token_classes_loss: 2.4654\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7746 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7641 - val_loss: 3.1374 - val_output_headline_vector_loss: 0.6190 - val_headline_token_classes_loss: 2.5184\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8233 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.8111 - val_loss: 3.5509 - val_output_headline_vector_loss: 0.7209 - val_headline_token_classes_loss: 2.8300\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7853 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7744 - val_loss: 3.3558 - val_output_headline_vector_loss: 0.6845 - val_headline_token_classes_loss: 2.6713\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9024 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8926 - val_loss: 3.2653 - val_output_headline_vector_loss: 0.7087 - val_headline_token_classes_loss: 2.5566\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9021 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8925 - val_loss: 3.5972 - val_output_headline_vector_loss: 0.8693 - val_headline_token_classes_loss: 2.7279\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7307 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7199 - val_loss: 3.3756 - val_output_headline_vector_loss: 0.6968 - val_headline_token_classes_loss: 2.6788\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7662 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7557 - val_loss: 3.6803 - val_output_headline_vector_loss: 0.8300 - val_headline_token_classes_loss: 2.8503\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8794 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8688 - val_loss: 3.7149 - val_output_headline_vector_loss: 0.7763 - val_headline_token_classes_loss: 2.9386\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8199 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8100 - val_loss: 3.6440 - val_output_headline_vector_loss: 0.7060 - val_headline_token_classes_loss: 2.9380\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7924 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7822 - val_loss: 3.3560 - val_output_headline_vector_loss: 0.6859 - val_headline_token_classes_loss: 2.6701\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8638 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8534 - val_loss: 5.5197 - val_output_headline_vector_loss: 1.3798 - val_headline_token_classes_loss: 4.1399\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8918 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8804 - val_loss: 5.3909 - val_output_headline_vector_loss: 1.3136 - val_headline_token_classes_loss: 4.0773\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8904 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8791 - val_loss: 4.4728 - val_output_headline_vector_loss: 1.0288 - val_headline_token_classes_loss: 3.4440\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0451 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0346 - val_loss: 5.0688 - val_output_headline_vector_loss: 1.2188 - val_headline_token_classes_loss: 3.8501\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9942 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9841 - val_loss: 4.7242 - val_output_headline_vector_loss: 1.0761 - val_headline_token_classes_loss: 3.6481\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9705 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9599 - val_loss: 4.6362 - val_output_headline_vector_loss: 1.0469 - val_headline_token_classes_loss: 3.5893\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9343 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9238 - val_loss: 5.4329 - val_output_headline_vector_loss: 1.4032 - val_headline_token_classes_loss: 4.0296\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7732 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7620 - val_loss: 4.5336 - val_output_headline_vector_loss: 1.0175 - val_headline_token_classes_loss: 3.5161\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8192 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8075 - val_loss: 4.9542 - val_output_headline_vector_loss: 1.1952 - val_headline_token_classes_loss: 3.7589\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9416 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9310 - val_loss: 4.5977 - val_output_headline_vector_loss: 1.0590 - val_headline_token_classes_loss: 3.5387\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9684 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9578 - val_loss: 4.8825 - val_output_headline_vector_loss: 1.2138 - val_headline_token_classes_loss: 3.6687\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8929 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8824 - val_loss: 5.4504 - val_output_headline_vector_loss: 1.4211 - val_headline_token_classes_loss: 4.0294\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8901 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8801 - val_loss: 4.7658 - val_output_headline_vector_loss: 1.1882 - val_headline_token_classes_loss: 3.5776\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7665 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 1.7539 - val_loss: 5.5562 - val_output_headline_vector_loss: 1.4717 - val_headline_token_classes_loss: 4.0845\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0241 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 2.0140 - val_loss: 4.8092 - val_output_headline_vector_loss: 1.2496 - val_headline_token_classes_loss: 3.5596\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8415 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8302 - val_loss: 4.4972 - val_output_headline_vector_loss: 1.0612 - val_headline_token_classes_loss: 3.4360\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8293 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8175 - val_loss: 4.6479 - val_output_headline_vector_loss: 1.2539 - val_headline_token_classes_loss: 3.3941\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8359 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8247 - val_loss: 5.3217 - val_output_headline_vector_loss: 1.4100 - val_headline_token_classes_loss: 3.9117\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8555 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8445 - val_loss: 4.8099 - val_output_headline_vector_loss: 1.1668 - val_headline_token_classes_loss: 3.6431\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8016 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7907 - val_loss: 4.5282 - val_output_headline_vector_loss: 1.1194 - val_headline_token_classes_loss: 3.4088\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9761 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9644 - val_loss: 5.2702 - val_output_headline_vector_loss: 1.5004 - val_headline_token_classes_loss: 3.7698\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7717 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7611 - val_loss: 4.8525 - val_output_headline_vector_loss: 1.3062 - val_headline_token_classes_loss: 3.5463\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8783 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8677 - val_loss: 4.8488 - val_output_headline_vector_loss: 1.2919 - val_headline_token_classes_loss: 3.5568\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8761 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.8638 - val_loss: 5.6676 - val_output_headline_vector_loss: 1.6583 - val_headline_token_classes_loss: 4.0093\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8338 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8237 - val_loss: 4.8032 - val_output_headline_vector_loss: 1.1863 - val_headline_token_classes_loss: 3.6169\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9104 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9000 - val_loss: 5.1407 - val_output_headline_vector_loss: 1.3466 - val_headline_token_classes_loss: 3.7940\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8348 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8248 - val_loss: 4.3836 - val_output_headline_vector_loss: 1.1337 - val_headline_token_classes_loss: 3.2499\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9067 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8963 - val_loss: 4.5977 - val_output_headline_vector_loss: 1.1771 - val_headline_token_classes_loss: 3.4206\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8190 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8084 - val_loss: 4.8794 - val_output_headline_vector_loss: 1.3554 - val_headline_token_classes_loss: 3.5240\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8441 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8336 - val_loss: 5.0742 - val_output_headline_vector_loss: 1.5199 - val_headline_token_classes_loss: 3.5543\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8566 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.8447 - val_loss: 4.7197 - val_output_headline_vector_loss: 1.3071 - val_headline_token_classes_loss: 3.4126\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8939 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8833 - val_loss: 4.8569 - val_output_headline_vector_loss: 1.3845 - val_headline_token_classes_loss: 3.4723\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7681 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7575 - val_loss: 5.5689 - val_output_headline_vector_loss: 1.6587 - val_headline_token_classes_loss: 3.9102\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9090 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.8993 - val_loss: 4.9252 - val_output_headline_vector_loss: 1.4038 - val_headline_token_classes_loss: 3.5214\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8911 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8804 - val_loss: 4.8029 - val_output_headline_vector_loss: 1.3217 - val_headline_token_classes_loss: 3.4811\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9287 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9182 - val_loss: 5.0643 - val_output_headline_vector_loss: 1.3469 - val_headline_token_classes_loss: 3.7173\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8012 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7911 - val_loss: 5.3578 - val_output_headline_vector_loss: 1.6982 - val_headline_token_classes_loss: 3.6596\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8438 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8323 - val_loss: 4.5993 - val_output_headline_vector_loss: 1.2441 - val_headline_token_classes_loss: 3.3553\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7261 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7154 - val_loss: 5.1749 - val_output_headline_vector_loss: 1.5995 - val_headline_token_classes_loss: 3.5755\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8640 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8529 - val_loss: 4.5846 - val_output_headline_vector_loss: 1.2926 - val_headline_token_classes_loss: 3.2920\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7755 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.7633 - val_loss: 5.1931 - val_output_headline_vector_loss: 1.5052 - val_headline_token_classes_loss: 3.6879\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9192 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9087 - val_loss: 4.8970 - val_output_headline_vector_loss: 1.3536 - val_headline_token_classes_loss: 3.5434\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8882 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8780 - val_loss: 5.3378 - val_output_headline_vector_loss: 1.5759 - val_headline_token_classes_loss: 3.7620\n",
      "Epoch 1646/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.9087 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8986 - val_loss: 5.2706 - val_output_headline_vector_loss: 1.5279 - val_headline_token_classes_loss: 3.7426\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8741 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8639 - val_loss: 4.8477 - val_output_headline_vector_loss: 1.4751 - val_headline_token_classes_loss: 3.3726\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7453 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7337 - val_loss: 4.3395 - val_output_headline_vector_loss: 1.1744 - val_headline_token_classes_loss: 3.1651\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8288 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8183 - val_loss: 5.3487 - val_output_headline_vector_loss: 1.6944 - val_headline_token_classes_loss: 3.6543\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8469 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8365 - val_loss: 4.8059 - val_output_headline_vector_loss: 1.3667 - val_headline_token_classes_loss: 3.4392\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8154 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8053 - val_loss: 5.0935 - val_output_headline_vector_loss: 1.4745 - val_headline_token_classes_loss: 3.6190\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8241 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8134 - val_loss: 5.0280 - val_output_headline_vector_loss: 1.5247 - val_headline_token_classes_loss: 3.5033\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7974 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7858 - val_loss: 5.0317 - val_output_headline_vector_loss: 1.5700 - val_headline_token_classes_loss: 3.4617\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8969 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8864 - val_loss: 5.0564 - val_output_headline_vector_loss: 1.3892 - val_headline_token_classes_loss: 3.6672\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9094 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8990 - val_loss: 5.5203 - val_output_headline_vector_loss: 1.6226 - val_headline_token_classes_loss: 3.8977\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8153 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8044 - val_loss: 5.1077 - val_output_headline_vector_loss: 1.6569 - val_headline_token_classes_loss: 3.4508\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9066 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8954 - val_loss: 5.0150 - val_output_headline_vector_loss: 1.3678 - val_headline_token_classes_loss: 3.6472\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8413 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8300 - val_loss: 5.5289 - val_output_headline_vector_loss: 1.5263 - val_headline_token_classes_loss: 4.0026\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8765 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.8671 - val_loss: 5.2351 - val_output_headline_vector_loss: 1.5099 - val_headline_token_classes_loss: 3.7252\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7536 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7423 - val_loss: 4.9808 - val_output_headline_vector_loss: 1.4207 - val_headline_token_classes_loss: 3.5601\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9705 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9595 - val_loss: 5.2241 - val_output_headline_vector_loss: 1.4620 - val_headline_token_classes_loss: 3.7621\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8182 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8075 - val_loss: 5.4189 - val_output_headline_vector_loss: 1.7232 - val_headline_token_classes_loss: 3.6957\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8948 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8845 - val_loss: 5.7285 - val_output_headline_vector_loss: 1.7570 - val_headline_token_classes_loss: 3.9715\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7636 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7529 - val_loss: 5.0106 - val_output_headline_vector_loss: 1.5060 - val_headline_token_classes_loss: 3.5046\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7843 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7730 - val_loss: 5.3969 - val_output_headline_vector_loss: 1.6942 - val_headline_token_classes_loss: 3.7027\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7883 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7769 - val_loss: 4.6254 - val_output_headline_vector_loss: 1.3737 - val_headline_token_classes_loss: 3.2517\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7650 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7552 - val_loss: 5.1073 - val_output_headline_vector_loss: 1.6440 - val_headline_token_classes_loss: 3.4633\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8620 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8506 - val_loss: 5.8339 - val_output_headline_vector_loss: 1.8373 - val_headline_token_classes_loss: 3.9966\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8208 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8101 - val_loss: 5.5445 - val_output_headline_vector_loss: 1.7749 - val_headline_token_classes_loss: 3.7695\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8085 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7977 - val_loss: 5.3305 - val_output_headline_vector_loss: 1.6817 - val_headline_token_classes_loss: 3.6489\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8507 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8403 - val_loss: 5.0498 - val_output_headline_vector_loss: 1.5834 - val_headline_token_classes_loss: 3.4665\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6970 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6864 - val_loss: 5.2321 - val_output_headline_vector_loss: 1.5786 - val_headline_token_classes_loss: 3.6535\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7630 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7520 - val_loss: 5.0115 - val_output_headline_vector_loss: 1.5760 - val_headline_token_classes_loss: 3.4355\n",
      "Epoch 1674/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9091 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8988 - val_loss: 5.5465 - val_output_headline_vector_loss: 1.7656 - val_headline_token_classes_loss: 3.7810\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8960 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8861 - val_loss: 4.8481 - val_output_headline_vector_loss: 1.5731 - val_headline_token_classes_loss: 3.2750\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7201 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7088 - val_loss: 5.1095 - val_output_headline_vector_loss: 1.6312 - val_headline_token_classes_loss: 3.4783\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6612 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6508 - val_loss: 5.2726 - val_output_headline_vector_loss: 1.7078 - val_headline_token_classes_loss: 3.5648\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7051 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6950 - val_loss: 5.3329 - val_output_headline_vector_loss: 1.8138 - val_headline_token_classes_loss: 3.5192\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7655 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7548 - val_loss: 4.0206 - val_output_headline_vector_loss: 1.2153 - val_headline_token_classes_loss: 2.8053\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7280 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7174 - val_loss: 4.0031 - val_output_headline_vector_loss: 1.1155 - val_headline_token_classes_loss: 2.8877\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7899 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7796 - val_loss: 4.1691 - val_output_headline_vector_loss: 1.1544 - val_headline_token_classes_loss: 3.0147\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8402 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8303 - val_loss: 3.7412 - val_output_headline_vector_loss: 1.0255 - val_headline_token_classes_loss: 2.7157\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7304 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7194 - val_loss: 3.9082 - val_output_headline_vector_loss: 0.9397 - val_headline_token_classes_loss: 2.9685\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7936 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7835 - val_loss: 4.4618 - val_output_headline_vector_loss: 1.3337 - val_headline_token_classes_loss: 3.1280\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7446 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7346 - val_loss: 4.9205 - val_output_headline_vector_loss: 1.5322 - val_headline_token_classes_loss: 3.3882\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7576 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7468 - val_loss: 4.4562 - val_output_headline_vector_loss: 1.2847 - val_headline_token_classes_loss: 3.1716\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7108 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6992 - val_loss: 4.2509 - val_output_headline_vector_loss: 1.4135 - val_headline_token_classes_loss: 2.8374\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7570 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7464 - val_loss: 3.9000 - val_output_headline_vector_loss: 1.1676 - val_headline_token_classes_loss: 2.7324\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7390 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7283 - val_loss: 12.1545 - val_output_headline_vector_loss: 9.4308 - val_headline_token_classes_loss: 2.7236\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8778 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8670 - val_loss: 3.1227 - val_output_headline_vector_loss: 0.4965 - val_headline_token_classes_loss: 2.6261\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8640 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8528 - val_loss: 2.8862 - val_output_headline_vector_loss: 0.3871 - val_headline_token_classes_loss: 2.4991\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8014 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7901 - val_loss: 2.8303 - val_output_headline_vector_loss: 0.4532 - val_headline_token_classes_loss: 2.3771\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8298 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8188 - val_loss: 3.0589 - val_output_headline_vector_loss: 0.0290 - val_headline_token_classes_loss: 3.0299\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8669 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8568 - val_loss: 2.5026 - val_output_headline_vector_loss: 0.0249 - val_headline_token_classes_loss: 2.4776\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7777 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7667 - val_loss: 2.6246 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 2.6070\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8191 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8086 - val_loss: 2.7004 - val_output_headline_vector_loss: 0.0266 - val_headline_token_classes_loss: 2.6738\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7695 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7590 - val_loss: 2.6002 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.5868\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7404 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7289 - val_loss: 2.8064 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.7912\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7992 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7882 - val_loss: 2.5447 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.5304\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9101 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8992 - val_loss: 2.7438 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.7297\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7509 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7403 - val_loss: 2.4505 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.4378\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8490 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8385 - val_loss: 2.7269 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.7116\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6380 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6277 - val_loss: 2.6663 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.6542\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7562 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7451 - val_loss: 2.4096 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.3967\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7524 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7408 - val_loss: 2.5659 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5552\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7876 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7775 - val_loss: 2.6066 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5962\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6756 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6647 - val_loss: 2.4980 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4867\n",
      "Epoch 1708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.7221 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7121 - val_loss: 2.4889 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4773\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7606 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7499 - val_loss: 2.8488 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8383\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6431 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6316 - val_loss: 2.7969 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7862\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7681 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7576 - val_loss: 2.8970 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8864\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7822 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7710 - val_loss: 2.8861 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.8750\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8973 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8873 - val_loss: 2.8221 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.8117\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6974 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6862 - val_loss: 2.4742 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4631\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7621 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7509 - val_loss: 2.6898 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 2.6728\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8376 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8261 - val_loss: 2.4404 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.4260\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8781 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8677 - val_loss: 2.9547 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.9394\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7263 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7150 - val_loss: 2.6901 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.6748\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7160 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7041 - val_loss: 2.6086 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 2.5924\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7801 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7693 - val_loss: 2.8095 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.7960\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7809 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7694 - val_loss: 2.5336 - val_output_headline_vector_loss: 0.0173 - val_headline_token_classes_loss: 2.5163\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7933 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7828 - val_loss: 2.2460 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.2310\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7556 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7448 - val_loss: 2.8063 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.7912\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8838 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8725 - val_loss: 2.7449 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.7313\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8324 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8216 - val_loss: 2.8442 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.8310\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7505 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7395 - val_loss: 2.6929 - val_output_headline_vector_loss: 0.0165 - val_headline_token_classes_loss: 2.6765\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7260 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7154 - val_loss: 2.6742 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.6588\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7643 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7541 - val_loss: 2.8734 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 2.8571\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8090 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7971 - val_loss: 2.6184 - val_output_headline_vector_loss: 0.0185 - val_headline_token_classes_loss: 2.5999\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7104 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6997 - val_loss: 2.7133 - val_output_headline_vector_loss: 0.0156 - val_headline_token_classes_loss: 2.6977\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7846 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7731 - val_loss: 2.5683 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 2.5528\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7132 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7022 - val_loss: 2.7974 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.7844\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8100 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7986 - val_loss: 2.9501 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.9374\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7475 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7366 - val_loss: 2.5779 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.5647\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7069 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6961 - val_loss: 2.5245 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.5119\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8474 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8371 - val_loss: 2.5840 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.5703\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7914 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7811 - val_loss: 2.8018 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7904\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7444 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7341 - val_loss: 2.7785 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.7644\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7941 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7838 - val_loss: 2.9116 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.9001\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8548 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8442 - val_loss: 2.7025 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6925\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8291 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8184 - val_loss: 2.8648 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8554\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8912 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8807 - val_loss: 2.8257 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.8134\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8204 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8100 - val_loss: 2.6344 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6241\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9543 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9440 - val_loss: 2.7751 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7636\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8069 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7961 - val_loss: 2.7734 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.7615\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8674 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8569 - val_loss: 2.7303 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7192\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8556 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8456 - val_loss: 2.5977 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5866\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8786 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8681 - val_loss: 2.5890 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5772\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8234 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8120 - val_loss: 2.7519 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7416\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7410 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7300 - val_loss: 2.6915 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6813\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8746 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8641 - val_loss: 2.6824 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6719\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8090 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7980 - val_loss: 2.4071 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3953\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8348 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8248 - val_loss: 2.4727 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.4608\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8035 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7924 - val_loss: 2.7875 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.7759\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8856 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8754 - val_loss: 2.4880 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4775\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6859 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6751 - val_loss: 2.5637 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5519\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8343 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8234 - val_loss: 2.7830 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.7731\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8378 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8267 - val_loss: 2.6558 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.6436\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8700 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8601 - val_loss: 2.8389 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.8295\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9269 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9162 - val_loss: 2.7227 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7121\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8845 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.8747 - val_loss: 2.8280 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.8173\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8178 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8080 - val_loss: 2.6781 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6662\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8166 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8060 - val_loss: 2.9038 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8935\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9051 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.8953 - val_loss: 2.3115 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3014\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8270 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8160 - val_loss: 2.8788 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.8677\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9274 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9170 - val_loss: 2.8028 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.7901\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9383 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9276 - val_loss: 2.7832 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.7720\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8936 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8829 - val_loss: 2.6034 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.5911\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8321 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8207 - val_loss: 2.5703 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.5582\n",
      "Epoch 1770/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 1.8220 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8116 - val_loss: 2.6460 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6349\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8621 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8519 - val_loss: 2.5899 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.5774\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8657 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8553 - val_loss: 2.8271 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.8175\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9441 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.9343 - val_loss: 2.6038 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5930\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8949 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8847 - val_loss: 2.6967 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6866\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9115 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9008 - val_loss: 2.7744 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.7644\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9143 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9041 - val_loss: 2.4979 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4874\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7775 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7663 - val_loss: 2.7137 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.7037\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8293 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8184 - val_loss: 2.5376 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5257\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9893 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9784 - val_loss: 2.3831 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3725\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9333 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9233 - val_loss: 2.4854 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.4733\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8528 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8426 - val_loss: 2.6279 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6167\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9383 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9269 - val_loss: 2.7851 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7737\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8687 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8575 - val_loss: 2.5319 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5206\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8875 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8777 - val_loss: 2.8242 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.8132\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9407 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9302 - val_loss: 2.8365 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8252\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8080 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7970 - val_loss: 2.8875 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8774\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8113 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8000 - val_loss: 2.8907 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.8793\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7151 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7034 - val_loss: 3.0432 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.0328\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8708 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8605 - val_loss: 2.4720 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4611\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9007 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8899 - val_loss: 2.8798 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8694\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7661 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7552 - val_loss: 2.7715 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7617\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8258 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8143 - val_loss: 3.1607 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 3.1511\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8002 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7886 - val_loss: 2.6353 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6248\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9178 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9070 - val_loss: 2.7050 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6942\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9034 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8924 - val_loss: 2.7161 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.7052\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8105 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7988 - val_loss: 2.7200 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7097\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8345 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8238 - val_loss: 2.8041 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7934\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8023 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7915 - val_loss: 2.5739 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5629\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9575 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9474 - val_loss: 2.9176 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.9072\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9560 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9459 - val_loss: 2.6485 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6372\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7718 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7611 - val_loss: 2.6519 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.6401\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7939 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7833 - val_loss: 2.7942 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7848\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7831 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7720 - val_loss: 2.6753 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6644\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8920 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8812 - val_loss: 2.4733 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4621\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9914 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9808 - val_loss: 2.9952 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9850\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8523 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8414 - val_loss: 2.8206 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.8104\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9429 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9320 - val_loss: 2.9162 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.9066\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8912 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8799 - val_loss: 2.7369 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7262\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8627 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8512 - val_loss: 2.5957 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5848\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8850 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8745 - val_loss: 2.8657 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8544\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8374 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8272 - val_loss: 2.5619 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.5503\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8016 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7897 - val_loss: 2.8834 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.8734\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1076 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0970 - val_loss: 2.7817 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7712\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0809 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0699 - val_loss: 2.7644 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.7554\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2408 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 2.2310 - val_loss: 2.6043 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5934\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0744 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0633 - val_loss: 2.5255 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5153\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0477 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0372 - val_loss: 2.5850 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5738\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0464 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0357 - val_loss: 2.6752 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6639\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9714 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9602 - val_loss: 2.5966 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.5845\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3866 - output_headline_vector_loss: 0.0093 - headline_token_classes_loss: 2.3773 - val_loss: 2.8785 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8686\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9523 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9410 - val_loss: 2.6619 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6504\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0671 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0566 - val_loss: 2.5740 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.5619\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1617 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 2.1518 - val_loss: 2.7929 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7822\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9831 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.9713 - val_loss: 2.7438 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7340\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9626 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9517 - val_loss: 2.6746 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6644\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2026 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 2.1929 - val_loss: 2.4785 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.4664\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9781 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9675 - val_loss: 2.4917 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4809\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9876 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.9754 - val_loss: 2.8522 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8419\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.9701 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9588 - val_loss: 2.8824 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8723\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.1149 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1044 - val_loss: 2.5243 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5131\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9951 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9847 - val_loss: 2.7841 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.7752\n",
      "Epoch 1832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 13s 3s/step - loss: 1.9671 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9562 - val_loss: 2.7834 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7740\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.0651 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0547 - val_loss: 3.0392 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.0287\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9365 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9252 - val_loss: 2.7811 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7700\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9957 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9851 - val_loss: 2.4717 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.4583\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.0925 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0817 - val_loss: 2.5611 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5501\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.0519 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.0410 - val_loss: 2.7482 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.7352\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2.0194 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0088 - val_loss: 2.4082 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3978\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2.1028 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0924 - val_loss: 2.3728 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3616\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.0176 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0071 - val_loss: 2.6657 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6555\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9818 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9712 - val_loss: 2.8046 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.7931\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.9646 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9542 - val_loss: 2.5912 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5797\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9290 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9185 - val_loss: 2.4967 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.4841\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9983 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9875 - val_loss: 2.6490 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6379\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9816 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9708 - val_loss: 2.6531 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6426\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2.0210 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0106 - val_loss: 2.5158 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.5045\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8900 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8795 - val_loss: 2.8472 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.8360\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2.1594 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 2.1492 - val_loss: 2.7742 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7646\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2.0269 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0159 - val_loss: 2.9109 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.9012\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 2.0137 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0026 - val_loss: 2.9597 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.9497\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2.0395 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0290 - val_loss: 2.5652 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5533\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9795 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9694 - val_loss: 2.5399 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5295\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8901 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8795 - val_loss: 2.6939 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.6833\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9102 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8991 - val_loss: 2.8856 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.8757\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2.0271 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0169 - val_loss: 2.9974 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.9875\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9681 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9572 - val_loss: 3.0036 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.9929\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.9499 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9394 - val_loss: 2.6668 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.6562\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8561 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8451 - val_loss: 2.3576 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.3447\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9086 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8982 - val_loss: 2.8078 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7967\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9814 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9705 - val_loss: 2.6455 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6357\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9768 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9656 - val_loss: 2.7411 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7300\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9304 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9195 - val_loss: 2.9685 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.9593\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.0096 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9985 - val_loss: 2.5661 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5554\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8620 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8506 - val_loss: 2.6265 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.6153\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9357 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9254 - val_loss: 2.8927 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.8835\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9834 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9724 - val_loss: 2.6451 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.6360\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8045 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.7924 - val_loss: 2.6205 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.6081\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9245 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9136 - val_loss: 2.3490 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.3352\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9539 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9438 - val_loss: 2.8353 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8247\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8982 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8870 - val_loss: 2.5490 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.5350\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9961 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9858 - val_loss: 2.8583 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8480\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.9331 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9219 - val_loss: 2.8722 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8624\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9950 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.9852 - val_loss: 2.7187 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7079\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9891 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9781 - val_loss: 2.8875 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.8781\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 2.0280 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.0180 - val_loss: 2.4323 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.4201\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9160 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9047 - val_loss: 2.6816 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6702\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9399 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9299 - val_loss: 2.7727 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7633\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9752 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.9656 - val_loss: 2.6507 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6413\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8946 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8832 - val_loss: 2.5156 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5057\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8384 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8270 - val_loss: 2.6812 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.6696\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9483 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.9383 - val_loss: 2.7475 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.7375\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8544 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8432 - val_loss: 3.1569 - val_output_headline_vector_loss: 0.0082 - val_headline_token_classes_loss: 3.1487\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8774 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8673 - val_loss: 2.5580 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5473\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8794 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8676 - val_loss: 2.6120 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.5989\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8049 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7940 - val_loss: 2.8268 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.8158\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9404 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9302 - val_loss: 3.0326 - val_output_headline_vector_loss: 0.0077 - val_headline_token_classes_loss: 3.0249\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9901 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9799 - val_loss: 2.6407 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6313\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8364 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8252 - val_loss: 2.5392 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5290\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8413 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8307 - val_loss: 2.6132 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.6003\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8129 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8016 - val_loss: 2.4648 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4538\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7659 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7558 - val_loss: 2.7242 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7141\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8775 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8674 - val_loss: 2.5086 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4986\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7742 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7628 - val_loss: 2.8399 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.8294\n",
      "Epoch 1894/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 3s/step - loss: 1.8667 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8563 - val_loss: 2.5441 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.5308\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.9576 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9476 - val_loss: 2.8048 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7945\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7268 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7152 - val_loss: 2.6102 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5998\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7502 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7392 - val_loss: 2.7313 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.7187\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7300 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7186 - val_loss: 2.6546 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.6420\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9124 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9018 - val_loss: 2.6624 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6525\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8597 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8492 - val_loss: 2.7152 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.7047\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8952 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8848 - val_loss: 2.6473 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6358\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8300 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8196 - val_loss: 2.8346 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8244\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9147 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9034 - val_loss: 2.6909 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6792\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9212 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9105 - val_loss: 2.7753 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.7636\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8578 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.8483 - val_loss: 2.6491 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.6370\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7915 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7807 - val_loss: 2.6302 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6191\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8799 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8702 - val_loss: 2.6971 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6863\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7113 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7002 - val_loss: 2.6472 - val_output_headline_vector_loss: 0.0086 - val_headline_token_classes_loss: 2.6386\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.7959 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7854 - val_loss: 2.6886 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.6737\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7259 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7148 - val_loss: 2.5117 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5008\n",
      "Epoch 1911/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8526 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8422 - val_loss: 2.7278 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.7187\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7921 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7809 - val_loss: 2.7930 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7829\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7918 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7817 - val_loss: 2.4821 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4710\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7017 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6909 - val_loss: 2.7419 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.7320\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7105 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6990 - val_loss: 2.8037 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7934\n",
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8283 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8180 - val_loss: 2.5644 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5538\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6926 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6821 - val_loss: 2.5368 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.5240\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7366 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7256 - val_loss: 2.6117 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6015\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6910 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6794 - val_loss: 2.3699 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.3603\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8430 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8324 - val_loss: 2.6462 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6361\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9982 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9879 - val_loss: 2.5026 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.4897\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8506 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8390 - val_loss: 2.5720 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5601\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8678 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8573 - val_loss: 2.5097 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.4978\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8113 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8002 - val_loss: 2.7348 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7236\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9809 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9706 - val_loss: 2.4763 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4655\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7191 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7080 - val_loss: 2.7384 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7280\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9358 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9247 - val_loss: 2.6446 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.6327\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8129 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8019 - val_loss: 2.3865 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3747\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9828 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9719 - val_loss: 2.7768 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7666\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8334 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8224 - val_loss: 2.4332 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4215\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9104 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9003 - val_loss: 2.6470 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6368\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9403 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9300 - val_loss: 2.6950 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.6830\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8153 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8049 - val_loss: 2.5691 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5584\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9033 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8929 - val_loss: 2.7347 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7244\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.7794 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7687 - val_loss: 2.6963 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.6868\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 2.0699 - output_headline_vector_loss: 0.0093 - headline_token_classes_loss: 2.0606 - val_loss: 2.6127 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6023\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8525 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8413 - val_loss: 2.7593 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.7485\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9037 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8926 - val_loss: 2.3867 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.3745\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8443 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8329 - val_loss: 2.7630 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7526\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8639 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8534 - val_loss: 2.7211 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7104\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9594 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9488 - val_loss: 2.7445 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 2.7357\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8550 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8444 - val_loss: 2.7657 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.7565\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8524 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8412 - val_loss: 2.8323 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8217\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.8902 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8802 - val_loss: 2.6345 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6241\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.8128 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8024 - val_loss: 2.5899 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5796\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9205 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.9107 - val_loss: 2.7505 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7408\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8624 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8526 - val_loss: 2.4711 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.4577\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8031 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7918 - val_loss: 2.2155 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.2030\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.9728 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9627 - val_loss: 2.7834 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7732\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9328 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9229 - val_loss: 2.5874 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5756\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.8482 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8375 - val_loss: 2.6685 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6576\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8431 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8331 - val_loss: 2.6680 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6576\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.9816 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9713 - val_loss: 2.4314 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4197\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7609 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7496 - val_loss: 2.6869 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.6746\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.7166 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7060 - val_loss: 2.6645 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.6531\n",
      "Epoch 1956/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 11s 3s/step - loss: 1.9723 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9620 - val_loss: 2.5227 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5125\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8127 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8014 - val_loss: 2.4976 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4854\n",
      "Epoch 1958/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8021 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7916 - val_loss: 2.5215 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5098\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7975 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7866 - val_loss: 2.8986 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.8897\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7934 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7824 - val_loss: 2.4933 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.4811\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.9097 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.9000 - val_loss: 2.5513 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.5394\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.8107 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7998 - val_loss: 2.8055 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.7963\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.8341 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8228 - val_loss: 2.6289 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.6187\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8785 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8677 - val_loss: 2.6913 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.6809\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8831 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8721 - val_loss: 2.7729 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.7591\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.9385 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9278 - val_loss: 2.6555 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6458\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8054 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7946 - val_loss: 2.7274 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7173\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.9557 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9457 - val_loss: 2.8182 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.8079\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.9401 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.9304 - val_loss: 2.6619 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.6527\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7934 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7825 - val_loss: 2.6187 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.6093\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8053 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7947 - val_loss: 2.9404 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.9310\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.8979 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8874 - val_loss: 2.7403 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7302\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.7758 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7646 - val_loss: 2.7073 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6968\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8638 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8534 - val_loss: 2.5251 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5160\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8004 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7900 - val_loss: 2.6048 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5940\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8398 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8296 - val_loss: 2.5364 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5266\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8164 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8058 - val_loss: 2.7322 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7226\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8894 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8789 - val_loss: 2.7692 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7594\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8722 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8612 - val_loss: 2.7534 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.7413\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7766 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7657 - val_loss: 2.5847 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5736\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.8669 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8553 - val_loss: 2.5308 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5192\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8511 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8395 - val_loss: 2.8390 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.8285\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.8496 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8395 - val_loss: 2.7415 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7317\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.7400 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7291 - val_loss: 2.6490 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.6403\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8453 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8347 - val_loss: 2.5890 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5783\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8118 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8016 - val_loss: 2.4333 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.4217\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.7081 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6981 - val_loss: 2.8523 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 2.8434\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8313 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8205 - val_loss: 2.4425 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4316\n",
      "Epoch 1989/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7651 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7544 - val_loss: 2.6065 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5959\n",
      "Epoch 1990/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7359 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7255 - val_loss: 2.7988 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7884\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6504 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6391 - val_loss: 3.0996 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 3.0901\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.7713 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7609 - val_loss: 2.4584 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.4462\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7493 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7381 - val_loss: 2.5037 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4933\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.7363 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7255 - val_loss: 2.5401 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5289\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.8352 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8246 - val_loss: 2.5014 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.4878\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6834 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6729 - val_loss: 2.5990 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.5867\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.8292 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8193 - val_loss: 2.4668 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4546\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7690 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7583 - val_loss: 2.6134 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6026\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.8190 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8088 - val_loss: 2.4946 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.4826\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7281 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7181 - val_loss: 2.9236 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9134\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(tdg, callbacks=[mc,tb], initial_epoch=0\n",
    "                           ,steps_per_epoch=train_steps_per_epoch\n",
    "                           ,validation_data=vdg\n",
    "                           ,validation_steps=val_steps_per_epoch\n",
    "                           ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# acc = hist.history['acc']\n",
    "# loss = hist.history['loss']\n",
    "\n",
    "# # Create count of the number of epochs\n",
    "# epoch_count = range(1, len(acc) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# # plt.plot(epoch_count, acc, 'b-')\n",
    "# fig, ax = plt.subplots(ncols=2,sharex=True)\n",
    "# ax[0].plot(epoch_count, loss, 'r--')\n",
    "# ax[0].legend(['Loss'])\n",
    "# ax[0].set_xlabel('Epoch')\n",
    "# ax[0].set_ylabel('Loss')\n",
    "# ax[1].plot(epoch_count, acc, 'b-')\n",
    "# ax[1].legend(['Accuracy'])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_xlabel('Accuracy')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.DataFrame(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['acc','val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `evaluate_generator` call to the Keras 2 API: `evaluate_generator(<generator..., steps=5, use_multiprocessing=True)`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.3137764930725098, 0.011120007000863552, 2.3026564598083494]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('weights/dnf300_sa_sent_hd_vector_word_gl.hdf5')\n",
    "model.evaluate_generator(test_dg,steps=5,pickle_safe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_dg)\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_idx = np.random.randint(50)\n",
    "# test_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : 93 : former nato chief: we need us as ‘world’s policeman’\n",
      "1 : 12 : jill stein endorsed donald trump\n",
      "2 : 30 : nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative\n",
      "3 : 99 : hillary personally ordered ‘donald duck’ troll campaign\n",
      "4 : 22 : pentagon officials furious after clinton announces us response time for nuclear launch during debate\n",
      "5 : 97 : hillary sold weapons to isis, wikileaks confirms\n",
      "6 : 22 : pentagon officials furious after clinton announces us response time for nuclear launch during debate\n",
      "7 : 0 : wikileaks confirms hillary sold weapons to isis... then drops another bombshell! breaking news\n",
      "8 : 11 : fbi agent suspected in hillary email leaks found dead in apparent murder-suicide\n",
      "9 : 91 : us officials see no link between trump and russia\n",
      "10 : 22 : pentagon officials furious after clinton announces us response time for nuclear launch during debate\n",
      "11 : 27 : trump accuses obama, hillary clinton of founding daesh\n",
      "12 : 12 : jill stein endorsed donald trump\n",
      "13 : 38 : hillary’s (islamic) america is already here where ‘muslim no-go zones’ are popping up all over michiganistan\n",
      "14 : 13 : hillary clinton in 2013: 'i would like to see people like donald trump run for office\n",
      "15 : 26 : wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting\n",
      "16 : 21 : isis leader calls for american muslim voters to support hillary clinton\n",
      "17 : 0 : wikileaks confirms hillary sold weapons to isis... then drops another bombshell! breaking news\n",
      "18 : 30 : nsa whistleblower says dnc email hack was not by russia, but by us intelligence | alternative\n",
      "19 : 2 : president obama confirms he will refuse to leave office if trump is elected\n",
      "20 : 22 : pentagon officials furious after clinton announces us response time for nuclear launch during debate\n",
      "21 : 34 : (video) female college students protesting because ‘trump is a rapist’\n",
      "22 : 97 : hillary sold weapons to isis, wikileaks confirms\n",
      "23 : 34 : (video) female college students protesting because ‘trump is a rapist’\n",
      "24 : 25 : erdoğan: us, the founder of isis\n",
      "25 : 93 : former nato chief: we need us as ‘world’s policeman’\n",
      "26 : 17 : ted cruz said 'if something happens to hillary' he'll 'run as a democrat against trump'\n",
      "27 : 4 : fbi director received millions from clinton foundation, his brother’s law firm does clinton’s taxes\n",
      "28 : 8 : hillary clinton cut her tax bill by 'donating' $1 million to herself via the clinton foundation?\n",
      "29 : 27 : trump accuses obama, hillary clinton of founding daesh\n",
      "30 : 21 : isis leader calls for american muslim voters to support hillary clinton\n",
      "31 : 25 : erdoğan: us, the founder of isis\n",
      "32 : 39 : doj's loretta lynch tried to squash comey's letter to congress\n",
      "33 : 95 : us threatens military hacks on russia’s electric, communications grids over election\n",
      "34 : 39 : doj's loretta lynch tried to squash comey's letter to congress\n",
      "35 : 97 : hillary sold weapons to isis, wikileaks confirms\n",
      "36 : 18 : clinton camp demands 'compliant citizenry' for master plan\n",
      "37 : 9 : obama declares his family will move to canada if trump is elected\n",
      "38 : 93 : former nato chief: we need us as ‘world’s policeman’\n",
      "39 : 95 : us threatens military hacks on russia’s electric, communications grids over election\n",
      "40 : 4 : fbi director received millions from clinton foundation, his brother’s law firm does clinton’s taxes\n",
      "41 : 3 : breaking: fraudulent clinton votes discovered by the tens of thousands\n",
      "42 : 95 : us threatens military hacks on russia’s electric, communications grids over election\n",
      "43 : 1 : hillary clinton wore secret earpiece during first presidential debate?\n",
      "44 : 26 : wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting\n",
      "45 : 92 : pentagon seeks another $6 billion for overseas troop deployments\n",
      "46 : 14 : department of homeland security chairman officially indicts hillary clinton of treason\n",
      "47 : 27 : trump accuses obama, hillary clinton of founding daesh\n",
      "48 : 95 : us threatens military hacks on russia’s electric, communications grids over election\n",
      "49 : 36 : hillary clinton’s sudden move of $1.8 billion to qatar central bank stuns financial world\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(x['headline'])):\n",
    "    \n",
    "    print(i,\":\",x['article_id'][i],':',x['headline'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An email released in the recent Wikileaks dump laid out Democrat presidential nominee Hillary Clinton’s real plan for the future — and it didn’t include justice, equality or fairness.',\n",
       " 'Instead, Clinton’s plan for the future revolved around maintaining political power while working to create an “unaware” and “compliant” citizenry.',\n",
       " 'The email came from Bill Ivey, who was appointed Chairman of the National Endowment for the Arts during President Bill Clinton’s second term.',\n",
       " 'It was sent to Hillary Clinton’s campaign chairman John Podesta on March 13, 2016.',\n",
       " 'In the email, Ivey considered how Clinton could fight against Trump’s appeal and suggested that simply falling back on previous policies wouldn’t work. “',\n",
       " 'And as I’ve mentioned, we’ve all been quite content to demean government, drop civics and in general conspire to produce an unaware and compliant citizenry,” he said.',\n",
       " 'Ivey admitted how the left has made secret plans to make the public oblivious to their devious plans, but he realized the public isn’t easy to manipulate, which is problematic for Democrats.',\n",
       " 'Unawareness among voters, he insinuated, was a positive for Clinton and the campaign she is running.']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx = 36\n",
    "x['sentences'][test_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(model.inputs,model.get_layer(name='ca1').output)\n",
    "model_2 = Model(model.inputs,model.get_layer(name='ca2').output)\n",
    "model_3 = Model(model.inputs,model.get_layer(name='ca3').output)\n",
    "model_4 = Model(model.inputs,model.get_layer(name='ca4').output)\n",
    "model_1.summary()\n",
    "model_2.summary()\n",
    "model_3.summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, b1, g1 = model_1.predict(x)\n",
    "_, b2, g2 = model_2.predict(x)\n",
    "_, b3, g3 = model_3.predict(x)\n",
    "_, b4, g4 = model_4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1,g2,g3,g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b1+b2+b3+b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 7, 5, 3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_N = 5\n",
    "t = b[test_idx][0][:len(x['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-279.0557"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "b[test_idx][0][:len(x['sentences'][test_idx])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"clinton camp demands 'compliant citizenry' for master plan\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[0, 1, 4]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x['headline'][test_idx])\n",
    "display(x['claims'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : An email released in the recent Wikileaks dump laid out Democrat presidential nominee Hillary Clinton’s real plan for the future — and it didn’t include justice, equality or fairness.\n",
      "2 : The email came from Bill Ivey, who was appointed Chairman of the National Endowment for the Arts during President Bill Clinton’s second term.\n",
      "7 : Unawareness among voters, he insinuated, was a positive for Clinton and the campaign she is running.\n",
      "5 : And as I’ve mentioned, we’ve all been quite content to demean government, drop civics and in general conspire to produce an unaware and compliant citizenry,” he said.\n",
      "3 : It was sent to Hillary Clinton’s campaign chairman John Podesta on March 13, 2016.\n"
     ]
    }
   ],
   "source": [
    "for s in t:\n",
    "    if s>=len(x['sentences'][test_idx]):continue\n",
    "    print(s,':',x['sentences'][test_idx][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-279.0557"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "h_s_attended_vector = b[test_idx][0][:len(x['sentences'][test_idx])]\n",
    "h_s_attended_vector.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h_s_attended_vector = pd.DataFrame(h_s_attended_vector)\n",
    "\n",
    "\n",
    "xw = df_h_s_attended_vector.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xw_scaled = min_max_scaler.fit_transform(xw)\n",
    "df_h_s_attended_vector = pd.DataFrame(xw_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c2885e048>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(2.0,7.0)})\n",
    "sns.heatmap(df_h_s_attended_vector, annot=True, cmap='YlGnBu', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa1 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa2 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa3 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa4 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s1 = Model(model.inputs,model.get_layer(name='sa1').output)\n",
    "model_s2 = Model(model.inputs,model.get_layer(name='sa2').output)\n",
    "model_s3 = Model(model.inputs,model.get_layer(name='sa3').output)\n",
    "model_s4 = Model(model.inputs,model.get_layer(name='sa4').output)\n",
    "model_s1.summary()\n",
    "model_s2.summary()\n",
    "model_s3.summary()\n",
    "model_s4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sb1, sg1 = model_s1.predict([x['sentence_vectors'],x['input_headline_vector']])\n",
    "_, sb2, sg2 = model_s2.predict(x)\n",
    "_, sb3, sg3 = model_s3.predict(x)\n",
    "_, sb4, sg4 = model_s4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922,\n",
       "        0.01742922, 0.01742922, 0.01742922, 0.01742922, 0.01742922],\n",
       "       dtype=float32),\n",
       " array([-0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904,\n",
       "        -0.0084904, -0.0084904, -0.0084904, -0.0084904, -0.0084904],\n",
       "       dtype=float32),\n",
       " array([-0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612,\n",
       "        -0.02535612, -0.02535612, -0.02535612, -0.02535612, -0.02535612],\n",
       "       dtype=float32),\n",
       " array([0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736,\n",
       "        0.00035736, 0.00035736, 0.00035736, 0.00035736, 0.00035736],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg1,sg2, sg3, sg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = sb1[test_idx]+sb2[test_idx]+sb3[test_idx]+sb4[test_idx]\n",
    "sb = sb[:len(x['sentences'][test_idx]),:len(x['sentences'][test_idx])]\n",
    "\n",
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb = pd.DataFrame(sb)\n",
    "\n",
    "\n",
    "zx = df_sb.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "zx_scaled = min_max_scaler.fit_transform(zx)\n",
    "df_sb = pd.DataFrame(zx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c28d204e0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14.0,12.0)})\n",
    "sns.heatmap(pd.DataFrame(df_sb),annot=True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An email released in the recent Wikileaks dump laid out Democrat presidential nominee Hillary Clinton’s real plan for the future — and it didn’t include justice, equality or fairness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Instead, Clinton’s plan for the future revolved around maintaining political power while working to create an “unaware” and “compliant” citizenry.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The email came from Bill Ivey, who was appointed Chairman of the National Endowment for the Arts during President Bill Clinton’s second term.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was sent to Hillary Clinton’s campaign chairman John Podesta on March 13, 2016.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the email, Ivey considered how Clinton could fight against Trump’s appeal and suggested that simply falling back on previous policies wouldn’t work. “</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>And as I’ve mentioned, we’ve all been quite content to demean government, drop civics and in general conspire to produce an unaware and compliant citizenry,” he said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ivey admitted how the left has made secret plans to make the public oblivious to their devious plans, but he realized the public isn’t easy to manipulate, which is problematic for Democrats.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Unawareness among voters, he insinuated, was a positive for Clinton and the campaign she is running.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                0\n",
       "0  An email released in the recent Wikileaks dump laid out Democrat presidential nominee Hillary Clinton’s real plan for the future — and it didn’t include justice, equality or fairness.       \n",
       "1  Instead, Clinton’s plan for the future revolved around maintaining political power while working to create an “unaware” and “compliant” citizenry.                                            \n",
       "2  The email came from Bill Ivey, who was appointed Chairman of the National Endowment for the Arts during President Bill Clinton’s second term.                                                 \n",
       "3  It was sent to Hillary Clinton’s campaign chairman John Podesta on March 13, 2016.                                                                                                            \n",
       "4  In the email, Ivey considered how Clinton could fight against Trump’s appeal and suggested that simply falling back on previous policies wouldn’t work. “                                     \n",
       "5  And as I’ve mentioned, we’ve all been quite content to demean government, drop civics and in general conspire to produce an unaware and compliant citizenry,” he said.                        \n",
       "6  Ivey admitted how the left has made secret plans to make the public oblivious to their devious plans, but he realized the public isn’t easy to manipulate, which is problematic for Democrats.\n",
       "7  Unawareness among voters, he insinuated, was a positive for Clinton and the campaign she is running.                                                                                          "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x['sentences'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf_eval():\n",
    "\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "\n",
    "    for idx in dnf_eval.id: \n",
    "        hd = dnf_eval[dnf_eval.id==idx]['headline'].values[0].lower()\n",
    "        ar_id = dnf_eval[dnf_eval.id==idx]['id'].values[0]\n",
    "        cl = dnf_eval[dnf_eval.id==idx]['claim_ids'].values[0]\n",
    "        ar_claims.append(cl)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "\n",
    "\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "    #         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "\n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "\n",
    "        inputs = {\n",
    "            'article_id': np.array(ar_ids)\n",
    "            ,'headline': np.array(hds)\n",
    "            ,'sentence_vectors' : np.array(ar_sents)\n",
    "            ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "            ,'claims':np.array(ar_claims)\n",
    "            ,'sentences':np.array(ar_sentences)\n",
    "        }\n",
    "        outputs = {\n",
    "            'headline_token_classes': np.array(ar_head_classes)\n",
    "            ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "        }\n",
    "    return inputs,outputs\n",
    "testX,testY = datagen_dnf_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4210000000000001, 0.5713333333333332, 0.4847793080282164)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(testX)\n",
    "_, b2, g2 = model_2.predict(testX)\n",
    "_, b3, g3 = model_3.predict(testX)\n",
    "_, b4, g4 = model_4.predict(testX)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in range(len(testX['headline'])):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(testX['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    pred = b[0][:len(testX['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "    \n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for p in pred:\n",
    "        if p in claims:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    for c in claims:\n",
    "        if c not in pred:\n",
    "            fn+=1\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "#     counter+=1\n",
    "#     if counter==5:\n",
    "#         break\n",
    "#     print(\"----------------------------\")\n",
    "#     for s in t:\n",
    "#         if s>=len(x['sentences'][test_idx]):continue\n",
    "#         x['sentences'][test_idx][s]\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31a8957e70b14ff99e1d419796d5e1e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddc53f9c0794f3ba159bd2e80db6d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.24255319148936166, 0.1014977929871547, 0.14311026405356092)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hd_tp_cdc = pd.read_csv('evaluation_set/cdc_ibm/headline_topic_mapping.csv')\n",
    "df_ar_cl_cdc = pd.read_csv('evaluation_set/cdc_ibm/article_claim_mapping.csv')\n",
    "df_hd_tp_dnf = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "df_hd_tp_dnf.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls']\n",
    "with open('evaluation_set/cdc_ibm/articles.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/cdc_ibm/article_vectors.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "df_hd_tp_cdc.keys(),df_ar_cl_cdc.keys(), len(articles.keys()), len(article_vectors.keys()), df_hd_tp_dnf.keys()\n",
    "test_titles = []\n",
    "for ar in df_ar_cl_cdc.Article.unique():\n",
    "    if len(df_ar_cl_cdc[df_ar_cl_cdc.Article==ar]['Claim'].values)>8:\n",
    "        test_titles.append(ar)\n",
    "ar_ids,ar_sents,ar_sentences,ar_head_vectors,ar_head_classes,hds,claims=[],[],[],[],[],[],[]\n",
    "for idx in tqdm_notebook(test_titles):\n",
    "#     print(idx)\n",
    "    hd = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['Headline'].values[0].lower()\n",
    "    hds.append(hd)\n",
    "    ar_id = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['article Id'].values[0]\n",
    "    cl = df_ar_cl_cdc[df_ar_cl_cdc.Article==idx]['Claim'].values\n",
    "    claims.append(cl)\n",
    "#     sentences=articles[ar_id]\n",
    "#     ar_sentences.append(ar_sentences)\n",
    "    #         print(len(sentences))\n",
    "    sents = np.zeros((max_sentences,300))\n",
    "    vectors = article_vectors[ar_id]\n",
    "    sents[:len(vectors)] = vectors[:max_sentences]\n",
    "    ar_ids.append(ar_id)\n",
    "    ar_sents.append(sents)\n",
    "    hd_nlp = nlp(hd.lower())\n",
    "    head_classes = np.zeros(50, dtype='int')\n",
    "    for i in range(len(hd_nlp)):\n",
    "        head_classes[i] = hd_nlp[i].rank\n",
    "    ar_head_vectors.append(hd_nlp.vector)\n",
    "    ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "inputs = {\n",
    "    'article_id': np.array(ar_ids)\n",
    "    ,'headline': np.array(hds)\n",
    "    ,'sentence_vectors' : np.array(ar_sents)\n",
    "#     ,'sentences' : np.array(ar_sentences)\n",
    "    ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "    ,'claims':np.array(claims)\n",
    "}\n",
    "outputs = {\n",
    "    'headline_token_classes': np.array(ar_head_classes)\n",
    "    ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "}\n",
    "threshold = 0.95\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(inputs)\n",
    "_, b2, g2 = model_2.predict(inputs)\n",
    "_, b3, g3 = model_3.predict(inputs)\n",
    "_, b4, g4 = model_4.predict(inputs)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in tqdm_notebook(range(len(inputs['headline']))):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(inputs['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    ids = b[0][:len(articles[inputs['article_id'][test_idx]])].argsort()[-best_N:][::-1]\n",
    "#     print(ids)\n",
    "    pred = np.array(articles[inputs['article_id'][test_idx]])[ids]\n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "        t5 = nlp(str(pred[i]))\n",
    "        flag = False\n",
    "        #pred_claim_sent.append(pred[i])\n",
    "    #     print(t5.vector)\n",
    "        for j in range(len(cl)):\n",
    "            _c = nlp(cl[j])\n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                tp+=1\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fp+=1\n",
    "        \n",
    "            \n",
    "   \n",
    "    #     print(t5.vector)\n",
    "    for j in range(len(cl)):\n",
    "        _c = nlp(cl[j])\n",
    "        flag = False\n",
    "        for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "            t5 = nlp(str(pred[i]))\n",
    "        \n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fn+=1\n",
    "         \n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
