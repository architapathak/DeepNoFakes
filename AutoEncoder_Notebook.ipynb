{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n3thrwKvocGL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import cv2 \n",
    "import os\n",
    "import keras\n",
    "import numpy as np\n",
    "import shutil\n",
    "import itertools\n",
    "# import imutils\n",
    "import matplotlib.pyplot as plt\n",
    "# from skimage.measure import compare_ssim as ssim\n",
    "from random import shuffle\n",
    "\n",
    "from keras import layers\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, MaxPooling1D, UpSampling2D, Conv2DTranspose, Flatten, GRU, Conv1D, UpSampling1D, Reshape, Concatenate, concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import squeeze\n",
    "from ann_visualizer.visualize import ann_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PNPaPvkf4O2-"
   },
   "outputs": [],
   "source": [
    "# Cropping out images to get only and clear images of brain \n",
    "def crop_images(img):\n",
    "    img = cv2.resize(img, dsize=(224,224), interpolation=cv2.INTER_CUBIC)\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "\n",
    "    thresh_img = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "    eroded = cv2.erode(thresh_img, None, iterations=2)\n",
    "    dilated = cv2.dilate(eroded, None, iterations=2)\n",
    "\n",
    "    contours = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = imutils.grab_contours(contours)\n",
    "    contour_area = max(contours, key=cv2.contourArea)\n",
    "\n",
    "    extreme_left = tuple(contour_area[contour_area[:, :, 0].argmin()][0])\n",
    "    extreme_right = tuple(contour_area[contour_area[:, :, 0].argmax()][0])\n",
    "    extreme_top = tuple(contour_area[contour_area[:, :, 1].argmin()][0])\n",
    "    extreme_bottom = tuple(contour_area[contour_area[:, :, 1].argmax()][0])\n",
    "\n",
    "    contour_img = cv2.drawContours(img.copy(), [contour_area], -1, (0, 255, 255), 4)\n",
    "\n",
    "    contour_point = cv2.circle(contour_img.copy(), extreme_left, 8, (0, 0, 255), -1)\n",
    "    contour_point = cv2.circle(contour_point, extreme_right, 8, (0, 255, 0), -1)\n",
    "    contour_point = cv2.circle(contour_point, extreme_top, 8, (255, 0, 0), -1)\n",
    "    contour_point = cv2.circle(contour_point, extreme_bottom, 8, (255, 255, 0), -1)\n",
    "\n",
    "    new_img = img[extreme_top[1]:extreme_bottom[1], extreme_left[0]:extreme_right[0]].copy()\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j3dVT015RDEv"
   },
   "outputs": [],
   "source": [
    "# Accessing dataset from folder\n",
    "def load_dataset_train():\n",
    "  path_train = glob.glob(\"/content/sample_data/train/*\")\n",
    "  X_train = []\n",
    "  shuffle(path_train)\n",
    "  for img in path_train:\n",
    "    n = cv2.imread(img)\n",
    "    n_img=crop_images(n)\n",
    "    X_train.append(n_img)\n",
    "  return np.array(X_train)\n",
    "\n",
    "def load_dataset_test():\n",
    "  path_test = glob.glob(\"/content/sample_data/test/*\")\n",
    "  X_test = []\n",
    "  shuffle(path_test)\n",
    "  for img in path_test:\n",
    "    n = cv2.imread(img)\n",
    "    n_img=crop_images(n)\n",
    "    X_test.append(n_img)\n",
    "  return np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bz73zxS39e2l"
   },
   "outputs": [],
   "source": [
    "# Preprocessing Images by resizing them and normalizing them \n",
    "def preprocess_images(input_images, img_size):\n",
    "    new_images = []\n",
    "    for img in input_images:\n",
    "        img = cv2.resize(img,dsize=img_size,interpolation=cv2.INTER_CUBIC)\n",
    "        img=img.astype('float32') / 255\n",
    "        new_images.append(img)\n",
    "    return np.array(new_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "colab_type": "code",
    "id": "-FQj7zV789Ob",
    "outputId": "3c8a6776-1f8d-4de6-b9a3-07fbbc0d5dd0"
   },
   "outputs": [],
   "source": [
    "# Loading Datasets and Plotting Images\n",
    "X_train_load=load_dataset_train()\n",
    "X_test_load=load_dataset_test()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train_load[0], cmap='gray')\n",
    "\n",
    "# Preporocessing and Plotting Images\n",
    "X_train=preprocess_images(X_train_load,(256,256))\n",
    "X_test=preprocess_images(X_test_load,(256,256))\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "print(X_train[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "way_5N-EMAen"
   },
   "outputs": [],
   "source": [
    "# Method to add noise to images\n",
    "def add_noise(input_images):\n",
    "  new_images=[]\n",
    "  for img in input_images:\n",
    "    img1 = img.copy()\n",
    "    rows,cols = img1.shape[0],img1.shape[1]\n",
    "    img1= img1+ 0.1 * np.random.normal(loc=0.0, scale=1.0, size=img1.shape)\n",
    "    new_images.append(img1)\n",
    "  return new_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "HGqP2M1NUBGW",
    "outputId": "162294f3-70ce-4111-a922-4d1929141a3f"
   },
   "outputs": [],
   "source": [
    "# Adding Noise \n",
    "X_train_noise=add_noise(X_train)\n",
    "X_test_noise=add_noise(X_test)\n",
    "\n",
    "# Training Image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(X_train_noise[0], cmap='gray')\n",
    "\n",
    "# Testing image\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.axis('off')\n",
    "plt.imshow(X_test_noise[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "colab_type": "code",
    "id": "B2agT0u9XUP7",
    "outputId": "bef64116-2bd5-40b2-96f8-26cab15737b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded.shape (?, 16, 16, 64)\n",
      "shaped.shape: (?, 16384, 1)\n",
      "conv2_b.shape: (?, 4096, 512)\n",
      "conv3.shape: (?, 4096, 256)\n",
      "Tconv4.shape: (?, 4096, 512)\n",
      "Tconv5.shape: (?, 4096, 1024)\n",
      "gru1.shape: (?, ?, 512)\n",
      "skip_1.shape: (?, 4096, 1024)\n",
      "gru2.shape: (?, ?, 1024)\n",
      "skip_2.shape: (?, 4096, 2048)\n",
      "skip_rnn.shape: (?, 4096, 256)\n",
      "shaped.shape: (?, 64, 64, 256)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 32) 9248        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 64)   36928       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "latent_cnn (MaxPooling2D)       (None, 16, 16, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 16384, 1)     0           latent_cnn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 16384, 1024)  4096        reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 8192, 512)    1573376     conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 4096, 256)    393472      conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 4096, 256)    65792       conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1D)  (None, 8192, 256)    0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 4096, 512)    393728      up_sampling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1D)  (None, 8192, 512)    0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 4096, 512)    0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 4096, 1024)   1573888     up_sampling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "latent_rnn (GRU)                (None, 4096, 1024)   4721664     max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4096, 2048)   0           conv1d_6[0][0]                   \n",
      "                                                                 latent_rnn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 4096, 256)    1573120     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (None, 64, 64, 256)  0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   147520      reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 128, 128, 64) 0           conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 64) 36928       up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 256, 256, 64) 0           conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 3)  1731        up_sampling2d_2[0][0]            \n",
      "==================================================================================================\n",
      "Total params: 10,550,883\n",
      "Trainable params: 10,550,883\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Denoising Autoencoder with Recurrent Skip Connections:\n",
    "# x_train=np.squeeze(X_train_noise)\n",
    "# y=np.squeeze(X_train)\n",
    "input_img = Input(shape=(256, 256,3))  \n",
    "\n",
    "x = Conv2D(32, (3, 3),strides=1, activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3),strides=1, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(64, (3, 3), strides=1, activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same', name = 'latent_cnn')(x)\n",
    "print('encoded.shape',encoded.shape)\n",
    "\n",
    "\n",
    "shaped=Reshape((16*16*64,1))(encoded)\n",
    "print('shaped.shape:',shaped.shape)\n",
    "\n",
    "# change value of strides to adjust the context look behind\n",
    "conv1 = Conv1D(1024,kernel_size=3,strides=1,activation='relu',padding='same')(shaped) \n",
    "conv2 = Conv1D(512,kernel_size=3,strides=2,activation='relu',padding='same')(conv1)\n",
    "conv2_b = MaxPooling1D(2)(conv2)\n",
    "print('conv2_b.shape:',conv2_b.shape)\n",
    "conv3 = Conv1D(256,kernel_size=3,strides=2,activation='relu',padding='same')(conv2) \n",
    "conv4 = Conv1D(256,kernel_size=1,strides=1,activation='relu',padding='same')(conv3) \n",
    "print('conv3.shape:',conv3.shape)\n",
    "\n",
    "#transpose\n",
    "Tconv4 = UpSampling1D(size=2)(conv4) \n",
    "Tconv4 = Conv1D(512,kernel_size=3,strides=2,activation='relu',padding='same')(Tconv4) \n",
    "print('Tconv4.shape:',Tconv4.shape)\n",
    "#transpose\n",
    "Tconv5 = UpSampling1D(size=2)(Tconv4) \n",
    "Tconv5 = Conv1D(1024,kernel_size=3,strides=2,activation='relu',padding='same')(Tconv5) \n",
    "print('Tconv5.shape:',Tconv5.shape)\n",
    "\n",
    "\n",
    "gru1 = GRU(512,activation='tanh', recurrent_activation='sigmoid',name='latent_rnn',return_sequences=True)(conv3)\n",
    "# gru1=Reshape((1,512))(gru1)\n",
    "print('gru1.shape:',gru1.shape)\n",
    "skip_1 = concatenate([Tconv4, gru1])\n",
    "print('skip_1.shape:',skip_1.shape) \n",
    "\n",
    "gru2 = GRU(1024,activation='tanh', recurrent_activation='sigmoid',name='latent_rnn',return_sequences=True)(conv2_b)\n",
    "# gru1=Reshape((1,512))(gru1)\n",
    "print('gru2.shape:',gru2.shape)\n",
    "skip_2 = concatenate([Tconv5, gru2])\n",
    "print('skip_2.shape:',skip_2.shape) \n",
    "\n",
    "\n",
    "skip_rnn = Conv1D(256,kernel_size=3, strides=1,activation='relu',padding='same')(skip_2)\n",
    "print('skip_rnn.shape:',skip_rnn.shape) \n",
    "# gru2 = GRU(512,activation='tanh', recurrent_activation='sigmoid', return_sequences=True)(shaped)\n",
    "# print('gru2.shape:',gru2.shape) \n",
    "# merge_2 = concatenate([x,gru2])\n",
    "\n",
    "shaped=Reshape((64,64,256))(skip_rnn)\n",
    "print('shaped.shape:',shaped.shape)\n",
    "\n",
    "x = Conv2DTranspose(64, (3, 3),strides=1, activation='relu', padding='same')(shaped)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2DTranspose(64, (3, 3),strides=1, activation='relu', padding='same')(x)\n",
    "# x = UpSampling2D((2, 2))(x)\n",
    "# x = Conv2DTranspose(32, (3, 3),strides=1, activation='relu', padding='same')(x)\n",
    "# x = UpSampling2D((2, 2))(x)\n",
    "# x = Conv2DTranspose(32, (3, 3),strides=1, activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2DTranspose(3, (3, 3),strides=1, activation='sigmoid', padding='same')(x)\n",
    "\n",
    "denoise_recur_auto_encoder = Model(input_img, decoded)\n",
    "denoise_recur_auto_encoder.summary()\n",
    "denoise_recur_auto_encoder.compile(optimizer=Adam(), loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-21d7dd498e3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mann_viz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdenoise_recur_auto_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"My first neural network\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ann_visualizer/visualize.py\u001b[0m in \u001b[0;36mann_viz\u001b[0;34m(model, view, filename, title)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mtitle\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \"\"\"\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "ann_viz(denoise_recur_auto_encoder, title=\"My first neural network\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
