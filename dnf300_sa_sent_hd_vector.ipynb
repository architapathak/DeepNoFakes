{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import spacy\n",
    "from keras.utils import to_categorical\n",
    "from spacy.lang.en import English\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.layers import BatchNormalization, Lambda, Concatenate, Dropout, Conv1D, MaxPooling1D, Input, TimeDistributed, Dense, LSTM, RepeatVector, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from AttentionModules import SelfAttention,CrossAttention\n",
    "import sys,os\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['authors', 'evidence', 'headline', 'id', 'reason', 'claims', 'type',\n",
       "        'urls'],\n",
       "       dtype='object'),\n",
       " Index(['authors', 'evidence', 'headline', 'id', 'reason', 'type', 'urls'], dtype='object'),\n",
       " 300,\n",
       " 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf300 = pd.read_json('evaluation_set/deepnofakes/dnf_300/combined_300.json').T\n",
    "dnf_eval = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V3.json')\n",
    "dnf_eval.columns = ['authors', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls'] \n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_array_id.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "dnf_eval.keys(), dnf300.keys(), len(articles.keys()), len(article_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "train_batchsize = 32\n",
    "val_batchsize = 32\n",
    "test_batchsize = 50\n",
    "train_steps_per_epoch = 4\n",
    "val_steps_per_epoch = 1\n",
    "epochs = 2000\n",
    "max_sentences = 0\n",
    "for idx in articles.keys():\n",
    "    num = len(articles[idx])\n",
    "    if num>=max_sentences:\n",
    "        max_sentences = num\n",
    "        \n",
    "max_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_titles = sorted(dnf_eval.headline.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = sorted(dnf300.headline.unique())\n",
    "non_test_titles = np.array(list(set(titles)-set(test_titles)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, val_index in kf.split(non_test_titles):\n",
    "    indices.append([train_index,val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 203 204 205 206 207 208 209 210 211\n",
      " 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229\n",
      " 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247\n",
      " 248 249 250 251 252] [153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170\n",
      " 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188\n",
      " 189 190 191 192 193 194 195 196 197 198 199 200 201 202]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(203, 50, 50)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_index, val_index = indices[np.random.randint(0,num_splits)]\n",
    "print(train_index,val_index)\n",
    "val_titles = non_test_titles[val_index]\n",
    "train_titles = non_test_titles[train_index]\n",
    "len(train_titles),len(val_titles),len(test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy():\n",
    "    sentencizer = English()\n",
    "    sentencizer.add_pipe(sentencizer.create_pipe('sentencizer'))\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    return sentencizer, nlp\n",
    "sentencizer, nlp = load_spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf(batchsize,dataframe,mode):\n",
    "    counter=0\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            idx=np.random.choice(train_titles)\n",
    "        elif mode=='val':\n",
    "            idx=np.random.choice(val_titles)\n",
    "        elif mode=='test':\n",
    "            idx=np.random.choice(test_titles)\n",
    "        idx = idx.strip()\n",
    "        \n",
    "            \n",
    "#         cl = dataframe[dataframe.Article==idx]['Claim'].values\n",
    "#         sentences=articles[ar_id]\n",
    "#         print(len(sentences))\n",
    "        if mode=='test':\n",
    "            hd = dnf_eval[dnf_eval.headline==idx]['headline'].values[0].lower()\n",
    "            ar_id = dnf_eval[dnf_eval.headline==idx]['id'].values[0]\n",
    "            cl = dnf_eval[dnf_eval.headline==idx]['claims'].values[0]\n",
    "            ar_claims.append(cl)\n",
    "            \n",
    "        else:\n",
    "            try:\n",
    "                hd = dataframe[dataframe.headline==idx]['headline'].values[0].lower()\n",
    "                ar_id = dataframe[dataframe.headline==idx]['id'].values[0]\n",
    "                ar_claims.append('None')\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(idx)\n",
    "        sentences = articles[ar_id]\n",
    "        vectors = article_vectors[ar_id]\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "#         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "        \n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "        counter+=1\n",
    "        if counter==batchsize:\n",
    "            inputs = {\n",
    "                'article_id': np.array(ar_ids)\n",
    "                ,'headline': np.array(hds)\n",
    "                ,'sentence_vectors' : np.array(ar_sents)\n",
    "                ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "                ,'claims':np.array(ar_claims)\n",
    "                ,'sentences':np.array(ar_sentences)\n",
    "            }\n",
    "            outputs = {\n",
    "                'headline_token_classes': np.array(ar_head_classes)\n",
    "                ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "            }\n",
    "            yield inputs,outputs\n",
    "            ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "            counter=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = datagen_dnf(train_batchsize,dnf300,mode='train')\n",
    "vdg = datagen_dnf(val_batchsize,dnf300,mode='val')\n",
    "test_dg = datagen_dnf(test_batchsize,dnf300,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(test_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['sentence_vectors'].shape, x['headline_vector'].shape, y['headline_token_classes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inp_sentence_vectors = Input(shape=(max_sentences, 300), name='sentence_vectors')\n",
    "    inp_headline_vector = Input(shape=(300,), name='input_headline_vector')\n",
    "    conv1 = Conv1D(filters=16,kernel_size=3,strides=1,activation='relu', padding='same')(inp_sentence_vectors)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv2 = Conv1D(filters=32,kernel_size=3,strides=1,activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    sent_sa_feat_1, sent_beta_1, sent_gamma_1 = SelfAttention(int(conv2.shape[-1]), name = 'sa1')(conv2)\n",
    "    sent_sa_feat_2, sent_beta_2, sent_gamma_2 = SelfAttention(int(conv2.shape[-1]), name = 'sa2')(conv2)\n",
    "    sent_sa_feat_3, sent_beta_3, sent_gamma_3 = SelfAttention(int(conv2.shape[-1]), name = 'sa3')(conv2)\n",
    "    sent_sa_feat_4, sent_beta_4, sent_gamma_4 = SelfAttention(int(conv2.shape[-1]), name = 'sa4')(conv2)\n",
    "    concat1 = Concatenate()([sent_sa_feat_1,sent_sa_feat_2,sent_sa_feat_3,sent_sa_feat_4])\n",
    "    conv3 = Conv1D(filters=256,kernel_size=3, strides=1, activation='relu', padding='same')(concat1)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    headline = Dense(256, activation='relu')(inp_headline_vector)\n",
    "    headline = Lambda(lambda x:K.expand_dims(x, axis=1))(headline)\n",
    "    headline = BatchNormalization()(headline)\n",
    "    sent_hd_sa_feat_1, sent_hd_beta_1, sent_hd_gamma_1 = CrossAttention(int(conv3.shape[-1]), name = 'ca1')([headline,conv3])\n",
    "    sent_hd_sa_feat_2, sent_hd_beta_2, sent_hd_gamma_2 = CrossAttention(int(conv3.shape[-1]), name = 'ca2')([headline,conv3])\n",
    "    sent_hd_sa_feat_3, sent_hd_beta_3, sent_hd_gamma_3 = CrossAttention(int(conv3.shape[-1]), name = 'ca3')([headline,conv3])\n",
    "    sent_hd_sa_feat_4, sent_hd_beta_4, sent_hd_gamma_4 = CrossAttention(int(conv3.shape[-1]), name = 'ca4')([headline,conv3])  \n",
    "    concat3 = Concatenate()([sent_hd_sa_feat_1,sent_hd_sa_feat_2,sent_hd_sa_feat_3,sent_hd_sa_feat_4])\n",
    "    concat3 = Dropout(0.5)(concat3)\n",
    "    concat3 = BatchNormalization()(concat3)\n",
    "    conv5 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(concat3)\n",
    "    conv6 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv5)\n",
    "    conv7 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv6)\n",
    "    conv8 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv7)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    gap = GlobalAveragePooling1D()(conv8)\n",
    "#     repeat = RepeatVector(50)(gap)\n",
    "#     lstm = LSTM(256,return_sequences=True)(repeat)\n",
    "    dense1 = Dense(512,activation='relu')(gap)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    gen_hd_vector = Dense(300,activation='linear', name='output_headline_vector')(dense1)\n",
    "    model = Model([inp_sentence_vectors,inp_headline_vector],gen_hd_vector)\n",
    "    return model\n",
    "model = build_model()\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001,beta_1=0.0,beta_2=0.99),loss='mse')\n",
    "model.summary()\n",
    "# print('model params:',model.count_params())\n",
    "SVG(model_to_dot(model,show_layer_names=True,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now()\n",
    "mc = ModelCheckpoint('weights/dnf300_sa_sent_hd_vector.hdf5',save_best_only=True,save_weights_only=True)\n",
    "tb = TensorBoard(batch_size=32,log_dir='logs/dnf300_sa_sent_hd_vector/{0}'.format(dt.timestamp()),write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.2944 - val_loss: 0.2150\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 0s 54ms/step - loss: 1.2715 - val_loss: 0.1970\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 0s 56ms/step - loss: 1.2647 - val_loss: 0.1948\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 1.2787 - val_loss: 0.1833\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 1.2404 - val_loss: 0.1787\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 1.2394 - val_loss: 0.1745\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 2s 515ms/step - loss: 1.2343 - val_loss: 0.1653\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 1.2214 - val_loss: 0.1612\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 1.2206 - val_loss: 0.1590\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 1.2088 - val_loss: 0.1539\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 1.1876 - val_loss: 0.1479\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 1.1997 - val_loss: 0.1452\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 1.1857 - val_loss: 0.1385\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 1.1794 - val_loss: 0.1338\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 1.1695 - val_loss: 0.1287\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 1.1504 - val_loss: 0.1259\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 1.1493 - val_loss: 0.1185\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 1.1708 - val_loss: 0.1175\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 1.1340 - val_loss: 0.1140\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 1.1351 - val_loss: 0.1138\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 1.1475 - val_loss: 0.1152\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 1.1211 - val_loss: 0.1109\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 1.1227 - val_loss: 0.1078\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 1.1121 - val_loss: 0.1031\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 1.0953 - val_loss: 0.1043\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 1.1027 - val_loss: 0.0967\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 1.0817 - val_loss: 0.0958\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 1.0850 - val_loss: 0.0962\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 1.0672 - val_loss: 0.0920\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 1.0666 - val_loss: 0.0925\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 1.0677 - val_loss: 0.0915\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 1.0566 - val_loss: 0.0893\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 1.0564 - val_loss: 0.0869\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 1.0342 - val_loss: 0.0864\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 1.0506 - val_loss: 0.0852\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 1.0227 - val_loss: 0.0829\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 1.0256 - val_loss: 0.0830\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 1.0265 - val_loss: 0.0811\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 1.0147 - val_loss: 0.0812\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 1.0073 - val_loss: 0.0808\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.9942 - val_loss: 0.0775\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 1.0131 - val_loss: 0.0774\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 2s 500ms/step - loss: 0.9696 - val_loss: 0.0774\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.9838 - val_loss: 0.0729\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.9786 - val_loss: 0.0733\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.9628 - val_loss: 0.0765\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.9525 - val_loss: 0.0750\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.9575 - val_loss: 0.0755\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.9455 - val_loss: 0.0762\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.9304 - val_loss: 0.0743\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.9355 - val_loss: 0.0738\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 0.9380 - val_loss: 0.0701\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.9406 - val_loss: 0.0724\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.9301 - val_loss: 0.0728\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.9323 - val_loss: 0.0722\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.9222 - val_loss: 0.0752\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.8820 - val_loss: 0.0701\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.9075 - val_loss: 0.0692\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.8943 - val_loss: 0.0707\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 3s 860ms/step - loss: 0.8858 - val_loss: 0.0729\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.8871 - val_loss: 0.0681\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.8846 - val_loss: 0.0685\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.8797 - val_loss: 0.0696\n",
      "Epoch 64/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.8590 - val_loss: 0.0666\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.8622 - val_loss: 0.0667\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 3s 860ms/step - loss: 0.8591 - val_loss: 0.0676\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.8466 - val_loss: 0.0635\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.8331 - val_loss: 0.0647\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.8505 - val_loss: 0.0672\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.8397 - val_loss: 0.0658\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.8167 - val_loss: 0.0633\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.8248 - val_loss: 0.0649\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.7997 - val_loss: 0.0643\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.8011 - val_loss: 0.0622\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.7941 - val_loss: 0.0630\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.7864 - val_loss: 0.0606\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.7856 - val_loss: 0.0625\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.7937 - val_loss: 0.0594\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.7777 - val_loss: 0.0615\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.7749 - val_loss: 0.0599\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.7628 - val_loss: 0.0609\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.7630 - val_loss: 0.0596\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 3s 822ms/step - loss: 0.7737 - val_loss: 0.0600\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.7520 - val_loss: 0.0564\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.7565 - val_loss: 0.0554\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.7564 - val_loss: 0.0568\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.7470 - val_loss: 0.0538\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.7451 - val_loss: 0.0560\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.7365 - val_loss: 0.0543\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 3s 821ms/step - loss: 0.7238 - val_loss: 0.0523\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.7164 - val_loss: 0.0503\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.7118 - val_loss: 0.0511\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.7119 - val_loss: 0.0522\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.7087 - val_loss: 0.0515\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.7000 - val_loss: 0.0491\n",
      "Epoch 96/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.7082 - val_loss: 0.0486\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.7024 - val_loss: 0.0489\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 2s 579ms/step - loss: 0.6978 - val_loss: 0.0479\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.6967 - val_loss: 0.0479\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.6777 - val_loss: 0.0480\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.6773 - val_loss: 0.0471\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 2s 549ms/step - loss: 0.6652 - val_loss: 0.0451\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.6643 - val_loss: 0.0480\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.6756 - val_loss: 0.0437\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.6652 - val_loss: 0.0424\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.6445 - val_loss: 0.0405\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.6591 - val_loss: 0.0431\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.6371 - val_loss: 0.0404\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.6400 - val_loss: 0.0397\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.6431 - val_loss: 0.0408\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.6344 - val_loss: 0.0398\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.6305 - val_loss: 0.0391\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.6378 - val_loss: 0.0395\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.6319 - val_loss: 0.0380\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.6163 - val_loss: 0.0396\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.6022 - val_loss: 0.0375\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.6103 - val_loss: 0.0397\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.6215 - val_loss: 0.0364\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.6178 - val_loss: 0.0366\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.6105 - val_loss: 0.0332\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.5926 - val_loss: 0.0337\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.5874 - val_loss: 0.0324\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.5826 - val_loss: 0.0319\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.5790 - val_loss: 0.0323\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.5836 - val_loss: 0.0316\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.5817 - val_loss: 0.0321\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.5733 - val_loss: 0.0324\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.5825 - val_loss: 0.0308\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.5822 - val_loss: 0.0299\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.5680 - val_loss: 0.0283\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.5642 - val_loss: 0.0278\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.5558 - val_loss: 0.0282\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.5463 - val_loss: 0.0283\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.5669 - val_loss: 0.0291\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.5600 - val_loss: 0.0289\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.5522 - val_loss: 0.0291\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.5361 - val_loss: 0.0273\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.5435 - val_loss: 0.0263\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.5412 - val_loss: 0.0279\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.5414 - val_loss: 0.0262\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.5326 - val_loss: 0.0254\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.5274 - val_loss: 0.0269\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.5274 - val_loss: 0.0246\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.5204 - val_loss: 0.0246\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.5229 - val_loss: 0.0238\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.5107 - val_loss: 0.0214\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.5048 - val_loss: 0.0264\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.5017 - val_loss: 0.0215\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.5096 - val_loss: 0.0221\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.5133 - val_loss: 0.0215\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.5072 - val_loss: 0.0217\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.4954 - val_loss: 0.0207\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.5037 - val_loss: 0.0230\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.4953 - val_loss: 0.0231\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.5002 - val_loss: 0.0225\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.4875 - val_loss: 0.0208\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.4974 - val_loss: 0.0224\n",
      "Epoch 158/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.4911 - val_loss: 0.0201\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.4747 - val_loss: 0.0209\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.4962 - val_loss: 0.0212\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.4847 - val_loss: 0.0213\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 605ms/step - loss: 0.4685 - val_loss: 0.0224\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.4707 - val_loss: 0.0191\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.4760 - val_loss: 0.0218\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.4603 - val_loss: 0.0197\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.4738 - val_loss: 0.0201\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.4593 - val_loss: 0.0194\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.4659 - val_loss: 0.0194\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.4633 - val_loss: 0.0176\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.4714 - val_loss: 0.0184\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.4541 - val_loss: 0.0177\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.4490 - val_loss: 0.0177\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.4510 - val_loss: 0.0172\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.4381 - val_loss: 0.0178\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.4528 - val_loss: 0.0181\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.4384 - val_loss: 0.0176\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.4444 - val_loss: 0.0152\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.4338 - val_loss: 0.0162\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.4313 - val_loss: 0.0181\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.4234 - val_loss: 0.0151\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.4245 - val_loss: 0.0175\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.4330 - val_loss: 0.0166\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.4241 - val_loss: 0.0173\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.4205 - val_loss: 0.0147\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.4254 - val_loss: 0.0177\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.4208 - val_loss: 0.0174\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.4348 - val_loss: 0.0161\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.4224 - val_loss: 0.0151\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.4281 - val_loss: 0.0165\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.4273 - val_loss: 0.0165\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.4084 - val_loss: 0.0161\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.4175 - val_loss: 0.0166\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.4120 - val_loss: 0.0168\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.4148 - val_loss: 0.0149\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.4074 - val_loss: 0.0180\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.4123 - val_loss: 0.0170\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.3944 - val_loss: 0.0151\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.4100 - val_loss: 0.0161\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.4012 - val_loss: 0.0144\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.4022 - val_loss: 0.0159\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.4024 - val_loss: 0.0158\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.3960 - val_loss: 0.0144\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.3946 - val_loss: 0.0154\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.3923 - val_loss: 0.0137\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.3974 - val_loss: 0.0139\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.3788 - val_loss: 0.0145\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 2s 591ms/step - loss: 0.3767 - val_loss: 0.0147\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.3774 - val_loss: 0.0152\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.3827 - val_loss: 0.0140\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.3758 - val_loss: 0.0145\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.3771 - val_loss: 0.0138\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.3716 - val_loss: 0.0148\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.3755 - val_loss: 0.0154\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.3782 - val_loss: 0.0149\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.3800 - val_loss: 0.0136\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.3721 - val_loss: 0.0118\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.3699 - val_loss: 0.0121\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.3720 - val_loss: 0.0142\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.3651 - val_loss: 0.0132\n",
      "Epoch 220/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.3651 - val_loss: 0.0143\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.3619 - val_loss: 0.0149\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.3789 - val_loss: 0.0146\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.3650 - val_loss: 0.0156\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.3508 - val_loss: 0.0145\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.3632 - val_loss: 0.0130\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.3549 - val_loss: 0.0133\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.3573 - val_loss: 0.0138\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.3607 - val_loss: 0.0142\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.3430 - val_loss: 0.0141\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.3407 - val_loss: 0.0134\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.3447 - val_loss: 0.0114\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.3352 - val_loss: 0.0134\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.3434 - val_loss: 0.0130\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.3393 - val_loss: 0.0125\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.3370 - val_loss: 0.0144\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.3468 - val_loss: 0.0157\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.3319 - val_loss: 0.0156\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.3284 - val_loss: 0.0133\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.3370 - val_loss: 0.0143\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.3373 - val_loss: 0.0147\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.3167 - val_loss: 0.0118\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.3274 - val_loss: 0.0144\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.3234 - val_loss: 0.0115\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.3232 - val_loss: 0.0121\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.3203 - val_loss: 0.0126\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.3425 - val_loss: 0.0145\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.3179 - val_loss: 0.0131\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.3183 - val_loss: 0.0136\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.3214 - val_loss: 0.0118\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.3197 - val_loss: 0.0126\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.3263 - val_loss: 0.0118\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.3206 - val_loss: 0.0120\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.3125 - val_loss: 0.0122\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.3136 - val_loss: 0.0118\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.3010 - val_loss: 0.0113\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.3034 - val_loss: 0.0131\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.3131 - val_loss: 0.0124\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.3085 - val_loss: 0.0159\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.3079 - val_loss: 0.0120\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.3149 - val_loss: 0.0134\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.2988 - val_loss: 0.0128\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.3006 - val_loss: 0.0103\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.3012 - val_loss: 0.0130\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.2940 - val_loss: 0.0114\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.3032 - val_loss: 0.0129\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 3s 778ms/step - loss: 0.3036 - val_loss: 0.0132\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.2831 - val_loss: 0.0125\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.3014 - val_loss: 0.0126\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.2849 - val_loss: 0.0120\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.2867 - val_loss: 0.0129\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.2887 - val_loss: 0.0114\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.2776 - val_loss: 0.0124\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.2765 - val_loss: 0.0134\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.2873 - val_loss: 0.0117\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.2927 - val_loss: 0.0103\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.2872 - val_loss: 0.0107\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.2839 - val_loss: 0.0140\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.2968 - val_loss: 0.0120\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.2922 - val_loss: 0.0125\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.2825 - val_loss: 0.0124\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.2701 - val_loss: 0.0127\n",
      "Epoch 282/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.2766 - val_loss: 0.0117\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.2746 - val_loss: 0.0131\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.2751 - val_loss: 0.0134\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.2833 - val_loss: 0.0115\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.2713 - val_loss: 0.0114\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.2776 - val_loss: 0.0129\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.2601 - val_loss: 0.0135\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.2671 - val_loss: 0.0142\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.2584 - val_loss: 0.0125\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 2s 563ms/step - loss: 0.2666 - val_loss: 0.0118\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.2572 - val_loss: 0.0174\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.2528 - val_loss: 0.0148\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.2560 - val_loss: 0.0125\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.2584 - val_loss: 0.0152\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.2620 - val_loss: 0.0144\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.2778 - val_loss: 0.0159\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.2532 - val_loss: 0.0140\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 2s 562ms/step - loss: 0.2449 - val_loss: 0.0126\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.2629 - val_loss: 0.0108\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.2536 - val_loss: 0.0133\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.2579 - val_loss: 0.0118\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.2482 - val_loss: 0.0114\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.2470 - val_loss: 0.0100\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.2559 - val_loss: 0.0120\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.2456 - val_loss: 0.0116\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.2545 - val_loss: 0.0123\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.2332 - val_loss: 0.0112\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.2429 - val_loss: 0.0113\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.2390 - val_loss: 0.0120\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.2464 - val_loss: 0.0113\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.2474 - val_loss: 0.0141\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.2360 - val_loss: 0.0125\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.2459 - val_loss: 0.0119\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.2260 - val_loss: 0.0125\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.2316 - val_loss: 0.0134\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.2545 - val_loss: 0.0130\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.2278 - val_loss: 0.0133\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.2406 - val_loss: 0.0136\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.2360 - val_loss: 0.0120\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.2360 - val_loss: 0.0138\n",
      "Epoch 322/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 661ms/step - loss: 0.2306 - val_loss: 0.0105\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.2402 - val_loss: 0.0114\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.2267 - val_loss: 0.0115\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.2416 - val_loss: 0.0115\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 3s 799ms/step - loss: 0.2170 - val_loss: 0.0115\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.2289 - val_loss: 0.0127\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.2225 - val_loss: 0.0126\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.2226 - val_loss: 0.0124\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.2070 - val_loss: 0.0106\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.2233 - val_loss: 0.0143\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.2013 - val_loss: 0.0112\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.2213 - val_loss: 0.0114\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.2192 - val_loss: 0.0116\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.2102 - val_loss: 0.0111\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.2047 - val_loss: 0.0134\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.1878 - val_loss: 0.0123\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.2125 - val_loss: 0.0109\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.2132 - val_loss: 0.0121\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.2044 - val_loss: 0.0133\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.2016 - val_loss: 0.0124\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.1906 - val_loss: 0.0105\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.2040 - val_loss: 0.0114\n",
      "Epoch 344/2000\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.1991 - val_loss: 0.0129\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.1982 - val_loss: 0.0112\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.2025 - val_loss: 0.0103\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.2115 - val_loss: 0.0115\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.2008 - val_loss: 0.0099\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.1907 - val_loss: 0.0116\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 0.1946 - val_loss: 0.0128\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.2098 - val_loss: 0.0113\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.2003 - val_loss: 0.0110\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.1672 - val_loss: 0.0102\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.1945 - val_loss: 0.0132\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.1742 - val_loss: 0.0113\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.1790 - val_loss: 0.0113\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.1940 - val_loss: 0.0120\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.1667 - val_loss: 0.0109\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.1856 - val_loss: 0.0108\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.1914 - val_loss: 0.0131\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.1684 - val_loss: 0.0105\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.1657 - val_loss: 0.0104\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.1395 - val_loss: 0.0102\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.1495 - val_loss: 0.0123\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.1392 - val_loss: 0.0114\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.1562 - val_loss: 0.0122\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.1251 - val_loss: 0.0126\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.1469 - val_loss: 0.0128\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.1010 - val_loss: 0.0119\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0799 - val_loss: 0.0141\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.0750 - val_loss: 0.0115\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0509 - val_loss: 0.0134\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0664 - val_loss: 0.0104\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0613 - val_loss: 0.0115\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0414 - val_loss: 0.0118\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0372 - val_loss: 0.0122\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0516 - val_loss: 0.0116\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0497 - val_loss: 0.0136\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0326 - val_loss: 0.0120\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0335 - val_loss: 0.0109\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0326 - val_loss: 0.0111\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0255 - val_loss: 0.0124\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0252 - val_loss: 0.0113\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0226 - val_loss: 0.0112\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 2s 557ms/step - loss: 0.0264 - val_loss: 0.0125\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 2s 591ms/step - loss: 0.0216 - val_loss: 0.0118\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0327 - val_loss: 0.0106\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0224 - val_loss: 0.0119\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0197 - val_loss: 0.0121\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0204 - val_loss: 0.0120\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0246 - val_loss: 0.0121\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0234 - val_loss: 0.0110\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0175 - val_loss: 0.0115\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0177 - val_loss: 0.0129\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0181 - val_loss: 0.0125\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0183 - val_loss: 0.0133\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 3s 808ms/step - loss: 0.0167 - val_loss: 0.0121\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0146 - val_loss: 0.0110\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0146 - val_loss: 0.0119\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0160 - val_loss: 0.0129\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0153 - val_loss: 0.0115\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0153 - val_loss: 0.0111\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0149 - val_loss: 0.0120\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0162 - val_loss: 0.0100\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0172 - val_loss: 0.0110\n",
      "Epoch 406/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0147 - val_loss: 0.0118\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.0139 - val_loss: 0.0105\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0129 - val_loss: 0.0123\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 2s 601ms/step - loss: 0.0143 - val_loss: 0.0113\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0137 - val_loss: 0.0108\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0140 - val_loss: 0.0116\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0130 - val_loss: 0.0094\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0137 - val_loss: 0.0117\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0121 - val_loss: 0.0092\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 2s 572ms/step - loss: 0.0118 - val_loss: 0.0106\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0132 - val_loss: 0.0126\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0130 - val_loss: 0.0108\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0119 - val_loss: 0.0100\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0117 - val_loss: 0.0160\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0119 - val_loss: 0.0102\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0126 - val_loss: 0.0114\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0121 - val_loss: 0.0118\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0120 - val_loss: 0.0111\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0139 - val_loss: 0.0115\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0147 - val_loss: 0.0120\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0117 - val_loss: 0.0111\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0127 - val_loss: 0.0102\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0097 - val_loss: 0.0124\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0103 - val_loss: 0.0086\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 2s 531ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 2s 531ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0132 - val_loss: 0.0115\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0205 - val_loss: 0.0094\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0111 - val_loss: 0.0096\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 2s 583ms/step - loss: 0.0105 - val_loss: 0.0134\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0119 - val_loss: 0.0111\n",
      "Epoch 468/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0111 - val_loss: 0.0112\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0101 - val_loss: 0.0130\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 482/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0096 - val_loss: 0.0094\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0109 - val_loss: 0.0134\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0099 - val_loss: 0.0108\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0118 - val_loss: 0.0109\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0112 - val_loss: 0.0134\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0117 - val_loss: 0.0113\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0112 - val_loss: 0.0107\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 2s 545ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0103 - val_loss: 0.0127\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 2s 568ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0105 - val_loss: 0.0119\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0116 - val_loss: 0.0114\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 2s 548ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 2s 541ms/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 530/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0125 - val_loss: 0.0105\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 2s 622ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0107 - val_loss: 0.1040\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0112 - val_loss: 0.0097\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0120 - val_loss: 0.0116\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0109 - val_loss: 0.0091\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 2s 547ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0126 - val_loss: 0.0123\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0111 - val_loss: 0.0093\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 2s 544ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0127 - val_loss: 0.0114\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0117 - val_loss: 0.0101\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0106 - val_loss: 0.0090\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0116 - val_loss: 0.0103\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0111 - val_loss: 0.0108\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0106 - val_loss: 0.0131\n",
      "Epoch 592/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 3s 810ms/step - loss: 0.0144 - val_loss: 0.0119\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 3s 850ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0102 - val_loss: 0.0125\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0116 - val_loss: 0.0099\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0113 - val_loss: 0.0117\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0112 - val_loss: 0.0115\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 2s 591ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0113 - val_loss: 0.0104\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0111 - val_loss: 0.0095\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0098 - val_loss: 0.0108\n",
      "Epoch 642/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0102 - val_loss: 0.0098\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0115 - val_loss: 0.0121\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 654/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0111 - val_loss: 0.0104\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0106 - val_loss: 0.0092\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0107 - val_loss: 0.0137\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 2s 561ms/step - loss: 0.0105 - val_loss: 0.0137\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0113 - val_loss: 0.0115\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0108 - val_loss: 0.0115\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0098 - val_loss: 0.0115\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0101 - val_loss: 0.0114\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0103 - val_loss: 0.0129\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0114 - val_loss: 0.0101\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0117 - val_loss: 0.0106\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0107 - val_loss: 0.0092\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 2s 555ms/step - loss: 0.0113 - val_loss: 0.0107\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0132 - val_loss: 0.0095\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 3s 796ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 716/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0107 - val_loss: 0.0095\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0118 - val_loss: 0.0101\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0106 - val_loss: 0.0125\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0098 - val_loss: 0.0107\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.0105 - val_loss: 0.0132\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0094 - val_loss: 0.0103\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 2s 580ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 3s 778ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 3s 789ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0105 - val_loss: 0.0096\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0095 - val_loss: 0.0104\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 778/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0112 - val_loss: 0.0135\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.0101 - val_loss: 0.0109\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 2s 584ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0103 - val_loss: 0.0122\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0097 - val_loss: 0.0095\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 2s 585ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0111 - val_loss: 0.0116\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 802/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 2s 577ms/step - loss: 0.0115 - val_loss: 0.0102\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0118 - val_loss: 0.0116\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 4s 879ms/step - loss: 0.0108 - val_loss: 0.0138\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0099 - val_loss: 0.0121\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0096 - val_loss: 0.0109\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0116 - val_loss: 0.0091\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0107 - val_loss: 0.0100\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0101 - val_loss: 0.0115\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 3s 784ms/step - loss: 0.0096 - val_loss: 0.0093\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 840/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0102 - val_loss: 0.0086\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0096 - val_loss: 0.0124\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 3s 785ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0110 - val_loss: 0.0121\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0099 - val_loss: 0.0115\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0106 - val_loss: 0.0117\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0113 - val_loss: 0.0103\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0100 - val_loss: 0.0106\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0095 - val_loss: 0.0114\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 3s 774ms/step - loss: 0.0099 - val_loss: 0.0109\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0100 - val_loss: 0.0115\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0127 - val_loss: 0.0110\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0111 - val_loss: 0.0134\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 902/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0117 - val_loss: 0.0107\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0113 - val_loss: 0.0129\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 2s 564ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0107 - val_loss: 0.0118\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0100 - val_loss: 0.0107\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0111 - val_loss: 0.0123\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.0101 - val_loss: 0.0118\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 3s 835ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0110 - val_loss: 0.0096\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0108 - val_loss: 0.0124\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 2s 569ms/step - loss: 0.0109 - val_loss: 0.0117\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0105 - val_loss: 0.0091\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0098 - val_loss: 0.0125\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 3s 819ms/step - loss: 0.0107 - val_loss: 0.0090\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0099 - val_loss: 0.0112\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0097 - val_loss: 0.0109\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0123 - val_loss: 0.0120\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0110 - val_loss: 0.0114\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 962/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 964/2000\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0109 - val_loss: 0.0105\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0102 - val_loss: 0.0099\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0095 - val_loss: 0.0101\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0110 - val_loss: 0.0091\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0116 - val_loss: 0.0118\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0103 - val_loss: 0.0099\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0101 - val_loss: 0.0091\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0101 - val_loss: 0.0098\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0106 - val_loss: 0.0087\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 3s 779ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0102 - val_loss: 0.0126\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 2s 621ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 2s 554ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0103 - val_loss: 0.0132\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0115 - val_loss: 0.0118\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 3s 789ms/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0106 - val_loss: 0.0112\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0115 - val_loss: 0.0113\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0094 - val_loss: 0.0127\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0117 - val_loss: 0.0116\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 2s 538ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0102 - val_loss: 0.0118\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0115 - val_loss: 0.0117\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0100 - val_loss: 0.0114\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 1026/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0112 - val_loss: 0.0093\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 2s 531ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0112 - val_loss: 0.0121\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0114 - val_loss: 0.0115\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 3s 687ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 1042/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0110 - val_loss: 0.0119\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0106 - val_loss: 0.0099\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0111 - val_loss: 0.0113\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0099 - val_loss: 0.0101\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0093 - val_loss: 0.0130\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0112 - val_loss: 0.0116\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0107 - val_loss: 0.0115\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0116 - val_loss: 0.0106\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 2s 588ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 1088/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0112 - val_loss: 0.0092\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0116 - val_loss: 0.0123\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 2s 620ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 3s 812ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.0098 - val_loss: 0.0105\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 2s 530ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0113 - val_loss: 0.0111\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0120 - val_loss: 0.0107\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0099 - val_loss: 0.0124\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0122 - val_loss: 0.0119\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0098 - val_loss: 0.0111\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0113 - val_loss: 0.0100\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 2s 589ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 2s 573ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 2s 537ms/step - loss: 0.0111 - val_loss: 0.0127\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0100 - val_loss: 0.0119\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0111 - val_loss: 0.0102\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0101 - val_loss: 0.0117\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0105 - val_loss: 0.0088\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0105 - val_loss: 0.0128\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 2s 574ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 2s 550ms/step - loss: 0.0117 - val_loss: 0.0126\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0119 - val_loss: 0.0121\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0098 - val_loss: 0.0112\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0110 - val_loss: 0.0092\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0109 - val_loss: 0.0121\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 1150/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0115 - val_loss: 0.0100\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0110 - val_loss: 0.0110\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 3s 795ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.0101 - val_loss: 0.0092\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0119 - val_loss: 0.0112\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0102 - val_loss: 0.0106\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 2s 625ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 3s 817ms/step - loss: 0.0102 - val_loss: 0.0085\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 3s 862ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0110 - val_loss: 0.0094\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0092 - val_loss: 0.0120\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 3s 830ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 3s 829ms/step - loss: 0.0099 - val_loss: 0.0106\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 3s 742ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0114 - val_loss: 0.0104\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0110 - val_loss: 0.0118\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0107 - val_loss: 0.0123\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 3s 783ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0109 - val_loss: 0.0104\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0119 - val_loss: 0.0105\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 1200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 779ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 3s 743ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0100 - val_loss: 0.0112\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0112 - val_loss: 0.0127\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0102 - val_loss: 0.0107\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1212/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0105 - val_loss: 0.0125\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.0118 - val_loss: 0.0105\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0103 - val_loss: 0.0088\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0111 - val_loss: 0.0107\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0116 - val_loss: 0.0101\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 3s 786ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0096 - val_loss: 0.0115\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 3s 804ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0097 - val_loss: 0.0112\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 3s 814ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0104 - val_loss: 0.0111\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0115 - val_loss: 0.0112\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0110 - val_loss: 0.0088\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0111 - val_loss: 0.0121\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0121 - val_loss: 0.0108\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 3s 646ms/step - loss: 0.0112 - val_loss: 0.0101\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 3s 728ms/step - loss: 0.0111 - val_loss: 0.0111\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 3s 802ms/step - loss: 0.0104 - val_loss: 0.0102\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0113 - val_loss: 0.0105\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0109 - val_loss: 0.0133\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 2s 584ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0116 - val_loss: 0.0113\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0110 - val_loss: 0.0116\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1274/2000\n",
      "4/4 [==============================] - 2s 623ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0106 - val_loss: 0.0102\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0107 - val_loss: 0.0122\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0110 - val_loss: 0.0101\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0120 - val_loss: 0.0115\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 2s 613ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.0123 - val_loss: 0.0092\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0103 - val_loss: 0.0120\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0109 - val_loss: 0.0106\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 3s 770ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0115 - val_loss: 0.0101\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0112 - val_loss: 0.0113\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 2s 602ms/step - loss: 0.0098 - val_loss: 0.0106\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0114 - val_loss: 0.0113\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 2s 513ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 2s 605ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0103 - val_loss: 0.0115\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 3s 631ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0109 - val_loss: 0.0115\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0105 - val_loss: 0.0112\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 2s 596ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0108 - val_loss: 0.0127\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0107 - val_loss: 0.0088\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0101 - val_loss: 0.0123\n",
      "Epoch 1336/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0101 - val_loss: 0.0111\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 3s 833ms/step - loss: 0.0108 - val_loss: 0.0112\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0102 - val_loss: 0.0103\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0103 - val_loss: 0.0124\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 3s 837ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 3s 738ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0095 - val_loss: 0.0121\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 2s 557ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1358/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0106 - val_loss: 0.0130\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0103 - val_loss: 0.0130\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0115 - val_loss: 0.0116\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0117 - val_loss: 0.0103\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0104 - val_loss: 0.0115\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0107 - val_loss: 0.0130\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0101 - val_loss: 0.0094\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0098 - val_loss: 0.0113\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0118 - val_loss: 0.0107\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 2s 581ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0105 - val_loss: 0.0102\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 3s 747ms/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 3s 860ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 3s 735ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0103 - val_loss: 0.0095\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0108 - val_loss: 0.0100\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0107 - val_loss: 0.0129\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 3s 703ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 1398/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0098 - val_loss: 0.0109\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 3s 630ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0116 - val_loss: 0.0110\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0095 - val_loss: 0.0103\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0095 - val_loss: 0.0120\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0100 - val_loss: 0.0118\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0115 - val_loss: 0.0123\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0114 - val_loss: 0.0106\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0100 - val_loss: 0.0126\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 3s 748ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0111 - val_loss: 0.0106\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0100 - val_loss: 0.0104\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0105 - val_loss: 0.0122\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0108 - val_loss: 0.0090\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0116 - val_loss: 0.0100\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0101 - val_loss: 0.0095\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 3s 764ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 2s 558ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 2s 546ms/step - loss: 0.0104 - val_loss: 0.0108\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0110 - val_loss: 0.0122\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0099 - val_loss: 0.0128\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0101 - val_loss: 0.0097\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 3s 762ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0123 - val_loss: 0.0107\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 3s 746ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 3s 714ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1460/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0112 - val_loss: 0.0126\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 3s 766ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.0104 - val_loss: 0.0133\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0106 - val_loss: 0.0127\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0116 - val_loss: 0.0112\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 3s 732ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0108 - val_loss: 0.0094\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0100 - val_loss: 0.0122\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0113 - val_loss: 0.0102\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 3s 629ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0104 - val_loss: 0.0094\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0104 - val_loss: 0.0138\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 2s 575ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0097 - val_loss: 0.0106\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 3s 666ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 2s 560ms/step - loss: 0.0104 - val_loss: 0.0126\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 2s 603ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 3s 761ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 2s 597ms/step - loss: 0.0115 - val_loss: 0.0132\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 2s 610ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.0105 - val_loss: 0.0101\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0117 - val_loss: 0.0119\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0113 - val_loss: 0.0119\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 2s 598ms/step - loss: 0.0099 - val_loss: 0.0125\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0114 - val_loss: 0.0119\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0104 - val_loss: 0.0096\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1516/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 771ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 3s 793ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 3s 691ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 1522/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0109 - val_loss: 0.0116\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0108 - val_loss: 0.0125\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 2s 582ms/step - loss: 0.0101 - val_loss: 0.0126\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0096 - val_loss: 0.0116\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0105 - val_loss: 0.0115\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0108 - val_loss: 0.0122\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 3s 679ms/step - loss: 0.0115 - val_loss: 0.0119\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0113 - val_loss: 0.0108\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0115 - val_loss: 0.0109\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0106 - val_loss: 0.0104\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 3s 686ms/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.0109 - val_loss: 0.0101\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.0103 - val_loss: 0.0094\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0105 - val_loss: 0.0097\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0101 - val_loss: 0.0108\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 3s 649ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 3s 642ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0100 - val_loss: 0.0124\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 3s 692ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 0.0109 - val_loss: 0.0110\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0097 - val_loss: 0.0107\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 3s 651ms/step - loss: 0.0109 - val_loss: 0.0128\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0101 - val_loss: 0.0104\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0103 - val_loss: 0.0133\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 3s 729ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 3s 853ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0111 - val_loss: 0.0115\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0108 - val_loss: 0.0104\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0098 - val_loss: 0.0110\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0095 - val_loss: 0.0117\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 2s 587ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 2s 600ms/step - loss: 0.0104 - val_loss: 0.0101\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1584/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0116 - val_loss: 0.0102\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0108 - val_loss: 0.0113\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 2s 551ms/step - loss: 0.0109 - val_loss: 0.0118\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 2s 604ms/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0107 - val_loss: 0.0136\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0102 - val_loss: 0.0096\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0106 - val_loss: 0.0120\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 3s 740ms/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0112 - val_loss: 0.0105\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0115 - val_loss: 0.0115\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0116 - val_loss: 0.0098\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 3s 656ms/step - loss: 0.0106 - val_loss: 0.0121\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 3s 702ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0102 - val_loss: 0.0088\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 2s 595ms/step - loss: 0.0109 - val_loss: 0.0102\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 3s 696ms/step - loss: 0.0101 - val_loss: 0.0129\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 3s 715ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0110 - val_loss: 0.0111\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0114 - val_loss: 0.0107\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0114 - val_loss: 0.0109\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0113 - val_loss: 0.0106\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 3s 777ms/step - loss: 0.0095 - val_loss: 0.0113\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 3s 727ms/step - loss: 0.0106 - val_loss: 0.0100\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 3s 668ms/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0097 - val_loss: 0.0104\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0107 - val_loss: 0.0098\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 3s 768ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 3s 769ms/step - loss: 0.0110 - val_loss: 0.0097\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 3s 684ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0100 - val_loss: 0.0096\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 3s 771ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0112 - val_loss: 0.0104\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 3s 628ms/step - loss: 0.0113 - val_loss: 0.0121\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 3s 632ms/step - loss: 0.0104 - val_loss: 0.0127\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0099 - val_loss: 0.0105\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0108 - val_loss: 0.0130\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0111 - val_loss: 0.0114\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 3s 700ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0116 - val_loss: 0.0119\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0107 - val_loss: 0.0107\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 3s 670ms/step - loss: 0.0109 - val_loss: 0.0098\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 3s 633ms/step - loss: 0.0100 - val_loss: 0.0110\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 3s 678ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1646/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0110 - val_loss: 0.0098\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0103 - val_loss: 0.0109\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 3s 763ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 3s 694ms/step - loss: 0.0103 - val_loss: 0.0106\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 2s 618ms/step - loss: 0.0103 - val_loss: 0.0100\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0102 - val_loss: 0.0121\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0099 - val_loss: 0.0092\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 3s 733ms/step - loss: 0.0105 - val_loss: 0.0087\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0117 - val_loss: 0.0091\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 2s 559ms/step - loss: 0.0108 - val_loss: 0.0114\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 3s 643ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0102 - val_loss: 0.0119\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 2s 590ms/step - loss: 0.0093 - val_loss: 0.0111\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0099 - val_loss: 0.0107\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0100 - val_loss: 0.0123\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 3s 737ms/step - loss: 0.0116 - val_loss: 0.0130\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 3s 756ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 3s 731ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0096 - val_loss: 0.0131\n",
      "Epoch 1674/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0114 - val_loss: 0.0121\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0104 - val_loss: 0.0113\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 3s 719ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 3s 754ms/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 3s 693ms/step - loss: 0.0112 - val_loss: 0.0108\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 3s 830ms/step - loss: 0.0113 - val_loss: 0.0122\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 3s 701ms/step - loss: 0.0105 - val_loss: 0.0117\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 3s 753ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 3s 790ms/step - loss: 0.0102 - val_loss: 0.0113\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0105 - val_loss: 0.0120\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0118 - val_loss: 0.0108\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 3s 717ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0121 - val_loss: 0.0127\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 2s 599ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 3s 671ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 3s 767ms/step - loss: 0.0103 - val_loss: 0.0118\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 3s 776ms/step - loss: 0.0108 - val_loss: 0.0116\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 3s 760ms/step - loss: 0.0098 - val_loss: 0.0116\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0107 - val_loss: 0.0106\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0113 - val_loss: 0.0120\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 3s 699ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0105 - val_loss: 0.0111\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 3s 681ms/step - loss: 0.0114 - val_loss: 0.0100\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 3s 673ms/step - loss: 0.0107 - val_loss: 0.0119\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 1708/2000\n",
      "4/4 [==============================] - 2s 576ms/step - loss: 0.0106 - val_loss: 0.0119\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 3s 655ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 3s 722ms/step - loss: 0.0108 - val_loss: 0.0099\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 3s 639ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 3s 800ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 3s 759ms/step - loss: 0.0113 - val_loss: 0.0097\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 3s 697ms/step - loss: 0.0110 - val_loss: 0.0129\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 2s 611ms/step - loss: 0.0101 - val_loss: 0.0119\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 2s 617ms/step - loss: 0.0108 - val_loss: 0.0117\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 3s 672ms/step - loss: 0.0099 - val_loss: 0.0117\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0102 - val_loss: 0.0122\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 3s 625ms/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 2s 616ms/step - loss: 0.0108 - val_loss: 0.0123\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0115 - val_loss: 0.0105\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0110 - val_loss: 0.0102\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0112 - val_loss: 0.0110\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0104 - val_loss: 0.0132\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0110 - val_loss: 0.0115\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 3s 775ms/step - loss: 0.0106 - val_loss: 0.0106\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 3s 739ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0107 - val_loss: 0.0087\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0113 - val_loss: 0.0126\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 3s 758ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 3s 765ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 3s 745ms/step - loss: 0.0102 - val_loss: 0.0115\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0104 - val_loss: 0.0118\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 3s 718ms/step - loss: 0.0109 - val_loss: 0.0095\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0108 - val_loss: 0.0095\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0103 - val_loss: 0.0123\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 3s 680ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0103 - val_loss: 0.0119\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 3s 782ms/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0110 - val_loss: 0.0083\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 3s 659ms/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 3s 741ms/step - loss: 0.0103 - val_loss: 0.0110\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 3s 648ms/step - loss: 0.0105 - val_loss: 0.0093\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 2s 607ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 3s 661ms/step - loss: 0.0108 - val_loss: 0.0121\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 3s 676ms/step - loss: 0.0110 - val_loss: 0.0105\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 3s 650ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 2s 612ms/step - loss: 0.0101 - val_loss: 0.0106\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0104 - val_loss: 0.0114\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0110 - val_loss: 0.0135\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 3s 677ms/step - loss: 0.0110 - val_loss: 0.0123\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 2s 609ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0105 - val_loss: 0.0104\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0099 - val_loss: 0.0118\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 3s 716ms/step - loss: 0.0110 - val_loss: 0.0126\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 2s 592ms/step - loss: 0.0107 - val_loss: 0.0134\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 3s 641ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0116 - val_loss: 0.0109\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 3s 636ms/step - loss: 0.0099 - val_loss: 0.0131\n",
      "Epoch 1770/2000\n",
      "4/4 [==============================] - 3s 723ms/step - loss: 0.0111 - val_loss: 0.0110\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 3s 669ms/step - loss: 0.0111 - val_loss: 0.0125\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 2s 539ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 2s 578ms/step - loss: 0.0107 - val_loss: 0.0117\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 3s 705ms/step - loss: 0.0108 - val_loss: 0.0110\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 3s 667ms/step - loss: 0.0106 - val_loss: 0.0114\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0121 - val_loss: 0.0111\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 3s 734ms/step - loss: 0.0106 - val_loss: 0.0122\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 3s 721ms/step - loss: 0.0111 - val_loss: 0.0101\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 3s 689ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 3s 688ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 3s 709ms/step - loss: 0.0099 - val_loss: 0.0113\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 3s 794ms/step - loss: 0.0097 - val_loss: 0.0105\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 3s 781ms/step - loss: 0.0104 - val_loss: 0.0090\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 3s 720ms/step - loss: 0.0107 - val_loss: 0.0109\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 3s 675ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0091 - val_loss: 0.0110\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 2s 619ms/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0112 - val_loss: 0.0102\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 3s 744ms/step - loss: 0.0116 - val_loss: 0.0096\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 3s 755ms/step - loss: 0.0109 - val_loss: 0.0093\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0113 - val_loss: 0.0084\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 3s 749ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 2s 615ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0105 - val_loss: 0.0116\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 3s 704ms/step - loss: 0.0102 - val_loss: 0.0123\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0105 - val_loss: 0.0143\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 3s 634ms/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 3s 647ms/step - loss: 0.0110 - val_loss: 0.0107\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 3s 695ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 3s 750ms/step - loss: 0.0099 - val_loss: 0.0103\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0108 - val_loss: 0.0108\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0107 - val_loss: 0.0096\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 3s 736ms/step - loss: 0.0105 - val_loss: 0.0099\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0110 - val_loss: 0.0113\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 2s 624ms/step - loss: 0.0111 - val_loss: 0.0100\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 2s 608ms/step - loss: 0.0118 - val_loss: 0.0121\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 3s 658ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 2s 567ms/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 2s 586ms/step - loss: 0.0105 - val_loss: 0.0100\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0108 - val_loss: 0.0093\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 3s 635ms/step - loss: 0.0103 - val_loss: 0.0112\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 2s 553ms/step - loss: 0.0102 - val_loss: 0.0108\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 3s 690ms/step - loss: 0.0113 - val_loss: 0.0116\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 3s 638ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 3s 662ms/step - loss: 0.0106 - val_loss: 0.0101\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 3s 637ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0107 - val_loss: 0.0091\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 3s 712ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 3s 707ms/step - loss: 0.0101 - val_loss: 0.0093\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 3s 710ms/step - loss: 0.0108 - val_loss: 0.0111\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 3s 682ms/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 3s 730ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 3s 640ms/step - loss: 0.0104 - val_loss: 0.0099\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 3s 645ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 558ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 3s 711ms/step - loss: 0.0108 - val_loss: 0.0092\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 3s 683ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0113 - val_loss: 0.0085\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 3s 660ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 3s 788ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 3s 708ms/step - loss: 0.0113 - val_loss: 0.0124\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 3s 652ms/step - loss: 0.0114 - val_loss: 0.0098\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 3s 674ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0100 - val_loss: 0.0127\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 3s 657ms/step - loss: 0.0102 - val_loss: 0.0109\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 3s 654ms/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 2s 594ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0112 - val_loss: 0.0095\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 3s 713ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 2s 606ms/step - loss: 0.0105 - val_loss: 0.0109\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 3s 706ms/step - loss: 0.0104 - val_loss: 0.0121\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 3s 626ms/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 3s 780ms/step - loss: 0.0103 - val_loss: 0.0091\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 3s 752ms/step - loss: 0.0110 - val_loss: 0.0095\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 3s 644ms/step - loss: 0.0112 - val_loss: 0.0109\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 3s 665ms/step - loss: 0.0106 - val_loss: 0.0094\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 3s 751ms/step - loss: 0.0107 - val_loss: 0.0120\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 3s 653ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 3s 627ms/step - loss: 0.0098 - val_loss: 0.0121\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 2s 614ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 3s 663ms/step - loss: 0.0102 - val_loss: 0.0116\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 0.0115 - val_loss: 0.0110\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 3s 725ms/step - loss: 0.0108 - val_loss: 0.0119\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 3s 726ms/step - loss: 0.0098 - val_loss: 0.0092\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 3s 772ms/step - loss: 0.0109 - val_loss: 0.0122\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 3s 724ms/step - loss: 0.0106 - val_loss: 0.0123\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 3s 757ms/step - loss: 0.0115 - val_loss: 0.0111\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 3s 664ms/step - loss: 0.0106 - val_loss: 0.0105\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 3s 819ms/step - loss: 0.0108 - val_loss: 0.0098\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 3s 685ms/step - loss: 0.0109 - val_loss: 0.0103\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 2s 524ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 2s 593ms/step - loss: 0.0101 - val_loss: 0.0112\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 2s 543ms/step - loss: 0.0105 - val_loss: 0.0126\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 2s 552ms/step - loss: 0.0107 - val_loss: 0.0108\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 2s 566ms/step - loss: 0.0102 - val_loss: 0.0130\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 2s 451ms/step - loss: 0.0116 - val_loss: 0.0111\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 2s 525ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 2s 475ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 2s 437ms/step - loss: 0.0105 - val_loss: 0.0113\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.0099 - val_loss: 0.0097\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 2s 401ms/step - loss: 0.0114 - val_loss: 0.0111\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 2s 408ms/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 0.0114 - val_loss: 0.0116\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.0107 - val_loss: 0.0101\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0106 - val_loss: 0.0108\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.0110 - val_loss: 0.0127\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.0102 - val_loss: 0.0112\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 2s 405ms/step - loss: 0.0112 - val_loss: 0.0106\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 2s 402ms/step - loss: 0.0110 - val_loss: 0.0133\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 0.0108 - val_loss: 0.0118\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 1894/2000\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0104 - val_loss: 0.0107\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 2s 390ms/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.0105 - val_loss: 0.0121\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0106 - val_loss: 0.0111\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0116 - val_loss: 0.0104\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.0105 - val_loss: 0.0110\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 2s 402ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0104 - val_loss: 0.0105\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.0098 - val_loss: 0.0102\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 2s 427ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 2s 398ms/step - loss: 0.0101 - val_loss: 0.0113\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 2s 392ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.0115 - val_loss: 0.0124\n",
      "Epoch 1911/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.0117 - val_loss: 0.0121\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.0107 - val_loss: 0.0116\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.0115 - val_loss: 0.0107\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.0107 - val_loss: 0.0114\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.0097 - val_loss: 0.0123\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0112 - val_loss: 0.0114\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 2s 399ms/step - loss: 0.0118 - val_loss: 0.0110\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 2s 431ms/step - loss: 0.0105 - val_loss: 0.0105\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.0109 - val_loss: 0.0100\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 2s 401ms/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 2s 407ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 2s 390ms/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 2s 401ms/step - loss: 0.0101 - val_loss: 0.0125\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0104 - val_loss: 0.0100\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 2s 401ms/step - loss: 0.0103 - val_loss: 0.0114\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 2s 428ms/step - loss: 0.0109 - val_loss: 0.0109\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.0111 - val_loss: 0.0122\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0106 - val_loss: 0.0109\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.0103 - val_loss: 0.0103\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.0102 - val_loss: 0.0095\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.0113 - val_loss: 0.0118\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.0107 - val_loss: 0.0097\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0108 - val_loss: 0.0102\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 2s 421ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.0109 - val_loss: 0.0097\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 2s 404ms/step - loss: 0.0099 - val_loss: 0.0094\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0100 - val_loss: 0.0113\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.0105 - val_loss: 0.0098\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 0.0105 - val_loss: 0.0095\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.0107 - val_loss: 0.0110\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0104 - val_loss: 0.0110\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 0.0100 - val_loss: 0.0091\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 2s 413ms/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 2s 424ms/step - loss: 0.0111 - val_loss: 0.0117\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 2s 405ms/step - loss: 0.0109 - val_loss: 0.0111\n",
      "Epoch 1956/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0117 - val_loss: 0.0112\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0104 - val_loss: 0.0109\n",
      "Epoch 1958/2000\n",
      "4/4 [==============================] - 2s 407ms/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0105 - val_loss: 0.0124\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0108 - val_loss: 0.0107\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.0110 - val_loss: 0.0130\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 2s 406ms/step - loss: 0.0109 - val_loss: 0.0099\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0109 - val_loss: 0.0114\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0105 - val_loss: 0.0106\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0111 - val_loss: 0.0097\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.0100 - val_loss: 0.0109\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 2s 397ms/step - loss: 0.0103 - val_loss: 0.0107\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0106 - val_loss: 0.0097\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 2s 409ms/step - loss: 0.0108 - val_loss: 0.0109\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 2s 419ms/step - loss: 0.0103 - val_loss: 0.0113\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 2s 409ms/step - loss: 0.0107 - val_loss: 0.0121\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 2s 412ms/step - loss: 0.0116 - val_loss: 0.0122\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0107 - val_loss: 0.0104\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.0108 - val_loss: 0.0097\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0103 - val_loss: 0.0116\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.0101 - val_loss: 0.0105\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 2s 410ms/step - loss: 0.0107 - val_loss: 0.0103\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 2s 416ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0109 - val_loss: 0.0119\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.0110 - val_loss: 0.0104\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.0102 - val_loss: 0.0117\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 2s 423ms/step - loss: 0.0106 - val_loss: 0.0113\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 2s 417ms/step - loss: 0.0102 - val_loss: 0.0110\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 2s 395ms/step - loss: 0.0106 - val_loss: 0.0116\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0101 - val_loss: 0.0122\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 2s 433ms/step - loss: 0.0106 - val_loss: 0.0110\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 2s 420ms/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 1989/2000\n",
      "4/4 [==============================] - 2s 391ms/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 1990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 2s 409ms/step - loss: 0.0105 - val_loss: 0.0118\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 2s 426ms/step - loss: 0.0105 - val_loss: 0.0107\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 2s 411ms/step - loss: 0.0101 - val_loss: 0.0102\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0111 - val_loss: 0.0120\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 2s 414ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 2s 396ms/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 2s 425ms/step - loss: 0.0108 - val_loss: 0.0105\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 2s 418ms/step - loss: 0.0112 - val_loss: 0.0120\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 2s 422ms/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0106 - val_loss: 0.0098\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 2s 415ms/step - loss: 0.0108 - val_loss: 0.0120\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(tdg, callbacks=[mc,tb], initial_epoch=0\n",
    "                           ,steps_per_epoch=train_steps_per_epoch\n",
    "                           ,validation_data=vdg\n",
    "                           ,validation_steps=val_steps_per_epoch\n",
    "                           ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# acc = hist.history['acc']\n",
    "# loss = hist.history['loss']\n",
    "\n",
    "# # Create count of the number of epochs\n",
    "# epoch_count = range(1, len(acc) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# # plt.plot(epoch_count, acc, 'b-')\n",
    "# fig, ax = plt.subplots(ncols=2,sharex=True)\n",
    "# ax[0].plot(epoch_count, loss, 'r--')\n",
    "# ax[0].legend(['Loss'])\n",
    "# ax[0].set_xlabel('Epoch')\n",
    "# ax[0].set_ylabel('Loss')\n",
    "# ax[1].plot(epoch_count, acc, 'b-')\n",
    "# ax[1].legend(['Accuracy'])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_xlabel('Accuracy')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.DataFrame(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['acc','val_acc']].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('weights/dnf300_sa_sent_hd_vector.hdf5')\n",
    "model.evaluate_generator(test_dg,steps=5,pickle_safe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_dg)\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(x['headline'])):\n",
    "    \n",
    "    print(i,':',x['headline'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hillary clinton in 2013: 'i would like to see people like donald trump run for office\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx = 3\n",
    "display(x['headline'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Before running against billionaire real estate mogul Donald Trump for the presidency, Secretary of State Hillary Clinton told an audience at a private, paid speech she wanted to see more successful businessmen and women run for office because they can’t be bought.',\n",
       " 'In a speech made public by Wikileaks – which released an email from Hillary for America Research Director Tony Caark containing three attached speeches given at a private Goldman Sachs events – Clinton spoke and took audience questions at the “Builders and Innovators Summit” hosted by Goldman Sachs on October 29, 2013.',\n",
       " 'Answering a question about businessmen in politics, Clinton said that they are “most often the people that look over the horizon,” and therefore share a vision that many politicians of today lack. “',\n",
       " 'And that’s a very good question and thank you for asking it.',\n",
       " 'Yes, I would love to see more businessmen go into politics because I believe they would bring in an entirely different mindset and strategies than what we’re used to seeing traditionally,” she opined.',\n",
       " 'And then she just had to go on. “',\n",
       " 'In fact, when you say businessmen and women, I can’t help but think of a particular one that I would just love to see running for the presidency at some point in the future,” Clinton added. “',\n",
       " 'I don’t know what it is exactly about him, I can’t quite put my finger on it, but my instinct is almost never wrong.',\n",
       " 'And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.”',\n",
       " 'Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “',\n",
       " 'And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.',\n",
       " 'I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['sentences'][test_idx]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 35, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 35, 16)       14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 35, 16)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 35, 32)       1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 35, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 35, 32)       128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 128)      0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 35, 256)      98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 35, 256)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 256)      1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 35, 256), (1 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 35, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 35, 16)       14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 35, 16)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 35, 32)       1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 35, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 35, 32)       128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 128)      0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 35, 256)      98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 35, 256)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 256)      1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 35, 256), (1 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 35, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 35, 16)       14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 35, 16)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 35, 32)       1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 35, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 35, 32)       128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 128)      0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 35, 256)      98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 35, 256)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 256)      1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 35, 256), (1 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 35, 300)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 35, 16)       14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 35, 16)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 35, 32)       1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 35, 32)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 35, 32)       128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 35, 32), (35 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35, 128)      0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 35, 256)      98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 35, 256)      0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 35, 256)      1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 35, 256), (1 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(model.inputs,model.get_layer(name='ca1').output)\n",
    "model_2 = Model(model.inputs,model.get_layer(name='ca2').output)\n",
    "model_3 = Model(model.inputs,model.get_layer(name='ca3').output)\n",
    "model_4 = Model(model.inputs,model.get_layer(name='ca4').output)\n",
    "model_1.summary()\n",
    "model_2.summary()\n",
    "model_3.summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, b1, g1 = model_1.predict(x)\n",
    "_, b2, g2 = model_2.predict(x)\n",
    "_, b3, g3 = model_3.predict(x)\n",
    "_, b4, g4 = model_4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g1,g2,g3,g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b1+b2+b3+b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11, 10,  9,  5,  8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_N = 5\n",
    "t = b[test_idx][0][:len(x['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.49168015"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "b[test_idx][0][:len(x['sentences'][test_idx])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"hillary clinton in 2013: 'i would like to see people like donald trump run for office\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Before running against billionaire real estate mogul Donald Trump for the presidency, Secretary of State Hillary Clinton told an audience at a private, paid speech she wanted to see more successful businessmen and women run for office because they can’t be bought.',\n",
       " 'And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.” Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.',\n",
       " 'I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x['headline'][test_idx])\n",
    "display(x['claims'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 : I also think he understands the philanthropic and charitable side of things quite well, which is a crucial skill for any politician,” she praised her current counter-candidate.\n",
      "10 : And I think that goes especially for Donald Trump, whose successful projects and business ventures have made him synonymous with big business and, more importantly, creating thousands of jobs.\n",
      "9 : Asked to elaborate on her statement, the former Secretary of State argued that she thinks that businessmen “can’t be bought” and that they’re “very honest.” “\n",
      "5 : And then she just had to go on. “\n",
      "8 : And it’s telling me that Donald Trump would be very successful if he were to venture into politics in the future.”\n"
     ]
    }
   ],
   "source": [
    "for s in t:\n",
    "    if s>=len(x['sentences'][test_idx]):continue\n",
    "    print(s,':',x['sentences'][test_idx][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-3.6989129"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "h_s_attended_vector = b[test_idx][0][:len(x['sentences'][test_idx])]\n",
    "h_s_attended_vector.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h_s_attended_vector = pd.DataFrame(h_s_attended_vector)\n",
    "\n",
    "\n",
    "xw = df_h_s_attended_vector.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xw_scaled = min_max_scaler.fit_transform(xw)\n",
    "df_h_s_attended_vector = pd.DataFrame(xw_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa031428748>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(2.0,7.0)})\n",
    "sns.heatmap(df_h_s_attended_vector, annot=True, cmap='YlGnBu', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 35, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 35, 16)            14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 32)            1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 35, 32)            128       \n",
      "_________________________________________________________________\n",
      "sa1 (SelfAttention)          [(None, 35, 32), (35, 35) 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 35, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 35, 16)            14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 32)            1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 35, 32)            128       \n",
      "_________________________________________________________________\n",
      "sa2 (SelfAttention)          [(None, 35, 32), (35, 35) 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 35, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 35, 16)            14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 32)            1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 35, 32)            128       \n",
      "_________________________________________________________________\n",
      "sa3 (SelfAttention)          [(None, 35, 32), (35, 35) 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 35, 300)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 35, 16)            14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 35, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 35, 32)            1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 35, 32)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 35, 32)            128       \n",
      "_________________________________________________________________\n",
      "sa4 (SelfAttention)          [(None, 35, 32), (35, 35) 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s1 = Model(model.inputs,model.get_layer(name='sa1').output)\n",
    "model_s2 = Model(model.inputs,model.get_layer(name='sa2').output)\n",
    "model_s3 = Model(model.inputs,model.get_layer(name='sa3').output)\n",
    "model_s4 = Model(model.inputs,model.get_layer(name='sa4').output)\n",
    "model_s1.summary()\n",
    "model_s2.summary()\n",
    "model_s3.summary()\n",
    "model_s4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sb1, sg1 = model_s1.predict([x['sentence_vectors'],x['input_headline_vector']])\n",
    "_, sb2, sg2 = model_s2.predict(x)\n",
    "_, sb3, sg3 = model_s3.predict(x)\n",
    "_, sb4, sg4 = model_s4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461,\n",
       "        0.00227461, 0.00227461, 0.00227461, 0.00227461, 0.00227461],\n",
       "       dtype=float32),\n",
       " array([-0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605,\n",
       "        -0.00252605, -0.00252605, -0.00252605, -0.00252605, -0.00252605],\n",
       "       dtype=float32),\n",
       " array([0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062,\n",
       "        0.00026062, 0.00026062, 0.00026062, 0.00026062, 0.00026062],\n",
       "       dtype=float32),\n",
       " array([0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785, 0.0028785,\n",
       "        0.0028785, 0.0028785], dtype=float32))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg1,sg2, sg3, sg4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = sb1[test_idx]+sb2[test_idx]+sb3[test_idx]+sb4[test_idx]\n",
    "sb = sb[:len(x['sentences'][test_idx]),:len(x['sentences'][test_idx])]\n",
    "\n",
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb = pd.DataFrame(sb)\n",
    "\n",
    "\n",
    "# zx = df_sb.values #returns a numpy array\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# zx_scaled = min_max_scaler.fit_transform(zx)\n",
    "# df_sb = pd.DataFrame(zx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa0301dc780>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14.0,12.0)})\n",
    "sns.heatmap(pd.DataFrame(df_sb),annot=True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This US has publicly threatened ‘retaliatory’ hacks against Russia for weeks now, based on allegations that Russia may have been involved in certain hacks related to Democratic presidential candidate Hillary Clinton.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Russia denied involvement and the US government has been unable to produce any concrete evidence of Russian involvement.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vice President Joe Biden went so far as to confirm the US had informed Vladimir Putin that the US would conduct revenge attacks “at the time of our choosing.”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The time may ultimately be America’s election day, according to officials familiar with the situation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NBC News has reported seeing top secret documents from these officials detailing potential US plans to launch military cyber attacks against Russia’s civilian infrastructure, with the documents claiming advanced US cyber weapons were prepared to take down Russia’s entire electricity grid, all telecommunications networks, and the Kremlin’s own command systems.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The reports are emerging in the context of US officials speculating that Russia might launch cyber attacks against the US during the election to try to disrupt it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Since they offered no evidence for this either, it raises concerns that the US is simply setting up a pretext for timing its own attacks around them.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>That officials are trying to assure the media that such huge attacks would only be launched in retaliation offers little comfort, given the administration’s willingness to claim anything and everything remotely election-related and embarrassing to the Clinton campaign as a Russian plot.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Such massive US attacks on Russian infrastructure, regardless of the pretext, would likely be seen as an act of war.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The US has made clear in the past they would regard cyber attacks of a large enough scale as equivalent to conventional military attacks, and given the scale that it being discussed it’s hard to imagine Russia would not react similarly.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                           0\n",
       "0  This US has publicly threatened ‘retaliatory’ hacks against Russia for weeks now, based on allegations that Russia may have been involved in certain hacks related to Democratic presidential candidate Hillary Clinton.                                                                                                                                                 \n",
       "1  Russia denied involvement and the US government has been unable to produce any concrete evidence of Russian involvement.                                                                                                                                                                                                                                                 \n",
       "2  Vice President Joe Biden went so far as to confirm the US had informed Vladimir Putin that the US would conduct revenge attacks “at the time of our choosing.”                                                                                                                                                                                                           \n",
       "3  The time may ultimately be America’s election day, according to officials familiar with the situation.                                                                                                                                                                                                                                                                   \n",
       "4  NBC News has reported seeing top secret documents from these officials detailing potential US plans to launch military cyber attacks against Russia’s civilian infrastructure, with the documents claiming advanced US cyber weapons were prepared to take down Russia’s entire electricity grid, all telecommunications networks, and the Kremlin’s own command systems.\n",
       "5  The reports are emerging in the context of US officials speculating that Russia might launch cyber attacks against the US during the election to try to disrupt it.                                                                                                                                                                                                      \n",
       "6  Since they offered no evidence for this either, it raises concerns that the US is simply setting up a pretext for timing its own attacks around them.                                                                                                                                                                                                                    \n",
       "7  That officials are trying to assure the media that such huge attacks would only be launched in retaliation offers little comfort, given the administration’s willingness to claim anything and everything remotely election-related and embarrassing to the Clinton campaign as a Russian plot.                                                                          \n",
       "8  Such massive US attacks on Russian infrastructure, regardless of the pretext, would likely be seen as an act of war.                                                                                                                                                                                                                                                     \n",
       "9  The US has made clear in the past they would regard cyber attacks of a large enough scale as equivalent to conventional military attacks, and given the scale that it being discussed it’s hard to imagine Russia would not react similarly.                                                                                                                             "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x['sentences'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
