{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sklearn.preprocessing as preprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import spacy\n",
    "from keras.utils import to_categorical\n",
    "from spacy.lang.en import English\n",
    "pd.set_option('display.max_colwidth', 0)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "from tqdm import tqdm_notebook\n",
    "from keras.layers import BatchNormalization, Lambda, Concatenate, Dropout, Conv1D, MaxPooling1D, Input, TimeDistributed, Dense, LSTM, RepeatVector, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from AttentionModules import SelfAttention, CrossAttention\n",
    "import sys,os\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "sess = tf.Session(config=config)\n",
    "set_session(sess)  # set this TensorFlow session as the default session for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['authors', 'claim_ids', 'evidence', 'headline', 'id', 'reason',\n",
       "        'claims', 'type', 'urls'],\n",
       "       dtype='object'),\n",
       " Index(['authors', 'headline', 'id', 'type', 'urls'], dtype='object'),\n",
       " 705,\n",
       " 705)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnf700 = pd.read_json('evaluation_set/deepnofakes/dnf_700/initial.json')\n",
    "dnf_eval = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "dnf_eval.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls'] \n",
    "with open('evaluation_set/deepnofakes/dnf_700/dnf700_sent_array_id.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_700/dnf700_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_array_id.p', 'rb') as fp:\n",
    "    articles300 = pickle.load(fp)\n",
    "with open('evaluation_set/deepnofakes/dnf_300/cleaned/cleaned_dnf300_sent_vector_array_id.p', 'rb') as fp:\n",
    "    article_vectors300 = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "dnf_eval.keys(), dnf700.keys(), len(articles.keys()), len(article_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_splits = 5\n",
    "kf = KFold(n_splits=num_splits)\n",
    "train_batchsize = 32\n",
    "val_batchsize = 32\n",
    "test_batchsize = 50\n",
    "train_steps_per_epoch = 4\n",
    "val_steps_per_epoch = 1\n",
    "epochs = 2000\n",
    "max_sentences = 500\n",
    "# for idx in articles.keys():\n",
    "#     num = len(articles[idx])\n",
    "#     if num>=max_sentences:\n",
    "#         max_sentences = num\n",
    "        \n",
    "max_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>headline</th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [authors, headline, id, type, urls]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdl = \"George Soros: Trump Will Win Popular Vote by a Landslide but Clinton Victory a 'Done Deal'\"\n",
    "hdl = \"Ted Cruz Said 'If Something Happens to Hillary' He'll 'Run as a Democrat Against Trump'\"\n",
    "# hdl = \"If You Thought The Trump Child Rape Case In NY Couldn’t Get Much Worse — You Were Wrong\"\n",
    "# hdl = \"California Set to Let Public Schools Teach Primarily in Spanish\"\n",
    "dnf700[dnf700.headline==hdl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "698"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = sorted(dnf700.headline.unique())\n",
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(VIDEO) Female College Students Protesting Because ‘Trump is a Rapist’',\n",
       " 'Assange Confirms: WikiLeaks Didn’t Get Emails From Russian Govt',\n",
       " 'BREAKING: Fraudulent Clinton Votes Discovered By The Tens Of Thousands',\n",
       " \"Clinton Camp Demands 'Compliant Citizenry' for Master Plan\",\n",
       " 'Clinton Received Debate Questions Week Before Debate',\n",
       " \"DOJ's Loretta Lynch Tried To Squash Comey's Letter To Congress\",\n",
       " 'Department of Homeland Security Chairman Officially Indicts Hillary Clinton of Treason',\n",
       " 'Developing: Obama WH admits that Hillary gave ISIS $400 million on accident',\n",
       " 'Erdoğan: US, the founder of ISIS',\n",
       " \"FANTASTIC! TRUMP'S 7 POINT PLAN To Reform Healthcare Begins With A Bombshell! » 100percentfedUp.com\",\n",
       " 'FBI Agent Suspected in Hillary Email Leaks Found Dead in Apparent Murder-Suicide',\n",
       " 'FBI Director Comey’s ‘Leaked’ Memo Explains Why He’s Reopening the Clinton Email Case',\n",
       " 'FBI director received millions from Clinton Foundation, his brother’s law firm does Clinton’s taxes',\n",
       " 'Former NATO Chief: We Need US as ‘World’s Policeman’',\n",
       " \"George Soros: Trump Will Win Popular Vote by a Landslide but Clinton Victory a 'Done Deal'\",\n",
       " 'HE’S NEVER SOLD AN ORIGINAL PAINTING UNTIL NOW…And This One’s Going In The White House',\n",
       " 'HILLARY’S (Islamic) AMERICA IS ALREADY HERE where ‘Muslim NO-GO ZONES’ are popping up all over Michiganistan',\n",
       " \"Hillary Clinton Cut Her Tax Bill by 'Donating' $1 Million to Herself via the Clinton Foundation?\",\n",
       " 'Hillary Clinton Used Hand Signals to Rig Debate?',\n",
       " \"Hillary Clinton Wore 'Secret Earpiece' During Commander-in-Chief Forum\",\n",
       " 'Hillary Clinton Wore Secret Earpiece During First Presidential Debate?',\n",
       " \"Hillary Clinton in 2013: 'I Would Like to See People Like Donald Trump Run for Office\",\n",
       " \"Hillary Clinton's 'Sudden Move' of $1.8 Billion to Qatar Central Bank Stuns Financial World\",\n",
       " 'Hillary Clinton’s Sudden Move Of $1.8 Billion To Qatar Central Bank Stuns Financial World',\n",
       " 'Hillary Friend Bribed FBI Agent and His Wife',\n",
       " 'Hillary Personally Ordered ‘Donald Duck’ Troll Campaign',\n",
       " 'Hillary Sold Weapons To ISIS, Wikileaks Confirms',\n",
       " 'ISIS Leader Calls for American Muslim Voters to Support Hillary Clinton',\n",
       " 'Jill Stein Endorsed Donald Trump',\n",
       " 'Julian Assange Makes VERY Suspect Post Election Announcement, Seeks Pardon From Trump',\n",
       " 'KREMLIN: Putin Congratulates Trump, Hopes to Work Together Major Issues',\n",
       " 'LOL! BRITISH WIFE Of LIB ACTOR Who Said: There Will Never Be A President Donald Trump…Warns Americans About President-Elect Trump [VIDEO]',\n",
       " 'Leaked 2013 Trump Tax Return Shows He Paid Over 40 Million in Taxes',\n",
       " 'NSA Whistleblower Says DNC Email Hack Was Not by Russia, but by US Intelligence | Alternative',\n",
       " 'Obama Declares His Family Will Move to Canada If Trump Is Elected',\n",
       " 'Pentagon Officials Furious After Clinton Announces US Response Time for Nuclear Launch During Debate',\n",
       " 'Pentagon Seeks Another $6 Billion for Overseas Troop Deployments',\n",
       " \"Physician Confirms Hillary Clinton Has Parkinson's Disease\",\n",
       " 'President Obama Confirms He Will Refuse to Leave Office If Trump Is Elected',\n",
       " 'Reddit Users Declare War On Hillary’s Paid Internet Trolls',\n",
       " \"Ted Cruz Said 'If Something Happens to Hillary' He'll 'Run as a Democrat Against Trump'\",\n",
       " 'The Clinton Foundation has purchased over $137 million of illegal arms and ammunition',\n",
       " 'Top aide: Hillary ‘still not perfect in her head’, Wikileaks',\n",
       " 'Trump accuses Obama, Hillary Clinton of founding Daesh',\n",
       " 'US Officials See No Link Between Trump and Russia',\n",
       " 'US Officials Try to Scare Voters With Terror Threat',\n",
       " 'US Threatens Military Hacks on Russia’s Electric, Communications Grids Over Election',\n",
       " 'WIKILEAKS: Hillary Got $12 Million for Clinton Charity As Quid Pro Quo For Morocco Meeting',\n",
       " 'WikiLeaks CONFIRMS Hillary Sold Weapons to ISIS... Then Drops Another BOMBSHELL! Breaking News',\n",
       " 'WikiLeaks: Hillary Clinton knew Saudi, Qatar were funding ISIS – but still took their money for Foundation']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_titles = sorted(dnf_eval.headline.unique())\n",
    "len(test_titles)\n",
    "test_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "653"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_test_titles = np.array(list(set(titles)-set(test_titles)))\n",
    "len(non_test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = []\n",
    "for train_index, val_index in kf.split(non_test_titles):\n",
    "    indices.append([train_index,val_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 262 263 264 265 266 267 268 269 270 271 272 273 274\n",
      " 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292\n",
      " 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310\n",
      " 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328\n",
      " 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346\n",
      " 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364\n",
      " 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382\n",
      " 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400\n",
      " 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418\n",
      " 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436\n",
      " 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454\n",
      " 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472\n",
      " 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490\n",
      " 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508\n",
      " 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526\n",
      " 527 528 529 530 531 532 533 534 535 536 537 538 539 540 541 542 543 544\n",
      " 545 546 547 548 549 550 551 552 553 554 555 556 557 558 559 560 561 562\n",
      " 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578 579 580\n",
      " 581 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597 598\n",
      " 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615 616\n",
      " 617 618 619 620 621 622 623 624 625 626 627 628 629 630 631 632 633 634\n",
      " 635 636 637 638 639 640 641 642 643 644 645 646 647 648 649 650 651 652] [131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148\n",
      " 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202\n",
      " 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220\n",
      " 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238\n",
      " 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256\n",
      " 257 258 259 260 261]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(522, 131, 50)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_index, val_index = indices[np.random.randint(0,num_splits)]\n",
    "print(train_index,val_index)\n",
    "val_titles = non_test_titles[val_index]\n",
    "train_titles = non_test_titles[train_index]\n",
    "len(train_titles),len(val_titles),len(test_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spacy():\n",
    "    sentencizer = English()\n",
    "    sentencizer.add_pipe(sentencizer.create_pipe('sentencizer'))\n",
    "    nlp = spacy.load(\"en_core_web_md\")\n",
    "    return sentencizer, nlp\n",
    "sentencizer, nlp = load_spacy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf(batchsize,dataframe,mode):\n",
    "    counter=0\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "    while True:\n",
    "        if mode=='train':\n",
    "            idx=np.random.choice(train_titles)\n",
    "        elif mode=='val':\n",
    "            idx=np.random.choice(val_titles)\n",
    "        elif mode=='test':\n",
    "            idx=np.random.choice(test_titles)\n",
    "        idx = idx.strip()\n",
    "        \n",
    "            \n",
    "#         cl = dataframe[dataframe.Article==idx]['Claim'].values\n",
    "#         sentences=articles[ar_id]\n",
    "#         print(len(sentences))\n",
    "        if mode=='test':\n",
    "            hd = dnf_eval[dnf_eval.headline==idx]['headline'].values[0].lower()\n",
    "            ar_id = dnf_eval[dnf_eval.headline==idx]['id'].values[0]\n",
    "            cl = dnf_eval[dnf_eval.headline==idx]['claims'].values[0]\n",
    "            ar_claims.append(cl)\n",
    "            sentences = articles300[ar_id]\n",
    "            vectors = article_vectors300[ar_id]\n",
    "        else:\n",
    "            try:\n",
    "                hd = dataframe[dataframe.headline==idx]['headline'].values[0].lower()\n",
    "                ar_id = dataframe[dataframe.headline==idx]['id'].values[0]\n",
    "                ar_claims.append('None')\n",
    "                sentences=articles[ar_id]\n",
    "                vectors = article_vectors[ar_id]\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "                print(idx)\n",
    "            \n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "#         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "        \n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "        counter+=1\n",
    "        if counter==batchsize:\n",
    "            inputs = {\n",
    "                'article_id': np.array(ar_ids)\n",
    "                ,'headline': np.array(hds)\n",
    "                ,'sentence_vectors' : np.array(ar_sents)\n",
    "                ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "                ,'claims':np.array(ar_claims)\n",
    "                ,'sentences':np.array(ar_sentences)\n",
    "            }\n",
    "            outputs = {\n",
    "                'headline_token_classes': np.array(ar_head_classes)\n",
    "                ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "            }\n",
    "            yield inputs,outputs\n",
    "            ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "            counter=0\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdg = datagen_dnf(train_batchsize,dnf700,mode='train')\n",
    "vdg = datagen_dnf(val_batchsize,dnf700,mode='val')\n",
    "test_dg = datagen_dnf(test_batchsize,dnf700,mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y = next(test_dg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x['sentence_vectors'].shape, x['headline_vector'].shape, y['headline_token_classes'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 500, 1024)    0           ca1[0][0]                        \n",
      "                                                                 ca2[0][0]                        \n",
      "                                                                 ca3[0][0]                        \n",
      "                                                                 ca4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 500, 1024)    0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 500, 1024)    4096        dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 250, 256)     786688      batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 125, 256)     196864      conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 63, 256)      196864      conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 32, 256)      196864      conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 256)      0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 256)      1024        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 256)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 50, 256)      0           global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 512)          131584      global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 50, 256)      525312      repeat_vector_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 512)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 50, 256)      0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512)          2048        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 50, 256)      1024        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output_headline_vector (Dense)  (None, 300)          153900      batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "headline_token_classes (TimeDis (None, 50, 20000)    5140000     batch_normalization_7[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 8,131,684\n",
      "Trainable params: 8,126,500\n",
      "Non-trainable params: 5,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"2213pt\" viewBox=\"0.00 0.00 1810.50 2213.00\" width=\"1811pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 2209)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-2209 1806.5,-2209 1806.5,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140138853107528 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140138853107528</title>\n",
       "<polygon fill=\"none\" points=\"857,-2158.5 857,-2204.5 1198,-2204.5 1198,-2158.5 857,-2158.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2177.8\">sentence_vectors: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2158.5 1033,-2204.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2189.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1033,-2181.5 1088,-2181.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-2166.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2158.5 1088,-2204.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2189.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1088,-2181.5 1198,-2181.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1143\" y=\"-2166.3\">(None, 500, 300)</text>\n",
       "</g>\n",
       "<!-- 140138853107920 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140138853107920</title>\n",
       "<polygon fill=\"none\" points=\"883.5,-2075.5 883.5,-2121.5 1171.5,-2121.5 1171.5,-2075.5 883.5,-2075.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"945\" y=\"-2094.8\">conv1d_1: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2075.5 1006.5,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2106.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1006.5,-2098.5 1061.5,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034\" y=\"-2083.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2075.5 1061.5,-2121.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2106.3\">(None, 500, 300)</text>\n",
       "<polyline fill=\"none\" points=\"1061.5,-2098.5 1171.5,-2098.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-2083.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 140138853107528&#45;&gt;140138853107920 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140138853107528-&gt;140138853107920</title>\n",
       "<path d=\"M1027.5,-2158.3799C1027.5,-2150.1745 1027.5,-2140.7679 1027.5,-2131.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2131.784 1027.5,-2121.784 1024.0001,-2131.784 1031.0001,-2131.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138853108032 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140138853108032</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1992.5 885.5,-2038.5 1169.5,-2038.5 1169.5,-1992.5 885.5,-1992.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-2011.8\">dropout_1: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1992.5 1010.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-2023.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-2015.5 1065.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-2000.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1992.5 1065.5,-2038.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-2023.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-2015.5 1169.5,-2015.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-2000.3\">(None, 500, 16)</text>\n",
       "</g>\n",
       "<!-- 140138853107920&#45;&gt;140138853108032 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140138853107920-&gt;140138853108032</title>\n",
       "<path d=\"M1027.5,-2075.3799C1027.5,-2067.1745 1027.5,-2057.7679 1027.5,-2048.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-2048.784 1027.5,-2038.784 1024.0001,-2048.784 1031.0001,-2048.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138853108760 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140138853108760</title>\n",
       "<polygon fill=\"none\" points=\"886.5,-1909.5 886.5,-1955.5 1168.5,-1955.5 1168.5,-1909.5 886.5,-1909.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1928.8\">conv1d_2: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1909.5 1009.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1940.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1009.5,-1932.5 1064.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1037\" y=\"-1917.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1909.5 1064.5,-1955.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1940.3\">(None, 500, 16)</text>\n",
       "<polyline fill=\"none\" points=\"1064.5,-1932.5 1168.5,-1932.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1116.5\" y=\"-1917.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140138853108032&#45;&gt;140138853108760 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140138853108032-&gt;140138853108760</title>\n",
       "<path d=\"M1027.5,-1992.3799C1027.5,-1984.1745 1027.5,-1974.7679 1027.5,-1965.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1965.784 1027.5,-1955.784 1024.0001,-1965.784 1031.0001,-1965.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138825468784 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140138825468784</title>\n",
       "<polygon fill=\"none\" points=\"885.5,-1826.5 885.5,-1872.5 1169.5,-1872.5 1169.5,-1826.5 885.5,-1826.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1845.8\">dropout_2: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1826.5 1010.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1857.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1010.5,-1849.5 1065.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1038\" y=\"-1834.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1826.5 1065.5,-1872.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1857.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1065.5,-1849.5 1169.5,-1849.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1117.5\" y=\"-1834.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140138853108760&#45;&gt;140138825468784 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140138853108760-&gt;140138825468784</title>\n",
       "<path d=\"M1027.5,-1909.3799C1027.5,-1901.1745 1027.5,-1891.7679 1027.5,-1882.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1882.784 1027.5,-1872.784 1024.0001,-1882.784 1031.0001,-1882.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138853250160 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140138853250160</title>\n",
       "<polygon fill=\"none\" points=\"818,-1743.5 818,-1789.5 1237,-1789.5 1237,-1743.5 818,-1743.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"948\" y=\"-1762.8\">batch_normalization_1: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1743.5 1078,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1774.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1078,-1766.5 1133,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1105.5\" y=\"-1751.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1743.5 1133,-1789.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1774.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1133,-1766.5 1237,-1766.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1185\" y=\"-1751.3\">(None, 500, 32)</text>\n",
       "</g>\n",
       "<!-- 140138825468784&#45;&gt;140138853250160 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140138825468784-&gt;140138853250160</title>\n",
       "<path d=\"M1027.5,-1826.3799C1027.5,-1818.1745 1027.5,-1808.7679 1027.5,-1799.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1031.0001,-1799.784 1027.5,-1789.784 1024.0001,-1799.784 1031.0001,-1799.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138825205016 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140138825205016</title>\n",
       "<polygon fill=\"none\" points=\"252.5,-1660.5 252.5,-1706.5 626.5,-1706.5 626.5,-1660.5 252.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"310\" y=\"-1679.8\">sa1: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1660.5 367.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"367.5,-1683.5 422.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"395\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1660.5 422.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"422.5,-1683.5 626.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138853250160&#45;&gt;140138825205016 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140138853250160-&gt;140138825205016</title>\n",
       "<path d=\"M864.4901,-1743.4901C786.1844,-1732.4367 692.2952,-1719.1837 612.7036,-1707.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"612.9631,-1704.4508 602.572,-1706.5187 611.9847,-1711.3821 612.9631,-1704.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138824707600 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140138824707600</title>\n",
       "<polygon fill=\"none\" points=\"644.5,-1660.5 644.5,-1706.5 1018.5,-1706.5 1018.5,-1660.5 644.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"702\" y=\"-1679.8\">sa2: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1660.5 759.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"759.5,-1683.5 814.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"787\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1660.5 814.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"814.5,-1683.5 1018.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"916.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138853250160&#45;&gt;140138824707600 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140138853250160-&gt;140138824707600</title>\n",
       "<path d=\"M973.1634,-1743.4901C949.0535,-1733.2803 920.5118,-1721.1938 895.3877,-1710.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"896.5156,-1707.2313 885.9423,-1706.5547 893.7859,-1713.6771 896.5156,-1707.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138823426568 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140138823426568</title>\n",
       "<polygon fill=\"none\" points=\"1036.5,-1660.5 1036.5,-1706.5 1410.5,-1706.5 1410.5,-1660.5 1036.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094\" y=\"-1679.8\">sa3: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1660.5 1151.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1151.5,-1683.5 1206.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1179\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1660.5 1206.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1206.5,-1683.5 1410.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1308.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138853250160&#45;&gt;140138823426568 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140138853250160-&gt;140138823426568</title>\n",
       "<path d=\"M1081.8366,-1743.4901C1105.9465,-1733.2803 1134.4882,-1721.1938 1159.6123,-1710.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1161.2141,-1713.6771 1169.0577,-1706.5547 1158.4844,-1707.2313 1161.2141,-1713.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138822702416 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140138822702416</title>\n",
       "<polygon fill=\"none\" points=\"1428.5,-1660.5 1428.5,-1706.5 1802.5,-1706.5 1802.5,-1660.5 1428.5,-1660.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1486\" y=\"-1679.8\">sa4: SelfAttention</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1660.5 1543.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1691.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1543.5,-1683.5 1598.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1571\" y=\"-1668.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1660.5 1598.5,-1706.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1691.3\">(None, 500, 32)</text>\n",
       "<polyline fill=\"none\" points=\"1598.5,-1683.5 1802.5,-1683.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1700.5\" y=\"-1668.3\">[(None, 500, 32), (500, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138853250160&#45;&gt;140138822702416 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140138853250160-&gt;140138822702416</title>\n",
       "<path d=\"M1190.5099,-1743.4901C1268.8156,-1732.4367 1362.7048,-1719.1837 1442.2964,-1707.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1443.0153,-1711.3821 1452.428,-1706.5187 1442.0369,-1704.4508 1443.0153,-1711.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821871488 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140138821871488</title>\n",
       "<polygon fill=\"none\" points=\"718,-1577.5 718,-1623.5 1337,-1623.5 1337,-1577.5 718,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"802\" y=\"-1596.8\">concatenate_1: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"886,-1577.5 886,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"886,-1600.5 941,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"913.5\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"941,-1577.5 941,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1608.3\">[(None, 500, 32), (None, 500, 32), (None, 500, 32), (None, 500, 32)]</text>\n",
       "<polyline fill=\"none\" points=\"941,-1600.5 1337,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1139\" y=\"-1585.3\">(None, 500, 128)</text>\n",
       "</g>\n",
       "<!-- 140138825205016&#45;&gt;140138821871488 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140138825205016-&gt;140138821871488</title>\n",
       "<path d=\"M602.5099,-1660.4901C680.8156,-1649.4367 774.7048,-1636.1837 854.2964,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"855.0153,-1628.3821 864.428,-1623.5187 854.0369,-1621.4508 855.0153,-1628.3821\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138824707600&#45;&gt;140138821871488 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140138824707600-&gt;140138821871488</title>\n",
       "<path d=\"M885.8366,-1660.4901C909.9465,-1650.2803 938.4882,-1638.1938 963.6123,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"965.2141,-1630.6771 973.0577,-1623.5547 962.4844,-1624.2313 965.2141,-1630.6771\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138823426568&#45;&gt;140138821871488 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140138823426568-&gt;140138821871488</title>\n",
       "<path d=\"M1169.1634,-1660.4901C1145.0535,-1650.2803 1116.5118,-1638.1938 1091.3877,-1627.5545\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1092.5156,-1624.2313 1081.9423,-1623.5547 1089.7859,-1630.6771 1092.5156,-1624.2313\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138822702416&#45;&gt;140138821871488 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140138822702416-&gt;140138821871488</title>\n",
       "<path d=\"M1452.4901,-1660.4901C1374.1844,-1649.4367 1280.2952,-1636.1837 1200.7036,-1624.9488\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1200.9631,-1621.4508 1190.572,-1623.5187 1199.9847,-1628.3821 1200.9631,-1621.4508\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138853108368 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140138853108368</title>\n",
       "<polygon fill=\"none\" points=\"357,-1577.5 357,-1623.5 700,-1623.5 700,-1577.5 357,-1577.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"459.5\" y=\"-1596.8\">input_headline_vector: InputLayer</text>\n",
       "<polyline fill=\"none\" points=\"562,-1577.5 562,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1608.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"562,-1600.5 617,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-1585.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"617,-1577.5 617,-1623.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1608.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"617,-1600.5 700,-1600.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"658.5\" y=\"-1585.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140138820818368 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140138820818368</title>\n",
       "<polygon fill=\"none\" points=\"439.5,-1494.5 439.5,-1540.5 679.5,-1540.5 679.5,-1494.5 439.5,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"490.5\" y=\"-1513.8\">dense_1: Dense</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1494.5 541.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"541.5,-1517.5 596.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"569\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1494.5 596.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1525.3\">(None, 300)</text>\n",
       "<polyline fill=\"none\" points=\"596.5,-1517.5 679.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"638\" y=\"-1502.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140138853108368&#45;&gt;140138820818368 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>140138853108368-&gt;140138820818368</title>\n",
       "<path d=\"M537.1352,-1577.3799C540.2665,-1568.9962 543.8662,-1559.3584 547.2495,-1550.2996\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"550.5834,-1551.3766 550.8036,-1540.784 544.0259,-1548.9273 550.5834,-1551.3766\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138824960432 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140138824960432</title>\n",
       "<polygon fill=\"none\" points=\"881.5,-1494.5 881.5,-1540.5 1169.5,-1540.5 1169.5,-1494.5 881.5,-1494.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"943\" y=\"-1513.8\">conv1d_3: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1494.5 1004.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1525.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1004.5,-1517.5 1059.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1032\" y=\"-1502.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1494.5 1059.5,-1540.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1525.3\">(None, 500, 128)</text>\n",
       "<polyline fill=\"none\" points=\"1059.5,-1517.5 1169.5,-1517.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1114.5\" y=\"-1502.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140138821871488&#45;&gt;140138824960432 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>140138821871488-&gt;140138824960432</title>\n",
       "<path d=\"M1026.9429,-1577.3799C1026.7452,-1569.1745 1026.5185,-1559.7679 1026.3043,-1550.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1029.801,-1550.6968 1026.0611,-1540.784 1022.8031,-1550.8655 1029.801,-1550.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138820567952 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>140138820567952</title>\n",
       "<polygon fill=\"none\" points=\"437,-1411.5 437,-1457.5 712,-1457.5 712,-1411.5 437,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"498.5\" y=\"-1430.8\">lambda_1: Lambda</text>\n",
       "<polyline fill=\"none\" points=\"560,-1411.5 560,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"560,-1434.5 615,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"587.5\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"615,-1411.5 615,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1442.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"615,-1434.5 712,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"663.5\" y=\"-1419.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140138820818368&#45;&gt;140138820567952 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>140138820818368-&gt;140138820567952</title>\n",
       "<path d=\"M563.6783,-1494.3799C565.1612,-1486.1745 566.8612,-1476.7679 568.4677,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"571.9578,-1468.2471 570.292,-1457.784 565.0693,-1467.0021 571.9578,-1468.2471\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821114456 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>140138821114456</title>\n",
       "<polygon fill=\"none\" points=\"876.5,-1411.5 876.5,-1457.5 1166.5,-1457.5 1166.5,-1411.5 876.5,-1411.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"939\" y=\"-1430.8\">dropout_3: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1411.5 1001.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1442.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1001.5,-1434.5 1056.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1029\" y=\"-1419.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1411.5 1056.5,-1457.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1442.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1056.5,-1434.5 1166.5,-1434.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1111.5\" y=\"-1419.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140138824960432&#45;&gt;140138821114456 -->\n",
       "<g class=\"edge\" id=\"edge17\">\n",
       "<title>140138824960432-&gt;140138821114456</title>\n",
       "<path d=\"M1024.3858,-1494.3799C1023.9903,-1486.1745 1023.537,-1476.7679 1023.1086,-1467.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1026.5995,-1467.6039 1022.6221,-1457.784 1019.6076,-1467.9409 1026.5995,-1467.6039\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138820411968 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>140138820411968</title>\n",
       "<polygon fill=\"none\" points=\"376.5,-1328.5 376.5,-1374.5 788.5,-1374.5 788.5,-1328.5 376.5,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"506.5\" y=\"-1347.8\">batch_normalization_3: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1328.5 636.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"636.5,-1351.5 691.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"664\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1328.5 691.5,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1359.3\">(None, 1, 256)</text>\n",
       "<polyline fill=\"none\" points=\"691.5,-1351.5 788.5,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"740\" y=\"-1336.3\">(None, 1, 256)</text>\n",
       "</g>\n",
       "<!-- 140138820567952&#45;&gt;140138820411968 -->\n",
       "<g class=\"edge\" id=\"edge18\">\n",
       "<title>140138820567952-&gt;140138820411968</title>\n",
       "<path d=\"M576.7284,-1411.3799C577.5193,-1403.1745 578.426,-1393.7679 579.2828,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"582.7801,-1385.0737 580.2558,-1374.784 575.8124,-1384.4021 582.7801,-1385.0737\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821113896 -->\n",
       "<g class=\"node\" id=\"node18\">\n",
       "<title>140138821113896</title>\n",
       "<polygon fill=\"none\" points=\"807,-1328.5 807,-1374.5 1232,-1374.5 1232,-1328.5 807,-1328.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"937\" y=\"-1347.8\">batch_normalization_2: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1328.5 1067,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1359.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1067,-1351.5 1122,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1094.5\" y=\"-1336.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1328.5 1122,-1374.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1359.3\">(None, 500, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1122,-1351.5 1232,-1351.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1177\" y=\"-1336.3\">(None, 500, 256)</text>\n",
       "</g>\n",
       "<!-- 140138821114456&#45;&gt;140138821113896 -->\n",
       "<g class=\"edge\" id=\"edge19\">\n",
       "<title>140138821114456-&gt;140138821113896</title>\n",
       "<path d=\"M1020.9429,-1411.3799C1020.7452,-1403.1745 1020.5185,-1393.7679 1020.3043,-1384.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1023.801,-1384.6968 1020.0611,-1374.784 1016.8031,-1384.8655 1023.801,-1384.6968\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138819822928 -->\n",
       "<g class=\"node\" id=\"node19\">\n",
       "<title>140138819822928</title>\n",
       "<polygon fill=\"none\" points=\"810,-1245.5 810,-1291.5 1197,-1291.5 1197,-1245.5 810,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872.5\" y=\"-1264.8\">ca1: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"935,-1245.5 935,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"935,-1268.5 990,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"962.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"990,-1245.5 990,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"990,-1268.5 1197,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1093.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138820411968&#45;&gt;140138819822928 -->\n",
       "<g class=\"edge\" id=\"edge20\">\n",
       "<title>140138820411968-&gt;140138819822928</title>\n",
       "<path d=\"M699.2129,-1328.4901C754.3078,-1317.6282 820.1773,-1304.642 876.519,-1293.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"877.4259,-1296.9229 886.5601,-1291.5547 876.0719,-1290.0551 877.4259,-1296.9229\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138818893024 -->\n",
       "<g class=\"node\" id=\"node20\">\n",
       "<title>140138818893024</title>\n",
       "<polygon fill=\"none\" points=\"1215,-1245.5 1215,-1291.5 1602,-1291.5 1602,-1245.5 1215,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1277.5\" y=\"-1264.8\">ca2: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1245.5 1340,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1340,-1268.5 1395,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1367.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1245.5 1395,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"1395,-1268.5 1602,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1498.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138820411968&#45;&gt;140138818893024 -->\n",
       "<g class=\"edge\" id=\"edge22\">\n",
       "<title>140138820411968-&gt;140138818893024</title>\n",
       "<path d=\"M788.5682,-1328.986C791.9028,-1328.6525 795.2153,-1328.3236 798.5,-1328 976.3881,-1310.477 1023.7095,-1310.5124 1204.8542,-1292.1557\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1205.3964,-1295.6187 1214.9903,-1291.1236 1204.6872,-1288.6547 1205.3964,-1295.6187\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138817881424 -->\n",
       "<g class=\"node\" id=\"node21\">\n",
       "<title>140138817881424</title>\n",
       "<polygon fill=\"none\" points=\"0,-1245.5 0,-1291.5 387,-1291.5 387,-1245.5 0,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62.5\" y=\"-1264.8\">ca3: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"125,-1245.5 125,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"125,-1268.5 180,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"152.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"180,-1245.5 180,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"180,-1268.5 387,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"283.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138820411968&#45;&gt;140138817881424 -->\n",
       "<g class=\"edge\" id=\"edge24\">\n",
       "<title>140138820411968-&gt;140138817881424</title>\n",
       "<path d=\"M474.6584,-1328.4901C423.962,-1317.6731 363.3923,-1304.7495 311.4764,-1293.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"312.0616,-1290.2185 301.5514,-1291.5547 310.6009,-1297.0644 312.0616,-1290.2185\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138817046400 -->\n",
       "<g class=\"node\" id=\"node22\">\n",
       "<title>140138817046400</title>\n",
       "<polygon fill=\"none\" points=\"405,-1245.5 405,-1291.5 792,-1291.5 792,-1245.5 405,-1245.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"467.5\" y=\"-1264.8\">ca4: CrossAttention</text>\n",
       "<polyline fill=\"none\" points=\"530,-1245.5 530,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1276.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"530,-1268.5 585,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"557.5\" y=\"-1253.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"585,-1245.5 585,-1291.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1276.3\">[(None, 1, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"585,-1268.5 792,-1268.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"688.5\" y=\"-1253.3\">[(None, 500, 256), (1, 500), (1,)]</text>\n",
       "</g>\n",
       "<!-- 140138820411968&#45;&gt;140138817046400 -->\n",
       "<g class=\"edge\" id=\"edge26\">\n",
       "<title>140138820411968-&gt;140138817046400</title>\n",
       "<path d=\"M586.9569,-1328.3799C588.5386,-1320.1745 590.352,-1310.7679 592.0656,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"595.5553,-1302.2658 594.0115,-1291.784 588.6818,-1300.9407 595.5553,-1302.2658\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821113896&#45;&gt;140138819822928 -->\n",
       "<g class=\"edge\" id=\"edge21\">\n",
       "<title>140138821113896-&gt;140138819822928</title>\n",
       "<path d=\"M1015.0431,-1328.3799C1013.4614,-1320.1745 1011.648,-1310.7679 1009.9344,-1301.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1013.3182,-1300.9407 1007.9885,-1291.784 1006.4447,-1302.2658 1013.3182,-1300.9407\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821113896&#45;&gt;140138818893024 -->\n",
       "<g class=\"edge\" id=\"edge23\">\n",
       "<title>140138821113896-&gt;140138818893024</title>\n",
       "<path d=\"M1127.3416,-1328.4901C1178.038,-1317.6731 1238.6077,-1304.7495 1290.5236,-1293.6723\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"1291.3991,-1297.0644 1300.4486,-1291.5547 1289.9384,-1290.2185 1291.3991,-1297.0644\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821113896&#45;&gt;140138817881424 -->\n",
       "<g class=\"edge\" id=\"edge25\">\n",
       "<title>140138821113896-&gt;140138817881424</title>\n",
       "<path d=\"M806.8249,-1328.9162C803.6957,-1328.6071 800.5859,-1328.3015 797.5,-1328 622.1938,-1310.873 575.6096,-1310.3786 397.0043,-1292.1432\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"397.3151,-1288.6568 387.0102,-1291.1184 396.601,-1295.6203 397.3151,-1288.6568\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138821113896&#45;&gt;140138817046400 -->\n",
       "<g class=\"edge\" id=\"edge27\">\n",
       "<title>140138821113896-&gt;140138817046400</title>\n",
       "<path d=\"M902.7871,-1328.4901C847.6922,-1317.6282 781.8227,-1304.642 725.481,-1293.5343\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"725.9281,-1290.0551 715.4399,-1291.5547 724.5741,-1296.9229 725.9281,-1290.0551\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140140759008368 -->\n",
       "<g class=\"node\" id=\"node23\">\n",
       "<title>140140759008368</title>\n",
       "<polygon fill=\"none\" points=\"477.5,-1162.5 477.5,-1208.5 1123.5,-1208.5 1123.5,-1162.5 477.5,-1162.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"561.5\" y=\"-1181.8\">concatenate_2: Concatenate</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1162.5 645.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1193.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645.5,-1185.5 700.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"673\" y=\"-1170.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1162.5 700.5,-1208.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1193.3\">[(None, 500, 256), (None, 500, 256), (None, 500, 256), (None, 500, 256)]</text>\n",
       "<polyline fill=\"none\" points=\"700.5,-1185.5 1123.5,-1185.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"912\" y=\"-1170.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140138819822928&#45;&gt;140140759008368 -->\n",
       "<g class=\"edge\" id=\"edge28\">\n",
       "<title>140138819822928-&gt;140140759008368</title>\n",
       "<path d=\"M947.2228,-1245.4901C922.1419,-1235.2353 892.4302,-1223.0872 866.3257,-1212.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"867.4675,-1209.0996 856.8867,-1208.5547 864.8183,-1215.579 867.4675,-1209.0996\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138818893024&#45;&gt;140140759008368 -->\n",
       "<g class=\"edge\" id=\"edge29\">\n",
       "<title>140138818893024-&gt;140140759008368</title>\n",
       "<path d=\"M1239.9455,-1245.4901C1158.8115,-1234.4142 1061.4981,-1221.1297 979.0922,-1209.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"979.5002,-1206.4035 969.1187,-1208.5187 978.5534,-1213.3392 979.5002,-1206.4035\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138817881424&#45;&gt;140140759008368 -->\n",
       "<g class=\"edge\" id=\"edge30\">\n",
       "<title>140138817881424-&gt;140140759008368</title>\n",
       "<path d=\"M361.7773,-1245.4901C442.7778,-1234.4142 539.9312,-1221.1297 622.2015,-1209.8802\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"622.725,-1213.3413 632.1586,-1208.5187 621.7766,-1206.4058 622.725,-1213.3413\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138817046400&#45;&gt;140140759008368 -->\n",
       "<g class=\"edge\" id=\"edge31\">\n",
       "<title>140138817046400-&gt;140140759008368</title>\n",
       "<path d=\"M654.5,-1245.4901C679.4573,-1235.2353 709.0226,-1223.0872 734.9986,-1212.414\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"736.4717,-1215.5927 744.3911,-1208.5547 733.8112,-1209.1179 736.4717,-1215.5927\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138819446656 -->\n",
       "<g class=\"node\" id=\"node24\">\n",
       "<title>140138819446656</title>\n",
       "<polygon fill=\"none\" points=\"652,-1079.5 652,-1125.5 949,-1125.5 949,-1079.5 652,-1079.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1098.8\">dropout_4: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"777,-1079.5 777,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1110.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"777,-1102.5 832,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"804.5\" y=\"-1087.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"832,-1079.5 832,-1125.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1110.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"832,-1102.5 949,-1102.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-1087.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140140759008368&#45;&gt;140138819446656 -->\n",
       "<g class=\"edge\" id=\"edge32\">\n",
       "<title>140140759008368-&gt;140138819446656</title>\n",
       "<path d=\"M800.5,-1162.3799C800.5,-1154.1745 800.5,-1144.7679 800.5,-1135.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1135.784 800.5,-1125.784 797.0001,-1135.784 804.0001,-1135.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138819446712 -->\n",
       "<g class=\"node\" id=\"node25\">\n",
       "<title>140138819446712</title>\n",
       "<polygon fill=\"none\" points=\"584.5,-996.5 584.5,-1042.5 1016.5,-1042.5 1016.5,-996.5 584.5,-996.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-1015.8\">batch_normalization_4: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-996.5 844.5,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-1027.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"844.5,-1019.5 899.5,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"872\" y=\"-1004.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-996.5 899.5,-1042.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-1027.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"899.5,-1019.5 1016.5,-1019.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-1004.3\">(None, 500, 1024)</text>\n",
       "</g>\n",
       "<!-- 140138819446656&#45;&gt;140138819446712 -->\n",
       "<g class=\"edge\" id=\"edge33\">\n",
       "<title>140138819446656-&gt;140138819446712</title>\n",
       "<path d=\"M800.5,-1079.3799C800.5,-1071.1745 800.5,-1061.7679 800.5,-1052.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-1052.784 800.5,-1042.784 797.0001,-1052.784 804.0001,-1052.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138819445760 -->\n",
       "<g class=\"node\" id=\"node26\">\n",
       "<title>140138819445760</title>\n",
       "<polygon fill=\"none\" points=\"653,-913.5 653,-959.5 948,-959.5 948,-913.5 653,-913.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"714.5\" y=\"-932.8\">conv1d_4: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"776,-913.5 776,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-944.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"776,-936.5 831,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"803.5\" y=\"-921.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"831,-913.5 831,-959.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-944.3\">(None, 500, 1024)</text>\n",
       "<polyline fill=\"none\" points=\"831,-936.5 948,-936.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-921.3\">(None, 250, 256)</text>\n",
       "</g>\n",
       "<!-- 140138819446712&#45;&gt;140138819445760 -->\n",
       "<g class=\"edge\" id=\"edge34\">\n",
       "<title>140138819446712-&gt;140138819445760</title>\n",
       "<path d=\"M800.5,-996.3799C800.5,-988.1745 800.5,-978.7679 800.5,-969.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-969.784 800.5,-959.784 797.0001,-969.784 804.0001,-969.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138815663688 -->\n",
       "<g class=\"node\" id=\"node27\">\n",
       "<title>140138815663688</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-830.5 656.5,-876.5 944.5,-876.5 944.5,-830.5 656.5,-830.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-849.8\">conv1d_5: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-830.5 779.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-861.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-853.5 834.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-838.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-830.5 834.5,-876.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-861.3\">(None, 250, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-853.5 944.5,-853.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-838.3\">(None, 125, 256)</text>\n",
       "</g>\n",
       "<!-- 140138819445760&#45;&gt;140138815663688 -->\n",
       "<g class=\"edge\" id=\"edge35\">\n",
       "<title>140138819445760-&gt;140138815663688</title>\n",
       "<path d=\"M800.5,-913.3799C800.5,-905.1745 800.5,-895.7679 800.5,-886.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-886.784 800.5,-876.784 797.0001,-886.784 804.0001,-886.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138814902056 -->\n",
       "<g class=\"node\" id=\"node28\">\n",
       "<title>140138814902056</title>\n",
       "<polygon fill=\"none\" points=\"656.5,-747.5 656.5,-793.5 944.5,-793.5 944.5,-747.5 656.5,-747.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"718\" y=\"-766.8\">conv1d_6: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-747.5 779.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-778.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"779.5,-770.5 834.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"807\" y=\"-755.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-747.5 834.5,-793.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-778.3\">(None, 125, 256)</text>\n",
       "<polyline fill=\"none\" points=\"834.5,-770.5 944.5,-770.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-755.3\">(None, 63, 256)</text>\n",
       "</g>\n",
       "<!-- 140138815663688&#45;&gt;140138814902056 -->\n",
       "<g class=\"edge\" id=\"edge36\">\n",
       "<title>140138815663688-&gt;140138814902056</title>\n",
       "<path d=\"M800.5,-830.3799C800.5,-822.1745 800.5,-812.7679 800.5,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-803.784 800.5,-793.784 797.0001,-803.784 804.0001,-803.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138814663760 -->\n",
       "<g class=\"node\" id=\"node29\">\n",
       "<title>140138814663760</title>\n",
       "<polygon fill=\"none\" points=\"659.5,-664.5 659.5,-710.5 941.5,-710.5 941.5,-664.5 659.5,-664.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-683.8\">conv1d_7: Conv1D</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-664.5 782.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-695.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"782.5,-687.5 837.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"810\" y=\"-672.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-664.5 837.5,-710.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-695.3\">(None, 63, 256)</text>\n",
       "<polyline fill=\"none\" points=\"837.5,-687.5 941.5,-687.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"889.5\" y=\"-672.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140138814902056&#45;&gt;140138814663760 -->\n",
       "<g class=\"edge\" id=\"edge37\">\n",
       "<title>140138814902056-&gt;140138814663760</title>\n",
       "<path d=\"M800.5,-747.3799C800.5,-739.1745 800.5,-729.7679 800.5,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-720.784 800.5,-710.784 797.0001,-720.784 804.0001,-720.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138813741600 -->\n",
       "<g class=\"node\" id=\"node30\">\n",
       "<title>140138813741600</title>\n",
       "<polygon fill=\"none\" points=\"658.5,-581.5 658.5,-627.5 942.5,-627.5 942.5,-581.5 658.5,-581.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-600.8\">dropout_5: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-581.5 783.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-612.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"783.5,-604.5 838.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"811\" y=\"-589.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-581.5 838.5,-627.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-612.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"838.5,-604.5 942.5,-604.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"890.5\" y=\"-589.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140138814663760&#45;&gt;140138813741600 -->\n",
       "<g class=\"edge\" id=\"edge38\">\n",
       "<title>140138814663760-&gt;140138813741600</title>\n",
       "<path d=\"M800.5,-664.3799C800.5,-656.1745 800.5,-646.7679 800.5,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-637.784 800.5,-627.784 797.0001,-637.784 804.0001,-637.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138813741656 -->\n",
       "<g class=\"node\" id=\"node31\">\n",
       "<title>140138813741656</title>\n",
       "<polygon fill=\"none\" points=\"591,-498.5 591,-544.5 1010,-544.5 1010,-498.5 591,-498.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-517.8\">batch_normalization_5: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"851,-498.5 851,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-529.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"851,-521.5 906,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"878.5\" y=\"-506.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"906,-498.5 906,-544.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-529.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"906,-521.5 1010,-521.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"958\" y=\"-506.3\">(None, 32, 256)</text>\n",
       "</g>\n",
       "<!-- 140138813741600&#45;&gt;140138813741656 -->\n",
       "<g class=\"edge\" id=\"edge39\">\n",
       "<title>140138813741600-&gt;140138813741656</title>\n",
       "<path d=\"M800.5,-581.3799C800.5,-573.1745 800.5,-563.7679 800.5,-554.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-554.784 800.5,-544.784 797.0001,-554.784 804.0001,-554.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138813742440 -->\n",
       "<g class=\"node\" id=\"node32\">\n",
       "<title>140138813742440</title>\n",
       "<polygon fill=\"none\" points=\"559.5,-415.5 559.5,-461.5 1041.5,-461.5 1041.5,-415.5 559.5,-415.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"721\" y=\"-434.8\">global_average_pooling1d_1: GlobalAveragePooling1D</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-415.5 882.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-446.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"882.5,-438.5 937.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-423.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-415.5 937.5,-461.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-446.3\">(None, 32, 256)</text>\n",
       "<polyline fill=\"none\" points=\"937.5,-438.5 1041.5,-438.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"989.5\" y=\"-423.3\">(None, 256)</text>\n",
       "</g>\n",
       "<!-- 140138813741656&#45;&gt;140138813742440 -->\n",
       "<g class=\"edge\" id=\"edge40\">\n",
       "<title>140138813741656-&gt;140138813742440</title>\n",
       "<path d=\"M800.5,-498.3799C800.5,-490.1745 800.5,-480.7679 800.5,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"804.0001,-471.784 800.5,-461.784 797.0001,-471.784 804.0001,-471.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138812186920 -->\n",
       "<g class=\"node\" id=\"node33\">\n",
       "<title>140138812186920</title>\n",
       "<polygon fill=\"none\" points=\"473.5,-332.5 473.5,-378.5 817.5,-378.5 817.5,-332.5 473.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"566\" y=\"-351.8\">repeat_vector_1: RepeatVector</text>\n",
       "<polyline fill=\"none\" points=\"658.5,-332.5 658.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"686\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"658.5,-355.5 713.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"686\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-332.5 713.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"765.5\" y=\"-363.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"713.5,-355.5 817.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"765.5\" y=\"-340.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140138813742440&#45;&gt;140138812186920 -->\n",
       "<g class=\"edge\" id=\"edge41\">\n",
       "<title>140138813742440-&gt;140138812186920</title>\n",
       "<path d=\"M757.3239,-415.3799C738.842,-405.4832 717.0966,-393.8388 697.7191,-383.4625\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"699.1811,-380.2752 688.7132,-378.6399 695.8766,-386.4461 699.1811,-380.2752\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138813343896 -->\n",
       "<g class=\"node\" id=\"node34\">\n",
       "<title>140138813343896</title>\n",
       "<polygon fill=\"none\" points=\"845.5,-332.5 845.5,-378.5 1085.5,-378.5 1085.5,-332.5 845.5,-332.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"896.5\" y=\"-351.8\">dense_2: Dense</text>\n",
       "<polyline fill=\"none\" points=\"947.5,-332.5 947.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"975\" y=\"-363.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"947.5,-355.5 1002.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"975\" y=\"-340.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1002.5,-332.5 1002.5,-378.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1044\" y=\"-363.3\">(None, 256)</text>\n",
       "<polyline fill=\"none\" points=\"1002.5,-355.5 1085.5,-355.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1044\" y=\"-340.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140138813742440&#45;&gt;140138813343896 -->\n",
       "<g class=\"edge\" id=\"edge42\">\n",
       "<title>140138813742440-&gt;140138813343896</title>\n",
       "<path d=\"M846.4617,-415.3799C866.314,-405.3936 889.7036,-393.6279 910.4713,-383.1811\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"912.1383,-386.2605 919.4989,-378.6399 908.9926,-380.0071 912.1383,-386.2605\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138812187312 -->\n",
       "<g class=\"node\" id=\"node35\">\n",
       "<title>140138812187312</title>\n",
       "<polygon fill=\"none\" points=\"493,-249.5 493,-295.5 750,-295.5 750,-249.5 493,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"542\" y=\"-268.8\">lstm_1: LSTM</text>\n",
       "<polyline fill=\"none\" points=\"591,-249.5 591,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"591,-272.5 646,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"646,-249.5 646,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-280.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"646,-272.5 750,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"698\" y=\"-257.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140138812186920&#45;&gt;140138812187312 -->\n",
       "<g class=\"edge\" id=\"edge43\">\n",
       "<title>140138812186920-&gt;140138812187312</title>\n",
       "<path d=\"M638.8147,-332.3799C636.4162,-324.0854 633.6629,-314.5633 631.0679,-305.5889\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"634.3728,-304.4182 628.2327,-295.784 627.6483,-306.3627 634.3728,-304.4182\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138812913760 -->\n",
       "<g class=\"node\" id=\"node36\">\n",
       "<title>140138812913760</title>\n",
       "<polygon fill=\"none\" points=\"839,-249.5 839,-295.5 1102,-295.5 1102,-249.5 839,-249.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"901.5\" y=\"-268.8\">dropout_6: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"964,-249.5 964,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"991.5\" y=\"-280.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"964,-272.5 1019,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"991.5\" y=\"-257.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1019,-249.5 1019,-295.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-280.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1019,-272.5 1102,-272.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060.5\" y=\"-257.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140138813343896&#45;&gt;140138812913760 -->\n",
       "<g class=\"edge\" id=\"edge44\">\n",
       "<title>140138813343896-&gt;140138812913760</title>\n",
       "<path d=\"M966.8928,-332.3799C967.3871,-324.1745 967.9537,-314.7679 968.4892,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"971.9896,-305.9764 969.0973,-295.784 965.0023,-305.5554 971.9896,-305.9764\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138810934944 -->\n",
       "<g class=\"node\" id=\"node37\">\n",
       "<title>140138810934944</title>\n",
       "<polygon fill=\"none\" points=\"467.5,-166.5 467.5,-212.5 751.5,-212.5 751.5,-166.5 467.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"530\" y=\"-185.8\">dropout_7: Dropout</text>\n",
       "<polyline fill=\"none\" points=\"592.5,-166.5 592.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"592.5,-189.5 647.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"620\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"647.5,-166.5 647.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699.5\" y=\"-197.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"647.5,-189.5 751.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"699.5\" y=\"-174.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140138812187312&#45;&gt;140138810934944 -->\n",
       "<g class=\"edge\" id=\"edge45\">\n",
       "<title>140138812187312-&gt;140138810934944</title>\n",
       "<path d=\"M618.1573,-249.3799C616.971,-241.1745 615.611,-231.7679 614.3258,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"617.7613,-222.1803 612.8664,-212.784 610.8334,-223.1819 617.7613,-222.1803\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138812913648 -->\n",
       "<g class=\"node\" id=\"node38\">\n",
       "<title>140138812913648</title>\n",
       "<polygon fill=\"none\" points=\"776.5,-166.5 776.5,-212.5 1174.5,-212.5 1174.5,-166.5 776.5,-166.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"906.5\" y=\"-185.8\">batch_normalization_6: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"1036.5,-166.5 1036.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064\" y=\"-197.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1036.5,-189.5 1091.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1064\" y=\"-174.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1091.5,-166.5 1091.5,-212.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1133\" y=\"-197.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1091.5,-189.5 1174.5,-189.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1133\" y=\"-174.3\">(None, 512)</text>\n",
       "</g>\n",
       "<!-- 140138812913760&#45;&gt;140138812913648 -->\n",
       "<g class=\"edge\" id=\"edge46\">\n",
       "<title>140138812913760-&gt;140138812913648</title>\n",
       "<path d=\"M971.8928,-249.3799C972.3871,-241.1745 972.9537,-231.7679 973.4892,-222.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"976.9896,-222.9764 974.0973,-212.784 970.0023,-222.5554 976.9896,-222.9764\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138810407904 -->\n",
       "<g class=\"node\" id=\"node39\">\n",
       "<title>140138810407904</title>\n",
       "<polygon fill=\"none\" points=\"385,-83.5 385,-129.5 804,-129.5 804,-83.5 385,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"515\" y=\"-102.8\">batch_normalization_7: BatchNormalization</text>\n",
       "<polyline fill=\"none\" points=\"645,-83.5 645,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"672.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"645,-106.5 700,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"672.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"700,-83.5 700,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"752\" y=\"-114.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"700,-106.5 804,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"752\" y=\"-91.3\">(None, 50, 256)</text>\n",
       "</g>\n",
       "<!-- 140138810934944&#45;&gt;140138810407904 -->\n",
       "<g class=\"edge\" id=\"edge47\">\n",
       "<title>140138810934944-&gt;140138810407904</title>\n",
       "<path d=\"M605.3217,-166.3799C603.8388,-158.1745 602.1388,-148.7679 600.5323,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"603.9307,-139.0021 598.708,-129.784 597.0422,-140.2471 603.9307,-139.0021\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138812645160 -->\n",
       "<g class=\"node\" id=\"node40\">\n",
       "<title>140138812645160</title>\n",
       "<polygon fill=\"none\" points=\"822,-83.5 822,-129.5 1145,-129.5 1145,-83.5 822,-83.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"914.5\" y=\"-102.8\">output_headline_vector: Dense</text>\n",
       "<polyline fill=\"none\" points=\"1007,-83.5 1007,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034.5\" y=\"-114.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"1007,-106.5 1062,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1034.5\" y=\"-91.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"1062,-83.5 1062,-129.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1103.5\" y=\"-114.3\">(None, 512)</text>\n",
       "<polyline fill=\"none\" points=\"1062,-106.5 1145,-106.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1103.5\" y=\"-91.3\">(None, 300)</text>\n",
       "</g>\n",
       "<!-- 140138812913648&#45;&gt;140138812645160 -->\n",
       "<g class=\"edge\" id=\"edge48\">\n",
       "<title>140138812913648-&gt;140138812645160</title>\n",
       "<path d=\"M977.7284,-166.3799C978.5193,-158.1745 979.426,-148.7679 980.2828,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"983.7801,-140.0737 981.2558,-129.784 976.8124,-139.4021 983.7801,-140.0737\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140138808991080 -->\n",
       "<g class=\"node\" id=\"node41\">\n",
       "<title>140138808991080</title>\n",
       "<polygon fill=\"none\" points=\"340,-.5 340,-46.5 849,-46.5 849,-.5 340,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"508.5\" y=\"-19.8\">headline_token_classes(dense_3): TimeDistributed(Dense)</text>\n",
       "<polyline fill=\"none\" points=\"677,-.5 677,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-31.3\">input:</text>\n",
       "<polyline fill=\"none\" points=\"677,-23.5 732,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"704.5\" y=\"-8.3\">output:</text>\n",
       "<polyline fill=\"none\" points=\"732,-.5 732,-46.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-31.3\">(None, 50, 256)</text>\n",
       "<polyline fill=\"none\" points=\"732,-23.5 849,-23.5 \" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"790.5\" y=\"-8.3\">(None, 50, 20000)</text>\n",
       "</g>\n",
       "<!-- 140138810407904&#45;&gt;140138808991080 -->\n",
       "<g class=\"edge\" id=\"edge49\">\n",
       "<title>140138810407904-&gt;140138808991080</title>\n",
       "<path d=\"M594.5,-83.3799C594.5,-75.1745 594.5,-65.7679 594.5,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"598.0001,-56.784 594.5,-46.784 591.0001,-56.784 598.0001,-56.784\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model():\n",
    "    inp_sentence_vectors = Input(shape=(max_sentences, 300), name='sentence_vectors')\n",
    "    inp_headline_vector = Input(shape=(300,), name='input_headline_vector')\n",
    "    conv1 = Conv1D(filters=16,kernel_size=3,strides=1,activation='relu', padding='same')(inp_sentence_vectors)\n",
    "    conv1 = Dropout(0.5)(conv1)\n",
    "    conv2 = Conv1D(filters=32,kernel_size=3,strides=1,activation='relu', padding='same')(conv1)\n",
    "    conv2 = Dropout(0.5)(conv2)\n",
    "    conv2 = BatchNormalization()(conv2)\n",
    "    sent_sa_feat_1, sent_beta_1, sent_gamma_1 = SelfAttention(int(conv2.shape[-1]), name = 'sa1')(conv2)\n",
    "    sent_sa_feat_2, sent_beta_2, sent_gamma_2 = SelfAttention(int(conv2.shape[-1]), name = 'sa2')(conv2)\n",
    "    sent_sa_feat_3, sent_beta_3, sent_gamma_3 = SelfAttention(int(conv2.shape[-1]), name = 'sa3')(conv2)\n",
    "    sent_sa_feat_4, sent_beta_4, sent_gamma_4 = SelfAttention(int(conv2.shape[-1]), name = 'sa4')(conv2)\n",
    "    concat1 = Concatenate()([sent_sa_feat_1,sent_sa_feat_2,sent_sa_feat_3,sent_sa_feat_4])\n",
    "    conv3 = Conv1D(filters=256,kernel_size=3, strides=1, activation='relu', padding='same')(concat1)\n",
    "    conv3 = Dropout(0.5)(conv3)\n",
    "    conv3 = BatchNormalization()(conv3)\n",
    "    headline = Dense(256, activation='relu')(inp_headline_vector)\n",
    "    headline = Lambda(lambda x:K.expand_dims(x, axis=1))(headline)\n",
    "    headline = BatchNormalization()(headline)\n",
    "    sent_hd_sa_feat_1, sent_hd_beta_1, sent_hd_gamma_1 = CrossAttention(int(conv3.shape[-1]), name = 'ca1')([headline,conv3])\n",
    "    sent_hd_sa_feat_2, sent_hd_beta_2, sent_hd_gamma_2 = CrossAttention(int(conv3.shape[-1]), name = 'ca2')([headline,conv3])\n",
    "    sent_hd_sa_feat_3, sent_hd_beta_3, sent_hd_gamma_3 = CrossAttention(int(conv3.shape[-1]), name = 'ca3')([headline,conv3])\n",
    "    sent_hd_sa_feat_4, sent_hd_beta_4, sent_hd_gamma_4 = CrossAttention(int(conv3.shape[-1]), name = 'ca4')([headline,conv3])  \n",
    "    concat3 = Concatenate()([sent_hd_sa_feat_1,sent_hd_sa_feat_2,sent_hd_sa_feat_3,sent_hd_sa_feat_4])\n",
    "    concat3 = Dropout(0.5)(concat3)\n",
    "    concat3 = BatchNormalization()(concat3)\n",
    "    conv5 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(concat3)\n",
    "    conv6 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv5)\n",
    "    conv7 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv6)\n",
    "    conv8 = Conv1D(filters=256,kernel_size=3, strides=2, activation='relu', padding='same')(conv7)\n",
    "    conv8 = Dropout(0.5)(conv8)\n",
    "    conv8 = BatchNormalization()(conv8)\n",
    "    gap = GlobalAveragePooling1D()(conv8)\n",
    "#     repeat = RepeatVector(50)(gap)\n",
    "#     lstm = LSTM(256,return_sequences=True)(repeat)\n",
    "    dense1 = Dense(512,activation='relu')(gap)\n",
    "    dense1 = Dropout(0.5)(dense1)\n",
    "    dense1 = BatchNormalization()(dense1)\n",
    "    gen_hd_vector = Dense(300,activation='linear', name='output_headline_vector')(dense1)\n",
    "    repeat = RepeatVector(50)(gap)\n",
    "    lstm1 = LSTM(256,return_sequences=True, activation='relu')(repeat)\n",
    "    lstm1 = Dropout(0.5)(lstm1)\n",
    "    lstm1 = BatchNormalization()(lstm1)\n",
    "    gen_hd_word = TimeDistributed(Dense(20000,activation='softmax'), name='headline_token_classes')(lstm1)\n",
    "    model = Model([inp_sentence_vectors,inp_headline_vector],[gen_hd_vector,gen_hd_word])\n",
    "    return model\n",
    "model = build_model()\n",
    "losses = {\n",
    "    'output_headline_vector':'mse'\n",
    "    ,'headline_token_classes':'categorical_crossentropy'\n",
    "}\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001,beta_1=0.0,beta_2=0.99),loss=losses)\n",
    "model.summary()\n",
    "# print('model params:',model.count_params())\n",
    "SVG(model_to_dot(model,show_layer_names=True,show_shapes=True).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = datetime.now()\n",
    "mc = ModelCheckpoint('weights/dnf700_sa_sent_hd_vector_word_gl.hdf5',save_best_only=True,save_weights_only=True)\n",
    "tb = TensorBoard(batch_size=32,log_dir='logs/dnf700_sa_sent_hd_vector_word_gl/{0}'.format(dt.timestamp()),write_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "4/4 [==============================] - 51s 13s/step - loss: 11.0744 - output_headline_vector_loss: 1.1674 - headline_token_classes_loss: 9.9070 - val_loss: 10.3892 - val_output_headline_vector_loss: 0.4492 - val_headline_token_classes_loss: 9.9400\n",
      "Epoch 2/2000\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 11.0579 - output_headline_vector_loss: 1.1545 - headline_token_classes_loss: 9.9034 - val_loss: 10.3178 - val_output_headline_vector_loss: 0.3825 - val_headline_token_classes_loss: 9.9352\n",
      "Epoch 3/2000\n",
      "4/4 [==============================] - 3s 698ms/step - loss: 11.0601 - output_headline_vector_loss: 1.1663 - headline_token_classes_loss: 9.8938 - val_loss: 10.2696 - val_output_headline_vector_loss: 0.3401 - val_headline_token_classes_loss: 9.9295\n",
      "Epoch 4/2000\n",
      "4/4 [==============================] - 2s 570ms/step - loss: 11.0296 - output_headline_vector_loss: 1.1417 - headline_token_classes_loss: 9.8879 - val_loss: 10.2082 - val_output_headline_vector_loss: 0.3072 - val_headline_token_classes_loss: 9.9010\n",
      "Epoch 5/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 11.0127 - output_headline_vector_loss: 1.1336 - headline_token_classes_loss: 9.8791 - val_loss: 10.1421 - val_output_headline_vector_loss: 0.2792 - val_headline_token_classes_loss: 9.8629\n",
      "Epoch 6/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 11.0035 - output_headline_vector_loss: 1.1348 - headline_token_classes_loss: 9.8687 - val_loss: 10.0356 - val_output_headline_vector_loss: 0.2618 - val_headline_token_classes_loss: 9.7738\n",
      "Epoch 7/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.9622 - output_headline_vector_loss: 1.1064 - headline_token_classes_loss: 9.8558 - val_loss: 9.8790 - val_output_headline_vector_loss: 0.2485 - val_headline_token_classes_loss: 9.6305\n",
      "Epoch 8/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.9632 - output_headline_vector_loss: 1.1122 - headline_token_classes_loss: 9.8510 - val_loss: 10.0222 - val_output_headline_vector_loss: 0.2489 - val_headline_token_classes_loss: 9.7733\n",
      "Epoch 9/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.9127 - output_headline_vector_loss: 1.0846 - headline_token_classes_loss: 9.8281 - val_loss: 10.0585 - val_output_headline_vector_loss: 0.2373 - val_headline_token_classes_loss: 9.8212\n",
      "Epoch 10/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.8799 - output_headline_vector_loss: 1.0805 - headline_token_classes_loss: 9.7994 - val_loss: 10.0173 - val_output_headline_vector_loss: 0.2382 - val_headline_token_classes_loss: 9.7790\n",
      "Epoch 11/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.8441 - output_headline_vector_loss: 1.0690 - headline_token_classes_loss: 9.7752 - val_loss: 9.9361 - val_output_headline_vector_loss: 0.2218 - val_headline_token_classes_loss: 9.7143\n",
      "Epoch 12/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.8041 - output_headline_vector_loss: 1.0584 - headline_token_classes_loss: 9.7457 - val_loss: 9.6224 - val_output_headline_vector_loss: 0.2239 - val_headline_token_classes_loss: 9.3985\n",
      "Epoch 13/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.8669 - output_headline_vector_loss: 1.0667 - headline_token_classes_loss: 9.8003 - val_loss: 9.5113 - val_output_headline_vector_loss: 0.2155 - val_headline_token_classes_loss: 9.2958\n",
      "Epoch 14/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 10.7804 - output_headline_vector_loss: 1.0500 - headline_token_classes_loss: 9.7304 - val_loss: 9.6226 - val_output_headline_vector_loss: 0.2065 - val_headline_token_classes_loss: 9.4161\n",
      "Epoch 15/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 10.7346 - output_headline_vector_loss: 1.0486 - headline_token_classes_loss: 9.6860 - val_loss: 9.1713 - val_output_headline_vector_loss: 0.1958 - val_headline_token_classes_loss: 8.9755\n",
      "Epoch 16/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 10.7211 - output_headline_vector_loss: 1.0384 - headline_token_classes_loss: 9.6827 - val_loss: 9.0174 - val_output_headline_vector_loss: 0.1895 - val_headline_token_classes_loss: 8.8279\n",
      "Epoch 17/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.6735 - output_headline_vector_loss: 1.0230 - headline_token_classes_loss: 9.6505 - val_loss: 8.2714 - val_output_headline_vector_loss: 0.1816 - val_headline_token_classes_loss: 8.0897\n",
      "Epoch 18/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 10.6884 - output_headline_vector_loss: 1.0102 - headline_token_classes_loss: 9.6782 - val_loss: 9.6192 - val_output_headline_vector_loss: 0.1815 - val_headline_token_classes_loss: 9.4377\n",
      "Epoch 19/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.6186 - output_headline_vector_loss: 1.0112 - headline_token_classes_loss: 9.6074 - val_loss: 8.2996 - val_output_headline_vector_loss: 0.1795 - val_headline_token_classes_loss: 8.1201\n",
      "Epoch 20/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 10.6356 - output_headline_vector_loss: 1.0013 - headline_token_classes_loss: 9.6344 - val_loss: 9.6147 - val_output_headline_vector_loss: 0.1744 - val_headline_token_classes_loss: 9.4402\n",
      "Epoch 21/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 10.5734 - output_headline_vector_loss: 1.0008 - headline_token_classes_loss: 9.5726 - val_loss: 8.8131 - val_output_headline_vector_loss: 0.1699 - val_headline_token_classes_loss: 8.6431\n",
      "Epoch 22/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.5800 - output_headline_vector_loss: 0.9937 - headline_token_classes_loss: 9.5863 - val_loss: 8.6565 - val_output_headline_vector_loss: 0.1520 - val_headline_token_classes_loss: 8.5045\n",
      "Epoch 23/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.5117 - output_headline_vector_loss: 0.9749 - headline_token_classes_loss: 9.5368 - val_loss: 9.5947 - val_output_headline_vector_loss: 0.1571 - val_headline_token_classes_loss: 9.4377\n",
      "Epoch 24/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.4900 - output_headline_vector_loss: 0.9661 - headline_token_classes_loss: 9.5239 - val_loss: 8.9335 - val_output_headline_vector_loss: 0.1536 - val_headline_token_classes_loss: 8.7799\n",
      "Epoch 25/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.4014 - output_headline_vector_loss: 0.9488 - headline_token_classes_loss: 9.4526 - val_loss: 7.9111 - val_output_headline_vector_loss: 0.1573 - val_headline_token_classes_loss: 7.7538\n",
      "Epoch 26/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.4041 - output_headline_vector_loss: 0.9565 - headline_token_classes_loss: 9.4476 - val_loss: 9.4844 - val_output_headline_vector_loss: 0.1582 - val_headline_token_classes_loss: 9.3262\n",
      "Epoch 27/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.4129 - output_headline_vector_loss: 0.9588 - headline_token_classes_loss: 9.4541 - val_loss: 8.8499 - val_output_headline_vector_loss: 0.1493 - val_headline_token_classes_loss: 8.7006\n",
      "Epoch 28/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 10.3022 - output_headline_vector_loss: 0.9437 - headline_token_classes_loss: 9.3585 - val_loss: 8.3600 - val_output_headline_vector_loss: 0.1408 - val_headline_token_classes_loss: 8.2192\n",
      "Epoch 29/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 10.3125 - output_headline_vector_loss: 0.9271 - headline_token_classes_loss: 9.3853 - val_loss: 8.9800 - val_output_headline_vector_loss: 0.1488 - val_headline_token_classes_loss: 8.8312\n",
      "Epoch 30/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.2645 - output_headline_vector_loss: 0.9252 - headline_token_classes_loss: 9.3393 - val_loss: 9.0112 - val_output_headline_vector_loss: 0.1373 - val_headline_token_classes_loss: 8.8738\n",
      "Epoch 31/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 10.1749 - output_headline_vector_loss: 0.9014 - headline_token_classes_loss: 9.2736 - val_loss: 7.9272 - val_output_headline_vector_loss: 0.1367 - val_headline_token_classes_loss: 7.7905\n",
      "Epoch 32/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 10.1716 - output_headline_vector_loss: 0.9201 - headline_token_classes_loss: 9.2515 - val_loss: 8.6752 - val_output_headline_vector_loss: 0.1330 - val_headline_token_classes_loss: 8.5422\n",
      "Epoch 33/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.1267 - output_headline_vector_loss: 0.9202 - headline_token_classes_loss: 9.2065 - val_loss: 9.2424 - val_output_headline_vector_loss: 0.1373 - val_headline_token_classes_loss: 9.1051\n",
      "Epoch 34/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.0923 - output_headline_vector_loss: 0.9158 - headline_token_classes_loss: 9.1765 - val_loss: 8.4368 - val_output_headline_vector_loss: 0.1402 - val_headline_token_classes_loss: 8.2966\n",
      "Epoch 35/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 10.0135 - output_headline_vector_loss: 0.8992 - headline_token_classes_loss: 9.1143 - val_loss: 8.3588 - val_output_headline_vector_loss: 0.1327 - val_headline_token_classes_loss: 8.2261\n",
      "Epoch 36/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.9829 - output_headline_vector_loss: 0.8894 - headline_token_classes_loss: 9.0934 - val_loss: 8.8360 - val_output_headline_vector_loss: 0.1425 - val_headline_token_classes_loss: 8.6934\n",
      "Epoch 37/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.9168 - output_headline_vector_loss: 0.8928 - headline_token_classes_loss: 9.0240 - val_loss: 8.5493 - val_output_headline_vector_loss: 0.1287 - val_headline_token_classes_loss: 8.4206\n",
      "Epoch 38/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.9106 - output_headline_vector_loss: 0.8884 - headline_token_classes_loss: 9.0222 - val_loss: 8.7788 - val_output_headline_vector_loss: 0.1271 - val_headline_token_classes_loss: 8.6516\n",
      "Epoch 39/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.7844 - output_headline_vector_loss: 0.8745 - headline_token_classes_loss: 8.9098 - val_loss: 8.6034 - val_output_headline_vector_loss: 0.1364 - val_headline_token_classes_loss: 8.4670\n",
      "Epoch 40/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.7035 - output_headline_vector_loss: 0.8604 - headline_token_classes_loss: 8.8431 - val_loss: 8.4572 - val_output_headline_vector_loss: 0.1295 - val_headline_token_classes_loss: 8.3277\n",
      "Epoch 41/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.6568 - output_headline_vector_loss: 0.8709 - headline_token_classes_loss: 8.7859 - val_loss: 8.4704 - val_output_headline_vector_loss: 0.1303 - val_headline_token_classes_loss: 8.3401\n",
      "Epoch 42/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.5851 - output_headline_vector_loss: 0.8470 - headline_token_classes_loss: 8.7381 - val_loss: 8.4663 - val_output_headline_vector_loss: 0.1313 - val_headline_token_classes_loss: 8.3351\n",
      "Epoch 43/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.5389 - output_headline_vector_loss: 0.8362 - headline_token_classes_loss: 8.7026 - val_loss: 8.2353 - val_output_headline_vector_loss: 0.1228 - val_headline_token_classes_loss: 8.1125\n",
      "Epoch 44/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.4478 - output_headline_vector_loss: 0.8445 - headline_token_classes_loss: 8.6033 - val_loss: 8.1055 - val_output_headline_vector_loss: 0.1296 - val_headline_token_classes_loss: 7.9759\n",
      "Epoch 45/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.4202 - output_headline_vector_loss: 0.8477 - headline_token_classes_loss: 8.5726 - val_loss: 7.9290 - val_output_headline_vector_loss: 0.1070 - val_headline_token_classes_loss: 7.8221\n",
      "Epoch 46/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.2508 - output_headline_vector_loss: 0.8120 - headline_token_classes_loss: 8.4388 - val_loss: 7.8509 - val_output_headline_vector_loss: 0.1198 - val_headline_token_classes_loss: 7.7311\n",
      "Epoch 47/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.2096 - output_headline_vector_loss: 0.8244 - headline_token_classes_loss: 8.3852 - val_loss: 7.6795 - val_output_headline_vector_loss: 0.1188 - val_headline_token_classes_loss: 7.5607\n",
      "Epoch 48/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.1299 - output_headline_vector_loss: 0.8047 - headline_token_classes_loss: 8.3253 - val_loss: 7.6025 - val_output_headline_vector_loss: 0.1107 - val_headline_token_classes_loss: 7.4918\n",
      "Epoch 49/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.0847 - output_headline_vector_loss: 0.8180 - headline_token_classes_loss: 8.2668 - val_loss: 7.2499 - val_output_headline_vector_loss: 0.1196 - val_headline_token_classes_loss: 7.1303\n",
      "Epoch 50/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.0073 - output_headline_vector_loss: 0.8058 - headline_token_classes_loss: 8.2016 - val_loss: 7.4454 - val_output_headline_vector_loss: 0.1059 - val_headline_token_classes_loss: 7.3395\n",
      "Epoch 51/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.9333 - output_headline_vector_loss: 0.8089 - headline_token_classes_loss: 8.1243 - val_loss: 7.6493 - val_output_headline_vector_loss: 0.1059 - val_headline_token_classes_loss: 7.5433\n",
      "Epoch 52/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.9141 - output_headline_vector_loss: 0.7858 - headline_token_classes_loss: 8.1282 - val_loss: 7.2756 - val_output_headline_vector_loss: 0.1121 - val_headline_token_classes_loss: 7.1635\n",
      "Epoch 53/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.8710 - output_headline_vector_loss: 0.7859 - headline_token_classes_loss: 8.0851 - val_loss: 7.1010 - val_output_headline_vector_loss: 0.1027 - val_headline_token_classes_loss: 6.9983\n",
      "Epoch 54/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.7683 - output_headline_vector_loss: 0.7772 - headline_token_classes_loss: 7.9911 - val_loss: 6.7557 - val_output_headline_vector_loss: 0.1051 - val_headline_token_classes_loss: 6.6507\n",
      "Epoch 55/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.7609 - output_headline_vector_loss: 0.7835 - headline_token_classes_loss: 7.9774 - val_loss: 7.9706 - val_output_headline_vector_loss: 0.0944 - val_headline_token_classes_loss: 7.8761\n",
      "Epoch 56/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.6610 - output_headline_vector_loss: 0.7759 - headline_token_classes_loss: 7.8851 - val_loss: 7.4677 - val_output_headline_vector_loss: 0.0994 - val_headline_token_classes_loss: 7.3684\n",
      "Epoch 57/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5646 - output_headline_vector_loss: 0.7510 - headline_token_classes_loss: 7.8136 - val_loss: 7.3298 - val_output_headline_vector_loss: 0.1030 - val_headline_token_classes_loss: 7.2268\n",
      "Epoch 58/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5513 - output_headline_vector_loss: 0.7643 - headline_token_classes_loss: 7.7869 - val_loss: 7.6593 - val_output_headline_vector_loss: 0.0959 - val_headline_token_classes_loss: 7.5634\n",
      "Epoch 59/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.4122 - output_headline_vector_loss: 0.7483 - headline_token_classes_loss: 7.6639 - val_loss: 7.1530 - val_output_headline_vector_loss: 0.0917 - val_headline_token_classes_loss: 7.0612\n",
      "Epoch 60/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.3894 - output_headline_vector_loss: 0.7493 - headline_token_classes_loss: 7.6401 - val_loss: 8.1785 - val_output_headline_vector_loss: 0.0876 - val_headline_token_classes_loss: 8.0909\n",
      "Epoch 61/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.2945 - output_headline_vector_loss: 0.7415 - headline_token_classes_loss: 7.5530 - val_loss: 7.6596 - val_output_headline_vector_loss: 0.0922 - val_headline_token_classes_loss: 7.5674\n",
      "Epoch 62/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.2224 - output_headline_vector_loss: 0.7360 - headline_token_classes_loss: 7.4864 - val_loss: 6.9470 - val_output_headline_vector_loss: 0.0863 - val_headline_token_classes_loss: 6.8607\n",
      "Epoch 63/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1781 - output_headline_vector_loss: 0.7340 - headline_token_classes_loss: 7.4441 - val_loss: 6.8953 - val_output_headline_vector_loss: 0.0823 - val_headline_token_classes_loss: 6.8130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.1073 - output_headline_vector_loss: 0.7389 - headline_token_classes_loss: 7.3685 - val_loss: 6.4103 - val_output_headline_vector_loss: 0.0955 - val_headline_token_classes_loss: 6.3148\n",
      "Epoch 65/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 8.0888 - output_headline_vector_loss: 0.7211 - headline_token_classes_loss: 7.3678 - val_loss: 6.6000 - val_output_headline_vector_loss: 0.0895 - val_headline_token_classes_loss: 6.5105\n",
      "Epoch 66/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.0220 - output_headline_vector_loss: 0.7177 - headline_token_classes_loss: 7.3043 - val_loss: 6.5876 - val_output_headline_vector_loss: 0.0812 - val_headline_token_classes_loss: 6.5064\n",
      "Epoch 67/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 7.9385 - output_headline_vector_loss: 0.6972 - headline_token_classes_loss: 7.2414 - val_loss: 6.1845 - val_output_headline_vector_loss: 0.0804 - val_headline_token_classes_loss: 6.1041\n",
      "Epoch 68/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8234 - output_headline_vector_loss: 0.7033 - headline_token_classes_loss: 7.1201 - val_loss: 6.3049 - val_output_headline_vector_loss: 0.0807 - val_headline_token_classes_loss: 6.2242\n",
      "Epoch 69/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.8748 - output_headline_vector_loss: 0.7094 - headline_token_classes_loss: 7.1654 - val_loss: 8.3323 - val_output_headline_vector_loss: 0.0790 - val_headline_token_classes_loss: 8.2533\n",
      "Epoch 70/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.7548 - output_headline_vector_loss: 0.6878 - headline_token_classes_loss: 7.0670 - val_loss: 7.4748 - val_output_headline_vector_loss: 0.0742 - val_headline_token_classes_loss: 7.4006\n",
      "Epoch 71/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5723 - output_headline_vector_loss: 0.6689 - headline_token_classes_loss: 6.9034 - val_loss: 6.6839 - val_output_headline_vector_loss: 0.0756 - val_headline_token_classes_loss: 6.6083\n",
      "Epoch 72/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.6185 - output_headline_vector_loss: 0.6867 - headline_token_classes_loss: 6.9318 - val_loss: 6.4573 - val_output_headline_vector_loss: 0.0763 - val_headline_token_classes_loss: 6.3810\n",
      "Epoch 73/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5127 - output_headline_vector_loss: 0.6863 - headline_token_classes_loss: 6.8264 - val_loss: 6.2020 - val_output_headline_vector_loss: 0.0742 - val_headline_token_classes_loss: 6.1278\n",
      "Epoch 74/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5669 - output_headline_vector_loss: 0.6719 - headline_token_classes_loss: 7.8950 - val_loss: 6.7214 - val_output_headline_vector_loss: 0.0712 - val_headline_token_classes_loss: 6.6503\n",
      "Epoch 75/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.7421 - output_headline_vector_loss: 0.6682 - headline_token_classes_loss: 9.0739 - val_loss: 10.0937 - val_output_headline_vector_loss: 0.0753 - val_headline_token_classes_loss: 10.0184\n",
      "Epoch 76/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.7186 - output_headline_vector_loss: 0.6754 - headline_token_classes_loss: 9.0433 - val_loss: 9.5702 - val_output_headline_vector_loss: 0.0716 - val_headline_token_classes_loss: 9.4986\n",
      "Epoch 77/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.6582 - output_headline_vector_loss: 0.6735 - headline_token_classes_loss: 8.9847 - val_loss: 9.6362 - val_output_headline_vector_loss: 0.0907 - val_headline_token_classes_loss: 9.5455\n",
      "Epoch 78/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.7107 - output_headline_vector_loss: 0.6642 - headline_token_classes_loss: 9.0466 - val_loss: 9.7687 - val_output_headline_vector_loss: 0.0849 - val_headline_token_classes_loss: 9.6838\n",
      "Epoch 79/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.6417 - output_headline_vector_loss: 0.6695 - headline_token_classes_loss: 8.9722 - val_loss: 9.8772 - val_output_headline_vector_loss: 0.0675 - val_headline_token_classes_loss: 9.8097\n",
      "Epoch 80/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.5975 - output_headline_vector_loss: 0.6542 - headline_token_classes_loss: 8.9433 - val_loss: 9.8673 - val_output_headline_vector_loss: 0.0693 - val_headline_token_classes_loss: 9.7980\n",
      "Epoch 81/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.6608 - output_headline_vector_loss: 0.6570 - headline_token_classes_loss: 9.0038 - val_loss: 9.9547 - val_output_headline_vector_loss: 0.0687 - val_headline_token_classes_loss: 9.8861\n",
      "Epoch 82/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.6176 - output_headline_vector_loss: 0.6730 - headline_token_classes_loss: 8.9446 - val_loss: 9.9813 - val_output_headline_vector_loss: 0.0663 - val_headline_token_classes_loss: 9.9150\n",
      "Epoch 83/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.6113 - output_headline_vector_loss: 0.6500 - headline_token_classes_loss: 8.9613 - val_loss: 9.9725 - val_output_headline_vector_loss: 0.0791 - val_headline_token_classes_loss: 9.8934\n",
      "Epoch 84/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.5406 - output_headline_vector_loss: 0.6494 - headline_token_classes_loss: 8.8912 - val_loss: 9.9795 - val_output_headline_vector_loss: 0.0677 - val_headline_token_classes_loss: 9.9118\n",
      "Epoch 85/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.5214 - output_headline_vector_loss: 0.6469 - headline_token_classes_loss: 8.8746 - val_loss: 9.8921 - val_output_headline_vector_loss: 0.0735 - val_headline_token_classes_loss: 9.8186\n",
      "Epoch 86/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.4947 - output_headline_vector_loss: 0.6385 - headline_token_classes_loss: 8.8562 - val_loss: 10.0007 - val_output_headline_vector_loss: 0.0646 - val_headline_token_classes_loss: 9.9360\n",
      "Epoch 87/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.5311 - output_headline_vector_loss: 0.6342 - headline_token_classes_loss: 8.8969 - val_loss: 9.8574 - val_output_headline_vector_loss: 0.0601 - val_headline_token_classes_loss: 9.7973\n",
      "Epoch 88/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.5089 - output_headline_vector_loss: 0.6407 - headline_token_classes_loss: 8.8681 - val_loss: 9.9594 - val_output_headline_vector_loss: 0.0633 - val_headline_token_classes_loss: 9.8962\n",
      "Epoch 89/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 9.4499 - output_headline_vector_loss: 0.6303 - headline_token_classes_loss: 8.8197 - val_loss: 9.9802 - val_output_headline_vector_loss: 0.0649 - val_headline_token_classes_loss: 9.9153\n",
      "Epoch 90/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.4244 - output_headline_vector_loss: 0.6097 - headline_token_classes_loss: 8.8148 - val_loss: 10.0180 - val_output_headline_vector_loss: 0.0647 - val_headline_token_classes_loss: 9.9532\n",
      "Epoch 91/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.3937 - output_headline_vector_loss: 0.6047 - headline_token_classes_loss: 8.7890 - val_loss: 9.9980 - val_output_headline_vector_loss: 0.0602 - val_headline_token_classes_loss: 9.9378\n",
      "Epoch 92/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.3880 - output_headline_vector_loss: 0.6100 - headline_token_classes_loss: 8.7780 - val_loss: 9.9662 - val_output_headline_vector_loss: 0.0609 - val_headline_token_classes_loss: 9.9053\n",
      "Epoch 93/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.3887 - output_headline_vector_loss: 0.5994 - headline_token_classes_loss: 8.7893 - val_loss: 9.9475 - val_output_headline_vector_loss: 0.0681 - val_headline_token_classes_loss: 9.8794\n",
      "Epoch 94/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.3301 - output_headline_vector_loss: 0.6122 - headline_token_classes_loss: 8.7179 - val_loss: 9.9349 - val_output_headline_vector_loss: 0.0599 - val_headline_token_classes_loss: 9.8750\n",
      "Epoch 95/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.3511 - output_headline_vector_loss: 0.6073 - headline_token_classes_loss: 8.7437 - val_loss: 9.9980 - val_output_headline_vector_loss: 0.0615 - val_headline_token_classes_loss: 9.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.3036 - output_headline_vector_loss: 0.5997 - headline_token_classes_loss: 8.7039 - val_loss: 9.8050 - val_output_headline_vector_loss: 0.0574 - val_headline_token_classes_loss: 9.7476\n",
      "Epoch 97/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.3048 - output_headline_vector_loss: 0.5908 - headline_token_classes_loss: 8.7141 - val_loss: 9.8903 - val_output_headline_vector_loss: 0.0594 - val_headline_token_classes_loss: 9.8309\n",
      "Epoch 98/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.2664 - output_headline_vector_loss: 0.5894 - headline_token_classes_loss: 8.6770 - val_loss: 9.8715 - val_output_headline_vector_loss: 0.0564 - val_headline_token_classes_loss: 9.8151\n",
      "Epoch 99/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 9.2196 - output_headline_vector_loss: 0.5922 - headline_token_classes_loss: 8.6274 - val_loss: 9.7412 - val_output_headline_vector_loss: 0.0614 - val_headline_token_classes_loss: 9.6798\n",
      "Epoch 100/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.1816 - output_headline_vector_loss: 0.5817 - headline_token_classes_loss: 8.6000 - val_loss: 9.7239 - val_output_headline_vector_loss: 0.0554 - val_headline_token_classes_loss: 9.6685\n",
      "Epoch 101/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.2210 - output_headline_vector_loss: 0.5757 - headline_token_classes_loss: 8.6454 - val_loss: 9.8418 - val_output_headline_vector_loss: 0.0644 - val_headline_token_classes_loss: 9.7774\n",
      "Epoch 102/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 9.1427 - output_headline_vector_loss: 0.5666 - headline_token_classes_loss: 8.5761 - val_loss: 9.8671 - val_output_headline_vector_loss: 0.0543 - val_headline_token_classes_loss: 9.8128\n",
      "Epoch 103/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.1361 - output_headline_vector_loss: 0.5833 - headline_token_classes_loss: 8.5528 - val_loss: 9.9125 - val_output_headline_vector_loss: 0.0562 - val_headline_token_classes_loss: 9.8563\n",
      "Epoch 104/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.1376 - output_headline_vector_loss: 0.5736 - headline_token_classes_loss: 8.5640 - val_loss: 9.8198 - val_output_headline_vector_loss: 0.0522 - val_headline_token_classes_loss: 9.7675\n",
      "Epoch 105/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.0710 - output_headline_vector_loss: 0.5583 - headline_token_classes_loss: 8.5127 - val_loss: 9.7946 - val_output_headline_vector_loss: 0.0520 - val_headline_token_classes_loss: 9.7426\n",
      "Epoch 106/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 9.1090 - output_headline_vector_loss: 0.5575 - headline_token_classes_loss: 8.5515 - val_loss: 9.7742 - val_output_headline_vector_loss: 0.0517 - val_headline_token_classes_loss: 9.7225\n",
      "Epoch 107/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.0502 - output_headline_vector_loss: 0.5552 - headline_token_classes_loss: 8.4950 - val_loss: 9.6970 - val_output_headline_vector_loss: 0.0487 - val_headline_token_classes_loss: 9.6483\n",
      "Epoch 108/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.0621 - output_headline_vector_loss: 0.5522 - headline_token_classes_loss: 8.5099 - val_loss: 9.6179 - val_output_headline_vector_loss: 0.0551 - val_headline_token_classes_loss: 9.5628\n",
      "Epoch 109/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.9909 - output_headline_vector_loss: 0.5430 - headline_token_classes_loss: 8.4479 - val_loss: 9.6825 - val_output_headline_vector_loss: 0.0576 - val_headline_token_classes_loss: 9.6249\n",
      "Epoch 110/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 9.0015 - output_headline_vector_loss: 0.5511 - headline_token_classes_loss: 8.4504 - val_loss: 9.6964 - val_output_headline_vector_loss: 0.0514 - val_headline_token_classes_loss: 9.6450\n",
      "Epoch 111/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.9720 - output_headline_vector_loss: 0.5448 - headline_token_classes_loss: 8.4272 - val_loss: 9.5096 - val_output_headline_vector_loss: 0.0562 - val_headline_token_classes_loss: 9.4534\n",
      "Epoch 112/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.9471 - output_headline_vector_loss: 0.5273 - headline_token_classes_loss: 8.4198 - val_loss: 9.7114 - val_output_headline_vector_loss: 0.0539 - val_headline_token_classes_loss: 9.6575\n",
      "Epoch 113/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.9255 - output_headline_vector_loss: 0.5202 - headline_token_classes_loss: 8.4053 - val_loss: 9.6244 - val_output_headline_vector_loss: 0.0487 - val_headline_token_classes_loss: 9.5758\n",
      "Epoch 114/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.9214 - output_headline_vector_loss: 0.5333 - headline_token_classes_loss: 8.3880 - val_loss: 9.6355 - val_output_headline_vector_loss: 0.0486 - val_headline_token_classes_loss: 9.5869\n",
      "Epoch 115/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.8866 - output_headline_vector_loss: 0.5228 - headline_token_classes_loss: 8.3638 - val_loss: 9.5806 - val_output_headline_vector_loss: 0.0549 - val_headline_token_classes_loss: 9.5257\n",
      "Epoch 116/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.8394 - output_headline_vector_loss: 0.5272 - headline_token_classes_loss: 8.3122 - val_loss: 9.6287 - val_output_headline_vector_loss: 0.0478 - val_headline_token_classes_loss: 9.5809\n",
      "Epoch 117/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.8799 - output_headline_vector_loss: 0.5191 - headline_token_classes_loss: 8.3608 - val_loss: 9.5985 - val_output_headline_vector_loss: 0.0491 - val_headline_token_classes_loss: 9.5494\n",
      "Epoch 118/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.8267 - output_headline_vector_loss: 0.5184 - headline_token_classes_loss: 8.3083 - val_loss: 9.5542 - val_output_headline_vector_loss: 0.0472 - val_headline_token_classes_loss: 9.5069\n",
      "Epoch 119/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.8232 - output_headline_vector_loss: 0.5167 - headline_token_classes_loss: 8.3065 - val_loss: 9.5325 - val_output_headline_vector_loss: 0.0464 - val_headline_token_classes_loss: 9.4861\n",
      "Epoch 120/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.8060 - output_headline_vector_loss: 0.5060 - headline_token_classes_loss: 8.2999 - val_loss: 9.4338 - val_output_headline_vector_loss: 0.0539 - val_headline_token_classes_loss: 9.3798\n",
      "Epoch 121/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.7928 - output_headline_vector_loss: 0.5129 - headline_token_classes_loss: 8.2799 - val_loss: 9.5244 - val_output_headline_vector_loss: 0.0481 - val_headline_token_classes_loss: 9.4764\n",
      "Epoch 122/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.7142 - output_headline_vector_loss: 0.5070 - headline_token_classes_loss: 8.2072 - val_loss: 9.5031 - val_output_headline_vector_loss: 0.0464 - val_headline_token_classes_loss: 9.4568\n",
      "Epoch 123/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.6965 - output_headline_vector_loss: 0.5042 - headline_token_classes_loss: 8.1923 - val_loss: 9.4003 - val_output_headline_vector_loss: 0.0507 - val_headline_token_classes_loss: 9.3496\n",
      "Epoch 124/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.6920 - output_headline_vector_loss: 0.5052 - headline_token_classes_loss: 8.1868 - val_loss: 9.4384 - val_output_headline_vector_loss: 0.0506 - val_headline_token_classes_loss: 9.3879\n",
      "Epoch 125/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.6590 - output_headline_vector_loss: 0.4956 - headline_token_classes_loss: 8.1634 - val_loss: 9.5267 - val_output_headline_vector_loss: 0.0479 - val_headline_token_classes_loss: 9.4787\n",
      "Epoch 126/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.6442 - output_headline_vector_loss: 0.4812 - headline_token_classes_loss: 8.1630 - val_loss: 9.4885 - val_output_headline_vector_loss: 0.0443 - val_headline_token_classes_loss: 9.4443\n",
      "Epoch 127/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.6120 - output_headline_vector_loss: 0.4833 - headline_token_classes_loss: 8.1288 - val_loss: 9.4376 - val_output_headline_vector_loss: 0.0427 - val_headline_token_classes_loss: 9.3949\n",
      "Epoch 128/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.6100 - output_headline_vector_loss: 0.4891 - headline_token_classes_loss: 8.1210 - val_loss: 9.4051 - val_output_headline_vector_loss: 0.0420 - val_headline_token_classes_loss: 9.3631\n",
      "Epoch 129/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5829 - output_headline_vector_loss: 0.4799 - headline_token_classes_loss: 8.1029 - val_loss: 9.4027 - val_output_headline_vector_loss: 0.0444 - val_headline_token_classes_loss: 9.3583\n",
      "Epoch 130/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.5718 - output_headline_vector_loss: 0.4754 - headline_token_classes_loss: 8.0964 - val_loss: 9.3984 - val_output_headline_vector_loss: 0.0513 - val_headline_token_classes_loss: 9.3471\n",
      "Epoch 131/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.5417 - output_headline_vector_loss: 0.4817 - headline_token_classes_loss: 8.0600 - val_loss: 10.4271 - val_output_headline_vector_loss: 0.0766 - val_headline_token_classes_loss: 10.3505\n",
      "Epoch 132/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.5834 - output_headline_vector_loss: 0.4730 - headline_token_classes_loss: 8.1104 - val_loss: 10.6715 - val_output_headline_vector_loss: 0.0661 - val_headline_token_classes_loss: 10.6054\n",
      "Epoch 133/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5692 - output_headline_vector_loss: 0.4596 - headline_token_classes_loss: 8.1096 - val_loss: 10.5678 - val_output_headline_vector_loss: 0.0603 - val_headline_token_classes_loss: 10.5075\n",
      "Epoch 134/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5431 - output_headline_vector_loss: 0.4717 - headline_token_classes_loss: 8.0714 - val_loss: 10.4201 - val_output_headline_vector_loss: 0.0697 - val_headline_token_classes_loss: 10.3504\n",
      "Epoch 135/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.4840 - output_headline_vector_loss: 0.4597 - headline_token_classes_loss: 8.0243 - val_loss: 10.6840 - val_output_headline_vector_loss: 0.0604 - val_headline_token_classes_loss: 10.6237\n",
      "Epoch 136/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.3952 - output_headline_vector_loss: 0.4652 - headline_token_classes_loss: 7.9301 - val_loss: 10.3662 - val_output_headline_vector_loss: 0.0659 - val_headline_token_classes_loss: 10.3003\n",
      "Epoch 137/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.5132 - output_headline_vector_loss: 0.4561 - headline_token_classes_loss: 8.0571 - val_loss: 10.5771 - val_output_headline_vector_loss: 0.0561 - val_headline_token_classes_loss: 10.5210\n",
      "Epoch 138/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.3674 - output_headline_vector_loss: 0.4438 - headline_token_classes_loss: 7.9236 - val_loss: 10.4634 - val_output_headline_vector_loss: 0.0526 - val_headline_token_classes_loss: 10.4108\n",
      "Epoch 139/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.4248 - output_headline_vector_loss: 0.4561 - headline_token_classes_loss: 7.9688 - val_loss: 10.3568 - val_output_headline_vector_loss: 0.0475 - val_headline_token_classes_loss: 10.3093\n",
      "Epoch 140/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.3890 - output_headline_vector_loss: 0.4537 - headline_token_classes_loss: 7.9353 - val_loss: 10.5143 - val_output_headline_vector_loss: 0.0499 - val_headline_token_classes_loss: 10.4644\n",
      "Epoch 141/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.3664 - output_headline_vector_loss: 0.4445 - headline_token_classes_loss: 7.9220 - val_loss: 10.3036 - val_output_headline_vector_loss: 0.0646 - val_headline_token_classes_loss: 10.2390\n",
      "Epoch 142/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.3866 - output_headline_vector_loss: 0.4299 - headline_token_classes_loss: 7.9567 - val_loss: 10.5989 - val_output_headline_vector_loss: 0.0456 - val_headline_token_classes_loss: 10.5534\n",
      "Epoch 143/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.3525 - output_headline_vector_loss: 0.4299 - headline_token_classes_loss: 7.9226 - val_loss: 10.5232 - val_output_headline_vector_loss: 0.0449 - val_headline_token_classes_loss: 10.4783\n",
      "Epoch 144/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.2738 - output_headline_vector_loss: 0.4337 - headline_token_classes_loss: 7.8400 - val_loss: 10.6624 - val_output_headline_vector_loss: 0.0476 - val_headline_token_classes_loss: 10.6148\n",
      "Epoch 145/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.2777 - output_headline_vector_loss: 0.4367 - headline_token_classes_loss: 7.8410 - val_loss: 10.5808 - val_output_headline_vector_loss: 0.0448 - val_headline_token_classes_loss: 10.5360\n",
      "Epoch 146/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.2136 - output_headline_vector_loss: 0.4335 - headline_token_classes_loss: 7.7801 - val_loss: 10.5976 - val_output_headline_vector_loss: 0.0454 - val_headline_token_classes_loss: 10.5522\n",
      "Epoch 147/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 8.2000 - output_headline_vector_loss: 0.4201 - headline_token_classes_loss: 7.7799 - val_loss: 10.4805 - val_output_headline_vector_loss: 0.0413 - val_headline_token_classes_loss: 10.4392\n",
      "Epoch 148/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1555 - output_headline_vector_loss: 0.4133 - headline_token_classes_loss: 7.7423 - val_loss: 10.5522 - val_output_headline_vector_loss: 0.0438 - val_headline_token_classes_loss: 10.5083\n",
      "Epoch 149/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.1723 - output_headline_vector_loss: 0.4226 - headline_token_classes_loss: 7.7496 - val_loss: 10.5259 - val_output_headline_vector_loss: 0.0416 - val_headline_token_classes_loss: 10.4843\n",
      "Epoch 150/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.1720 - output_headline_vector_loss: 0.4013 - headline_token_classes_loss: 7.7707 - val_loss: 10.3997 - val_output_headline_vector_loss: 0.0396 - val_headline_token_classes_loss: 10.3601\n",
      "Epoch 151/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.1643 - output_headline_vector_loss: 0.4218 - headline_token_classes_loss: 7.7424 - val_loss: 10.5936 - val_output_headline_vector_loss: 0.0411 - val_headline_token_classes_loss: 10.5525\n",
      "Epoch 152/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 8.1320 - output_headline_vector_loss: 0.4063 - headline_token_classes_loss: 7.7257 - val_loss: 10.1877 - val_output_headline_vector_loss: 0.0499 - val_headline_token_classes_loss: 10.1379\n",
      "Epoch 153/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.1344 - output_headline_vector_loss: 0.4044 - headline_token_classes_loss: 7.7301 - val_loss: 10.5023 - val_output_headline_vector_loss: 0.0399 - val_headline_token_classes_loss: 10.4624\n",
      "Epoch 154/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.0142 - output_headline_vector_loss: 0.4080 - headline_token_classes_loss: 7.6062 - val_loss: 10.3471 - val_output_headline_vector_loss: 0.0351 - val_headline_token_classes_loss: 10.3120\n",
      "Epoch 155/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.0393 - output_headline_vector_loss: 0.3983 - headline_token_classes_loss: 7.6410 - val_loss: 10.3522 - val_output_headline_vector_loss: 0.0433 - val_headline_token_classes_loss: 10.3088\n",
      "Epoch 156/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.9961 - output_headline_vector_loss: 0.4062 - headline_token_classes_loss: 7.5899 - val_loss: 10.3762 - val_output_headline_vector_loss: 0.0366 - val_headline_token_classes_loss: 10.3397\n",
      "Epoch 157/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 8.0510 - output_headline_vector_loss: 0.3976 - headline_token_classes_loss: 7.6534 - val_loss: 10.4963 - val_output_headline_vector_loss: 0.0371 - val_headline_token_classes_loss: 10.4592\n",
      "Epoch 158/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 7.9926 - output_headline_vector_loss: 0.3971 - headline_token_classes_loss: 7.5955 - val_loss: 10.3730 - val_output_headline_vector_loss: 0.0335 - val_headline_token_classes_loss: 10.3395\n",
      "Epoch 159/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.9409 - output_headline_vector_loss: 0.3851 - headline_token_classes_loss: 7.5558 - val_loss: 10.2889 - val_output_headline_vector_loss: 0.0398 - val_headline_token_classes_loss: 10.2491\n",
      "Epoch 160/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.9281 - output_headline_vector_loss: 0.3888 - headline_token_classes_loss: 7.5394 - val_loss: 10.4851 - val_output_headline_vector_loss: 0.0344 - val_headline_token_classes_loss: 10.4507\n",
      "Epoch 161/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.8982 - output_headline_vector_loss: 0.3809 - headline_token_classes_loss: 7.5172 - val_loss: 10.3864 - val_output_headline_vector_loss: 0.0322 - val_headline_token_classes_loss: 10.3543\n",
      "Epoch 162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8932 - output_headline_vector_loss: 0.3841 - headline_token_classes_loss: 7.5091 - val_loss: 10.3542 - val_output_headline_vector_loss: 0.0381 - val_headline_token_classes_loss: 10.3161\n",
      "Epoch 163/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8507 - output_headline_vector_loss: 0.3798 - headline_token_classes_loss: 7.4710 - val_loss: 10.4537 - val_output_headline_vector_loss: 0.0322 - val_headline_token_classes_loss: 10.4215\n",
      "Epoch 164/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8259 - output_headline_vector_loss: 0.3739 - headline_token_classes_loss: 7.4520 - val_loss: 10.1287 - val_output_headline_vector_loss: 0.0315 - val_headline_token_classes_loss: 10.0972\n",
      "Epoch 165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.8391 - output_headline_vector_loss: 0.3672 - headline_token_classes_loss: 7.4719 - val_loss: 10.3318 - val_output_headline_vector_loss: 0.0311 - val_headline_token_classes_loss: 10.3006\n",
      "Epoch 166/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.7708 - output_headline_vector_loss: 0.3610 - headline_token_classes_loss: 7.4097 - val_loss: 10.2063 - val_output_headline_vector_loss: 0.0349 - val_headline_token_classes_loss: 10.1714\n",
      "Epoch 167/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.7679 - output_headline_vector_loss: 0.3735 - headline_token_classes_loss: 7.3944 - val_loss: 10.2656 - val_output_headline_vector_loss: 0.0295 - val_headline_token_classes_loss: 10.2361\n",
      "Epoch 168/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.7970 - output_headline_vector_loss: 0.3681 - headline_token_classes_loss: 7.4289 - val_loss: 10.2422 - val_output_headline_vector_loss: 0.0285 - val_headline_token_classes_loss: 10.2137\n",
      "Epoch 169/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.7275 - output_headline_vector_loss: 0.3666 - headline_token_classes_loss: 7.3608 - val_loss: 10.0288 - val_output_headline_vector_loss: 0.0321 - val_headline_token_classes_loss: 9.9968\n",
      "Epoch 170/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.6878 - output_headline_vector_loss: 0.3600 - headline_token_classes_loss: 7.3278 - val_loss: 10.0350 - val_output_headline_vector_loss: 0.0338 - val_headline_token_classes_loss: 10.0012\n",
      "Epoch 171/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.7273 - output_headline_vector_loss: 0.3612 - headline_token_classes_loss: 7.3660 - val_loss: 10.0858 - val_output_headline_vector_loss: 0.0342 - val_headline_token_classes_loss: 10.0516\n",
      "Epoch 172/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.6851 - output_headline_vector_loss: 0.3497 - headline_token_classes_loss: 7.3354 - val_loss: 10.1850 - val_output_headline_vector_loss: 0.0278 - val_headline_token_classes_loss: 10.1572\n",
      "Epoch 173/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.5827 - output_headline_vector_loss: 0.3553 - headline_token_classes_loss: 7.2273 - val_loss: 10.2437 - val_output_headline_vector_loss: 0.0290 - val_headline_token_classes_loss: 10.2146\n",
      "Epoch 174/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.6283 - output_headline_vector_loss: 0.3505 - headline_token_classes_loss: 7.2778 - val_loss: 10.0042 - val_output_headline_vector_loss: 0.0320 - val_headline_token_classes_loss: 9.9722\n",
      "Epoch 175/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.5761 - output_headline_vector_loss: 0.3493 - headline_token_classes_loss: 7.2269 - val_loss: 9.9932 - val_output_headline_vector_loss: 0.0311 - val_headline_token_classes_loss: 9.9621\n",
      "Epoch 176/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5880 - output_headline_vector_loss: 0.3463 - headline_token_classes_loss: 7.2417 - val_loss: 10.0410 - val_output_headline_vector_loss: 0.0300 - val_headline_token_classes_loss: 10.0110\n",
      "Epoch 177/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5674 - output_headline_vector_loss: 0.3387 - headline_token_classes_loss: 7.2287 - val_loss: 9.9643 - val_output_headline_vector_loss: 0.0295 - val_headline_token_classes_loss: 9.9348\n",
      "Epoch 178/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5441 - output_headline_vector_loss: 0.3396 - headline_token_classes_loss: 7.2045 - val_loss: 9.9937 - val_output_headline_vector_loss: 0.0287 - val_headline_token_classes_loss: 9.9650\n",
      "Epoch 179/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.5221 - output_headline_vector_loss: 0.3261 - headline_token_classes_loss: 7.1960 - val_loss: 9.6903 - val_output_headline_vector_loss: 0.0325 - val_headline_token_classes_loss: 9.6578\n",
      "Epoch 180/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.5715 - output_headline_vector_loss: 0.3268 - headline_token_classes_loss: 7.2447 - val_loss: 10.1397 - val_output_headline_vector_loss: 0.0306 - val_headline_token_classes_loss: 10.1091\n",
      "Epoch 181/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.4954 - output_headline_vector_loss: 0.3202 - headline_token_classes_loss: 7.1752 - val_loss: 10.0444 - val_output_headline_vector_loss: 0.0302 - val_headline_token_classes_loss: 10.0142\n",
      "Epoch 182/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.3867 - output_headline_vector_loss: 0.3339 - headline_token_classes_loss: 7.0528 - val_loss: 9.4911 - val_output_headline_vector_loss: 0.0373 - val_headline_token_classes_loss: 9.4538\n",
      "Epoch 183/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.4394 - output_headline_vector_loss: 0.3170 - headline_token_classes_loss: 7.1224 - val_loss: 10.1298 - val_output_headline_vector_loss: 0.0309 - val_headline_token_classes_loss: 10.0989\n",
      "Epoch 184/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.3691 - output_headline_vector_loss: 0.3261 - headline_token_classes_loss: 7.0429 - val_loss: 9.9690 - val_output_headline_vector_loss: 0.0301 - val_headline_token_classes_loss: 9.9389\n",
      "Epoch 185/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.4233 - output_headline_vector_loss: 0.3131 - headline_token_classes_loss: 7.1102 - val_loss: 9.9134 - val_output_headline_vector_loss: 0.0271 - val_headline_token_classes_loss: 9.8863\n",
      "Epoch 186/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.3959 - output_headline_vector_loss: 0.3226 - headline_token_classes_loss: 7.0733 - val_loss: 9.9033 - val_output_headline_vector_loss: 0.0264 - val_headline_token_classes_loss: 9.8769\n",
      "Epoch 187/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.3732 - output_headline_vector_loss: 0.3180 - headline_token_classes_loss: 7.0553 - val_loss: 9.8151 - val_output_headline_vector_loss: 0.0265 - val_headline_token_classes_loss: 9.7886\n",
      "Epoch 188/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.3001 - output_headline_vector_loss: 0.3072 - headline_token_classes_loss: 6.9929 - val_loss: 9.8625 - val_output_headline_vector_loss: 0.0273 - val_headline_token_classes_loss: 9.8352\n",
      "Epoch 189/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 7.2889 - output_headline_vector_loss: 0.3090 - headline_token_classes_loss: 6.9800 - val_loss: 9.8115 - val_output_headline_vector_loss: 0.0267 - val_headline_token_classes_loss: 9.7848\n",
      "Epoch 190/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.4130 - output_headline_vector_loss: 0.3094 - headline_token_classes_loss: 7.1036 - val_loss: 9.7886 - val_output_headline_vector_loss: 0.0262 - val_headline_token_classes_loss: 9.7624\n",
      "Epoch 191/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.2684 - output_headline_vector_loss: 0.3053 - headline_token_classes_loss: 6.9631 - val_loss: 9.8424 - val_output_headline_vector_loss: 0.0259 - val_headline_token_classes_loss: 9.8165\n",
      "Epoch 192/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.2072 - output_headline_vector_loss: 0.3002 - headline_token_classes_loss: 6.9070 - val_loss: 9.7625 - val_output_headline_vector_loss: 0.0250 - val_headline_token_classes_loss: 9.7374\n",
      "Epoch 193/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.2357 - output_headline_vector_loss: 0.2980 - headline_token_classes_loss: 6.9378 - val_loss: 9.7701 - val_output_headline_vector_loss: 0.0248 - val_headline_token_classes_loss: 9.7454\n",
      "Epoch 194/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.1376 - output_headline_vector_loss: 0.2962 - headline_token_classes_loss: 6.8414 - val_loss: 9.8245 - val_output_headline_vector_loss: 0.0256 - val_headline_token_classes_loss: 9.7990\n",
      "Epoch 195/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.2069 - output_headline_vector_loss: 0.2925 - headline_token_classes_loss: 6.9145 - val_loss: 9.8125 - val_output_headline_vector_loss: 0.0249 - val_headline_token_classes_loss: 9.7876\n",
      "Epoch 196/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.1201 - output_headline_vector_loss: 0.2937 - headline_token_classes_loss: 6.8264 - val_loss: 9.6488 - val_output_headline_vector_loss: 0.0234 - val_headline_token_classes_loss: 9.6254\n",
      "Epoch 197/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.1285 - output_headline_vector_loss: 0.2823 - headline_token_classes_loss: 6.8463 - val_loss: 9.7843 - val_output_headline_vector_loss: 0.0272 - val_headline_token_classes_loss: 9.7570\n",
      "Epoch 198/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.1997 - output_headline_vector_loss: 0.2729 - headline_token_classes_loss: 6.9268 - val_loss: 9.6565 - val_output_headline_vector_loss: 0.0275 - val_headline_token_classes_loss: 9.6291\n",
      "Epoch 199/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 7.0998 - output_headline_vector_loss: 0.2805 - headline_token_classes_loss: 6.8193 - val_loss: 9.6651 - val_output_headline_vector_loss: 0.0222 - val_headline_token_classes_loss: 9.6429\n",
      "Epoch 200/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.0778 - output_headline_vector_loss: 0.2795 - headline_token_classes_loss: 6.7982 - val_loss: 9.5859 - val_output_headline_vector_loss: 0.0288 - val_headline_token_classes_loss: 9.5571\n",
      "Epoch 201/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.0421 - output_headline_vector_loss: 0.2748 - headline_token_classes_loss: 6.7673 - val_loss: 9.6797 - val_output_headline_vector_loss: 0.0231 - val_headline_token_classes_loss: 9.6567\n",
      "Epoch 202/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 7.0426 - output_headline_vector_loss: 0.2750 - headline_token_classes_loss: 6.7676 - val_loss: 9.5598 - val_output_headline_vector_loss: 0.0218 - val_headline_token_classes_loss: 9.5380\n",
      "Epoch 203/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.9684 - output_headline_vector_loss: 0.2845 - headline_token_classes_loss: 6.6839 - val_loss: 9.4992 - val_output_headline_vector_loss: 0.0234 - val_headline_token_classes_loss: 9.4758\n",
      "Epoch 204/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.9202 - output_headline_vector_loss: 0.2737 - headline_token_classes_loss: 6.6464 - val_loss: 9.6034 - val_output_headline_vector_loss: 0.0234 - val_headline_token_classes_loss: 9.5801\n",
      "Epoch 205/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 6.9926 - output_headline_vector_loss: 0.2642 - headline_token_classes_loss: 6.7284 - val_loss: 9.6209 - val_output_headline_vector_loss: 0.0225 - val_headline_token_classes_loss: 9.5984\n",
      "Epoch 206/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.9018 - output_headline_vector_loss: 0.2626 - headline_token_classes_loss: 6.6392 - val_loss: 9.5932 - val_output_headline_vector_loss: 0.0220 - val_headline_token_classes_loss: 9.5712\n",
      "Epoch 207/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.9813 - output_headline_vector_loss: 0.2603 - headline_token_classes_loss: 6.7209 - val_loss: 9.3988 - val_output_headline_vector_loss: 0.0260 - val_headline_token_classes_loss: 9.3728\n",
      "Epoch 208/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.8801 - output_headline_vector_loss: 0.2595 - headline_token_classes_loss: 6.6206 - val_loss: 9.5893 - val_output_headline_vector_loss: 0.0211 - val_headline_token_classes_loss: 9.5681\n",
      "Epoch 209/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.8559 - output_headline_vector_loss: 0.2637 - headline_token_classes_loss: 6.5922 - val_loss: 9.5650 - val_output_headline_vector_loss: 0.0215 - val_headline_token_classes_loss: 9.5435\n",
      "Epoch 210/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.8752 - output_headline_vector_loss: 0.2601 - headline_token_classes_loss: 6.6151 - val_loss: 9.4643 - val_output_headline_vector_loss: 0.0229 - val_headline_token_classes_loss: 9.4413\n",
      "Epoch 211/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.7880 - output_headline_vector_loss: 0.2527 - headline_token_classes_loss: 6.5352 - val_loss: 9.2642 - val_output_headline_vector_loss: 0.0217 - val_headline_token_classes_loss: 9.2425\n",
      "Epoch 212/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.8815 - output_headline_vector_loss: 0.2509 - headline_token_classes_loss: 6.6306 - val_loss: 9.5375 - val_output_headline_vector_loss: 0.0216 - val_headline_token_classes_loss: 9.5159\n",
      "Epoch 213/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.8315 - output_headline_vector_loss: 0.2476 - headline_token_classes_loss: 6.5839 - val_loss: 9.4087 - val_output_headline_vector_loss: 0.0255 - val_headline_token_classes_loss: 9.3832\n",
      "Epoch 214/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.7182 - output_headline_vector_loss: 0.2513 - headline_token_classes_loss: 6.4669 - val_loss: 9.3771 - val_output_headline_vector_loss: 0.0203 - val_headline_token_classes_loss: 9.3568\n",
      "Epoch 215/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.6769 - output_headline_vector_loss: 0.2483 - headline_token_classes_loss: 6.4286 - val_loss: 9.2197 - val_output_headline_vector_loss: 0.0237 - val_headline_token_classes_loss: 9.1961\n",
      "Epoch 216/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.7078 - output_headline_vector_loss: 0.2495 - headline_token_classes_loss: 6.4583 - val_loss: 9.3941 - val_output_headline_vector_loss: 0.0194 - val_headline_token_classes_loss: 9.3747\n",
      "Epoch 217/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.6726 - output_headline_vector_loss: 0.2353 - headline_token_classes_loss: 6.4374 - val_loss: 9.4209 - val_output_headline_vector_loss: 0.0201 - val_headline_token_classes_loss: 9.4008\n",
      "Epoch 218/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.6099 - output_headline_vector_loss: 0.2429 - headline_token_classes_loss: 6.3671 - val_loss: 9.3293 - val_output_headline_vector_loss: 0.0190 - val_headline_token_classes_loss: 9.3102\n",
      "Epoch 219/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.6046 - output_headline_vector_loss: 0.2306 - headline_token_classes_loss: 6.3740 - val_loss: 9.2600 - val_output_headline_vector_loss: 0.0238 - val_headline_token_classes_loss: 9.2362\n",
      "Epoch 220/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 6.5925 - output_headline_vector_loss: 0.2340 - headline_token_classes_loss: 6.3585 - val_loss: 9.3219 - val_output_headline_vector_loss: 0.0242 - val_headline_token_classes_loss: 9.2977\n",
      "Epoch 221/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.6378 - output_headline_vector_loss: 0.2333 - headline_token_classes_loss: 6.4045 - val_loss: 9.4012 - val_output_headline_vector_loss: 0.0188 - val_headline_token_classes_loss: 9.3825\n",
      "Epoch 222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.6188 - output_headline_vector_loss: 0.2328 - headline_token_classes_loss: 6.3860 - val_loss: 9.1065 - val_output_headline_vector_loss: 0.0211 - val_headline_token_classes_loss: 9.0854\n",
      "Epoch 223/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.5164 - output_headline_vector_loss: 0.2334 - headline_token_classes_loss: 6.2830 - val_loss: 9.3428 - val_output_headline_vector_loss: 0.0192 - val_headline_token_classes_loss: 9.3236\n",
      "Epoch 224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.5306 - output_headline_vector_loss: 0.2235 - headline_token_classes_loss: 6.3071 - val_loss: 9.4083 - val_output_headline_vector_loss: 0.0197 - val_headline_token_classes_loss: 9.3886\n",
      "Epoch 225/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.4777 - output_headline_vector_loss: 0.2246 - headline_token_classes_loss: 6.2531 - val_loss: 9.1502 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 9.1326\n",
      "Epoch 226/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.5076 - output_headline_vector_loss: 0.2201 - headline_token_classes_loss: 6.2875 - val_loss: 9.2470 - val_output_headline_vector_loss: 0.0195 - val_headline_token_classes_loss: 9.2275\n",
      "Epoch 227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.4756 - output_headline_vector_loss: 0.2171 - headline_token_classes_loss: 6.2586 - val_loss: 9.2652 - val_output_headline_vector_loss: 0.0168 - val_headline_token_classes_loss: 9.2483\n",
      "Epoch 228/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.4112 - output_headline_vector_loss: 0.2143 - headline_token_classes_loss: 6.1969 - val_loss: 9.0599 - val_output_headline_vector_loss: 0.0191 - val_headline_token_classes_loss: 9.0408\n",
      "Epoch 229/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.4482 - output_headline_vector_loss: 0.2200 - headline_token_classes_loss: 6.2282 - val_loss: 9.3226 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 9.3047\n",
      "Epoch 230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.3801 - output_headline_vector_loss: 0.2180 - headline_token_classes_loss: 6.1621 - val_loss: 9.2492 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 9.2309\n",
      "Epoch 231/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.3120 - output_headline_vector_loss: 0.2105 - headline_token_classes_loss: 6.1015 - val_loss: 9.3566 - val_output_headline_vector_loss: 0.0206 - val_headline_token_classes_loss: 9.3359\n",
      "Epoch 232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.3596 - output_headline_vector_loss: 0.2129 - headline_token_classes_loss: 6.1466 - val_loss: 9.0181 - val_output_headline_vector_loss: 0.0241 - val_headline_token_classes_loss: 8.9941\n",
      "Epoch 233/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.3042 - output_headline_vector_loss: 0.2052 - headline_token_classes_loss: 6.0990 - val_loss: 8.9294 - val_output_headline_vector_loss: 0.0218 - val_headline_token_classes_loss: 8.9076\n",
      "Epoch 234/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.3281 - output_headline_vector_loss: 0.2063 - headline_token_classes_loss: 6.1217 - val_loss: 9.2879 - val_output_headline_vector_loss: 0.0178 - val_headline_token_classes_loss: 9.2701\n",
      "Epoch 235/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.2367 - output_headline_vector_loss: 0.2071 - headline_token_classes_loss: 6.0296 - val_loss: 9.1491 - val_output_headline_vector_loss: 0.0204 - val_headline_token_classes_loss: 9.1287\n",
      "Epoch 236/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.2606 - output_headline_vector_loss: 0.2095 - headline_token_classes_loss: 6.0511 - val_loss: 9.2070 - val_output_headline_vector_loss: 0.0190 - val_headline_token_classes_loss: 9.1880\n",
      "Epoch 237/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.2624 - output_headline_vector_loss: 0.2028 - headline_token_classes_loss: 6.0597 - val_loss: 9.1816 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 9.1635\n",
      "Epoch 238/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.1756 - output_headline_vector_loss: 0.2046 - headline_token_classes_loss: 5.9710 - val_loss: 9.0218 - val_output_headline_vector_loss: 0.0167 - val_headline_token_classes_loss: 9.0051\n",
      "Epoch 239/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.1847 - output_headline_vector_loss: 0.1954 - headline_token_classes_loss: 5.9893 - val_loss: 8.9665 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 8.9493\n",
      "Epoch 240/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.0919 - output_headline_vector_loss: 0.1994 - headline_token_classes_loss: 5.8924 - val_loss: 9.2210 - val_output_headline_vector_loss: 0.0197 - val_headline_token_classes_loss: 9.2013\n",
      "Epoch 241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.1385 - output_headline_vector_loss: 0.1945 - headline_token_classes_loss: 5.9440 - val_loss: 9.0273 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 9.0103\n",
      "Epoch 242/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.0871 - output_headline_vector_loss: 0.1910 - headline_token_classes_loss: 5.8961 - val_loss: 9.1170 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 9.1001\n",
      "Epoch 243/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.2080 - output_headline_vector_loss: 0.1898 - headline_token_classes_loss: 6.0183 - val_loss: 8.7425 - val_output_headline_vector_loss: 0.0244 - val_headline_token_classes_loss: 8.7182\n",
      "Epoch 244/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.0751 - output_headline_vector_loss: 0.1934 - headline_token_classes_loss: 5.8817 - val_loss: 8.8754 - val_output_headline_vector_loss: 0.0174 - val_headline_token_classes_loss: 8.8580\n",
      "Epoch 245/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.9754 - output_headline_vector_loss: 0.1855 - headline_token_classes_loss: 5.7899 - val_loss: 8.6943 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 8.6763\n",
      "Epoch 246/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.9825 - output_headline_vector_loss: 0.1855 - headline_token_classes_loss: 5.7970 - val_loss: 8.9295 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 8.9119\n",
      "Epoch 247/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.0891 - output_headline_vector_loss: 0.1960 - headline_token_classes_loss: 5.8931 - val_loss: 8.8166 - val_output_headline_vector_loss: 0.0175 - val_headline_token_classes_loss: 8.7991\n",
      "Epoch 248/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 6.0767 - output_headline_vector_loss: 0.1800 - headline_token_classes_loss: 5.8966 - val_loss: 8.8819 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 8.8656\n",
      "Epoch 249/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 6.1162 - output_headline_vector_loss: 0.1795 - headline_token_classes_loss: 5.9367 - val_loss: 8.9194 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 8.9032\n",
      "Epoch 250/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.9688 - output_headline_vector_loss: 0.1819 - headline_token_classes_loss: 5.7868 - val_loss: 8.2079 - val_output_headline_vector_loss: 0.0287 - val_headline_token_classes_loss: 8.1792\n",
      "Epoch 251/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.9468 - output_headline_vector_loss: 0.1832 - headline_token_classes_loss: 5.7635 - val_loss: 8.6859 - val_output_headline_vector_loss: 0.0246 - val_headline_token_classes_loss: 8.6613\n",
      "Epoch 252/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.8902 - output_headline_vector_loss: 0.1759 - headline_token_classes_loss: 5.7143 - val_loss: 8.6633 - val_output_headline_vector_loss: 0.0224 - val_headline_token_classes_loss: 8.6408\n",
      "Epoch 253/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.8781 - output_headline_vector_loss: 0.1704 - headline_token_classes_loss: 5.7077 - val_loss: 8.6901 - val_output_headline_vector_loss: 0.0217 - val_headline_token_classes_loss: 8.6684\n",
      "Epoch 254/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.8131 - output_headline_vector_loss: 0.1734 - headline_token_classes_loss: 5.6397 - val_loss: 8.6592 - val_output_headline_vector_loss: 0.0210 - val_headline_token_classes_loss: 8.6382\n",
      "Epoch 255/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.9134 - output_headline_vector_loss: 0.1715 - headline_token_classes_loss: 5.7419 - val_loss: 8.6342 - val_output_headline_vector_loss: 0.0207 - val_headline_token_classes_loss: 8.6134\n",
      "Epoch 256/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.9605 - output_headline_vector_loss: 0.1675 - headline_token_classes_loss: 5.7929 - val_loss: 8.5193 - val_output_headline_vector_loss: 0.0196 - val_headline_token_classes_loss: 8.4998\n",
      "Epoch 257/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.8936 - output_headline_vector_loss: 0.1700 - headline_token_classes_loss: 5.7236 - val_loss: 8.6152 - val_output_headline_vector_loss: 0.0191 - val_headline_token_classes_loss: 8.5961\n",
      "Epoch 258/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.8193 - output_headline_vector_loss: 0.1681 - headline_token_classes_loss: 5.6512 - val_loss: 8.6137 - val_output_headline_vector_loss: 0.0188 - val_headline_token_classes_loss: 8.5949\n",
      "Epoch 259/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.7837 - output_headline_vector_loss: 0.1672 - headline_token_classes_loss: 5.6165 - val_loss: 8.5009 - val_output_headline_vector_loss: 0.0220 - val_headline_token_classes_loss: 8.4789\n",
      "Epoch 260/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.7549 - output_headline_vector_loss: 0.1650 - headline_token_classes_loss: 5.5899 - val_loss: 8.5528 - val_output_headline_vector_loss: 0.0184 - val_headline_token_classes_loss: 8.5344\n",
      "Epoch 261/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.7096 - output_headline_vector_loss: 0.1645 - headline_token_classes_loss: 5.5451 - val_loss: 8.6537 - val_output_headline_vector_loss: 0.0213 - val_headline_token_classes_loss: 8.6324\n",
      "Epoch 262/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.7910 - output_headline_vector_loss: 0.1635 - headline_token_classes_loss: 5.6275 - val_loss: 8.5234 - val_output_headline_vector_loss: 0.0226 - val_headline_token_classes_loss: 8.5008\n",
      "Epoch 263/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.7376 - output_headline_vector_loss: 0.1624 - headline_token_classes_loss: 5.5751 - val_loss: 8.3823 - val_output_headline_vector_loss: 0.0186 - val_headline_token_classes_loss: 8.3637\n",
      "Epoch 264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6819 - output_headline_vector_loss: 0.1562 - headline_token_classes_loss: 5.5256 - val_loss: 8.1966 - val_output_headline_vector_loss: 0.0252 - val_headline_token_classes_loss: 8.1714\n",
      "Epoch 265/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6638 - output_headline_vector_loss: 0.1549 - headline_token_classes_loss: 5.5089 - val_loss: 8.5078 - val_output_headline_vector_loss: 0.0197 - val_headline_token_classes_loss: 8.4881\n",
      "Epoch 266/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5358 - output_headline_vector_loss: 0.1586 - headline_token_classes_loss: 5.3771 - val_loss: 8.6203 - val_output_headline_vector_loss: 0.0198 - val_headline_token_classes_loss: 8.6004\n",
      "Epoch 267/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.7240 - output_headline_vector_loss: 0.1537 - headline_token_classes_loss: 5.5704 - val_loss: 8.3073 - val_output_headline_vector_loss: 0.0214 - val_headline_token_classes_loss: 8.2859\n",
      "Epoch 268/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.6835 - output_headline_vector_loss: 0.1604 - headline_token_classes_loss: 5.5231 - val_loss: 8.5122 - val_output_headline_vector_loss: 0.0186 - val_headline_token_classes_loss: 8.4936\n",
      "Epoch 269/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.6426 - output_headline_vector_loss: 0.1557 - headline_token_classes_loss: 5.4869 - val_loss: 8.4640 - val_output_headline_vector_loss: 0.0187 - val_headline_token_classes_loss: 8.4453\n",
      "Epoch 270/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.5014 - output_headline_vector_loss: 0.1502 - headline_token_classes_loss: 5.3512 - val_loss: 8.4990 - val_output_headline_vector_loss: 0.0200 - val_headline_token_classes_loss: 8.4789\n",
      "Epoch 271/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 5.5340 - output_headline_vector_loss: 0.1511 - headline_token_classes_loss: 5.3829 - val_loss: 8.5600 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 8.5418\n",
      "Epoch 272/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.4838 - output_headline_vector_loss: 0.1474 - headline_token_classes_loss: 5.3364 - val_loss: 8.5750 - val_output_headline_vector_loss: 0.0184 - val_headline_token_classes_loss: 8.5565\n",
      "Epoch 273/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.5582 - output_headline_vector_loss: 0.1417 - headline_token_classes_loss: 5.4166 - val_loss: 8.4409 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 8.4250\n",
      "Epoch 274/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.4889 - output_headline_vector_loss: 0.1416 - headline_token_classes_loss: 5.3474 - val_loss: 8.4038 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 8.3889\n",
      "Epoch 275/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.4347 - output_headline_vector_loss: 0.1444 - headline_token_classes_loss: 5.2903 - val_loss: 8.3250 - val_output_headline_vector_loss: 0.0187 - val_headline_token_classes_loss: 8.3063\n",
      "Epoch 276/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.5081 - output_headline_vector_loss: 0.1396 - headline_token_classes_loss: 5.3685 - val_loss: 8.4252 - val_output_headline_vector_loss: 0.0164 - val_headline_token_classes_loss: 8.4087\n",
      "Epoch 277/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3815 - output_headline_vector_loss: 0.1403 - headline_token_classes_loss: 5.2412 - val_loss: 8.5605 - val_output_headline_vector_loss: 0.0173 - val_headline_token_classes_loss: 8.5432\n",
      "Epoch 278/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.4729 - output_headline_vector_loss: 0.1367 - headline_token_classes_loss: 5.3362 - val_loss: 8.3602 - val_output_headline_vector_loss: 0.0156 - val_headline_token_classes_loss: 8.3446\n",
      "Epoch 279/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.4674 - output_headline_vector_loss: 0.1393 - headline_token_classes_loss: 5.3280 - val_loss: 8.4283 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 8.4130\n",
      "Epoch 280/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.3701 - output_headline_vector_loss: 0.1431 - headline_token_classes_loss: 5.2271 - val_loss: 8.5124 - val_output_headline_vector_loss: 0.0166 - val_headline_token_classes_loss: 8.4958\n",
      "Epoch 281/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.4004 - output_headline_vector_loss: 0.1341 - headline_token_classes_loss: 5.2662 - val_loss: 8.5031 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 8.4868\n",
      "Epoch 282/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 5.3044 - output_headline_vector_loss: 0.1356 - headline_token_classes_loss: 5.1688 - val_loss: 8.4303 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 8.4150\n",
      "Epoch 283/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.3569 - output_headline_vector_loss: 0.1319 - headline_token_classes_loss: 5.2250 - val_loss: 8.2283 - val_output_headline_vector_loss: 0.0189 - val_headline_token_classes_loss: 8.2093\n",
      "Epoch 284/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.4128 - output_headline_vector_loss: 0.1275 - headline_token_classes_loss: 5.2854 - val_loss: 8.3888 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 8.3735\n",
      "Epoch 285/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.3259 - output_headline_vector_loss: 0.1343 - headline_token_classes_loss: 5.1916 - val_loss: 8.4655 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 8.4507\n",
      "Epoch 286/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.3767 - output_headline_vector_loss: 0.1291 - headline_token_classes_loss: 5.2475 - val_loss: 8.2900 - val_output_headline_vector_loss: 0.0204 - val_headline_token_classes_loss: 8.2696\n",
      "Epoch 287/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.3297 - output_headline_vector_loss: 0.1279 - headline_token_classes_loss: 5.2018 - val_loss: 8.2881 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 8.2737\n",
      "Epoch 288/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.2316 - output_headline_vector_loss: 0.1236 - headline_token_classes_loss: 5.1080 - val_loss: 8.1025 - val_output_headline_vector_loss: 0.0184 - val_headline_token_classes_loss: 8.0840\n",
      "Epoch 289/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1667 - output_headline_vector_loss: 0.1294 - headline_token_classes_loss: 5.0373 - val_loss: 8.0937 - val_output_headline_vector_loss: 0.0175 - val_headline_token_classes_loss: 8.0761\n",
      "Epoch 290/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.1477 - output_headline_vector_loss: 0.1288 - headline_token_classes_loss: 5.0189 - val_loss: 8.1970 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 8.1834\n",
      "Epoch 291/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.1892 - output_headline_vector_loss: 0.1183 - headline_token_classes_loss: 5.0709 - val_loss: 8.2649 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 8.2511\n",
      "Epoch 292/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1481 - output_headline_vector_loss: 0.1281 - headline_token_classes_loss: 5.0200 - val_loss: 8.3098 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 8.2948\n",
      "Epoch 293/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 5.0812 - output_headline_vector_loss: 0.1224 - headline_token_classes_loss: 4.9588 - val_loss: 8.2640 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 8.2501\n",
      "Epoch 294/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0875 - output_headline_vector_loss: 0.1223 - headline_token_classes_loss: 4.9651 - val_loss: 8.1889 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 8.1739\n",
      "Epoch 295/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.1864 - output_headline_vector_loss: 0.1196 - headline_token_classes_loss: 5.0668 - val_loss: 7.9515 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 7.9339\n",
      "Epoch 296/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.1298 - output_headline_vector_loss: 0.1166 - headline_token_classes_loss: 5.0132 - val_loss: 7.8013 - val_output_headline_vector_loss: 0.0157 - val_headline_token_classes_loss: 7.7855\n",
      "Epoch 297/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1663 - output_headline_vector_loss: 0.1198 - headline_token_classes_loss: 5.0466 - val_loss: 8.2852 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 8.2709\n",
      "Epoch 298/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 5.0779 - output_headline_vector_loss: 0.1195 - headline_token_classes_loss: 4.9584 - val_loss: 8.1332 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 8.1208\n",
      "Epoch 299/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0109 - output_headline_vector_loss: 0.1155 - headline_token_classes_loss: 4.8955 - val_loss: 8.2721 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 8.2572\n",
      "Epoch 300/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.1071 - output_headline_vector_loss: 0.1124 - headline_token_classes_loss: 4.9947 - val_loss: 8.1433 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 8.1301\n",
      "Epoch 301/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0771 - output_headline_vector_loss: 0.1075 - headline_token_classes_loss: 4.9696 - val_loss: 8.1254 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 8.1112\n",
      "Epoch 302/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0670 - output_headline_vector_loss: 0.1183 - headline_token_classes_loss: 4.9487 - val_loss: 8.1876 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 8.1739\n",
      "Epoch 303/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9817 - output_headline_vector_loss: 0.1074 - headline_token_classes_loss: 4.8743 - val_loss: 8.0716 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 8.0563\n",
      "Epoch 304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9979 - output_headline_vector_loss: 0.1110 - headline_token_classes_loss: 4.8869 - val_loss: 7.9460 - val_output_headline_vector_loss: 0.0179 - val_headline_token_classes_loss: 7.9282\n",
      "Epoch 305/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9925 - output_headline_vector_loss: 0.1064 - headline_token_classes_loss: 4.8861 - val_loss: 7.9113 - val_output_headline_vector_loss: 0.0174 - val_headline_token_classes_loss: 7.8939\n",
      "Epoch 306/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 5.0089 - output_headline_vector_loss: 0.1061 - headline_token_classes_loss: 4.9027 - val_loss: 8.0561 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 8.0428\n",
      "Epoch 307/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9932 - output_headline_vector_loss: 0.1096 - headline_token_classes_loss: 4.8836 - val_loss: 7.7866 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 7.7703\n",
      "Epoch 308/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.8799 - output_headline_vector_loss: 0.1088 - headline_token_classes_loss: 4.7711 - val_loss: 7.9502 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 7.9367\n",
      "Epoch 309/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9720 - output_headline_vector_loss: 0.1062 - headline_token_classes_loss: 4.8658 - val_loss: 7.8929 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 7.8784\n",
      "Epoch 310/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9223 - output_headline_vector_loss: 0.1054 - headline_token_classes_loss: 4.8169 - val_loss: 7.9747 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 7.9611\n",
      "Epoch 311/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8579 - output_headline_vector_loss: 0.1077 - headline_token_classes_loss: 4.7502 - val_loss: 7.9062 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 7.8911\n",
      "Epoch 312/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.9496 - output_headline_vector_loss: 0.1029 - headline_token_classes_loss: 4.8467 - val_loss: 7.9902 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 7.9762\n",
      "Epoch 313/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8702 - output_headline_vector_loss: 0.1004 - headline_token_classes_loss: 4.7697 - val_loss: 7.7138 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 7.7009\n",
      "Epoch 314/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.9156 - output_headline_vector_loss: 0.1018 - headline_token_classes_loss: 4.8137 - val_loss: 7.8613 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 7.8501\n",
      "Epoch 315/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8722 - output_headline_vector_loss: 0.0978 - headline_token_classes_loss: 4.7744 - val_loss: 7.9635 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 7.9499\n",
      "Epoch 316/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7506 - output_headline_vector_loss: 0.0966 - headline_token_classes_loss: 4.6540 - val_loss: 7.9596 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 7.9457\n",
      "Epoch 317/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8014 - output_headline_vector_loss: 0.1000 - headline_token_classes_loss: 4.7014 - val_loss: 7.8260 - val_output_headline_vector_loss: 0.0171 - val_headline_token_classes_loss: 7.8089\n",
      "Epoch 318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8593 - output_headline_vector_loss: 0.0967 - headline_token_classes_loss: 4.7626 - val_loss: 7.7518 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 7.7342\n",
      "Epoch 319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.8253 - output_headline_vector_loss: 0.0942 - headline_token_classes_loss: 4.7311 - val_loss: 7.7839 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 7.7713\n",
      "Epoch 320/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7543 - output_headline_vector_loss: 0.0951 - headline_token_classes_loss: 4.6592 - val_loss: 7.6461 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 7.6308\n",
      "Epoch 321/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7194 - output_headline_vector_loss: 0.0919 - headline_token_classes_loss: 4.6275 - val_loss: 7.9080 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 7.8944\n",
      "Epoch 322/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 4.7648 - output_headline_vector_loss: 0.0910 - headline_token_classes_loss: 4.6738 - val_loss: 7.8152 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 7.8038\n",
      "Epoch 323/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.6880 - output_headline_vector_loss: 0.0970 - headline_token_classes_loss: 4.5910 - val_loss: 7.7385 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 7.7257\n",
      "Epoch 324/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.6786 - output_headline_vector_loss: 0.0867 - headline_token_classes_loss: 4.5919 - val_loss: 7.8308 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 7.8166\n",
      "Epoch 325/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.7968 - output_headline_vector_loss: 0.0884 - headline_token_classes_loss: 4.7084 - val_loss: 7.7924 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 7.7792\n",
      "Epoch 326/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.7701 - output_headline_vector_loss: 0.0882 - headline_token_classes_loss: 4.6819 - val_loss: 7.3904 - val_output_headline_vector_loss: 0.0202 - val_headline_token_classes_loss: 7.3702\n",
      "Epoch 327/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.7132 - output_headline_vector_loss: 0.0934 - headline_token_classes_loss: 4.6198 - val_loss: 7.5385 - val_output_headline_vector_loss: 0.0160 - val_headline_token_classes_loss: 7.5225\n",
      "Epoch 328/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.7379 - output_headline_vector_loss: 0.0869 - headline_token_classes_loss: 4.6511 - val_loss: 7.7087 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 7.6959\n",
      "Epoch 329/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6203 - output_headline_vector_loss: 0.0874 - headline_token_classes_loss: 4.5329 - val_loss: 7.5359 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 7.5197\n",
      "Epoch 330/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.7130 - output_headline_vector_loss: 0.0866 - headline_token_classes_loss: 4.6264 - val_loss: 7.6735 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 7.6595\n",
      "Epoch 331/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.6485 - output_headline_vector_loss: 0.0850 - headline_token_classes_loss: 4.5635 - val_loss: 7.7442 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 7.7318\n",
      "Epoch 332/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5883 - output_headline_vector_loss: 0.0875 - headline_token_classes_loss: 4.5008 - val_loss: 7.3241 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 7.3069\n",
      "Epoch 333/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5154 - output_headline_vector_loss: 0.0870 - headline_token_classes_loss: 4.4284 - val_loss: 7.3535 - val_output_headline_vector_loss: 0.0178 - val_headline_token_classes_loss: 7.3357\n",
      "Epoch 334/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5946 - output_headline_vector_loss: 0.0850 - headline_token_classes_loss: 4.5096 - val_loss: 7.5127 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 7.5000\n",
      "Epoch 335/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4002 - output_headline_vector_loss: 0.0819 - headline_token_classes_loss: 4.3183 - val_loss: 7.6047 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 7.5923\n",
      "Epoch 336/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5206 - output_headline_vector_loss: 0.0795 - headline_token_classes_loss: 4.4411 - val_loss: 7.5912 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 7.5771\n",
      "Epoch 337/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4614 - output_headline_vector_loss: 0.0834 - headline_token_classes_loss: 4.3780 - val_loss: 7.5869 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 7.5740\n",
      "Epoch 338/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6577 - output_headline_vector_loss: 0.0786 - headline_token_classes_loss: 4.5791 - val_loss: 7.6673 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 7.6545\n",
      "Epoch 339/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4635 - output_headline_vector_loss: 0.0836 - headline_token_classes_loss: 4.3799 - val_loss: 7.5920 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 7.5803\n",
      "Epoch 340/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5421 - output_headline_vector_loss: 0.0777 - headline_token_classes_loss: 4.4644 - val_loss: 7.5959 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 7.5844\n",
      "Epoch 341/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4931 - output_headline_vector_loss: 0.0780 - headline_token_classes_loss: 4.4151 - val_loss: 7.3883 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 7.3753\n",
      "Epoch 342/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4263 - output_headline_vector_loss: 0.0777 - headline_token_classes_loss: 4.3486 - val_loss: 7.5381 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 7.5259\n",
      "Epoch 343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6015 - output_headline_vector_loss: 0.0784 - headline_token_classes_loss: 4.5231 - val_loss: 7.3173 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 7.3027\n",
      "Epoch 344/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 4.3506 - output_headline_vector_loss: 0.0815 - headline_token_classes_loss: 4.2691 - val_loss: 7.6011 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 7.5880\n",
      "Epoch 345/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.5467 - output_headline_vector_loss: 0.0730 - headline_token_classes_loss: 4.4737 - val_loss: 7.5993 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 7.5869\n",
      "Epoch 346/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.6383 - output_headline_vector_loss: 0.0772 - headline_token_classes_loss: 4.5611 - val_loss: 7.4002 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 7.3866\n",
      "Epoch 347/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4971 - output_headline_vector_loss: 0.0759 - headline_token_classes_loss: 4.4211 - val_loss: 6.9798 - val_output_headline_vector_loss: 0.0222 - val_headline_token_classes_loss: 6.9576\n",
      "Epoch 348/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3906 - output_headline_vector_loss: 0.0748 - headline_token_classes_loss: 4.3157 - val_loss: 7.6993 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 7.6852\n",
      "Epoch 349/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3011 - output_headline_vector_loss: 0.0740 - headline_token_classes_loss: 4.2271 - val_loss: 7.4485 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 7.4373\n",
      "Epoch 350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4997 - output_headline_vector_loss: 0.0717 - headline_token_classes_loss: 4.4280 - val_loss: 7.5491 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 7.5354\n",
      "Epoch 351/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5137 - output_headline_vector_loss: 0.0683 - headline_token_classes_loss: 4.4454 - val_loss: 7.5515 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 7.5393\n",
      "Epoch 352/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4909 - output_headline_vector_loss: 0.0741 - headline_token_classes_loss: 4.4168 - val_loss: 7.5353 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 7.5218\n",
      "Epoch 353/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.2683 - output_headline_vector_loss: 0.0710 - headline_token_classes_loss: 4.1974 - val_loss: 7.4203 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 7.4086\n",
      "Epoch 354/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4718 - output_headline_vector_loss: 0.0675 - headline_token_classes_loss: 4.4043 - val_loss: 7.5699 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 7.5563\n",
      "Epoch 355/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4122 - output_headline_vector_loss: 0.0668 - headline_token_classes_loss: 4.3453 - val_loss: 7.4090 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 7.3977\n",
      "Epoch 356/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3367 - output_headline_vector_loss: 0.0682 - headline_token_classes_loss: 4.2685 - val_loss: 7.4727 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 7.4602\n",
      "Epoch 357/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3909 - output_headline_vector_loss: 0.0679 - headline_token_classes_loss: 4.3230 - val_loss: 7.2399 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 7.2284\n",
      "Epoch 358/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3044 - output_headline_vector_loss: 0.0653 - headline_token_classes_loss: 4.2392 - val_loss: 7.3236 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 7.3112\n",
      "Epoch 359/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.5287 - output_headline_vector_loss: 0.0725 - headline_token_classes_loss: 4.4562 - val_loss: 7.3058 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 7.2937\n",
      "Epoch 360/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.3803 - output_headline_vector_loss: 0.0677 - headline_token_classes_loss: 4.3127 - val_loss: 7.1488 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 7.1379\n",
      "Epoch 361/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 4.5050 - output_headline_vector_loss: 0.0647 - headline_token_classes_loss: 4.4404 - val_loss: 7.3583 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 7.3461\n",
      "Epoch 362/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.4074 - output_headline_vector_loss: 0.0642 - headline_token_classes_loss: 4.3432 - val_loss: 7.1162 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 7.1009\n",
      "Epoch 363/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.3961 - output_headline_vector_loss: 0.0648 - headline_token_classes_loss: 4.3312 - val_loss: 7.2243 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 7.2118\n",
      "Epoch 364/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.4530 - output_headline_vector_loss: 0.0650 - headline_token_classes_loss: 4.3880 - val_loss: 7.3390 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 7.3263\n",
      "Epoch 365/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3091 - output_headline_vector_loss: 0.0671 - headline_token_classes_loss: 4.2420 - val_loss: 7.1563 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 7.1444\n",
      "Epoch 366/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2859 - output_headline_vector_loss: 0.0621 - headline_token_classes_loss: 4.2238 - val_loss: 7.3291 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 7.3141\n",
      "Epoch 367/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2003 - output_headline_vector_loss: 0.0657 - headline_token_classes_loss: 4.1346 - val_loss: 7.3649 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 7.3509\n",
      "Epoch 368/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.2079 - output_headline_vector_loss: 0.0637 - headline_token_classes_loss: 4.1442 - val_loss: 7.0939 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 7.0817\n",
      "Epoch 369/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3374 - output_headline_vector_loss: 0.0628 - headline_token_classes_loss: 4.2746 - val_loss: 6.9398 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 6.9250\n",
      "Epoch 370/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.4151 - output_headline_vector_loss: 0.0610 - headline_token_classes_loss: 4.3541 - val_loss: 7.0693 - val_output_headline_vector_loss: 0.0165 - val_headline_token_classes_loss: 7.0529\n",
      "Epoch 371/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3922 - output_headline_vector_loss: 0.0588 - headline_token_classes_loss: 4.3333 - val_loss: 7.0654 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 7.0541\n",
      "Epoch 372/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2806 - output_headline_vector_loss: 0.0603 - headline_token_classes_loss: 4.2203 - val_loss: 7.1561 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 7.1439\n",
      "Epoch 373/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3175 - output_headline_vector_loss: 0.0648 - headline_token_classes_loss: 4.2528 - val_loss: 7.0585 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 7.0463\n",
      "Epoch 374/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.2621 - output_headline_vector_loss: 0.0593 - headline_token_classes_loss: 4.2028 - val_loss: 6.9980 - val_output_headline_vector_loss: 0.0161 - val_headline_token_classes_loss: 6.9819\n",
      "Epoch 375/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.1546 - output_headline_vector_loss: 0.0602 - headline_token_classes_loss: 4.0944 - val_loss: 6.8740 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 6.8642\n",
      "Epoch 376/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.2054 - output_headline_vector_loss: 0.0590 - headline_token_classes_loss: 4.1463 - val_loss: 6.9446 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 6.9334\n",
      "Epoch 377/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.3037 - output_headline_vector_loss: 0.0594 - headline_token_classes_loss: 4.2443 - val_loss: 6.9447 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 6.9345\n",
      "Epoch 378/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.1535 - output_headline_vector_loss: 0.0570 - headline_token_classes_loss: 4.0964 - val_loss: 6.6199 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 6.6069\n",
      "Epoch 379/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3852 - output_headline_vector_loss: 0.0571 - headline_token_classes_loss: 4.3281 - val_loss: 6.5048 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 6.4918\n",
      "Epoch 380/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.2945 - output_headline_vector_loss: 0.0575 - headline_token_classes_loss: 4.2370 - val_loss: 6.5415 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 6.5290\n",
      "Epoch 381/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0695 - output_headline_vector_loss: 0.0627 - headline_token_classes_loss: 4.0068 - val_loss: 6.3794 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 6.3667\n",
      "Epoch 382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.1186 - output_headline_vector_loss: 0.0557 - headline_token_classes_loss: 4.0630 - val_loss: 6.3998 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 6.3873\n",
      "Epoch 383/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0946 - output_headline_vector_loss: 0.0532 - headline_token_classes_loss: 4.0414 - val_loss: 6.5160 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 6.5037\n",
      "Epoch 384/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0967 - output_headline_vector_loss: 0.0533 - headline_token_classes_loss: 4.0434 - val_loss: 6.2529 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 6.2416\n",
      "Epoch 385/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.1127 - output_headline_vector_loss: 0.0555 - headline_token_classes_loss: 4.0572 - val_loss: 6.3057 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 6.2877\n",
      "Epoch 386/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.3210 - output_headline_vector_loss: 0.0538 - headline_token_classes_loss: 4.2672 - val_loss: 6.4663 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 6.4520\n",
      "Epoch 387/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 4.0061 - output_headline_vector_loss: 0.0529 - headline_token_classes_loss: 3.9533 - val_loss: 6.4322 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 6.4200\n",
      "Epoch 388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9529 - output_headline_vector_loss: 0.0568 - headline_token_classes_loss: 3.8961 - val_loss: 7.0565 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 7.0407\n",
      "Epoch 389/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9830 - output_headline_vector_loss: 0.0551 - headline_token_classes_loss: 3.9278 - val_loss: 6.6795 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 6.6640\n",
      "Epoch 390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8909 - output_headline_vector_loss: 0.0528 - headline_token_classes_loss: 3.8381 - val_loss: 7.0420 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 7.0292\n",
      "Epoch 391/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 4.0235 - output_headline_vector_loss: 0.0532 - headline_token_classes_loss: 3.9703 - val_loss: 6.7990 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 6.7889\n",
      "Epoch 392/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.8702 - output_headline_vector_loss: 0.0549 - headline_token_classes_loss: 3.8153 - val_loss: 6.9817 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 6.9678\n",
      "Epoch 393/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8868 - output_headline_vector_loss: 0.0536 - headline_token_classes_loss: 3.8332 - val_loss: 6.5994 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 6.5867\n",
      "Epoch 394/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0712 - output_headline_vector_loss: 0.0494 - headline_token_classes_loss: 4.0218 - val_loss: 6.9072 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 6.8956\n",
      "Epoch 395/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9196 - output_headline_vector_loss: 0.0503 - headline_token_classes_loss: 3.8692 - val_loss: 7.0664 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 7.0545\n",
      "Epoch 396/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.8586 - output_headline_vector_loss: 0.0501 - headline_token_classes_loss: 3.8086 - val_loss: 6.9053 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 6.8944\n",
      "Epoch 397/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 3.8662 - output_headline_vector_loss: 0.0484 - headline_token_classes_loss: 3.8177 - val_loss: 6.9335 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 6.9208\n",
      "Epoch 398/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8679 - output_headline_vector_loss: 0.0510 - headline_token_classes_loss: 3.8169 - val_loss: 6.7605 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 6.7464\n",
      "Epoch 399/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.8025 - output_headline_vector_loss: 0.0520 - headline_token_classes_loss: 3.7505 - val_loss: 6.7531 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 6.7425\n",
      "Epoch 400/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9938 - output_headline_vector_loss: 0.0495 - headline_token_classes_loss: 3.9443 - val_loss: 6.9418 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 6.9307\n",
      "Epoch 401/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 4.0056 - output_headline_vector_loss: 0.0494 - headline_token_classes_loss: 3.9563 - val_loss: 6.9460 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 6.9343\n",
      "Epoch 402/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.8287 - output_headline_vector_loss: 0.0467 - headline_token_classes_loss: 3.7820 - val_loss: 6.7175 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 6.7032\n",
      "Epoch 403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7653 - output_headline_vector_loss: 0.0496 - headline_token_classes_loss: 3.7157 - val_loss: 6.6982 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 6.6878\n",
      "Epoch 404/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7856 - output_headline_vector_loss: 0.0494 - headline_token_classes_loss: 3.7363 - val_loss: 6.8140 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 6.8024\n",
      "Epoch 405/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7367 - output_headline_vector_loss: 0.0500 - headline_token_classes_loss: 3.6867 - val_loss: 6.5756 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 6.5660\n",
      "Epoch 406/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 3.7581 - output_headline_vector_loss: 0.0486 - headline_token_classes_loss: 3.7095 - val_loss: 6.8247 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 6.8123\n",
      "Epoch 407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9147 - output_headline_vector_loss: 0.0451 - headline_token_classes_loss: 3.8696 - val_loss: 6.8095 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 6.7989\n",
      "Epoch 408/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9046 - output_headline_vector_loss: 0.0433 - headline_token_classes_loss: 3.8612 - val_loss: 6.6408 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 6.6302\n",
      "Epoch 409/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6778 - output_headline_vector_loss: 0.0469 - headline_token_classes_loss: 3.6309 - val_loss: 6.4645 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 6.4511\n",
      "Epoch 410/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.9402 - output_headline_vector_loss: 0.0445 - headline_token_classes_loss: 3.8957 - val_loss: 6.6884 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 6.6767\n",
      "Epoch 411/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.8260 - output_headline_vector_loss: 0.0468 - headline_token_classes_loss: 3.7792 - val_loss: 6.5635 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 6.5492\n",
      "Epoch 412/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8621 - output_headline_vector_loss: 0.0419 - headline_token_classes_loss: 3.8202 - val_loss: 6.6716 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 6.6598\n",
      "Epoch 413/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8001 - output_headline_vector_loss: 0.0437 - headline_token_classes_loss: 3.7564 - val_loss: 6.5999 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 6.5894\n",
      "Epoch 414/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6894 - output_headline_vector_loss: 0.0443 - headline_token_classes_loss: 3.6451 - val_loss: 6.7361 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 6.7249\n",
      "Epoch 415/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.9350 - output_headline_vector_loss: 0.0441 - headline_token_classes_loss: 3.8908 - val_loss: 6.4133 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 6.3992\n",
      "Epoch 416/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.5848 - output_headline_vector_loss: 0.0456 - headline_token_classes_loss: 3.5392 - val_loss: 6.4451 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 6.4299\n",
      "Epoch 417/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6941 - output_headline_vector_loss: 0.0445 - headline_token_classes_loss: 3.6496 - val_loss: 6.6718 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 6.6579\n",
      "Epoch 418/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6663 - output_headline_vector_loss: 0.0418 - headline_token_classes_loss: 3.6245 - val_loss: 6.5344 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 6.5239\n",
      "Epoch 419/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.8733 - output_headline_vector_loss: 0.0398 - headline_token_classes_loss: 3.8334 - val_loss: 6.5739 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 6.5618\n",
      "Epoch 420/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 3.6732 - output_headline_vector_loss: 0.0413 - headline_token_classes_loss: 3.6320 - val_loss: 6.4984 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 6.4883\n",
      "Epoch 421/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7112 - output_headline_vector_loss: 0.0415 - headline_token_classes_loss: 3.6697 - val_loss: 6.2744 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 6.2637\n",
      "Epoch 422/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.8679 - output_headline_vector_loss: 0.0403 - headline_token_classes_loss: 3.8276 - val_loss: 6.6007 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 6.5897\n",
      "Epoch 423/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.6355 - output_headline_vector_loss: 0.0417 - headline_token_classes_loss: 3.5938 - val_loss: 6.4630 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 6.4524\n",
      "Epoch 424/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7879 - output_headline_vector_loss: 0.0401 - headline_token_classes_loss: 3.7478 - val_loss: 6.3931 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 6.3825\n",
      "Epoch 425/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6325 - output_headline_vector_loss: 0.0413 - headline_token_classes_loss: 3.5912 - val_loss: 6.2289 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 6.2182\n",
      "Epoch 426/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7071 - output_headline_vector_loss: 0.0382 - headline_token_classes_loss: 3.6689 - val_loss: 6.2455 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 6.2315\n",
      "Epoch 427/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6505 - output_headline_vector_loss: 0.0399 - headline_token_classes_loss: 3.6105 - val_loss: 6.4615 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 6.4504\n",
      "Epoch 428/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.6613 - output_headline_vector_loss: 0.0388 - headline_token_classes_loss: 3.6225 - val_loss: 6.5326 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 6.5210\n",
      "Epoch 429/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.8291 - output_headline_vector_loss: 0.0390 - headline_token_classes_loss: 3.7901 - val_loss: 5.9754 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 5.9667\n",
      "Epoch 430/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.7858 - output_headline_vector_loss: 0.0380 - headline_token_classes_loss: 3.7478 - val_loss: 6.0653 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 6.0563\n",
      "Epoch 431/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7827 - output_headline_vector_loss: 0.0378 - headline_token_classes_loss: 3.7449 - val_loss: 6.4458 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 6.4339\n",
      "Epoch 432/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6813 - output_headline_vector_loss: 0.0384 - headline_token_classes_loss: 3.6429 - val_loss: 6.4399 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 6.4291\n",
      "Epoch 433/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.7496 - output_headline_vector_loss: 0.0387 - headline_token_classes_loss: 3.7109 - val_loss: 6.4998 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 6.4869\n",
      "Epoch 434/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.5829 - output_headline_vector_loss: 0.0373 - headline_token_classes_loss: 3.5456 - val_loss: 6.0991 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 6.0808\n",
      "Epoch 435/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5967 - output_headline_vector_loss: 0.0368 - headline_token_classes_loss: 3.5599 - val_loss: 6.1854 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 6.1750\n",
      "Epoch 436/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 3.6336 - output_headline_vector_loss: 0.0361 - headline_token_classes_loss: 3.5975 - val_loss: 6.2254 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 6.2153\n",
      "Epoch 437/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5934 - output_headline_vector_loss: 0.0371 - headline_token_classes_loss: 3.5563 - val_loss: 5.9905 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 5.9808\n",
      "Epoch 438/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6692 - output_headline_vector_loss: 0.0378 - headline_token_classes_loss: 3.6314 - val_loss: 6.2629 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 6.2499\n",
      "Epoch 439/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5544 - output_headline_vector_loss: 0.0368 - headline_token_classes_loss: 3.5176 - val_loss: 6.0286 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 6.0175\n",
      "Epoch 440/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4564 - output_headline_vector_loss: 0.0343 - headline_token_classes_loss: 3.4220 - val_loss: 6.2469 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 6.2357\n",
      "Epoch 441/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6666 - output_headline_vector_loss: 0.0338 - headline_token_classes_loss: 3.6329 - val_loss: 6.3476 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 6.3323\n",
      "Epoch 442/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6075 - output_headline_vector_loss: 0.0329 - headline_token_classes_loss: 3.5746 - val_loss: 6.2207 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 6.2055\n",
      "Epoch 443/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5387 - output_headline_vector_loss: 0.0364 - headline_token_classes_loss: 3.5023 - val_loss: 6.0267 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 6.0126\n",
      "Epoch 444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6541 - output_headline_vector_loss: 0.0353 - headline_token_classes_loss: 3.6188 - val_loss: 5.9932 - val_output_headline_vector_loss: 0.0186 - val_headline_token_classes_loss: 5.9746\n",
      "Epoch 445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4893 - output_headline_vector_loss: 0.0332 - headline_token_classes_loss: 3.4561 - val_loss: 6.2952 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 6.2860\n",
      "Epoch 446/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.5372 - output_headline_vector_loss: 0.0335 - headline_token_classes_loss: 3.5036 - val_loss: 6.3921 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 6.3813\n",
      "Epoch 447/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6066 - output_headline_vector_loss: 0.0349 - headline_token_classes_loss: 3.5717 - val_loss: 6.4364 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 6.4244\n",
      "Epoch 448/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.7104 - output_headline_vector_loss: 0.0338 - headline_token_classes_loss: 3.6765 - val_loss: 6.4022 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 6.3902\n",
      "Epoch 449/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4357 - output_headline_vector_loss: 0.0323 - headline_token_classes_loss: 3.4035 - val_loss: 6.3707 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 6.3598\n",
      "Epoch 450/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.6862 - output_headline_vector_loss: 0.0323 - headline_token_classes_loss: 3.6538 - val_loss: 6.3546 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 6.3431\n",
      "Epoch 451/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.6588 - output_headline_vector_loss: 0.0327 - headline_token_classes_loss: 3.6261 - val_loss: 6.4975 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 6.4854\n",
      "Epoch 452/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.5308 - output_headline_vector_loss: 0.0333 - headline_token_classes_loss: 3.4975 - val_loss: 5.8345 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 5.8227\n",
      "Epoch 453/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.5888 - output_headline_vector_loss: 0.0322 - headline_token_classes_loss: 3.5566 - val_loss: 5.9549 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 5.9437\n",
      "Epoch 454/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.3642 - output_headline_vector_loss: 0.0337 - headline_token_classes_loss: 3.3305 - val_loss: 5.9171 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 5.9049\n",
      "Epoch 455/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4413 - output_headline_vector_loss: 0.0311 - headline_token_classes_loss: 3.4102 - val_loss: 5.8475 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 5.8360\n",
      "Epoch 456/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.4565 - output_headline_vector_loss: 0.0326 - headline_token_classes_loss: 3.4239 - val_loss: 5.3215 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 5.3116\n",
      "Epoch 457/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.3007 - output_headline_vector_loss: 0.0306 - headline_token_classes_loss: 3.2700 - val_loss: 5.6157 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 5.6050\n",
      "Epoch 458/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.2787 - output_headline_vector_loss: 0.0318 - headline_token_classes_loss: 3.2470 - val_loss: 5.6741 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 5.6633\n",
      "Epoch 459/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.3060 - output_headline_vector_loss: 0.0303 - headline_token_classes_loss: 3.2757 - val_loss: 5.6378 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 5.6223\n",
      "Epoch 460/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.2369 - output_headline_vector_loss: 0.0313 - headline_token_classes_loss: 3.2056 - val_loss: 5.4997 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 5.4904\n",
      "Epoch 461/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.2928 - output_headline_vector_loss: 0.0292 - headline_token_classes_loss: 3.2636 - val_loss: 5.3437 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 5.3345\n",
      "Epoch 462/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.3232 - output_headline_vector_loss: 0.0296 - headline_token_classes_loss: 3.2936 - val_loss: 5.7542 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 5.7415\n",
      "Epoch 463/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.3303 - output_headline_vector_loss: 0.0300 - headline_token_classes_loss: 3.3003 - val_loss: 5.4702 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 5.4555\n",
      "Epoch 464/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.2721 - output_headline_vector_loss: 0.0307 - headline_token_classes_loss: 3.2413 - val_loss: 5.3620 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 5.3478\n",
      "Epoch 465/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 3.4337 - output_headline_vector_loss: 0.0281 - headline_token_classes_loss: 3.4056 - val_loss: 5.4196 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 5.4093\n",
      "Epoch 466/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2975 - output_headline_vector_loss: 0.0293 - headline_token_classes_loss: 3.2682 - val_loss: 5.6593 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 5.6483\n",
      "Epoch 467/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.2925 - output_headline_vector_loss: 0.0288 - headline_token_classes_loss: 3.2637 - val_loss: 5.4528 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 5.4436\n",
      "Epoch 468/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 3.3480 - output_headline_vector_loss: 0.0291 - headline_token_classes_loss: 3.3190 - val_loss: 5.5080 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 5.4974\n",
      "Epoch 469/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4352 - output_headline_vector_loss: 0.0299 - headline_token_classes_loss: 3.4052 - val_loss: 5.7140 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 5.7025\n",
      "Epoch 470/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3691 - output_headline_vector_loss: 0.0298 - headline_token_classes_loss: 3.3393 - val_loss: 5.5640 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 5.5525\n",
      "Epoch 471/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.2795 - output_headline_vector_loss: 0.0279 - headline_token_classes_loss: 3.2515 - val_loss: 5.4091 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 5.3983\n",
      "Epoch 472/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.4022 - output_headline_vector_loss: 0.0264 - headline_token_classes_loss: 3.3758 - val_loss: 5.6168 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 5.6017\n",
      "Epoch 473/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 3.2826 - output_headline_vector_loss: 0.0289 - headline_token_classes_loss: 3.2537 - val_loss: 5.5658 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 5.5549\n",
      "Epoch 474/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 3.3222 - output_headline_vector_loss: 0.0276 - headline_token_classes_loss: 3.2947 - val_loss: 3.3629 - val_output_headline_vector_loss: 0.2103 - val_headline_token_classes_loss: 3.1525\n",
      "Epoch 475/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.9717 - output_headline_vector_loss: 0.0285 - headline_token_classes_loss: 2.9432 - val_loss: 3.5977 - val_output_headline_vector_loss: 0.0729 - val_headline_token_classes_loss: 3.5248\n",
      "Epoch 476/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7040 - output_headline_vector_loss: 0.0289 - headline_token_classes_loss: 2.6751 - val_loss: 3.3708 - val_output_headline_vector_loss: 0.0414 - val_headline_token_classes_loss: 3.3294\n",
      "Epoch 477/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6937 - output_headline_vector_loss: 0.0289 - headline_token_classes_loss: 2.6647 - val_loss: 3.9489 - val_output_headline_vector_loss: 0.0329 - val_headline_token_classes_loss: 3.9161\n",
      "Epoch 478/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7436 - output_headline_vector_loss: 0.0274 - headline_token_classes_loss: 2.7161 - val_loss: 3.8371 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 3.8200\n",
      "Epoch 479/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7401 - output_headline_vector_loss: 0.0267 - headline_token_classes_loss: 2.7135 - val_loss: 3.7768 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 3.7618\n",
      "Epoch 480/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7520 - output_headline_vector_loss: 0.0254 - headline_token_classes_loss: 2.7266 - val_loss: 3.7474 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 3.7332\n",
      "Epoch 481/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7659 - output_headline_vector_loss: 0.0276 - headline_token_classes_loss: 2.7383 - val_loss: 4.0426 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 4.0284\n",
      "Epoch 482/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7671 - output_headline_vector_loss: 0.0288 - headline_token_classes_loss: 2.7383 - val_loss: 3.8921 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 3.8772\n",
      "Epoch 483/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7424 - output_headline_vector_loss: 0.0252 - headline_token_classes_loss: 2.7171 - val_loss: 3.9069 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 3.8954\n",
      "Epoch 484/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.8324 - output_headline_vector_loss: 0.0251 - headline_token_classes_loss: 2.8073 - val_loss: 3.7152 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 3.7021\n",
      "Epoch 485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8335 - output_headline_vector_loss: 0.0249 - headline_token_classes_loss: 2.8087 - val_loss: 3.9676 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 3.9562\n",
      "Epoch 486/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7320 - output_headline_vector_loss: 0.0258 - headline_token_classes_loss: 2.7061 - val_loss: 4.0217 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 4.0097\n",
      "Epoch 487/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7818 - output_headline_vector_loss: 0.0245 - headline_token_classes_loss: 2.7573 - val_loss: 4.2275 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 4.2149\n",
      "Epoch 488/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8480 - output_headline_vector_loss: 0.0257 - headline_token_classes_loss: 2.8223 - val_loss: 3.9222 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 3.9079\n",
      "Epoch 489/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7013 - output_headline_vector_loss: 0.0250 - headline_token_classes_loss: 2.6763 - val_loss: 3.9223 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.9112\n",
      "Epoch 490/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.8252 - output_headline_vector_loss: 0.0243 - headline_token_classes_loss: 2.8009 - val_loss: 4.1778 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 4.1651\n",
      "Epoch 491/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7225 - output_headline_vector_loss: 0.0262 - headline_token_classes_loss: 2.6962 - val_loss: 4.1175 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 4.1057\n",
      "Epoch 492/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4991 - output_headline_vector_loss: 0.0273 - headline_token_classes_loss: 2.4717 - val_loss: 4.0458 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 4.0359\n",
      "Epoch 493/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6567 - output_headline_vector_loss: 0.0246 - headline_token_classes_loss: 2.6321 - val_loss: 4.0265 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 4.0121\n",
      "Epoch 494/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6764 - output_headline_vector_loss: 0.0240 - headline_token_classes_loss: 2.6525 - val_loss: 4.1427 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 4.1317\n",
      "Epoch 495/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7525 - output_headline_vector_loss: 0.0242 - headline_token_classes_loss: 2.7283 - val_loss: 4.3419 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 4.3298\n",
      "Epoch 496/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6935 - output_headline_vector_loss: 0.0253 - headline_token_classes_loss: 2.6683 - val_loss: 4.3454 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 4.3333\n",
      "Epoch 497/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.6604 - output_headline_vector_loss: 0.0244 - headline_token_classes_loss: 2.6360 - val_loss: 3.9432 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 3.9322\n",
      "Epoch 498/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5370 - output_headline_vector_loss: 0.0246 - headline_token_classes_loss: 2.5125 - val_loss: 4.1617 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 4.1499\n",
      "Epoch 499/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7153 - output_headline_vector_loss: 0.0217 - headline_token_classes_loss: 2.6936 - val_loss: 4.0591 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 4.0489\n",
      "Epoch 500/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6957 - output_headline_vector_loss: 0.0232 - headline_token_classes_loss: 2.6724 - val_loss: 4.0823 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 4.0716\n",
      "Epoch 501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7435 - output_headline_vector_loss: 0.0220 - headline_token_classes_loss: 2.7214 - val_loss: 3.9416 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.9312\n",
      "Epoch 502/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6743 - output_headline_vector_loss: 0.0229 - headline_token_classes_loss: 2.6515 - val_loss: 4.1771 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 4.1658\n",
      "Epoch 503/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6256 - output_headline_vector_loss: 0.0249 - headline_token_classes_loss: 2.6008 - val_loss: 4.0405 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 4.0299\n",
      "Epoch 504/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6648 - output_headline_vector_loss: 0.0245 - headline_token_classes_loss: 2.6403 - val_loss: 3.9659 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 3.9511\n",
      "Epoch 505/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5860 - output_headline_vector_loss: 0.0223 - headline_token_classes_loss: 2.5637 - val_loss: 4.2134 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 4.2018\n",
      "Epoch 506/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.6319 - output_headline_vector_loss: 0.0236 - headline_token_classes_loss: 2.6083 - val_loss: 4.2164 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 4.2037\n",
      "Epoch 507/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.7892 - output_headline_vector_loss: 0.0210 - headline_token_classes_loss: 2.7682 - val_loss: 3.9545 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.9439\n",
      "Epoch 508/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6666 - output_headline_vector_loss: 0.0223 - headline_token_classes_loss: 2.6443 - val_loss: 3.8721 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 3.8572\n",
      "Epoch 509/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5903 - output_headline_vector_loss: 0.0221 - headline_token_classes_loss: 2.5682 - val_loss: 4.0239 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 4.0137\n",
      "Epoch 510/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7034 - output_headline_vector_loss: 0.0243 - headline_token_classes_loss: 2.6791 - val_loss: 4.2341 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 4.2224\n",
      "Epoch 511/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6944 - output_headline_vector_loss: 0.0233 - headline_token_classes_loss: 2.6711 - val_loss: 3.8801 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.8690\n",
      "Epoch 512/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.6527 - output_headline_vector_loss: 0.0213 - headline_token_classes_loss: 2.6314 - val_loss: 4.0571 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 4.0451\n",
      "Epoch 513/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5851 - output_headline_vector_loss: 0.0210 - headline_token_classes_loss: 2.5641 - val_loss: 3.9001 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 3.8908\n",
      "Epoch 514/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5622 - output_headline_vector_loss: 0.0207 - headline_token_classes_loss: 2.5415 - val_loss: 4.0261 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 4.0151\n",
      "Epoch 515/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6690 - output_headline_vector_loss: 0.0213 - headline_token_classes_loss: 2.6478 - val_loss: 4.0863 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 4.0720\n",
      "Epoch 516/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6129 - output_headline_vector_loss: 0.0215 - headline_token_classes_loss: 2.5915 - val_loss: 4.0603 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 4.0484\n",
      "Epoch 517/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7455 - output_headline_vector_loss: 0.0214 - headline_token_classes_loss: 2.7241 - val_loss: 3.8002 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 3.7865\n",
      "Epoch 518/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5260 - output_headline_vector_loss: 0.0217 - headline_token_classes_loss: 2.5044 - val_loss: 3.8447 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 3.8313\n",
      "Epoch 519/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6512 - output_headline_vector_loss: 0.0202 - headline_token_classes_loss: 2.6310 - val_loss: 4.0301 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 4.0192\n",
      "Epoch 520/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5243 - output_headline_vector_loss: 0.0202 - headline_token_classes_loss: 2.5040 - val_loss: 3.9845 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 3.9725\n",
      "Epoch 521/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5933 - output_headline_vector_loss: 0.0216 - headline_token_classes_loss: 2.5717 - val_loss: 4.0114 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 3.9984\n",
      "Epoch 522/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7637 - output_headline_vector_loss: 0.0199 - headline_token_classes_loss: 2.7438 - val_loss: 3.9742 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.9637\n",
      "Epoch 523/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5881 - output_headline_vector_loss: 0.0202 - headline_token_classes_loss: 2.5679 - val_loss: 3.9544 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.9440\n",
      "Epoch 524/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6815 - output_headline_vector_loss: 0.0199 - headline_token_classes_loss: 2.6616 - val_loss: 4.0894 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 4.0773\n",
      "Epoch 525/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6785 - output_headline_vector_loss: 0.0198 - headline_token_classes_loss: 2.6588 - val_loss: 3.9596 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 3.9501\n",
      "Epoch 526/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6333 - output_headline_vector_loss: 0.0201 - headline_token_classes_loss: 2.6132 - val_loss: 4.0442 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 4.0327\n",
      "Epoch 527/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6673 - output_headline_vector_loss: 0.0185 - headline_token_classes_loss: 2.6488 - val_loss: 4.1271 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 4.1137\n",
      "Epoch 528/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5063 - output_headline_vector_loss: 0.0198 - headline_token_classes_loss: 2.4865 - val_loss: 3.8348 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 3.8199\n",
      "Epoch 529/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6218 - output_headline_vector_loss: 0.0198 - headline_token_classes_loss: 2.6019 - val_loss: 3.9563 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 3.9454\n",
      "Epoch 530/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 17s 4s/step - loss: 2.5315 - output_headline_vector_loss: 0.0203 - headline_token_classes_loss: 2.5112 - val_loss: 4.1787 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 4.1663\n",
      "Epoch 531/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5806 - output_headline_vector_loss: 0.0202 - headline_token_classes_loss: 2.5604 - val_loss: 3.6467 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 3.6377\n",
      "Epoch 532/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6175 - output_headline_vector_loss: 0.0182 - headline_token_classes_loss: 2.5993 - val_loss: 3.6541 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 3.6443\n",
      "Epoch 533/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5246 - output_headline_vector_loss: 0.0180 - headline_token_classes_loss: 2.5065 - val_loss: 4.1417 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 4.1302\n",
      "Epoch 534/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.7444 - output_headline_vector_loss: 0.0187 - headline_token_classes_loss: 2.7256 - val_loss: 3.8795 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.8689\n",
      "Epoch 535/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5255 - output_headline_vector_loss: 0.0188 - headline_token_classes_loss: 2.5067 - val_loss: 3.8734 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.8630\n",
      "Epoch 536/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5974 - output_headline_vector_loss: 0.0191 - headline_token_classes_loss: 2.5783 - val_loss: 3.6277 - val_output_headline_vector_loss: 0.0208 - val_headline_token_classes_loss: 3.6069\n",
      "Epoch 537/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5345 - output_headline_vector_loss: 0.0190 - headline_token_classes_loss: 2.5155 - val_loss: 3.6898 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 3.6766\n",
      "Epoch 538/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6352 - output_headline_vector_loss: 0.0188 - headline_token_classes_loss: 2.6164 - val_loss: 3.8714 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.8598\n",
      "Epoch 539/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5577 - output_headline_vector_loss: 0.0176 - headline_token_classes_loss: 2.5401 - val_loss: 3.7749 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.7646\n",
      "Epoch 540/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4543 - output_headline_vector_loss: 0.0182 - headline_token_classes_loss: 2.4361 - val_loss: 4.0047 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 3.9918\n",
      "Epoch 541/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6646 - output_headline_vector_loss: 0.0183 - headline_token_classes_loss: 2.6463 - val_loss: 4.0448 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 4.0311\n",
      "Epoch 542/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.6893 - output_headline_vector_loss: 0.0182 - headline_token_classes_loss: 2.6711 - val_loss: 4.0838 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 4.0721\n",
      "Epoch 543/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5205 - output_headline_vector_loss: 0.0188 - headline_token_classes_loss: 2.5017 - val_loss: 3.8108 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 3.7959\n",
      "Epoch 544/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.7271 - output_headline_vector_loss: 0.0185 - headline_token_classes_loss: 2.7086 - val_loss: 3.9283 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.9182\n",
      "Epoch 545/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4601 - output_headline_vector_loss: 0.0182 - headline_token_classes_loss: 2.4419 - val_loss: 3.6388 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 3.6262\n",
      "Epoch 546/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5193 - output_headline_vector_loss: 0.0181 - headline_token_classes_loss: 2.5012 - val_loss: 3.7074 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 3.6940\n",
      "Epoch 547/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5500 - output_headline_vector_loss: 0.0180 - headline_token_classes_loss: 2.5320 - val_loss: 3.8266 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 3.8118\n",
      "Epoch 548/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4788 - output_headline_vector_loss: 0.0189 - headline_token_classes_loss: 2.4599 - val_loss: 3.6603 - val_output_headline_vector_loss: 0.0088 - val_headline_token_classes_loss: 3.6515\n",
      "Epoch 549/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4749 - output_headline_vector_loss: 0.0168 - headline_token_classes_loss: 2.4580 - val_loss: 3.7321 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.7219\n",
      "Epoch 550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5865 - output_headline_vector_loss: 0.0171 - headline_token_classes_loss: 2.5694 - val_loss: 3.9067 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.8963\n",
      "Epoch 551/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5921 - output_headline_vector_loss: 0.0177 - headline_token_classes_loss: 2.5744 - val_loss: 3.8340 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.8233\n",
      "Epoch 552/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5672 - output_headline_vector_loss: 0.0165 - headline_token_classes_loss: 2.5507 - val_loss: 3.9748 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 3.9605\n",
      "Epoch 553/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6480 - output_headline_vector_loss: 0.0166 - headline_token_classes_loss: 2.6314 - val_loss: 3.7859 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 3.7740\n",
      "Epoch 554/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5668 - output_headline_vector_loss: 0.0175 - headline_token_classes_loss: 2.5493 - val_loss: 3.9038 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 3.8890\n",
      "Epoch 555/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4464 - output_headline_vector_loss: 0.0180 - headline_token_classes_loss: 2.4284 - val_loss: 3.9069 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.8958\n",
      "Epoch 556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6077 - output_headline_vector_loss: 0.0170 - headline_token_classes_loss: 2.5907 - val_loss: 3.7759 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.7648\n",
      "Epoch 557/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6419 - output_headline_vector_loss: 0.0173 - headline_token_classes_loss: 2.6246 - val_loss: 3.7823 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 3.7676\n",
      "Epoch 558/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4678 - output_headline_vector_loss: 0.0188 - headline_token_classes_loss: 2.4490 - val_loss: 3.9846 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.9730\n",
      "Epoch 559/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5172 - output_headline_vector_loss: 0.0179 - headline_token_classes_loss: 2.4993 - val_loss: 3.9478 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 3.9364\n",
      "Epoch 560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5609 - output_headline_vector_loss: 0.0168 - headline_token_classes_loss: 2.5441 - val_loss: 4.0924 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 4.0791\n",
      "Epoch 561/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4950 - output_headline_vector_loss: 0.0176 - headline_token_classes_loss: 2.4775 - val_loss: 4.0036 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 3.9903\n",
      "Epoch 562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5517 - output_headline_vector_loss: 0.0170 - headline_token_classes_loss: 2.5347 - val_loss: 3.9154 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 3.9033\n",
      "Epoch 563/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3842 - output_headline_vector_loss: 0.0176 - headline_token_classes_loss: 2.3667 - val_loss: 3.8744 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.8633\n",
      "Epoch 564/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4642 - output_headline_vector_loss: 0.0173 - headline_token_classes_loss: 2.4469 - val_loss: 3.8664 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 3.8540\n",
      "Epoch 565/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6345 - output_headline_vector_loss: 0.0155 - headline_token_classes_loss: 2.6190 - val_loss: 3.7527 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 3.7347\n",
      "Epoch 566/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5440 - output_headline_vector_loss: 0.0162 - headline_token_classes_loss: 2.5278 - val_loss: 3.5809 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 3.5717\n",
      "Epoch 567/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.5720 - output_headline_vector_loss: 0.0162 - headline_token_classes_loss: 2.5558 - val_loss: 3.7744 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.7638\n",
      "Epoch 568/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5009 - output_headline_vector_loss: 0.0156 - headline_token_classes_loss: 2.4853 - val_loss: 4.1325 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 4.1201\n",
      "Epoch 569/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4878 - output_headline_vector_loss: 0.0165 - headline_token_classes_loss: 2.4712 - val_loss: 3.7786 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.7675\n",
      "Epoch 570/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5503 - output_headline_vector_loss: 0.0157 - headline_token_classes_loss: 2.5346 - val_loss: 3.6934 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 3.6825\n",
      "Epoch 571/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5388 - output_headline_vector_loss: 0.0163 - headline_token_classes_loss: 2.5225 - val_loss: 3.8758 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 3.8613\n",
      "Epoch 572/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4810 - output_headline_vector_loss: 0.0166 - headline_token_classes_loss: 2.4644 - val_loss: 3.7995 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 3.7886\n",
      "Epoch 573/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4448 - output_headline_vector_loss: 0.0162 - headline_token_classes_loss: 2.4286 - val_loss: 3.7348 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 3.7206\n",
      "Epoch 574/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5774 - output_headline_vector_loss: 0.0160 - headline_token_classes_loss: 2.5613 - val_loss: 3.8314 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.8201\n",
      "Epoch 575/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5308 - output_headline_vector_loss: 0.0161 - headline_token_classes_loss: 2.5147 - val_loss: 3.9706 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 3.9607\n",
      "Epoch 576/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.6743 - output_headline_vector_loss: 0.0154 - headline_token_classes_loss: 2.6588 - val_loss: 3.6308 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.6205\n",
      "Epoch 577/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.5336 - output_headline_vector_loss: 0.0156 - headline_token_classes_loss: 2.5180 - val_loss: 3.7774 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 3.7656\n",
      "Epoch 578/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4984 - output_headline_vector_loss: 0.0161 - headline_token_classes_loss: 2.4823 - val_loss: 3.6377 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 3.6239\n",
      "Epoch 579/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4404 - output_headline_vector_loss: 0.0155 - headline_token_classes_loss: 2.4248 - val_loss: 3.7590 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.7485\n",
      "Epoch 580/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.4918 - output_headline_vector_loss: 0.0159 - headline_token_classes_loss: 2.4759 - val_loss: 3.7281 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.7175\n",
      "Epoch 581/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5058 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.4908 - val_loss: 3.6344 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.6241\n",
      "Epoch 582/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4339 - output_headline_vector_loss: 0.0169 - headline_token_classes_loss: 2.4170 - val_loss: 3.8012 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.7896\n",
      "Epoch 583/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4972 - output_headline_vector_loss: 0.0146 - headline_token_classes_loss: 2.4825 - val_loss: 3.7705 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 3.7606\n",
      "Epoch 584/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4757 - output_headline_vector_loss: 0.0153 - headline_token_classes_loss: 2.4604 - val_loss: 3.8759 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.8643\n",
      "Epoch 585/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4008 - output_headline_vector_loss: 0.0153 - headline_token_classes_loss: 2.3856 - val_loss: 3.8655 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.8550\n",
      "Epoch 586/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5427 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.5277 - val_loss: 3.7542 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.7430\n",
      "Epoch 587/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5486 - output_headline_vector_loss: 0.0149 - headline_token_classes_loss: 2.5337 - val_loss: 3.6376 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.6274\n",
      "Epoch 588/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4008 - output_headline_vector_loss: 0.0147 - headline_token_classes_loss: 2.3861 - val_loss: 3.5456 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 3.5360\n",
      "Epoch 589/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.5341 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.5190 - val_loss: 3.6242 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.6137\n",
      "Epoch 590/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5151 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.5000 - val_loss: 3.7538 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.7426\n",
      "Epoch 591/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5385 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.5235 - val_loss: 3.6894 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 3.6778\n",
      "Epoch 592/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.4028 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.3878 - val_loss: 3.7906 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.7793\n",
      "Epoch 593/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4886 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.4745 - val_loss: 3.6909 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.6798\n",
      "Epoch 594/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4094 - output_headline_vector_loss: 0.0156 - headline_token_classes_loss: 2.3938 - val_loss: 3.7047 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 3.6946\n",
      "Epoch 595/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3764 - output_headline_vector_loss: 0.0152 - headline_token_classes_loss: 2.3612 - val_loss: 3.6679 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 3.6578\n",
      "Epoch 596/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.6346 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.6208 - val_loss: 3.7734 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.7632\n",
      "Epoch 597/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3794 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.3652 - val_loss: 3.7155 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.7044\n",
      "Epoch 598/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4247 - output_headline_vector_loss: 0.0149 - headline_token_classes_loss: 2.4097 - val_loss: 3.7005 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.6898\n",
      "Epoch 599/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4875 - output_headline_vector_loss: 0.0150 - headline_token_classes_loss: 2.4726 - val_loss: 3.6961 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.6854\n",
      "Epoch 600/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4466 - output_headline_vector_loss: 0.0140 - headline_token_classes_loss: 2.4327 - val_loss: 3.7571 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.7460\n",
      "Epoch 601/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4420 - output_headline_vector_loss: 0.0152 - headline_token_classes_loss: 2.4268 - val_loss: 3.7968 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 3.7845\n",
      "Epoch 602/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4486 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.4335 - val_loss: 3.7452 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.7336\n",
      "Epoch 603/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4969 - output_headline_vector_loss: 0.0144 - headline_token_classes_loss: 2.4824 - val_loss: 3.6761 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 3.6652\n",
      "Epoch 604/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4881 - output_headline_vector_loss: 0.0148 - headline_token_classes_loss: 2.4733 - val_loss: 3.5242 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 3.5145\n",
      "Epoch 605/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3509 - output_headline_vector_loss: 0.0141 - headline_token_classes_loss: 2.3368 - val_loss: 3.6044 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 3.5897\n",
      "Epoch 606/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3862 - output_headline_vector_loss: 0.0138 - headline_token_classes_loss: 2.3723 - val_loss: 3.4470 - val_output_headline_vector_loss: 0.0177 - val_headline_token_classes_loss: 3.4293\n",
      "Epoch 607/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4920 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.4792 - val_loss: 3.6252 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 3.6110\n",
      "Epoch 608/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2749 - output_headline_vector_loss: 0.0137 - headline_token_classes_loss: 2.2612 - val_loss: 3.7307 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.7200\n",
      "Epoch 609/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4964 - output_headline_vector_loss: 0.0138 - headline_token_classes_loss: 2.4826 - val_loss: 3.6025 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 3.5899\n",
      "Epoch 610/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4520 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.4393 - val_loss: 3.5629 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 3.5487\n",
      "Epoch 611/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.6279 - output_headline_vector_loss: 0.0136 - headline_token_classes_loss: 2.6144 - val_loss: 3.6060 - val_output_headline_vector_loss: 0.0178 - val_headline_token_classes_loss: 3.5882\n",
      "Epoch 612/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3563 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.3412 - val_loss: 3.5255 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 3.5164\n",
      "Epoch 613/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3572 - output_headline_vector_loss: 0.0151 - headline_token_classes_loss: 2.3420 - val_loss: 3.7144 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 3.7020\n",
      "Epoch 614/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.5328 - output_headline_vector_loss: 0.0133 - headline_token_classes_loss: 2.5194 - val_loss: 3.4999 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 3.4901\n",
      "Epoch 615/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4779 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.4644 - val_loss: 3.6302 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.6199\n",
      "Epoch 616/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4027 - output_headline_vector_loss: 0.0147 - headline_token_classes_loss: 2.3880 - val_loss: 3.6035 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 3.5918\n",
      "Epoch 617/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4896 - output_headline_vector_loss: 0.0133 - headline_token_classes_loss: 2.4763 - val_loss: 3.5908 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 3.5809\n",
      "Epoch 618/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3706 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.3580 - val_loss: 3.6495 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.6384\n",
      "Epoch 619/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3780 - output_headline_vector_loss: 0.0138 - headline_token_classes_loss: 2.3642 - val_loss: 3.5552 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 3.5450\n",
      "Epoch 620/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3918 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 2.3788 - val_loss: 3.5069 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 3.4922\n",
      "Epoch 621/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3472 - output_headline_vector_loss: 0.0132 - headline_token_classes_loss: 2.3340 - val_loss: 3.6876 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.6768\n",
      "Epoch 622/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4515 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 2.4384 - val_loss: 3.6839 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.6723\n",
      "Epoch 623/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3820 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.3692 - val_loss: 3.3368 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 3.3185\n",
      "Epoch 624/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.4293 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.4164 - val_loss: 3.5283 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.5170\n",
      "Epoch 625/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.5058 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.4915 - val_loss: 3.6977 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.6869\n",
      "Epoch 626/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3750 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.3625 - val_loss: 3.5298 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.5191\n",
      "Epoch 627/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3983 - output_headline_vector_loss: 0.0138 - headline_token_classes_loss: 2.3845 - val_loss: 3.5775 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 3.5655\n",
      "Epoch 628/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3271 - output_headline_vector_loss: 0.0140 - headline_token_classes_loss: 2.3131 - val_loss: 3.5103 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.4995\n",
      "Epoch 629/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2375 - output_headline_vector_loss: 0.0138 - headline_token_classes_loss: 2.2237 - val_loss: 3.5556 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 3.5439\n",
      "Epoch 630/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.4257 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 2.4127 - val_loss: 3.5791 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 3.5665\n",
      "Epoch 631/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2860 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.2734 - val_loss: 3.4308 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 3.4208\n",
      "Epoch 632/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2864 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.2736 - val_loss: 3.4542 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 3.4393\n",
      "Epoch 633/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3429 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.3294 - val_loss: 3.6653 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 3.6524\n",
      "Epoch 634/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.4111 - output_headline_vector_loss: 0.0133 - headline_token_classes_loss: 2.3978 - val_loss: 3.4573 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 3.4459\n",
      "Epoch 635/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2716 - output_headline_vector_loss: 0.0147 - headline_token_classes_loss: 2.2569 - val_loss: 3.4729 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 3.4625\n",
      "Epoch 636/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3438 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.3300 - val_loss: 3.6508 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.6392\n",
      "Epoch 637/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3709 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.3573 - val_loss: 3.4249 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 3.4118\n",
      "Epoch 638/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4400 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 2.4270 - val_loss: 3.4650 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.4547\n",
      "Epoch 639/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3470 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.3346 - val_loss: 3.4818 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.4710\n",
      "Epoch 640/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.4048 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.3909 - val_loss: 3.4426 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.4320\n",
      "Epoch 641/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3051 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.2916 - val_loss: 3.3993 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 3.3842\n",
      "Epoch 642/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3821 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.3702 - val_loss: 3.5034 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 3.4889\n",
      "Epoch 643/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1677 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.1535 - val_loss: 3.6759 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 3.6647\n",
      "Epoch 644/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3514 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.3389 - val_loss: 3.5592 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 3.5471\n",
      "Epoch 645/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2966 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.2841 - val_loss: 3.4533 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 3.4418\n",
      "Epoch 646/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2852 - output_headline_vector_loss: 0.0132 - headline_token_classes_loss: 2.2720 - val_loss: 3.4719 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.4611\n",
      "Epoch 647/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3430 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.3304 - val_loss: 3.1875 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 3.1706\n",
      "Epoch 648/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3015 - output_headline_vector_loss: 0.0141 - headline_token_classes_loss: 2.2874 - val_loss: 3.3605 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.3502\n",
      "Epoch 649/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2623 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.2501 - val_loss: 3.3365 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 3.3265\n",
      "Epoch 650/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3021 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.2902 - val_loss: 3.2121 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 3.1983\n",
      "Epoch 651/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3445 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.3321 - val_loss: 3.3357 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 3.3215\n",
      "Epoch 652/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2981 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.2856 - val_loss: 3.3231 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.3126\n",
      "Epoch 653/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2768 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 2.2638 - val_loss: 3.2547 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 3.2396\n",
      "Epoch 654/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 2.2756 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.2632 - val_loss: 3.4406 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 3.4318\n",
      "Epoch 655/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3571 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.3442 - val_loss: 3.3744 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 3.3626\n",
      "Epoch 656/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3898 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.3779 - val_loss: 3.2216 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 3.2081\n",
      "Epoch 657/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3229 - output_headline_vector_loss: 0.0139 - headline_token_classes_loss: 2.3090 - val_loss: 3.2793 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.2688\n",
      "Epoch 658/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3363 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.3243 - val_loss: 3.2268 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.2162\n",
      "Epoch 659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1520 - output_headline_vector_loss: 0.0142 - headline_token_classes_loss: 2.1377 - val_loss: 3.3472 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 3.3359\n",
      "Epoch 660/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2440 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.2319 - val_loss: 3.3253 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 3.3098\n",
      "Epoch 661/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3889 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.3769 - val_loss: 3.2903 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.2796\n",
      "Epoch 662/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2851 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.2722 - val_loss: 3.2700 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.2592\n",
      "Epoch 663/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3642 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.3525 - val_loss: 3.4293 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 3.4165\n",
      "Epoch 664/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2756 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 2.2625 - val_loss: 3.2959 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 3.2834\n",
      "Epoch 665/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3160 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.3041 - val_loss: 3.2681 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 3.2556\n",
      "Epoch 666/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2682 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.2559 - val_loss: 3.2957 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 3.2862\n",
      "Epoch 667/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2433 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.2322 - val_loss: 3.0629 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 3.0486\n",
      "Epoch 668/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3511 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.3390 - val_loss: 3.3225 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 3.3126\n",
      "Epoch 669/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2908 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.2788 - val_loss: 3.2586 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 3.2463\n",
      "Epoch 670/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2242 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.2114 - val_loss: 3.2246 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 3.2139\n",
      "Epoch 671/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1662 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.1534 - val_loss: 3.0821 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 3.0697\n",
      "Epoch 672/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1866 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.1739 - val_loss: 3.1076 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 3.0927\n",
      "Epoch 673/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1901 - output_headline_vector_loss: 0.0129 - headline_token_classes_loss: 2.1773 - val_loss: 3.2835 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.2724\n",
      "Epoch 674/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1859 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.1744 - val_loss: 3.3004 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 3.2885\n",
      "Epoch 675/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.3384 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.3272 - val_loss: 3.2547 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 3.2450\n",
      "Epoch 676/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2351 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.2224 - val_loss: 3.0231 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 3.0088\n",
      "Epoch 677/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3421 - output_headline_vector_loss: 0.0132 - headline_token_classes_loss: 2.3290 - val_loss: 3.3286 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 3.3156\n",
      "Epoch 678/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3594 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.3476 - val_loss: 3.2314 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 3.2204\n",
      "Epoch 679/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1456 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 2.1328 - val_loss: 3.2781 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 3.2660\n",
      "Epoch 680/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3258 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.3136 - val_loss: 3.0574 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 3.0471\n",
      "Epoch 681/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1973 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.1860 - val_loss: 3.2250 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 3.2135\n",
      "Epoch 682/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2829 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.2709 - val_loss: 3.0625 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 3.0529\n",
      "Epoch 683/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2492 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.2366 - val_loss: 3.2063 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 3.1934\n",
      "Epoch 684/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1572 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.1449 - val_loss: 3.2756 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 3.2624\n",
      "Epoch 685/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1466 - output_headline_vector_loss: 0.0135 - headline_token_classes_loss: 2.1331 - val_loss: 3.1319 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 3.1190\n",
      "Epoch 686/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2772 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.2650 - val_loss: 3.1344 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 3.1253\n",
      "Epoch 687/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1648 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.1533 - val_loss: 3.1149 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.1043\n",
      "Epoch 688/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2023 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.1907 - val_loss: 3.1531 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 3.1407\n",
      "Epoch 689/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3021 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.2896 - val_loss: 3.1509 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 3.1412\n",
      "Epoch 690/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1202 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1081 - val_loss: 3.0366 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 3.0265\n",
      "Epoch 691/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2938 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.2816 - val_loss: 3.1587 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 3.1466\n",
      "Epoch 692/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3100 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.2995 - val_loss: 3.0252 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 3.0142\n",
      "Epoch 693/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2592 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.2467 - val_loss: 3.0221 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 3.0103\n",
      "Epoch 694/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.3560 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.3442 - val_loss: 3.1652 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 3.1525\n",
      "Epoch 695/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3173 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.3061 - val_loss: 3.0668 - val_output_headline_vector_loss: 0.0165 - val_headline_token_classes_loss: 3.0503\n",
      "Epoch 696/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.3203 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.3089 - val_loss: 2.9761 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.9663\n",
      "Epoch 697/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1937 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 2.1806 - val_loss: 3.0755 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.0649\n",
      "Epoch 698/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3174 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.3054 - val_loss: 3.0915 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 3.0807\n",
      "Epoch 699/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1700 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.1575 - val_loss: 3.0469 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 3.0364\n",
      "Epoch 700/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1542 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.1424 - val_loss: 3.1056 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.0950\n",
      "Epoch 701/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1125 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1004 - val_loss: 3.0082 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.9976\n",
      "Epoch 702/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2934 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.2821 - val_loss: 3.0522 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 3.0413\n",
      "Epoch 703/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1631 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.1508 - val_loss: 3.1163 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 3.1041\n",
      "Epoch 704/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1937 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1824 - val_loss: 2.8580 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.8431\n",
      "Epoch 705/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2654 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.2538 - val_loss: 2.8588 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.8460\n",
      "Epoch 706/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1678 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.1553 - val_loss: 2.8541 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.8410\n",
      "Epoch 707/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2039 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.1920 - val_loss: 2.8735 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.8590\n",
      "Epoch 708/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1170 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.1056 - val_loss: 3.0662 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 3.0543\n",
      "Epoch 709/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.3082 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.2966 - val_loss: 2.9952 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9850\n",
      "Epoch 710/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2158 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.2046 - val_loss: 3.0754 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 3.0661\n",
      "Epoch 711/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1943 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.1824 - val_loss: 3.0356 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 3.0242\n",
      "Epoch 712/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0987 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.0862 - val_loss: 2.9753 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.9648\n",
      "Epoch 713/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2067 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.1946 - val_loss: 3.0574 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 3.0458\n",
      "Epoch 714/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1644 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.1519 - val_loss: 3.0119 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.0013\n",
      "Epoch 715/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2030 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.1917 - val_loss: 3.0264 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 3.0150\n",
      "Epoch 716/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 2.1338 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.1212 - val_loss: 2.9176 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.9040\n",
      "Epoch 717/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0255 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.0139 - val_loss: 3.0211 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 3.0109\n",
      "Epoch 718/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1009 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.0885 - val_loss: 3.1262 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 3.1162\n",
      "Epoch 719/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1001 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 2.0880 - val_loss: 2.9668 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.9561\n",
      "Epoch 720/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1236 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.1116 - val_loss: 3.0141 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 3.0022\n",
      "Epoch 721/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0757 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.0634 - val_loss: 2.8420 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.8328\n",
      "Epoch 722/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2381 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 2.2258 - val_loss: 3.0595 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 3.0478\n",
      "Epoch 723/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0615 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 2.0489 - val_loss: 2.7453 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7349\n",
      "Epoch 724/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1973 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1862 - val_loss: 2.8965 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.8856\n",
      "Epoch 725/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0779 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0662 - val_loss: 2.7461 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.7310\n",
      "Epoch 726/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1057 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.0930 - val_loss: 2.8768 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.8636\n",
      "Epoch 727/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2037 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.1929 - val_loss: 2.8130 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.8000\n",
      "Epoch 728/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1284 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1171 - val_loss: 3.0728 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 3.0622\n",
      "Epoch 729/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1024 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.0908 - val_loss: 2.9001 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8900\n",
      "Epoch 730/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1273 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.1157 - val_loss: 2.9294 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.9198\n",
      "Epoch 731/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0826 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.0713 - val_loss: 2.9157 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.9023\n",
      "Epoch 732/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.2225 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 2.2103 - val_loss: 2.8492 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.8379\n",
      "Epoch 733/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1019 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0910 - val_loss: 2.9820 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.9713\n",
      "Epoch 734/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0808 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0691 - val_loss: 2.9405 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.9307\n",
      "Epoch 735/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0944 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.0824 - val_loss: 2.9929 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.9828\n",
      "Epoch 736/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0920 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.0803 - val_loss: 2.8455 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.8328\n",
      "Epoch 737/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0345 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.0217 - val_loss: 2.9194 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.9068\n",
      "Epoch 738/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.2415 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.2307 - val_loss: 2.7365 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.7220\n",
      "Epoch 739/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 2.2014 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.1905 - val_loss: 2.8410 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.8301\n",
      "Epoch 740/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.2070 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1957 - val_loss: 2.7296 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7195\n",
      "Epoch 741/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0899 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0798 - val_loss: 2.8452 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.8318\n",
      "Epoch 742/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1468 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.1351 - val_loss: 2.9652 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.9543\n",
      "Epoch 743/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0803 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.0683 - val_loss: 2.7108 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7001\n",
      "Epoch 744/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 2.0650 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0540 - val_loss: 2.7178 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.7077\n",
      "Epoch 745/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9769 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 1.9638 - val_loss: 2.7400 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.7263\n",
      "Epoch 746/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1217 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 2.1092 - val_loss: 2.8337 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.8216\n",
      "Epoch 747/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9965 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9852 - val_loss: 2.7316 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.7199\n",
      "Epoch 748/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2323 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 2.2221 - val_loss: 2.8478 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.8351\n",
      "Epoch 749/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0899 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.0786 - val_loss: 2.8752 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.8655\n",
      "Epoch 750/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0933 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0823 - val_loss: 2.7761 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7654\n",
      "Epoch 751/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1444 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.1329 - val_loss: 2.7109 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.7002\n",
      "Epoch 752/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0229 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0120 - val_loss: 2.7201 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7089\n",
      "Epoch 753/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1255 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1144 - val_loss: 2.7423 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.7300\n",
      "Epoch 754/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0939 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.0820 - val_loss: 2.6427 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.6302\n",
      "Epoch 755/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9292 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9175 - val_loss: 2.7875 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.7758\n",
      "Epoch 756/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9236 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.9112 - val_loss: 2.7567 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7465\n",
      "Epoch 757/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0425 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0307 - val_loss: 2.7620 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.7509\n",
      "Epoch 758/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1524 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.1420 - val_loss: 2.7805 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7683\n",
      "Epoch 759/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9482 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.9357 - val_loss: 2.9029 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.8932\n",
      "Epoch 760/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9894 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.9776 - val_loss: 2.7634 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.7520\n",
      "Epoch 761/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0453 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 2.0335 - val_loss: 2.7355 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.7216\n",
      "Epoch 762/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1530 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.1420 - val_loss: 2.7148 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.7044\n",
      "Epoch 763/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9533 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9421 - val_loss: 2.6003 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.5876\n",
      "Epoch 764/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1020 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0908 - val_loss: 2.5978 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5863\n",
      "Epoch 765/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1482 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.1358 - val_loss: 2.7694 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7593\n",
      "Epoch 766/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0698 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 2.0581 - val_loss: 2.7370 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.7272\n",
      "Epoch 767/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.2265 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.2155 - val_loss: 2.5358 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.5204\n",
      "Epoch 768/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.1750 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.1631 - val_loss: 2.6230 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.6132\n",
      "Epoch 769/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9859 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9752 - val_loss: 2.6605 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6488\n",
      "Epoch 770/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1937 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.1830 - val_loss: 2.7010 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6908\n",
      "Epoch 771/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0334 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.0218 - val_loss: 2.8068 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.7940\n",
      "Epoch 772/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1844 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.1744 - val_loss: 2.5627 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5513\n",
      "Epoch 773/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0637 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 2.0512 - val_loss: 2.8038 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.7927\n",
      "Epoch 774/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1821 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.1710 - val_loss: 2.6897 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.6779\n",
      "Epoch 775/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0241 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0130 - val_loss: 2.6534 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.6396\n",
      "Epoch 776/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.1631 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.1525 - val_loss: 2.6924 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.6823\n",
      "Epoch 777/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.1408 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.1295 - val_loss: 2.6364 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6256\n",
      "Epoch 778/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.9920 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9807 - val_loss: 2.6387 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.6275\n",
      "Epoch 779/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0884 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0774 - val_loss: 2.5772 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.5643\n",
      "Epoch 780/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0991 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 2.0864 - val_loss: 2.5223 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5115\n",
      "Epoch 781/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9581 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9471 - val_loss: 2.5558 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.5445\n",
      "Epoch 782/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1260 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.1145 - val_loss: 2.5378 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5258\n",
      "Epoch 783/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1816 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 2.1696 - val_loss: 2.5891 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.5740\n",
      "Epoch 784/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0721 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0607 - val_loss: 2.6010 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5905\n",
      "Epoch 785/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1058 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0949 - val_loss: 2.5703 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.5588\n",
      "Epoch 786/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9634 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.9514 - val_loss: 2.6360 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.6250\n",
      "Epoch 787/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0662 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0550 - val_loss: 2.5698 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.5571\n",
      "Epoch 788/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9267 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.9150 - val_loss: 2.4905 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4803\n",
      "Epoch 789/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1014 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0901 - val_loss: 2.6401 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6302\n",
      "Epoch 790/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1542 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 2.1423 - val_loss: 2.6653 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6551\n",
      "Epoch 791/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9838 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9720 - val_loss: 2.6836 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.6727\n",
      "Epoch 792/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0843 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 2.0727 - val_loss: 2.6951 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6840\n",
      "Epoch 793/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0972 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0863 - val_loss: 2.6871 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.6764\n",
      "Epoch 794/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0605 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0496 - val_loss: 2.5803 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5706\n",
      "Epoch 795/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0472 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0360 - val_loss: 2.6019 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.5899\n",
      "Epoch 796/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9995 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.9879 - val_loss: 2.4765 - val_output_headline_vector_loss: 0.0164 - val_headline_token_classes_loss: 2.4601\n",
      "Epoch 797/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1414 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 2.1306 - val_loss: 2.3116 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.2970\n",
      "Epoch 798/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0679 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0570 - val_loss: 2.5742 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5632\n",
      "Epoch 799/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9781 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9677 - val_loss: 2.3735 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3619\n",
      "Epoch 800/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0688 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0578 - val_loss: 2.5633 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5535\n",
      "Epoch 801/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0978 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0870 - val_loss: 2.7320 - val_output_headline_vector_loss: 0.0089 - val_headline_token_classes_loss: 2.7231\n",
      "Epoch 802/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9675 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9564 - val_loss: 2.4083 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.3931\n",
      "Epoch 803/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0277 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0163 - val_loss: 2.5602 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.5484\n",
      "Epoch 804/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9760 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9651 - val_loss: 2.5151 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5039\n",
      "Epoch 805/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0327 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0218 - val_loss: 2.4527 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4419\n",
      "Epoch 806/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0389 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0275 - val_loss: 2.4586 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4483\n",
      "Epoch 807/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8654 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.8537 - val_loss: 2.4622 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.4498\n",
      "Epoch 808/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9008 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8898 - val_loss: 2.4484 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4385\n",
      "Epoch 809/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0168 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0059 - val_loss: 2.6137 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.6030\n",
      "Epoch 810/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0017 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.9897 - val_loss: 2.7379 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.7274\n",
      "Epoch 811/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8862 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8746 - val_loss: 2.3822 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.3698\n",
      "Epoch 812/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 2.0494 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 2.0383 - val_loss: 2.3651 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3535\n",
      "Epoch 813/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 2.0655 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0552 - val_loss: 2.5135 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5034\n",
      "Epoch 814/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0638 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0535 - val_loss: 2.4295 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4184\n",
      "Epoch 815/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0093 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9981 - val_loss: 2.6992 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.6857\n",
      "Epoch 816/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0195 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0083 - val_loss: 2.3601 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.3450\n",
      "Epoch 817/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0005 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9888 - val_loss: 2.6031 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.5913\n",
      "Epoch 818/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9909 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9794 - val_loss: 2.4808 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.4713\n",
      "Epoch 819/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1265 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.1156 - val_loss: 2.3723 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3621\n",
      "Epoch 820/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9481 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9377 - val_loss: 2.5267 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5171\n",
      "Epoch 821/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9924 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9812 - val_loss: 2.3923 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.3786\n",
      "Epoch 822/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9456 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9343 - val_loss: 2.3983 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3883\n",
      "Epoch 823/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9108 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.8989 - val_loss: 2.3043 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2928\n",
      "Epoch 824/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9926 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9814 - val_loss: 2.5983 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5869\n",
      "Epoch 825/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9344 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9227 - val_loss: 2.5394 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5286\n",
      "Epoch 826/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9779 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9669 - val_loss: 2.4746 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4649\n",
      "Epoch 827/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9139 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.9016 - val_loss: 2.3888 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3763\n",
      "Epoch 828/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0096 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9993 - val_loss: 2.5424 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5320\n",
      "Epoch 829/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0098 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9983 - val_loss: 2.5895 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5791\n",
      "Epoch 830/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8415 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8297 - val_loss: 2.4394 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4284\n",
      "Epoch 831/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9358 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9250 - val_loss: 2.3673 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.3531\n",
      "Epoch 832/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9412 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.9298 - val_loss: 2.2457 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 2.2294\n",
      "Epoch 833/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9576 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.9454 - val_loss: 2.3030 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2916\n",
      "Epoch 834/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0798 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0691 - val_loss: 2.4004 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3903\n",
      "Epoch 835/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8423 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.8303 - val_loss: 2.2800 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.2673\n",
      "Epoch 836/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9594 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.9480 - val_loss: 2.5525 - val_output_headline_vector_loss: 0.0086 - val_headline_token_classes_loss: 2.5439\n",
      "Epoch 837/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9670 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.9547 - val_loss: 2.2905 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2799\n",
      "Epoch 838/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8828 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8720 - val_loss: 2.4473 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.4376\n",
      "Epoch 839/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9434 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9326 - val_loss: 2.3151 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.3024\n",
      "Epoch 840/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.8663 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8548 - val_loss: 2.3888 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3771\n",
      "Epoch 841/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9892 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9786 - val_loss: 2.4310 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4188\n",
      "Epoch 842/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9953 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9848 - val_loss: 2.1842 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.1702\n",
      "Epoch 843/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9067 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.8951 - val_loss: 2.3517 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3411\n",
      "Epoch 844/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0280 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0174 - val_loss: 2.3820 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.3723\n",
      "Epoch 845/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0082 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9974 - val_loss: 2.3881 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.3746\n",
      "Epoch 846/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7625 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.7501 - val_loss: 2.5354 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.5241\n",
      "Epoch 847/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.1019 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 2.0906 - val_loss: 2.3050 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2946\n",
      "Epoch 848/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9144 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9028 - val_loss: 2.1595 - val_output_headline_vector_loss: 0.0157 - val_headline_token_classes_loss: 2.1438\n",
      "Epoch 849/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7790 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.7670 - val_loss: 2.5151 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5045\n",
      "Epoch 850/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0220 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0114 - val_loss: 2.2537 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.2384\n",
      "Epoch 851/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9650 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.9536 - val_loss: 2.1671 - val_output_headline_vector_loss: 0.0173 - val_headline_token_classes_loss: 2.1498\n",
      "Epoch 852/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8443 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8327 - val_loss: 2.5289 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5182\n",
      "Epoch 853/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0438 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 2.0323 - val_loss: 2.3371 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.3252\n",
      "Epoch 854/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9652 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.9538 - val_loss: 2.1694 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1573\n",
      "Epoch 855/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0348 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 2.0234 - val_loss: 2.3765 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3648\n",
      "Epoch 856/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9879 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9775 - val_loss: 2.2674 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.2576\n",
      "Epoch 857/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8758 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8646 - val_loss: 2.3185 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3085\n",
      "Epoch 858/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8877 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8767 - val_loss: 2.2846 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2742\n",
      "Epoch 859/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8679 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8567 - val_loss: 2.4043 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.3924\n",
      "Epoch 860/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8451 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8337 - val_loss: 2.2182 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.2067\n",
      "Epoch 861/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8626 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8514 - val_loss: 2.2773 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2667\n",
      "Epoch 862/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7516 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7401 - val_loss: 2.2714 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2604\n",
      "Epoch 863/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9908 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9801 - val_loss: 2.5556 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.5426\n",
      "Epoch 864/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0143 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0037 - val_loss: 2.2772 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2662\n",
      "Epoch 865/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8919 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8809 - val_loss: 2.3023 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.2901\n",
      "Epoch 866/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8237 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8128 - val_loss: 2.2198 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2095\n",
      "Epoch 867/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9679 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9567 - val_loss: 2.2419 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2305\n",
      "Epoch 868/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9199 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9082 - val_loss: 2.4063 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3959\n",
      "Epoch 869/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8557 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.8433 - val_loss: 2.2564 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2448\n",
      "Epoch 870/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8524 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8412 - val_loss: 2.4169 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4065\n",
      "Epoch 871/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9159 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9052 - val_loss: 2.3806 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3705\n",
      "Epoch 872/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8936 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8829 - val_loss: 2.3227 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.3100\n",
      "Epoch 873/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0398 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 2.0292 - val_loss: 2.3204 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.3072\n",
      "Epoch 874/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9449 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9342 - val_loss: 2.5024 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.4928\n",
      "Epoch 875/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9041 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8929 - val_loss: 2.3443 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3345\n",
      "Epoch 876/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8375 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8264 - val_loss: 2.3928 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3815\n",
      "Epoch 877/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9600 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9491 - val_loss: 2.3043 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2932\n",
      "Epoch 878/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8504 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8392 - val_loss: 2.1674 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1531\n",
      "Epoch 879/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8415 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.8292 - val_loss: 2.2602 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2486\n",
      "Epoch 880/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8658 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8556 - val_loss: 2.3406 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3292\n",
      "Epoch 881/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8127 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8012 - val_loss: 2.1852 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.1727\n",
      "Epoch 882/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9159 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9044 - val_loss: 2.3805 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3698\n",
      "Epoch 883/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9098 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8990 - val_loss: 2.2388 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.2256\n",
      "Epoch 884/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8484 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8370 - val_loss: 2.4031 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3927\n",
      "Epoch 885/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8664 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8550 - val_loss: 2.2733 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2625\n",
      "Epoch 886/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7355 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 1.7228 - val_loss: 2.2911 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2806\n",
      "Epoch 887/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8797 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8679 - val_loss: 2.1917 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.1816\n",
      "Epoch 888/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9360 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9249 - val_loss: 2.3052 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.2932\n",
      "Epoch 889/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9299 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9193 - val_loss: 2.1733 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.1603\n",
      "Epoch 890/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9325 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9218 - val_loss: 2.2305 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.2170\n",
      "Epoch 891/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8559 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8450 - val_loss: 2.2288 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.2186\n",
      "Epoch 892/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9270 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9165 - val_loss: 2.2394 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.2276\n",
      "Epoch 893/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7678 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7575 - val_loss: 2.4320 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4216\n",
      "Epoch 894/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7836 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7722 - val_loss: 2.0953 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.0810\n",
      "Epoch 895/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8820 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8713 - val_loss: 2.3701 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3596\n",
      "Epoch 896/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7898 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7779 - val_loss: 2.1854 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.1738\n",
      "Epoch 897/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7977 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7860 - val_loss: 2.4463 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4364\n",
      "Epoch 898/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7812 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7694 - val_loss: 2.1951 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.1829\n",
      "Epoch 899/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7887 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7775 - val_loss: 2.2147 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2035\n",
      "Epoch 900/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7125 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 1.6999 - val_loss: 2.2454 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2341\n",
      "Epoch 901/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8452 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8339 - val_loss: 2.4112 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4005\n",
      "Epoch 902/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.8883 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8775 - val_loss: 2.2037 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 2.1865\n",
      "Epoch 903/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8271 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8157 - val_loss: 2.3304 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.3192\n",
      "Epoch 904/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7735 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7616 - val_loss: 2.2317 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2206\n",
      "Epoch 905/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7905 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7794 - val_loss: 2.4988 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4877\n",
      "Epoch 906/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.9167 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9065 - val_loss: 2.3042 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2927\n",
      "Epoch 907/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8610 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8499 - val_loss: 2.1440 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.1328\n",
      "Epoch 908/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9594 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9487 - val_loss: 2.3981 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3878\n",
      "Epoch 909/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9840 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9736 - val_loss: 2.3919 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3819\n",
      "Epoch 910/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7710 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7593 - val_loss: 2.3802 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3692\n",
      "Epoch 911/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8014 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7903 - val_loss: 2.3067 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.2943\n",
      "Epoch 912/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8784 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8673 - val_loss: 2.2456 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2348\n",
      "Epoch 913/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8075 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7959 - val_loss: 2.1943 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1800\n",
      "Epoch 914/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8542 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8432 - val_loss: 2.4322 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4222\n",
      "Epoch 915/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9112 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.8994 - val_loss: 2.4167 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4066\n",
      "Epoch 916/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9057 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8945 - val_loss: 2.2361 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2247\n",
      "Epoch 917/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7960 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7850 - val_loss: 2.4633 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.4539\n",
      "Epoch 918/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8287 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8179 - val_loss: 2.3048 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.2933\n",
      "Epoch 919/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8568 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8456 - val_loss: 2.3771 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3665\n",
      "Epoch 920/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8228 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8120 - val_loss: 2.1776 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1632\n",
      "Epoch 921/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9907 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9801 - val_loss: 2.2879 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.2755\n",
      "Epoch 922/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7974 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7858 - val_loss: 2.3099 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2986\n",
      "Epoch 923/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8085 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7977 - val_loss: 2.2816 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.2697\n",
      "Epoch 924/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7899 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7792 - val_loss: 2.2230 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2117\n",
      "Epoch 925/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8281 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8172 - val_loss: 2.3560 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3446\n",
      "Epoch 926/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8500 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8382 - val_loss: 2.3146 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3041\n",
      "Epoch 927/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7903 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7792 - val_loss: 2.3901 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3795\n",
      "Epoch 928/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8029 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7923 - val_loss: 2.2312 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.2165\n",
      "Epoch 929/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8000 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7892 - val_loss: 2.1728 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.1584\n",
      "Epoch 930/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9263 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9151 - val_loss: 2.2693 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.2576\n",
      "Epoch 931/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9480 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9369 - val_loss: 2.1445 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.1316\n",
      "Epoch 932/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8185 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8073 - val_loss: 2.3112 - val_output_headline_vector_loss: 0.0166 - val_headline_token_classes_loss: 2.2945\n",
      "Epoch 933/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7166 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7051 - val_loss: 2.4195 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4094\n",
      "Epoch 934/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9522 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9414 - val_loss: 2.3320 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3221\n",
      "Epoch 935/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8855 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8745 - val_loss: 2.2985 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.2887\n",
      "Epoch 936/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9169 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9057 - val_loss: 2.4132 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.4012\n",
      "Epoch 937/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7741 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7623 - val_loss: 2.3165 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3050\n",
      "Epoch 938/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8514 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8414 - val_loss: 2.4634 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.4499\n",
      "Epoch 939/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7332 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7216 - val_loss: 2.3413 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3296\n",
      "Epoch 940/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8264 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8161 - val_loss: 2.3625 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3511\n",
      "Epoch 941/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6827 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.6709 - val_loss: 2.2494 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.2353\n",
      "Epoch 942/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7482 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7367 - val_loss: 2.3495 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3381\n",
      "Epoch 943/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8735 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8634 - val_loss: 2.2646 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2541\n",
      "Epoch 944/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8118 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8009 - val_loss: 2.2844 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.2748\n",
      "Epoch 945/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7417 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7307 - val_loss: 2.2985 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.2848\n",
      "Epoch 946/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8548 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8441 - val_loss: 2.2414 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2297\n",
      "Epoch 947/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8127 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.8011 - val_loss: 2.1924 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.1820\n",
      "Epoch 948/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7976 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7868 - val_loss: 2.2609 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2491\n",
      "Epoch 949/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8664 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8553 - val_loss: 2.2079 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.1950\n",
      "Epoch 950/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7130 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.7010 - val_loss: 2.2694 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2583\n",
      "Epoch 951/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8540 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8430 - val_loss: 2.3061 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.2960\n",
      "Epoch 952/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7788 - output_headline_vector_loss: 0.0125 - headline_token_classes_loss: 1.7663 - val_loss: 2.1356 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.1202\n",
      "Epoch 953/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9435 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9334 - val_loss: 2.2901 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2794\n",
      "Epoch 954/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8948 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8834 - val_loss: 2.3541 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.3407\n",
      "Epoch 955/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9103 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8993 - val_loss: 2.3386 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3277\n",
      "Epoch 956/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8568 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8454 - val_loss: 2.2738 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.2629\n",
      "Epoch 957/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6866 - output_headline_vector_loss: 0.0124 - headline_token_classes_loss: 1.6742 - val_loss: 2.3373 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3254\n",
      "Epoch 958/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8020 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7905 - val_loss: 2.3344 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.3212\n",
      "Epoch 959/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8922 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8813 - val_loss: 2.4050 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.3938\n",
      "Epoch 960/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7673 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7563 - val_loss: 2.1664 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.1533\n",
      "Epoch 961/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6722 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6608 - val_loss: 2.4527 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4424\n",
      "Epoch 962/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7951 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7842 - val_loss: 2.1918 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.1784\n",
      "Epoch 963/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7871 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7761 - val_loss: 2.3079 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.2956\n",
      "Epoch 964/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7804 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7688 - val_loss: 2.2716 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2608\n",
      "Epoch 965/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7413 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7301 - val_loss: 2.1729 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.1618\n",
      "Epoch 966/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7554 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7448 - val_loss: 2.3983 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3859\n",
      "Epoch 967/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7371 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7255 - val_loss: 2.2545 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.2413\n",
      "Epoch 968/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8097 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7987 - val_loss: 2.3319 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3206\n",
      "Epoch 969/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8627 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8513 - val_loss: 2.2214 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.2075\n",
      "Epoch 970/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8874 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8761 - val_loss: 2.2083 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1969\n",
      "Epoch 971/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7993 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7884 - val_loss: 2.1657 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1543\n",
      "Epoch 972/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8561 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8454 - val_loss: 2.4544 - val_output_headline_vector_loss: 0.0171 - val_headline_token_classes_loss: 2.4373\n",
      "Epoch 973/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8214 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8100 - val_loss: 2.3496 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3381\n",
      "Epoch 974/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8378 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8265 - val_loss: 2.6560 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.6468\n",
      "Epoch 975/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7694 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7575 - val_loss: 2.4180 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4074\n",
      "Epoch 976/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7811 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7697 - val_loss: 2.4978 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4867\n",
      "Epoch 977/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8115 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8003 - val_loss: 2.1326 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.1187\n",
      "Epoch 978/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7019 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6908 - val_loss: 2.2570 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.2448\n",
      "Epoch 979/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9281 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9177 - val_loss: 2.5258 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5156\n",
      "Epoch 980/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7991 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7877 - val_loss: 2.1263 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.1115\n",
      "Epoch 981/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8064 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7960 - val_loss: 2.2775 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.2627\n",
      "Epoch 982/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6352 - output_headline_vector_loss: 0.0130 - headline_token_classes_loss: 1.6222 - val_loss: 2.5712 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5614\n",
      "Epoch 983/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8065 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7954 - val_loss: 2.3790 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.3656\n",
      "Epoch 984/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7900 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7796 - val_loss: 2.4946 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4839\n",
      "Epoch 985/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7234 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7117 - val_loss: 2.4437 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4335\n",
      "Epoch 986/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7288 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7171 - val_loss: 2.4309 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4204\n",
      "Epoch 987/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7874 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7762 - val_loss: 2.1987 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.1868\n",
      "Epoch 988/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7527 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7422 - val_loss: 2.2883 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.2760\n",
      "Epoch 989/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7938 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7833 - val_loss: 2.2278 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2167\n",
      "Epoch 990/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7601 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.7481 - val_loss: 2.4312 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4207\n",
      "Epoch 991/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8600 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8493 - val_loss: 2.1401 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.1297\n",
      "Epoch 992/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7087 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6972 - val_loss: 2.6680 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6577\n",
      "Epoch 993/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6818 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6701 - val_loss: 2.1899 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.1751\n",
      "Epoch 994/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6966 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6852 - val_loss: 2.3078 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2962\n",
      "Epoch 995/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7999 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7888 - val_loss: 2.4962 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4853\n",
      "Epoch 996/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6730 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 1.6603 - val_loss: 2.3838 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.3691\n",
      "Epoch 997/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7516 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7398 - val_loss: 2.1285 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1178\n",
      "Epoch 998/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8105 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7988 - val_loss: 2.3989 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.3846\n",
      "Epoch 999/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9289 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.9190 - val_loss: 2.3897 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.3770\n",
      "Epoch 1000/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7828 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7711 - val_loss: 2.2084 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.1973\n",
      "Epoch 1001/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8158 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.8041 - val_loss: 2.6298 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.6187\n",
      "Epoch 1002/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6852 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6741 - val_loss: 2.3513 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3404\n",
      "Epoch 1003/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8716 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8615 - val_loss: 2.3084 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.2939\n",
      "Epoch 1004/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7571 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7458 - val_loss: 2.4008 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3903\n",
      "Epoch 1005/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7610 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7498 - val_loss: 2.2211 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.2074\n",
      "Epoch 1006/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7545 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7439 - val_loss: 2.4040 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.3909\n",
      "Epoch 1007/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7784 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7676 - val_loss: 2.2751 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2634\n",
      "Epoch 1008/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8333 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8232 - val_loss: 2.2677 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.2527\n",
      "Epoch 1009/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7686 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7567 - val_loss: 2.1613 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1503\n",
      "Epoch 1010/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8059 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7953 - val_loss: 2.1397 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.1272\n",
      "Epoch 1011/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7973 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7862 - val_loss: 2.3338 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3229\n",
      "Epoch 1012/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7240 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7123 - val_loss: 2.2317 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2206\n",
      "Epoch 1013/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7098 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6980 - val_loss: 2.2881 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2765\n",
      "Epoch 1014/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7265 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7153 - val_loss: 2.2128 - val_output_headline_vector_loss: 0.0174 - val_headline_token_classes_loss: 2.1954\n",
      "Epoch 1015/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8265 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8165 - val_loss: 2.1994 - val_output_headline_vector_loss: 0.0169 - val_headline_token_classes_loss: 2.1825\n",
      "Epoch 1016/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7874 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7764 - val_loss: 2.3675 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.3543\n",
      "Epoch 1017/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8516 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.8419 - val_loss: 2.3040 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.2902\n",
      "Epoch 1018/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6679 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6566 - val_loss: 2.3213 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3097\n",
      "Epoch 1019/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7582 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7470 - val_loss: 2.2533 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.2388\n",
      "Epoch 1020/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8990 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8879 - val_loss: 2.1695 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.1550\n",
      "Epoch 1021/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8683 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8578 - val_loss: 2.3644 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3527\n",
      "Epoch 1022/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8366 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8268 - val_loss: 2.3948 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.3811\n",
      "Epoch 1023/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7654 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7543 - val_loss: 2.2711 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2607\n",
      "Epoch 1024/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6672 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6553 - val_loss: 2.2231 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2121\n",
      "Epoch 1025/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7455 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7346 - val_loss: 2.3402 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3304\n",
      "Epoch 1026/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7681 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7575 - val_loss: 2.4576 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4476\n",
      "Epoch 1027/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7283 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7178 - val_loss: 2.4120 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.3988\n",
      "Epoch 1028/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7745 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7636 - val_loss: 2.3386 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3277\n",
      "Epoch 1029/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7425 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7311 - val_loss: 2.5922 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.5812\n",
      "Epoch 1030/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7234 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7127 - val_loss: 2.4938 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.4784\n",
      "Epoch 1031/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7942 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7832 - val_loss: 2.5404 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5306\n",
      "Epoch 1032/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8028 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7914 - val_loss: 2.6131 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6033\n",
      "Epoch 1033/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8334 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8231 - val_loss: 2.2592 - val_output_headline_vector_loss: 0.0179 - val_headline_token_classes_loss: 2.2413\n",
      "Epoch 1034/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8286 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8178 - val_loss: 2.3401 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3286\n",
      "Epoch 1035/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7296 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7181 - val_loss: 2.2377 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2269\n",
      "Epoch 1036/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8197 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8086 - val_loss: 2.1212 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 2.1049\n",
      "Epoch 1037/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8121 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8007 - val_loss: 2.3106 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3006\n",
      "Epoch 1038/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6534 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6417 - val_loss: 2.3565 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.3432\n",
      "Epoch 1039/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8231 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8122 - val_loss: 2.2071 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1928\n",
      "Epoch 1040/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7685 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7573 - val_loss: 2.5064 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.4926\n",
      "Epoch 1041/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8130 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8025 - val_loss: 2.1560 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.1414\n",
      "Epoch 1042/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7382 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7264 - val_loss: 2.1979 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1865\n",
      "Epoch 1043/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7602 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7493 - val_loss: 2.3811 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3710\n",
      "Epoch 1044/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7336 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7222 - val_loss: 2.8134 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.8029\n",
      "Epoch 1045/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8424 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8317 - val_loss: 2.4338 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4235\n",
      "Epoch 1046/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8149 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8039 - val_loss: 2.2579 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.2440\n",
      "Epoch 1047/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7373 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7264 - val_loss: 2.2999 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.2897\n",
      "Epoch 1048/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6719 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6604 - val_loss: 2.6430 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.6303\n",
      "Epoch 1049/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8529 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8420 - val_loss: 2.2971 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 2.2812\n",
      "Epoch 1050/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7842 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7744 - val_loss: 2.2626 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2510\n",
      "Epoch 1051/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7864 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7757 - val_loss: 2.6289 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.6182\n",
      "Epoch 1052/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7965 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7857 - val_loss: 2.8463 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.8368\n",
      "Epoch 1053/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7453 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7336 - val_loss: 2.0851 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.0693\n",
      "Epoch 1054/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7518 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7411 - val_loss: 2.4741 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4639\n",
      "Epoch 1055/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8583 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8474 - val_loss: 2.2768 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.2650\n",
      "Epoch 1056/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8648 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8538 - val_loss: 2.4522 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4421\n",
      "Epoch 1057/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7671 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7555 - val_loss: 2.5663 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5562\n",
      "Epoch 1058/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8097 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7987 - val_loss: 2.7194 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.7093\n",
      "Epoch 1059/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7923 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7820 - val_loss: 2.5320 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5219\n",
      "Epoch 1060/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6862 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6745 - val_loss: 2.4730 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4633\n",
      "Epoch 1061/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8130 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.8033 - val_loss: 2.0299 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.0179\n",
      "Epoch 1062/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6888 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6773 - val_loss: 2.2257 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2149\n",
      "Epoch 1063/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8213 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8104 - val_loss: 2.0948 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.0820\n",
      "Epoch 1064/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6915 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6802 - val_loss: 2.4543 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.4421\n",
      "Epoch 1065/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8798 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8690 - val_loss: 2.3163 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.3014\n",
      "Epoch 1066/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8366 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8253 - val_loss: 2.3517 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3406\n",
      "Epoch 1067/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7595 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7494 - val_loss: 2.2221 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2112\n",
      "Epoch 1068/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6573 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6459 - val_loss: 2.2086 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.1938\n",
      "Epoch 1069/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9027 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8928 - val_loss: 2.4424 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4324\n",
      "Epoch 1070/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7295 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.7172 - val_loss: 2.1665 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.1564\n",
      "Epoch 1071/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7681 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7570 - val_loss: 2.3819 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.3680\n",
      "Epoch 1072/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7369 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7251 - val_loss: 2.3594 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3487\n",
      "Epoch 1073/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7339 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7224 - val_loss: 2.4263 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4153\n",
      "Epoch 1074/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7713 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7604 - val_loss: 2.3641 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.3544\n",
      "Epoch 1075/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7090 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6978 - val_loss: 2.2591 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2481\n",
      "Epoch 1076/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8138 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8027 - val_loss: 2.9939 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.9835\n",
      "Epoch 1077/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9822 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9715 - val_loss: 2.3790 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3679\n",
      "Epoch 1078/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8856 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8750 - val_loss: 2.3173 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3063\n",
      "Epoch 1079/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7515 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.7395 - val_loss: 2.1855 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.1749\n",
      "Epoch 1080/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7585 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7477 - val_loss: 2.3466 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.3371\n",
      "Epoch 1081/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7798 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7691 - val_loss: 2.5339 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.5204\n",
      "Epoch 1082/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8945 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8835 - val_loss: 2.3016 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2906\n",
      "Epoch 1083/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7451 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7336 - val_loss: 2.1313 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.1163\n",
      "Epoch 1084/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7765 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7645 - val_loss: 2.4080 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.3983\n",
      "Epoch 1085/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7335 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7224 - val_loss: 2.3227 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3119\n",
      "Epoch 1086/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8126 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8025 - val_loss: 2.3122 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.2999\n",
      "Epoch 1087/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7720 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7609 - val_loss: 2.5616 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.5492\n",
      "Epoch 1088/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7282 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7167 - val_loss: 2.3239 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.3117\n",
      "Epoch 1089/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7607 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7497 - val_loss: 2.4300 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4200\n",
      "Epoch 1090/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8545 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8438 - val_loss: 2.1956 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1850\n",
      "Epoch 1091/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8583 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8480 - val_loss: 2.3201 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3093\n",
      "Epoch 1092/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8256 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8144 - val_loss: 2.2818 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2711\n",
      "Epoch 1093/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8809 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8707 - val_loss: 2.2524 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2404\n",
      "Epoch 1094/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9082 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8980 - val_loss: 2.0570 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.0431\n",
      "Epoch 1095/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7304 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7190 - val_loss: 2.4544 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.4451\n",
      "Epoch 1096/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8165 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8061 - val_loss: 2.1714 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.1593\n",
      "Epoch 1097/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7952 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7839 - val_loss: 2.2843 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.2734\n",
      "Epoch 1098/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8268 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8167 - val_loss: 2.5707 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.5595\n",
      "Epoch 1099/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7852 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7737 - val_loss: 2.4537 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.4423\n",
      "Epoch 1100/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7941 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7833 - val_loss: 2.1578 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1435\n",
      "Epoch 1101/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8105 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7995 - val_loss: 1.9806 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 1.9692\n",
      "Epoch 1102/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7167 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7050 - val_loss: 2.0506 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 2.0323\n",
      "Epoch 1103/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8157 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8048 - val_loss: 2.3221 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3120\n",
      "Epoch 1104/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8370 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8257 - val_loss: 2.2923 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.2799\n",
      "Epoch 1105/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7708 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7608 - val_loss: 2.0168 - val_output_headline_vector_loss: 0.0156 - val_headline_token_classes_loss: 2.0012\n",
      "Epoch 1106/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7533 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7430 - val_loss: 2.2590 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2485\n",
      "Epoch 1107/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8553 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8454 - val_loss: 2.3705 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.3582\n",
      "Epoch 1108/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7022 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6904 - val_loss: 2.2155 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2047\n",
      "Epoch 1109/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7380 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7272 - val_loss: 2.0382 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.0224\n",
      "Epoch 1110/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7518 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7408 - val_loss: 2.4987 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.4894\n",
      "Epoch 1111/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7324 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7217 - val_loss: 2.3519 - val_output_headline_vector_loss: 0.0365 - val_headline_token_classes_loss: 2.3154\n",
      "Epoch 1112/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6933 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6817 - val_loss: 2.2548 - val_output_headline_vector_loss: 0.0379 - val_headline_token_classes_loss: 2.2169\n",
      "Epoch 1113/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8572 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8463 - val_loss: 2.3098 - val_output_headline_vector_loss: 0.0295 - val_headline_token_classes_loss: 2.2803\n",
      "Epoch 1114/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7041 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6925 - val_loss: 2.5711 - val_output_headline_vector_loss: 0.0190 - val_headline_token_classes_loss: 2.5522\n",
      "Epoch 1115/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8984 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8881 - val_loss: 2.1938 - val_output_headline_vector_loss: 0.0241 - val_headline_token_classes_loss: 2.1697\n",
      "Epoch 1116/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7891 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7781 - val_loss: 2.2948 - val_output_headline_vector_loss: 0.0201 - val_headline_token_classes_loss: 2.2746\n",
      "Epoch 1117/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8072 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.7977 - val_loss: 2.1019 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.0866\n",
      "Epoch 1118/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7536 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7426 - val_loss: 2.0687 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.0541\n",
      "Epoch 1119/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6863 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6749 - val_loss: 2.4018 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3893\n",
      "Epoch 1120/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9750 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.9651 - val_loss: 2.0391 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 2.0216\n",
      "Epoch 1121/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8035 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7924 - val_loss: 2.3195 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.3055\n",
      "Epoch 1122/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7180 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7065 - val_loss: 2.3154 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.3026\n",
      "Epoch 1123/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8145 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8039 - val_loss: 2.3182 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.3047\n",
      "Epoch 1124/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6604 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6490 - val_loss: 2.1266 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1159\n",
      "Epoch 1125/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7439 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7326 - val_loss: 2.0782 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.0629\n",
      "Epoch 1126/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6880 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.6761 - val_loss: 2.3450 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3340\n",
      "Epoch 1127/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7540 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7431 - val_loss: 2.3938 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3839\n",
      "Epoch 1128/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8447 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8337 - val_loss: 2.1908 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.1750\n",
      "Epoch 1129/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7207 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7092 - val_loss: 2.5006 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4902\n",
      "Epoch 1130/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7698 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7583 - val_loss: 2.3840 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3742\n",
      "Epoch 1131/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8929 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8821 - val_loss: 2.2585 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2468\n",
      "Epoch 1132/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7025 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6921 - val_loss: 2.0284 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.0161\n",
      "Epoch 1133/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8795 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8686 - val_loss: 2.3637 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3529\n",
      "Epoch 1134/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7627 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7514 - val_loss: 2.4393 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4296\n",
      "Epoch 1135/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7463 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7362 - val_loss: 2.2220 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2106\n",
      "Epoch 1136/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7616 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7501 - val_loss: 2.2744 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2630\n",
      "Epoch 1137/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6996 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6892 - val_loss: 2.3498 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3392\n",
      "Epoch 1138/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7766 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7649 - val_loss: 2.4206 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.4071\n",
      "Epoch 1139/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8166 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8061 - val_loss: 2.0608 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.0463\n",
      "Epoch 1140/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8299 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8190 - val_loss: 2.0395 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.0286\n",
      "Epoch 1141/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7876 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7760 - val_loss: 2.1225 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.1090\n",
      "Epoch 1142/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7698 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7592 - val_loss: 2.2118 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2007\n",
      "Epoch 1143/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7017 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6906 - val_loss: 2.1045 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.0927\n",
      "Epoch 1144/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7003 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6897 - val_loss: 2.4800 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.4707\n",
      "Epoch 1145/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6910 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6792 - val_loss: 2.0889 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.0770\n",
      "Epoch 1146/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7461 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7354 - val_loss: 2.1951 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1834\n",
      "Epoch 1147/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6919 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 1.6793 - val_loss: 2.1585 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.1483\n",
      "Epoch 1148/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7161 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7045 - val_loss: 2.1128 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.1012\n",
      "Epoch 1149/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6971 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6860 - val_loss: 2.2615 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2510\n",
      "Epoch 1150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7727 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7624 - val_loss: 2.0806 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.0690\n",
      "Epoch 1151/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7726 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7621 - val_loss: 2.4137 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4025\n",
      "Epoch 1152/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8521 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8420 - val_loss: 2.3130 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3012\n",
      "Epoch 1153/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8071 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7954 - val_loss: 2.2408 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.2299\n",
      "Epoch 1154/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6452 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6333 - val_loss: 2.0048 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 1.9936\n",
      "Epoch 1155/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8457 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8357 - val_loss: 2.3978 - val_output_headline_vector_loss: 0.0159 - val_headline_token_classes_loss: 2.3819\n",
      "Epoch 1156/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7657 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7550 - val_loss: 2.0382 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.0233\n",
      "Epoch 1157/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7092 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6982 - val_loss: 1.9046 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 1.8908\n",
      "Epoch 1158/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8867 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8756 - val_loss: 2.2965 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2852\n",
      "Epoch 1159/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6960 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.6838 - val_loss: 2.3396 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.3265\n",
      "Epoch 1160/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7528 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7424 - val_loss: 2.2993 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2880\n",
      "Epoch 1161/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8439 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8336 - val_loss: 2.2065 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1958\n",
      "Epoch 1162/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7952 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7844 - val_loss: 2.4894 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4785\n",
      "Epoch 1163/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6278 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 1.6151 - val_loss: 1.8775 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 1.8623\n",
      "Epoch 1164/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7490 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7380 - val_loss: 2.0736 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.0620\n",
      "Epoch 1165/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7521 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7410 - val_loss: 2.0597 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.0454\n",
      "Epoch 1166/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7138 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7032 - val_loss: 2.1281 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1174\n",
      "Epoch 1167/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8824 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8714 - val_loss: 2.3683 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3580\n",
      "Epoch 1168/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7864 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7762 - val_loss: 2.0022 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 1.9910\n",
      "Epoch 1169/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6154 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.6033 - val_loss: 2.1090 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.0940\n",
      "Epoch 1170/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7603 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7493 - val_loss: 2.7436 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.7338\n",
      "Epoch 1171/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8175 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8066 - val_loss: 2.2324 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.2199\n",
      "Epoch 1172/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7972 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7870 - val_loss: 2.2000 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.1856\n",
      "Epoch 1173/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7016 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6904 - val_loss: 2.1561 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.1448\n",
      "Epoch 1174/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8748 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8644 - val_loss: 2.1855 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.1718\n",
      "Epoch 1175/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7398 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.7279 - val_loss: 2.2134 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.2036\n",
      "Epoch 1176/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7617 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7512 - val_loss: 2.1563 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.1417\n",
      "Epoch 1177/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6812 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6697 - val_loss: 2.4411 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4313\n",
      "Epoch 1178/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7251 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7136 - val_loss: 1.9642 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 1.9514\n",
      "Epoch 1179/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7445 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7338 - val_loss: 2.1977 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1863\n",
      "Epoch 1180/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8233 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8128 - val_loss: 2.3186 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.3058\n",
      "Epoch 1181/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7700 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7590 - val_loss: 2.3352 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.3259\n",
      "Epoch 1182/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6731 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6620 - val_loss: 1.9314 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 1.9169\n",
      "Epoch 1183/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7540 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7433 - val_loss: 2.1669 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1559\n",
      "Epoch 1184/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6322 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6211 - val_loss: 2.2198 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2077\n",
      "Epoch 1185/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8954 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8852 - val_loss: 2.3584 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3486\n",
      "Epoch 1186/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7281 - output_headline_vector_loss: 0.0126 - headline_token_classes_loss: 1.7155 - val_loss: 2.0575 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.0449\n",
      "Epoch 1187/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7602 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7500 - val_loss: 2.3281 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3175\n",
      "Epoch 1188/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7679 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7570 - val_loss: 2.3738 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.3647\n",
      "Epoch 1189/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6663 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6545 - val_loss: 2.1501 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1386\n",
      "Epoch 1190/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8565 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8461 - val_loss: 2.2207 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2104\n",
      "Epoch 1191/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7807 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7699 - val_loss: 2.2851 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2730\n",
      "Epoch 1192/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7656 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7551 - val_loss: 2.3554 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.3406\n",
      "Epoch 1193/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7483 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.7364 - val_loss: 2.5644 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5548\n",
      "Epoch 1194/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7366 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7259 - val_loss: 2.3740 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3622\n",
      "Epoch 1195/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7151 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7035 - val_loss: 2.1706 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.1554\n",
      "Epoch 1196/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7675 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7567 - val_loss: 2.3371 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3267\n",
      "Epoch 1197/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8858 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8758 - val_loss: 2.2640 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.2539\n",
      "Epoch 1198/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8603 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8503 - val_loss: 2.2485 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.2353\n",
      "Epoch 1199/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7396 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7289 - val_loss: 2.4647 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.4554\n",
      "Epoch 1200/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6434 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6316 - val_loss: 2.4465 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.4340\n",
      "Epoch 1201/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7807 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7697 - val_loss: 2.2401 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2291\n",
      "Epoch 1202/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6968 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6856 - val_loss: 1.9174 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 1.9043\n",
      "Epoch 1203/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8239 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8125 - val_loss: 2.2616 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2511\n",
      "Epoch 1204/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7866 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7764 - val_loss: 2.1692 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1575\n",
      "Epoch 1205/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7713 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7601 - val_loss: 2.1451 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.1309\n",
      "Epoch 1206/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7692 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7587 - val_loss: 2.1689 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.1544\n",
      "Epoch 1207/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6905 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6796 - val_loss: 2.4572 - val_output_headline_vector_loss: 0.0085 - val_headline_token_classes_loss: 2.4487\n",
      "Epoch 1208/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7941 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7832 - val_loss: 2.5068 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4963\n",
      "Epoch 1209/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7656 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7547 - val_loss: 2.4645 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4543\n",
      "Epoch 1210/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7009 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6900 - val_loss: 2.1784 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.1644\n",
      "Epoch 1211/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7110 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7006 - val_loss: 2.1993 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.1857\n",
      "Epoch 1212/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 1.6958 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6850 - val_loss: 2.2192 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.2061\n",
      "Epoch 1213/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8101 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7995 - val_loss: 2.1682 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1575\n",
      "Epoch 1214/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7679 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7572 - val_loss: 2.1678 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1570\n",
      "Epoch 1215/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6528 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6422 - val_loss: 2.4678 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.4563\n",
      "Epoch 1216/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6769 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6656 - val_loss: 2.2502 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.2384\n",
      "Epoch 1217/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6252 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6138 - val_loss: 2.3224 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3109\n",
      "Epoch 1218/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7085 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6974 - val_loss: 2.4155 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.4018\n",
      "Epoch 1219/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8318 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8212 - val_loss: 2.0473 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.0319\n",
      "Epoch 1220/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6258 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6145 - val_loss: 2.6378 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.6278\n",
      "Epoch 1221/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7044 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6937 - val_loss: 2.1416 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.1264\n",
      "Epoch 1222/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7215 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7102 - val_loss: 2.3410 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3300\n",
      "Epoch 1223/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6061 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.5943 - val_loss: 1.9907 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 1.9753\n",
      "Epoch 1224/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7607 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7500 - val_loss: 2.4120 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4013\n",
      "Epoch 1225/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6537 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6432 - val_loss: 2.5154 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5044\n",
      "Epoch 1226/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7421 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7315 - val_loss: 2.3882 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.3745\n",
      "Epoch 1227/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6995 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6890 - val_loss: 2.5276 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5177\n",
      "Epoch 1228/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6962 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6857 - val_loss: 2.4230 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4124\n",
      "Epoch 1229/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7132 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7025 - val_loss: 2.1246 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1103\n",
      "Epoch 1230/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7395 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7286 - val_loss: 2.5556 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5448\n",
      "Epoch 1231/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6882 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6774 - val_loss: 2.1317 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1210\n",
      "Epoch 1232/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7432 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7328 - val_loss: 2.5041 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4938\n",
      "Epoch 1233/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7452 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7339 - val_loss: 2.1627 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1520\n",
      "Epoch 1234/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7362 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7254 - val_loss: 2.1404 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 2.1241\n",
      "Epoch 1235/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7403 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7289 - val_loss: 2.5739 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.5638\n",
      "Epoch 1236/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6923 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6823 - val_loss: 2.2845 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.2723\n",
      "Epoch 1237/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7238 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7134 - val_loss: 2.2356 - val_output_headline_vector_loss: 0.0165 - val_headline_token_classes_loss: 2.2191\n",
      "Epoch 1238/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7449 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7339 - val_loss: 2.3480 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3370\n",
      "Epoch 1239/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7089 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6986 - val_loss: 2.2299 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2192\n",
      "Epoch 1240/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7261 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7153 - val_loss: 2.4335 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.4219\n",
      "Epoch 1241/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6590 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6481 - val_loss: 2.3764 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3665\n",
      "Epoch 1242/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7430 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7325 - val_loss: 1.9550 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 1.9439\n",
      "Epoch 1243/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6274 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6159 - val_loss: 2.2567 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2461\n",
      "Epoch 1244/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7376 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7272 - val_loss: 2.2997 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.2897\n",
      "Epoch 1245/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6758 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6651 - val_loss: 2.3247 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3143\n",
      "Epoch 1246/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6668 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.6547 - val_loss: 2.4168 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4069\n",
      "Epoch 1247/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7197 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7097 - val_loss: 2.1925 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1819\n",
      "Epoch 1248/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7433 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7329 - val_loss: 2.4027 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3917\n",
      "Epoch 1249/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7844 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7744 - val_loss: 2.3790 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.3695\n",
      "Epoch 1250/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7840 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7738 - val_loss: 2.2403 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2292\n",
      "Epoch 1251/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7098 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6993 - val_loss: 2.3372 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3271\n",
      "Epoch 1252/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8138 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8030 - val_loss: 2.3598 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3494\n",
      "Epoch 1253/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7366 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7255 - val_loss: 2.2491 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.2382\n",
      "Epoch 1254/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7343 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7236 - val_loss: 2.1865 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.1746\n",
      "Epoch 1255/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7797 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7687 - val_loss: 2.3143 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3046\n",
      "Epoch 1256/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6680 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6565 - val_loss: 2.1400 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.1265\n",
      "Epoch 1257/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7833 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7718 - val_loss: 2.2529 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.2386\n",
      "Epoch 1258/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7759 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7653 - val_loss: 2.3036 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2931\n",
      "Epoch 1259/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6712 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6599 - val_loss: 2.2107 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.1969\n",
      "Epoch 1260/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7912 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7808 - val_loss: 2.3559 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.3463\n",
      "Epoch 1261/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6552 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6439 - val_loss: 2.3579 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.3459\n",
      "Epoch 1262/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6692 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6579 - val_loss: 2.0297 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.0182\n",
      "Epoch 1263/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6579 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6466 - val_loss: 2.2408 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2301\n",
      "Epoch 1264/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7055 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6952 - val_loss: 2.1840 - val_output_headline_vector_loss: 0.0249 - val_headline_token_classes_loss: 2.1592\n",
      "Epoch 1265/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7345 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7235 - val_loss: 2.2776 - val_output_headline_vector_loss: 0.0734 - val_headline_token_classes_loss: 2.2042\n",
      "Epoch 1266/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7342 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.7219 - val_loss: 2.2772 - val_output_headline_vector_loss: 0.0392 - val_headline_token_classes_loss: 2.2380\n",
      "Epoch 1267/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7648 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7547 - val_loss: 2.3707 - val_output_headline_vector_loss: 0.0300 - val_headline_token_classes_loss: 2.3407\n",
      "Epoch 1268/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6859 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6752 - val_loss: 2.2736 - val_output_headline_vector_loss: 0.0369 - val_headline_token_classes_loss: 2.2367\n",
      "Epoch 1269/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7660 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7552 - val_loss: 2.2293 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2184\n",
      "Epoch 1270/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6663 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6549 - val_loss: 2.2013 - val_output_headline_vector_loss: 0.0183 - val_headline_token_classes_loss: 2.1830\n",
      "Epoch 1271/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7152 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7047 - val_loss: 2.1115 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.0985\n",
      "Epoch 1272/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6899 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6794 - val_loss: 2.1886 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1769\n",
      "Epoch 1273/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7120 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7012 - val_loss: 2.1623 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.1476\n",
      "Epoch 1274/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 14s 4s/step - loss: 1.7872 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7770 - val_loss: 2.1842 - val_output_headline_vector_loss: 0.0188 - val_headline_token_classes_loss: 2.1654\n",
      "Epoch 1275/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8622 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8513 - val_loss: 2.5389 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.5282\n",
      "Epoch 1276/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6159 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6054 - val_loss: 2.2309 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.2179\n",
      "Epoch 1277/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7339 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7236 - val_loss: 2.2231 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.2121\n",
      "Epoch 1278/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6540 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6430 - val_loss: 2.3560 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3447\n",
      "Epoch 1279/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7136 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7026 - val_loss: 2.5469 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5364\n",
      "Epoch 1280/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7231 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7120 - val_loss: 2.1068 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.0930\n",
      "Epoch 1281/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6992 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6883 - val_loss: 2.3196 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3097\n",
      "Epoch 1282/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6415 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.6295 - val_loss: 19.7967 - val_output_headline_vector_loss: 9.8232 - val_headline_token_classes_loss: 9.9735\n",
      "Epoch 1283/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9545 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.9425 - val_loss: 3.4771 - val_output_headline_vector_loss: 1.3623 - val_headline_token_classes_loss: 2.1148\n",
      "Epoch 1284/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9900 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9793 - val_loss: 2.9771 - val_output_headline_vector_loss: 0.4762 - val_headline_token_classes_loss: 2.5009\n",
      "Epoch 1285/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0740 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0635 - val_loss: 2.4916 - val_output_headline_vector_loss: 0.2192 - val_headline_token_classes_loss: 2.2724\n",
      "Epoch 1286/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1030 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 2.0918 - val_loss: 2.3532 - val_output_headline_vector_loss: 0.0859 - val_headline_token_classes_loss: 2.2674\n",
      "Epoch 1287/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9001 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8893 - val_loss: 2.3553 - val_output_headline_vector_loss: 0.0489 - val_headline_token_classes_loss: 2.3065\n",
      "Epoch 1288/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9441 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.9343 - val_loss: 2.3435 - val_output_headline_vector_loss: 0.0300 - val_headline_token_classes_loss: 2.3134\n",
      "Epoch 1289/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9447 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9341 - val_loss: 2.2616 - val_output_headline_vector_loss: 0.0230 - val_headline_token_classes_loss: 2.2385\n",
      "Epoch 1290/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9600 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9494 - val_loss: 2.1261 - val_output_headline_vector_loss: 0.0225 - val_headline_token_classes_loss: 2.1036\n",
      "Epoch 1291/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0137 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0035 - val_loss: 2.3938 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.3802\n",
      "Epoch 1292/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8489 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8374 - val_loss: 2.3654 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3537\n",
      "Epoch 1293/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9005 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8897 - val_loss: 2.4043 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3940\n",
      "Epoch 1294/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7950 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7840 - val_loss: 2.0494 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.0373\n",
      "Epoch 1295/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8238 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8131 - val_loss: 2.1096 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.0951\n",
      "Epoch 1296/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6823 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.6704 - val_loss: 1.9393 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 1.9275\n",
      "Epoch 1297/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8003 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7892 - val_loss: 2.3430 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3327\n",
      "Epoch 1298/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8340 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8229 - val_loss: 2.1780 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1674\n",
      "Epoch 1299/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8025 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7916 - val_loss: 2.4057 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3941\n",
      "Epoch 1300/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9737 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9632 - val_loss: 1.9196 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 1.9065\n",
      "Epoch 1301/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7386 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7274 - val_loss: 2.0044 - val_output_headline_vector_loss: 0.0189 - val_headline_token_classes_loss: 1.9854\n",
      "Epoch 1302/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8754 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8651 - val_loss: 2.0046 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 1.9926\n",
      "Epoch 1303/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9044 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8939 - val_loss: 2.0066 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 1.9957\n",
      "Epoch 1304/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7498 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7388 - val_loss: 2.2110 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1990\n",
      "Epoch 1305/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7031 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6927 - val_loss: 2.2624 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2507\n",
      "Epoch 1306/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7869 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7763 - val_loss: 2.4847 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4735\n",
      "Epoch 1307/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8476 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8374 - val_loss: 2.3982 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3873\n",
      "Epoch 1308/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7629 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7518 - val_loss: 2.2532 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.2413\n",
      "Epoch 1309/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7338 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7227 - val_loss: 2.1821 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.1698\n",
      "Epoch 1310/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7637 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7531 - val_loss: 2.2691 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.2541\n",
      "Epoch 1311/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9746 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9645 - val_loss: 1.9047 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 1.8933\n",
      "Epoch 1312/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7739 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7636 - val_loss: 2.3619 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3519\n",
      "Epoch 1313/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7058 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6941 - val_loss: 2.1198 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.1082\n",
      "Epoch 1314/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7581 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7473 - val_loss: 2.4055 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3946\n",
      "Epoch 1315/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7075 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6967 - val_loss: 2.1500 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.1360\n",
      "Epoch 1316/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7617 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7500 - val_loss: 2.2927 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2820\n",
      "Epoch 1317/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8436 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8326 - val_loss: 2.5370 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.5277\n",
      "Epoch 1318/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8208 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8104 - val_loss: 2.3946 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.3848\n",
      "Epoch 1319/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8719 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8610 - val_loss: 2.1539 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.1392\n",
      "Epoch 1320/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8977 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8868 - val_loss: 2.2628 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2511\n",
      "Epoch 1321/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6839 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6726 - val_loss: 2.2218 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.2070\n",
      "Epoch 1322/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8438 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8331 - val_loss: 2.2139 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.2011\n",
      "Epoch 1323/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7526 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7410 - val_loss: 2.2038 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.1926\n",
      "Epoch 1324/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8047 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7938 - val_loss: 2.1325 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.1213\n",
      "Epoch 1325/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8478 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8377 - val_loss: 2.4132 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4028\n",
      "Epoch 1326/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8892 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8789 - val_loss: 2.0374 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.0261\n",
      "Epoch 1327/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7884 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7773 - val_loss: 2.2036 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.1924\n",
      "Epoch 1328/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7206 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7094 - val_loss: 2.4197 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.4053\n",
      "Epoch 1329/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7369 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7261 - val_loss: 2.3557 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3452\n",
      "Epoch 1330/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8745 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8635 - val_loss: 2.3626 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3515\n",
      "Epoch 1331/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7718 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7609 - val_loss: 2.1825 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.1706\n",
      "Epoch 1332/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7706 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7596 - val_loss: 2.1173 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.1029\n",
      "Epoch 1333/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8019 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7911 - val_loss: 2.0008 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 1.9899\n",
      "Epoch 1334/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7845 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7732 - val_loss: 2.3565 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3458\n",
      "Epoch 1335/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7009 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6899 - val_loss: 2.1857 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.1735\n",
      "Epoch 1336/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.6769 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6651 - val_loss: 2.1016 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.0910\n",
      "Epoch 1337/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7266 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7149 - val_loss: 2.6373 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.6281\n",
      "Epoch 1338/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6363 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6247 - val_loss: 2.2553 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2440\n",
      "Epoch 1339/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7626 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7510 - val_loss: 1.8722 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 1.8612\n",
      "Epoch 1340/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6591 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6480 - val_loss: 2.2858 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2755\n",
      "Epoch 1341/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6492 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.6374 - val_loss: 2.1926 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.1777\n",
      "Epoch 1342/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7297 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7192 - val_loss: 2.3258 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 2.3095\n",
      "Epoch 1343/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8363 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8263 - val_loss: 2.3909 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3808\n",
      "Epoch 1344/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7797 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7693 - val_loss: 2.1564 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.1453\n",
      "Epoch 1345/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7433 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7332 - val_loss: 2.1542 - val_output_headline_vector_loss: 0.0157 - val_headline_token_classes_loss: 2.1386\n",
      "Epoch 1346/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7894 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7790 - val_loss: 2.1670 - val_output_headline_vector_loss: 0.0167 - val_headline_token_classes_loss: 2.1503\n",
      "Epoch 1347/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7433 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7319 - val_loss: 2.5121 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.5015\n",
      "Epoch 1348/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.7585 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7484 - val_loss: 2.1442 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.1309\n",
      "Epoch 1349/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7317 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7204 - val_loss: 2.4407 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.4281\n",
      "Epoch 1350/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6869 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6761 - val_loss: 1.9854 - val_output_headline_vector_loss: 0.0177 - val_headline_token_classes_loss: 1.9677\n",
      "Epoch 1351/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8482 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8378 - val_loss: 2.1319 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1204\n",
      "Epoch 1352/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7622 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7515 - val_loss: 2.2741 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2630\n",
      "Epoch 1353/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6479 - output_headline_vector_loss: 0.0127 - headline_token_classes_loss: 1.6352 - val_loss: 2.4577 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4475\n",
      "Epoch 1354/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6429 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6325 - val_loss: 2.0457 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.0356\n",
      "Epoch 1355/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6928 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6811 - val_loss: 1.9846 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 1.9727\n",
      "Epoch 1356/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6645 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6540 - val_loss: 2.3047 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.2914\n",
      "Epoch 1357/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8064 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7960 - val_loss: 2.3307 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3203\n",
      "Epoch 1358/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7706 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7604 - val_loss: 2.4363 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4262\n",
      "Epoch 1359/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7260 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7154 - val_loss: 2.3672 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3546\n",
      "Epoch 1360/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7621 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7516 - val_loss: 2.3621 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3519\n",
      "Epoch 1361/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7896 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7786 - val_loss: 2.4397 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.4303\n",
      "Epoch 1362/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7550 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7447 - val_loss: 2.4191 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.4049\n",
      "Epoch 1363/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7230 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7119 - val_loss: 2.2309 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.2167\n",
      "Epoch 1364/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7447 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7340 - val_loss: 2.3642 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.3517\n",
      "Epoch 1365/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6003 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.5894 - val_loss: 2.3868 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3769\n",
      "Epoch 1366/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7229 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7116 - val_loss: 2.2794 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2684\n",
      "Epoch 1367/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6983 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6875 - val_loss: 2.2768 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.2634\n",
      "Epoch 1368/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8121 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8014 - val_loss: 2.2898 - val_output_headline_vector_loss: 0.0174 - val_headline_token_classes_loss: 2.2724\n",
      "Epoch 1369/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6574 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6471 - val_loss: 2.3610 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3503\n",
      "Epoch 1370/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7050 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6943 - val_loss: 2.4119 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.4017\n",
      "Epoch 1371/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7786 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7678 - val_loss: 2.2305 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.2190\n",
      "Epoch 1372/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6859 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6754 - val_loss: 2.0806 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.0693\n",
      "Epoch 1373/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6501 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6389 - val_loss: 2.3948 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3839\n",
      "Epoch 1374/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7280 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7171 - val_loss: 2.3993 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3891\n",
      "Epoch 1375/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7002 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6897 - val_loss: 2.1194 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1074\n",
      "Epoch 1376/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7975 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7873 - val_loss: 2.0835 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.0734\n",
      "Epoch 1377/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6461 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6344 - val_loss: 1.9961 - val_output_headline_vector_loss: 0.0191 - val_headline_token_classes_loss: 1.9770\n",
      "Epoch 1378/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.6957 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6852 - val_loss: 2.4563 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.4452\n",
      "Epoch 1379/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8122 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8017 - val_loss: 2.1000 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.0886\n",
      "Epoch 1380/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7452 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7345 - val_loss: 2.2433 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.2290\n",
      "Epoch 1381/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7180 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7073 - val_loss: 2.2609 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.2468\n",
      "Epoch 1382/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7262 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7151 - val_loss: 2.2170 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2054\n",
      "Epoch 1383/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8303 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8199 - val_loss: 2.1122 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1007\n",
      "Epoch 1384/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7512 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7405 - val_loss: 2.3841 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3735\n",
      "Epoch 1385/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8283 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8183 - val_loss: 2.0501 - val_output_headline_vector_loss: 0.0180 - val_headline_token_classes_loss: 2.0321\n",
      "Epoch 1386/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8631 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8530 - val_loss: 2.2043 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.1922\n",
      "Epoch 1387/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9011 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8900 - val_loss: 2.0081 - val_output_headline_vector_loss: 0.0172 - val_headline_token_classes_loss: 1.9909\n",
      "Epoch 1388/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7594 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7482 - val_loss: 2.2739 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.2638\n",
      "Epoch 1389/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8541 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8432 - val_loss: 2.1135 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.0983\n",
      "Epoch 1390/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8602 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8498 - val_loss: 2.3982 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3881\n",
      "Epoch 1391/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8074 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7962 - val_loss: 2.1238 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.1112\n",
      "Epoch 1392/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8035 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7930 - val_loss: 2.2405 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2297\n",
      "Epoch 1393/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8645 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8534 - val_loss: 2.0865 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.0764\n",
      "Epoch 1394/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8502 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8391 - val_loss: 2.5384 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5280\n",
      "Epoch 1395/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8709 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8602 - val_loss: 2.2954 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2841\n",
      "Epoch 1396/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8382 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8278 - val_loss: 1.9350 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 1.9240\n",
      "Epoch 1397/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8456 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8349 - val_loss: 2.1841 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.1739\n",
      "Epoch 1398/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.9022 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8909 - val_loss: 2.5007 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4909\n",
      "Epoch 1399/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9629 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.9511 - val_loss: 2.2575 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.2479\n",
      "Epoch 1400/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9449 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9343 - val_loss: 2.2259 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.2136\n",
      "Epoch 1401/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0426 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 2.0321 - val_loss: 2.3677 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3579\n",
      "Epoch 1402/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9532 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9420 - val_loss: 2.1797 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.1680\n",
      "Epoch 1403/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0312 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 2.0203 - val_loss: 2.3913 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.3780\n",
      "Epoch 1404/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1327 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.1220 - val_loss: 2.3268 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3164\n",
      "Epoch 1405/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0697 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0594 - val_loss: 2.2232 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2116\n",
      "Epoch 1406/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9341 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.9227 - val_loss: 2.3462 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3355\n",
      "Epoch 1407/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9899 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9789 - val_loss: 2.3935 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3830\n",
      "Epoch 1408/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9783 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9681 - val_loss: 2.2916 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2808\n",
      "Epoch 1409/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9811 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9700 - val_loss: 2.2906 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2794\n",
      "Epoch 1410/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1078 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0975 - val_loss: 2.0894 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.0746\n",
      "Epoch 1411/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1451 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.1348 - val_loss: 2.1953 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.1849\n",
      "Epoch 1412/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8785 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.8662 - val_loss: 2.5281 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.5185\n",
      "Epoch 1413/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0828 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0721 - val_loss: 2.1796 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1679\n",
      "Epoch 1414/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8636 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.8518 - val_loss: 2.1595 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.1463\n",
      "Epoch 1415/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0517 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 2.0410 - val_loss: 1.9701 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 1.9568\n",
      "Epoch 1416/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0172 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0069 - val_loss: 2.2740 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2635\n",
      "Epoch 1417/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.1014 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0910 - val_loss: 2.0780 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.0665\n",
      "Epoch 1418/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9436 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9325 - val_loss: 2.1703 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1596\n",
      "Epoch 1419/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9902 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.9793 - val_loss: 2.1393 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1284\n",
      "Epoch 1420/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9092 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8984 - val_loss: 2.4820 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.4715\n",
      "Epoch 1421/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9331 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9226 - val_loss: 2.2253 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.2099\n",
      "Epoch 1422/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8975 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8868 - val_loss: 2.1671 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1556\n",
      "Epoch 1423/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9629 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9524 - val_loss: 2.3177 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.3050\n",
      "Epoch 1424/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9374 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.9261 - val_loss: 2.4540 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4443\n",
      "Epoch 1425/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0854 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 2.0754 - val_loss: 2.5131 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.5030\n",
      "Epoch 1426/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8281 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8169 - val_loss: 2.3246 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3143\n",
      "Epoch 1427/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0727 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 2.0624 - val_loss: 2.4146 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.4051\n",
      "Epoch 1428/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8901 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8792 - val_loss: 2.5904 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5805\n",
      "Epoch 1429/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8795 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8683 - val_loss: 2.3080 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.2982\n",
      "Epoch 1430/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0983 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 2.0873 - val_loss: 2.7417 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.7314\n",
      "Epoch 1431/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0009 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9904 - val_loss: 2.1899 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.1788\n",
      "Epoch 1432/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8784 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8679 - val_loss: 2.3525 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3421\n",
      "Epoch 1433/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8480 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8366 - val_loss: 2.1996 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.1850\n",
      "Epoch 1434/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7953 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7836 - val_loss: 1.9540 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 1.9387\n",
      "Epoch 1435/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9347 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.9237 - val_loss: 2.2991 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.2896\n",
      "Epoch 1436/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 2.0251 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.0151 - val_loss: 2.0092 - val_output_headline_vector_loss: 0.0161 - val_headline_token_classes_loss: 1.9931\n",
      "Epoch 1437/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9799 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9691 - val_loss: 2.3685 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3576\n",
      "Epoch 1438/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8308 - output_headline_vector_loss: 0.0131 - headline_token_classes_loss: 1.8177 - val_loss: 2.4197 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4084\n",
      "Epoch 1439/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8473 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8363 - val_loss: 2.3234 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.3096\n",
      "Epoch 1440/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8648 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.8534 - val_loss: 2.1307 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.1186\n",
      "Epoch 1441/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9532 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.9436 - val_loss: 2.2584 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2478\n",
      "Epoch 1442/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9388 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9280 - val_loss: 2.1889 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1770\n",
      "Epoch 1443/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9488 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.9376 - val_loss: 2.5450 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.5353\n",
      "Epoch 1444/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8471 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8358 - val_loss: 2.0889 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.0744\n",
      "Epoch 1445/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9630 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.9519 - val_loss: 2.2112 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.1962\n",
      "Epoch 1446/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9536 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9436 - val_loss: 2.2949 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.2816\n",
      "Epoch 1447/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9239 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.9122 - val_loss: 1.9403 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 1.9295\n",
      "Epoch 1448/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8392 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8291 - val_loss: 1.9474 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 1.9344\n",
      "Epoch 1449/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9701 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9597 - val_loss: 2.3191 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3074\n",
      "Epoch 1450/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8411 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8296 - val_loss: 2.1077 - val_output_headline_vector_loss: 0.0138 - val_headline_token_classes_loss: 2.0939\n",
      "Epoch 1451/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8194 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8088 - val_loss: 2.3159 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3057\n",
      "Epoch 1452/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9712 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9609 - val_loss: 2.2716 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2600\n",
      "Epoch 1453/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8925 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.8811 - val_loss: 2.4882 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4784\n",
      "Epoch 1454/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9497 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9388 - val_loss: 2.2117 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2003\n",
      "Epoch 1455/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9063 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8956 - val_loss: 2.2489 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2375\n",
      "Epoch 1456/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8436 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8334 - val_loss: 2.3869 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.3776\n",
      "Epoch 1457/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8639 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8531 - val_loss: 2.0932 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.0799\n",
      "Epoch 1458/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9212 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9103 - val_loss: 2.6501 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.6381\n",
      "Epoch 1459/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7664 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7551 - val_loss: 2.2755 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2641\n",
      "Epoch 1460/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.8891 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8780 - val_loss: 2.0710 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.0561\n",
      "Epoch 1461/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8579 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8477 - val_loss: 2.4443 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4342\n",
      "Epoch 1462/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8170 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8065 - val_loss: 2.4367 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4254\n",
      "Epoch 1463/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8007 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.7884 - val_loss: 2.0899 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.0798\n",
      "Epoch 1464/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9172 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.9057 - val_loss: 2.3264 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3163\n",
      "Epoch 1465/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9987 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.9891 - val_loss: 2.4677 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4576\n",
      "Epoch 1466/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.9034 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8924 - val_loss: 2.0051 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 1.9932\n",
      "Epoch 1467/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8121 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8011 - val_loss: 2.4335 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4222\n",
      "Epoch 1468/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7914 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7808 - val_loss: 2.5112 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5013\n",
      "Epoch 1469/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9643 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.9539 - val_loss: 2.2188 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2081\n",
      "Epoch 1470/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9130 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9027 - val_loss: 2.3382 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3275\n",
      "Epoch 1471/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8126 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8020 - val_loss: 2.6651 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.6516\n",
      "Epoch 1472/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8381 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8275 - val_loss: 1.9982 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 1.9871\n",
      "Epoch 1473/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8527 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8429 - val_loss: 2.3049 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.2952\n",
      "Epoch 1474/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8747 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8648 - val_loss: 2.1630 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.1529\n",
      "Epoch 1475/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8073 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7962 - val_loss: 2.0972 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.0863\n",
      "Epoch 1476/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9290 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.9195 - val_loss: 2.0472 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.0346\n",
      "Epoch 1477/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8468 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8361 - val_loss: 2.2423 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2317\n",
      "Epoch 1478/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9624 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.9522 - val_loss: 2.3621 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.3504\n",
      "Epoch 1479/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7876 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7767 - val_loss: 2.1256 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1142\n",
      "Epoch 1480/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8766 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8660 - val_loss: 2.0067 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 1.9954\n",
      "Epoch 1481/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6471 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6363 - val_loss: 2.0362 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.0249\n",
      "Epoch 1482/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7491 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7373 - val_loss: 2.3480 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3377\n",
      "Epoch 1483/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.8585 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.8474 - val_loss: 2.0307 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.0186\n",
      "Epoch 1484/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7882 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7771 - val_loss: 1.8972 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 1.8842\n",
      "Epoch 1485/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8842 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8737 - val_loss: 2.1568 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.1415\n",
      "Epoch 1486/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8747 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8641 - val_loss: 2.2151 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2035\n",
      "Epoch 1487/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7864 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7759 - val_loss: 2.3463 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3353\n",
      "Epoch 1488/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7739 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7628 - val_loss: 2.1987 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1870\n",
      "Epoch 1489/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8117 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8010 - val_loss: 2.4254 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4138\n",
      "Epoch 1490/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8072 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7962 - val_loss: 2.2660 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2548\n",
      "Epoch 1491/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8686 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8585 - val_loss: 2.2625 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.2525\n",
      "Epoch 1492/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7598 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7490 - val_loss: 2.4341 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4236\n",
      "Epoch 1493/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7899 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7798 - val_loss: 2.1051 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.0938\n",
      "Epoch 1494/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 2.0173 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 2.0071 - val_loss: 2.0357 - val_output_headline_vector_loss: 0.0152 - val_headline_token_classes_loss: 2.0205\n",
      "Epoch 1495/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8257 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8157 - val_loss: 2.1276 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1170\n",
      "Epoch 1496/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8403 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8291 - val_loss: 2.3304 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.3197\n",
      "Epoch 1497/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8008 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7901 - val_loss: 2.0536 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.0408\n",
      "Epoch 1498/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7646 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7539 - val_loss: 1.9804 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 1.9628\n",
      "Epoch 1499/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8712 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.8614 - val_loss: 2.3237 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3137\n",
      "Epoch 1500/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7795 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7697 - val_loss: 2.3568 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.3472\n",
      "Epoch 1501/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7495 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7387 - val_loss: 2.0920 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.0788\n",
      "Epoch 1502/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8716 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8611 - val_loss: 2.1609 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.1504\n",
      "Epoch 1503/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7507 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7390 - val_loss: 2.5614 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.5519\n",
      "Epoch 1504/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9476 - output_headline_vector_loss: 0.0094 - headline_token_classes_loss: 1.9382 - val_loss: 1.9519 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 1.9412\n",
      "Epoch 1505/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7219 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7105 - val_loss: 1.9378 - val_output_headline_vector_loss: 0.0215 - val_headline_token_classes_loss: 1.9163\n",
      "Epoch 1506/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8265 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8159 - val_loss: 2.3277 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3173\n",
      "Epoch 1507/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8291 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8185 - val_loss: 1.9776 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 1.9651\n",
      "Epoch 1508/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8532 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8433 - val_loss: 2.1951 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.1827\n",
      "Epoch 1509/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7093 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6976 - val_loss: 2.0887 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.0777\n",
      "Epoch 1510/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8102 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7994 - val_loss: 2.1436 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.1324\n",
      "Epoch 1511/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9758 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.9658 - val_loss: 2.1363 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1248\n",
      "Epoch 1512/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8551 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8438 - val_loss: 2.4138 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.4012\n",
      "Epoch 1513/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9075 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8975 - val_loss: 2.1040 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.0918\n",
      "Epoch 1514/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6904 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6792 - val_loss: 2.2037 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1917\n",
      "Epoch 1515/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7931 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7830 - val_loss: 2.3233 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3134\n",
      "Epoch 1516/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7790 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7678 - val_loss: 2.2229 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.2083\n",
      "Epoch 1517/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7552 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7453 - val_loss: 2.2214 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.2078\n",
      "Epoch 1518/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7328 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7214 - val_loss: 2.4282 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4182\n",
      "Epoch 1519/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7043 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6936 - val_loss: 2.0958 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.0842\n",
      "Epoch 1520/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9215 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9112 - val_loss: 2.1527 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.1411\n",
      "Epoch 1521/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6846 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6734 - val_loss: 2.0058 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 1.9950\n",
      "Epoch 1522/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.7892 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7778 - val_loss: 1.7648 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 1.7530\n",
      "Epoch 1523/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7604 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7494 - val_loss: 2.4995 - val_output_headline_vector_loss: 0.0083 - val_headline_token_classes_loss: 2.4912\n",
      "Epoch 1524/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8765 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8662 - val_loss: 2.2896 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.2747\n",
      "Epoch 1525/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7589 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7484 - val_loss: 2.4654 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.4538\n",
      "Epoch 1526/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8698 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8597 - val_loss: 2.0888 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.0749\n",
      "Epoch 1527/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7669 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7555 - val_loss: 2.2775 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2671\n",
      "Epoch 1528/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8466 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8359 - val_loss: 2.3685 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3576\n",
      "Epoch 1529/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7107 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6997 - val_loss: 2.3649 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3538\n",
      "Epoch 1530/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9097 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8990 - val_loss: 2.0225 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.0115\n",
      "Epoch 1531/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7875 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7770 - val_loss: 2.2715 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2609\n",
      "Epoch 1532/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7887 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7784 - val_loss: 2.1033 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.0890\n",
      "Epoch 1533/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7118 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7006 - val_loss: 2.1246 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1140\n",
      "Epoch 1534/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9338 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.9235 - val_loss: 2.5129 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5032\n",
      "Epoch 1535/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7323 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7218 - val_loss: 2.4332 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4235\n",
      "Epoch 1536/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8633 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8527 - val_loss: 2.3123 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3023\n",
      "Epoch 1537/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7721 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7617 - val_loss: 2.3487 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3378\n",
      "Epoch 1538/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7907 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7801 - val_loss: 2.2660 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2543\n",
      "Epoch 1539/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6877 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6763 - val_loss: 2.2508 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2398\n",
      "Epoch 1540/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7136 - output_headline_vector_loss: 0.0123 - headline_token_classes_loss: 1.7014 - val_loss: 2.2182 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2070\n",
      "Epoch 1541/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.9269 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9168 - val_loss: 1.9955 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 1.9841\n",
      "Epoch 1542/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6679 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6567 - val_loss: 2.1188 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.1063\n",
      "Epoch 1543/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7657 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7547 - val_loss: 2.1762 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.1615\n",
      "Epoch 1544/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7727 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7621 - val_loss: 2.0517 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.0406\n",
      "Epoch 1545/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7713 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7609 - val_loss: 1.9555 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 1.9426\n",
      "Epoch 1546/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7312 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7197 - val_loss: 2.1015 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.0889\n",
      "Epoch 1547/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6463 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6359 - val_loss: 2.0262 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.0147\n",
      "Epoch 1548/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7759 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7655 - val_loss: 2.3228 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.3095\n",
      "Epoch 1549/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7535 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7429 - val_loss: 2.2602 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2492\n",
      "Epoch 1550/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7388 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7278 - val_loss: 1.8190 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 1.8036\n",
      "Epoch 1551/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7859 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7748 - val_loss: 2.1339 - val_output_headline_vector_loss: 0.0154 - val_headline_token_classes_loss: 2.1185\n",
      "Epoch 1552/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.9447 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9341 - val_loss: 2.2378 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2261\n",
      "Epoch 1553/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7497 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7392 - val_loss: 2.0907 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.0786\n",
      "Epoch 1554/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7966 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7852 - val_loss: 2.4540 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.4428\n",
      "Epoch 1555/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6543 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6431 - val_loss: 2.2744 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.2646\n",
      "Epoch 1556/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7720 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7605 - val_loss: 2.2037 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.1916\n",
      "Epoch 1557/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8136 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.8032 - val_loss: 2.3192 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3076\n",
      "Epoch 1558/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7116 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7006 - val_loss: 2.4690 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4587\n",
      "Epoch 1559/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8764 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8655 - val_loss: 2.1740 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1634\n",
      "Epoch 1560/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7841 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7735 - val_loss: 2.5062 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.4975\n",
      "Epoch 1561/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6699 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6593 - val_loss: 2.1408 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1291\n",
      "Epoch 1562/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7763 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7656 - val_loss: 2.3322 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3221\n",
      "Epoch 1563/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7310 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7194 - val_loss: 2.1888 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.1764\n",
      "Epoch 1564/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7371 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7260 - val_loss: 2.2377 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.2262\n",
      "Epoch 1565/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8856 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8750 - val_loss: 2.1434 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1319\n",
      "Epoch 1566/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8572 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.8461 - val_loss: 2.2908 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.2813\n",
      "Epoch 1567/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8253 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8153 - val_loss: 2.2540 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2430\n",
      "Epoch 1568/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7103 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6993 - val_loss: 2.0934 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.0788\n",
      "Epoch 1569/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7432 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7324 - val_loss: 2.1096 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.0987\n",
      "Epoch 1570/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7780 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7675 - val_loss: 2.0815 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.0706\n",
      "Epoch 1571/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8767 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8660 - val_loss: 2.2474 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.2333\n",
      "Epoch 1572/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7252 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7140 - val_loss: 2.1982 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.1881\n",
      "Epoch 1573/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6819 - output_headline_vector_loss: 0.0128 - headline_token_classes_loss: 1.6692 - val_loss: 2.2058 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 2.1903\n",
      "Epoch 1574/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8435 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8330 - val_loss: 2.2866 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2751\n",
      "Epoch 1575/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8302 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8199 - val_loss: 1.8719 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 1.8565\n",
      "Epoch 1576/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7924 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7824 - val_loss: 2.3793 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3694\n",
      "Epoch 1577/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7602 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7498 - val_loss: 2.2097 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.1970\n",
      "Epoch 1578/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6520 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6407 - val_loss: 2.4282 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.4185\n",
      "Epoch 1579/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7954 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7843 - val_loss: 2.6065 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5961\n",
      "Epoch 1580/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7643 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7539 - val_loss: 2.1820 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.1715\n",
      "Epoch 1581/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6868 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6761 - val_loss: 2.4478 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.4383\n",
      "Epoch 1582/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7093 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6978 - val_loss: 2.0447 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.0309\n",
      "Epoch 1583/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6916 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6814 - val_loss: 2.2996 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.2876\n",
      "Epoch 1584/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.7886 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7779 - val_loss: 2.4452 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.4338\n",
      "Epoch 1585/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6629 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6513 - val_loss: 2.3308 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3208\n",
      "Epoch 1586/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8404 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.8295 - val_loss: 2.2293 - val_output_headline_vector_loss: 0.0160 - val_headline_token_classes_loss: 2.2133\n",
      "Epoch 1587/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7333 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7229 - val_loss: 2.2434 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.2325\n",
      "Epoch 1588/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7397 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7288 - val_loss: 2.0416 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.0267\n",
      "Epoch 1589/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7681 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7571 - val_loss: 2.0669 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.0553\n",
      "Epoch 1590/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8598 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8497 - val_loss: 2.1431 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.1310\n",
      "Epoch 1591/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6484 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6369 - val_loss: 2.3335 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3231\n",
      "Epoch 1592/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6874 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.6755 - val_loss: 2.0470 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.0362\n",
      "Epoch 1593/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7962 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7850 - val_loss: 2.4598 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.4462\n",
      "Epoch 1594/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8078 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7972 - val_loss: 2.4059 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3957\n",
      "Epoch 1595/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7058 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.6938 - val_loss: 2.4165 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.4007\n",
      "Epoch 1596/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.8284 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8184 - val_loss: 2.5536 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5432\n",
      "Epoch 1597/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7673 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7570 - val_loss: 1.9660 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 1.9532\n",
      "Epoch 1598/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6771 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6665 - val_loss: 2.0277 - val_output_headline_vector_loss: 0.0168 - val_headline_token_classes_loss: 2.0109\n",
      "Epoch 1599/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.6787 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6681 - val_loss: 2.2826 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2715\n",
      "Epoch 1600/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8683 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8581 - val_loss: 2.1605 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.1496\n",
      "Epoch 1601/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7084 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6978 - val_loss: 2.2284 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.2159\n",
      "Epoch 1602/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8499 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8397 - val_loss: 2.4873 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4770\n",
      "Epoch 1603/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7272 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7169 - val_loss: 2.2733 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2626\n",
      "Epoch 1604/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7515 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7402 - val_loss: 2.1924 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1814\n",
      "Epoch 1605/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7070 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6960 - val_loss: 2.2318 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2205\n",
      "Epoch 1606/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8394 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8288 - val_loss: 2.2501 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.2368\n",
      "Epoch 1607/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6799 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6686 - val_loss: 2.3572 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3470\n",
      "Epoch 1608/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7786 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7672 - val_loss: 2.3349 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3249\n",
      "Epoch 1609/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5988 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.5884 - val_loss: 2.4693 - val_output_headline_vector_loss: 0.0160 - val_headline_token_classes_loss: 2.4532\n",
      "Epoch 1610/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6993 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6887 - val_loss: 2.0002 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 1.9881\n",
      "Epoch 1611/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8695 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8594 - val_loss: 2.2542 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2439\n",
      "Epoch 1612/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6687 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.6585 - val_loss: 2.1391 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.1244\n",
      "Epoch 1613/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7331 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7218 - val_loss: 2.1545 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1428\n",
      "Epoch 1614/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7893 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7790 - val_loss: 2.1378 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.1279\n",
      "Epoch 1615/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6679 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6567 - val_loss: 1.9663 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 1.9546\n",
      "Epoch 1616/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8394 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.8286 - val_loss: 2.1474 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.1332\n",
      "Epoch 1617/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7774 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.7679 - val_loss: 2.4898 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.4766\n",
      "Epoch 1618/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6940 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6833 - val_loss: 2.1804 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.1695\n",
      "Epoch 1619/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7852 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7753 - val_loss: 2.4051 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.3932\n",
      "Epoch 1620/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7853 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7744 - val_loss: 1.7989 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 1.7834\n",
      "Epoch 1621/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6743 - output_headline_vector_loss: 0.0121 - headline_token_classes_loss: 1.6623 - val_loss: 2.0876 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.0758\n",
      "Epoch 1622/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6661 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6552 - val_loss: 2.2053 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1945\n",
      "Epoch 1623/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7409 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7306 - val_loss: 2.1384 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1274\n",
      "Epoch 1624/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7152 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7038 - val_loss: 2.1804 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 2.1653\n",
      "Epoch 1625/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7050 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6944 - val_loss: 2.0069 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 1.9893\n",
      "Epoch 1626/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7111 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7005 - val_loss: 2.2318 - val_output_headline_vector_loss: 0.0211 - val_headline_token_classes_loss: 2.2108\n",
      "Epoch 1627/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7351 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7250 - val_loss: 2.1223 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.1110\n",
      "Epoch 1628/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7356 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7252 - val_loss: 2.1135 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.1008\n",
      "Epoch 1629/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8287 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.8184 - val_loss: 2.2105 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.1999\n",
      "Epoch 1630/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7541 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7437 - val_loss: 2.3380 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.3277\n",
      "Epoch 1631/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6513 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6403 - val_loss: 2.3771 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3668\n",
      "Epoch 1632/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7162 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7056 - val_loss: 2.1180 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.1057\n",
      "Epoch 1633/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6914 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6803 - val_loss: 2.3330 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3226\n",
      "Epoch 1634/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7939 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7832 - val_loss: 2.0423 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.0272\n",
      "Epoch 1635/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7018 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6908 - val_loss: 2.2952 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.2815\n",
      "Epoch 1636/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6353 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6245 - val_loss: 2.1845 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.1723\n",
      "Epoch 1637/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8734 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8628 - val_loss: 2.2933 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.2836\n",
      "Epoch 1638/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6364 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6255 - val_loss: 2.1673 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.1539\n",
      "Epoch 1639/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6990 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6886 - val_loss: 2.3230 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.3135\n",
      "Epoch 1640/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7351 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.7239 - val_loss: 2.1948 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1828\n",
      "Epoch 1641/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7243 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7138 - val_loss: 2.2024 - val_output_headline_vector_loss: 0.0174 - val_headline_token_classes_loss: 2.1850\n",
      "Epoch 1642/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7452 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7341 - val_loss: 2.4713 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.4598\n",
      "Epoch 1643/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7183 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7070 - val_loss: 2.1832 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.1693\n",
      "Epoch 1644/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.5912 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.5792 - val_loss: 1.8133 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 1.8013\n",
      "Epoch 1645/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7277 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7173 - val_loss: 2.1092 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.0975\n",
      "Epoch 1646/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 15s 4s/step - loss: 1.6723 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6616 - val_loss: 2.2316 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.2216\n",
      "Epoch 1647/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6524 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6415 - val_loss: 2.2742 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2635\n",
      "Epoch 1648/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6882 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6770 - val_loss: 1.9932 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 1.9823\n",
      "Epoch 1649/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7197 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7089 - val_loss: 2.3918 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.3806\n",
      "Epoch 1650/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7028 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6921 - val_loss: 2.3449 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.3355\n",
      "Epoch 1651/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.6321 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6211 - val_loss: 2.2985 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.2851\n",
      "Epoch 1652/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6051 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.5931 - val_loss: 2.4711 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4613\n",
      "Epoch 1653/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7762 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7653 - val_loss: 2.4047 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3945\n",
      "Epoch 1654/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8027 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7929 - val_loss: 2.0434 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 2.0279\n",
      "Epoch 1655/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7810 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7700 - val_loss: 2.3186 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3079\n",
      "Epoch 1656/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6663 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6555 - val_loss: 2.2421 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.2301\n",
      "Epoch 1657/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6840 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6730 - val_loss: 2.6279 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.6173\n",
      "Epoch 1658/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7916 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7813 - val_loss: 2.2744 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2638\n",
      "Epoch 1659/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5994 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.5877 - val_loss: 2.1783 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.1666\n",
      "Epoch 1660/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9431 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9330 - val_loss: 2.0771 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.0651\n",
      "Epoch 1661/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7260 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7145 - val_loss: 2.1319 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.1196\n",
      "Epoch 1662/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6187 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6070 - val_loss: 1.9489 - val_output_headline_vector_loss: 0.0181 - val_headline_token_classes_loss: 1.9307\n",
      "Epoch 1663/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.9179 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.9072 - val_loss: 2.2661 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.2564\n",
      "Epoch 1664/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.8003 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7899 - val_loss: 2.1384 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.1232\n",
      "Epoch 1665/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7410 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7300 - val_loss: 2.3472 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.3360\n",
      "Epoch 1666/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6715 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6604 - val_loss: 2.3529 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.3436\n",
      "Epoch 1667/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7047 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6938 - val_loss: 2.4507 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.4411\n",
      "Epoch 1668/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7228 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7123 - val_loss: 2.2974 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.2877\n",
      "Epoch 1669/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7781 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7682 - val_loss: 2.4457 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4358\n",
      "Epoch 1670/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8167 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.8066 - val_loss: 2.1785 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.1647\n",
      "Epoch 1671/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7137 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7034 - val_loss: 2.1036 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.0918\n",
      "Epoch 1672/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8440 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.8341 - val_loss: 2.2365 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2261\n",
      "Epoch 1673/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6594 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6480 - val_loss: 2.2759 - val_output_headline_vector_loss: 0.0135 - val_headline_token_classes_loss: 2.2624\n",
      "Epoch 1674/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7455 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7352 - val_loss: 2.3962 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3860\n",
      "Epoch 1675/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7667 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7558 - val_loss: 2.4046 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.3924\n",
      "Epoch 1676/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7272 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7163 - val_loss: 2.1788 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1680\n",
      "Epoch 1677/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7880 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7770 - val_loss: 2.2558 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2444\n",
      "Epoch 1678/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7358 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7256 - val_loss: 2.3958 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.3833\n",
      "Epoch 1679/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7347 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.7234 - val_loss: 2.2000 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1891\n",
      "Epoch 1680/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7361 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7253 - val_loss: 2.1989 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1881\n",
      "Epoch 1681/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7803 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7702 - val_loss: 2.2195 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.2061\n",
      "Epoch 1682/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7035 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6929 - val_loss: 2.2882 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2776\n",
      "Epoch 1683/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6542 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6430 - val_loss: 2.2399 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2285\n",
      "Epoch 1684/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6782 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6671 - val_loss: 2.3532 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3425\n",
      "Epoch 1685/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6693 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6592 - val_loss: 2.0566 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.0456\n",
      "Epoch 1686/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7806 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7699 - val_loss: 2.4560 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4456\n",
      "Epoch 1687/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8764 - output_headline_vector_loss: 0.0094 - headline_token_classes_loss: 1.8670 - val_loss: 2.2468 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.2355\n",
      "Epoch 1688/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6846 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6738 - val_loss: 1.9517 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 1.9347\n",
      "Epoch 1689/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6836 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6730 - val_loss: 2.2518 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2414\n",
      "Epoch 1690/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.5784 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.5681 - val_loss: 2.5744 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.5647\n",
      "Epoch 1691/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7754 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7652 - val_loss: 2.2274 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.2137\n",
      "Epoch 1692/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7069 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6957 - val_loss: 2.1711 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1597\n",
      "Epoch 1693/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6413 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.6296 - val_loss: 2.1087 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.0938\n",
      "Epoch 1694/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7104 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6998 - val_loss: 2.0785 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.0660\n",
      "Epoch 1695/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6263 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6153 - val_loss: 2.2211 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2101\n",
      "Epoch 1696/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.4862 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.4744 - val_loss: 2.3799 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3683\n",
      "Epoch 1697/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5834 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.5712 - val_loss: 1.8951 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 1.8830\n",
      "Epoch 1698/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6394 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6281 - val_loss: 2.0503 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.0383\n",
      "Epoch 1699/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6877 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6765 - val_loss: 2.1975 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.1840\n",
      "Epoch 1700/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7801 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7697 - val_loss: 2.1971 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.1861\n",
      "Epoch 1701/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6914 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6802 - val_loss: 1.9832 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 1.9702\n",
      "Epoch 1702/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7477 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7371 - val_loss: 2.0944 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.0836\n",
      "Epoch 1703/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7071 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6969 - val_loss: 2.1859 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1742\n",
      "Epoch 1704/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7405 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7300 - val_loss: 2.0569 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.0420\n",
      "Epoch 1705/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6768 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6667 - val_loss: 2.3489 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3378\n",
      "Epoch 1706/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6938 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6828 - val_loss: 2.0659 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.0554\n",
      "Epoch 1707/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7658 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7551 - val_loss: 2.1935 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.1834\n",
      "Epoch 1708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 16s 4s/step - loss: 1.6344 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6233 - val_loss: 2.7270 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.7174\n",
      "Epoch 1709/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5629 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.5521 - val_loss: 2.1507 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 2.1375\n",
      "Epoch 1710/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6068 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.5963 - val_loss: 2.1512 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1405\n",
      "Epoch 1711/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7321 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7216 - val_loss: 2.3457 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3351\n",
      "Epoch 1712/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6385 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6273 - val_loss: 2.3250 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3141\n",
      "Epoch 1713/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7688 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7586 - val_loss: 2.3030 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.2920\n",
      "Epoch 1714/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6628 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6513 - val_loss: 2.5145 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.5028\n",
      "Epoch 1715/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6762 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6646 - val_loss: 2.0219 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.0106\n",
      "Epoch 1716/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6287 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6183 - val_loss: 2.4934 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.4817\n",
      "Epoch 1717/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6947 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6838 - val_loss: 2.2819 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.2720\n",
      "Epoch 1718/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6268 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6162 - val_loss: 2.2850 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2746\n",
      "Epoch 1719/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6573 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.6453 - val_loss: 2.5219 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.5077\n",
      "Epoch 1720/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6358 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6254 - val_loss: 2.2243 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.2121\n",
      "Epoch 1721/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7208 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7104 - val_loss: 2.2087 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.1971\n",
      "Epoch 1722/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7546 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7446 - val_loss: 1.9705 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 1.9585\n",
      "Epoch 1723/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7152 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7046 - val_loss: 2.3078 - val_output_headline_vector_loss: 0.0160 - val_headline_token_classes_loss: 2.2918\n",
      "Epoch 1724/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5742 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.5628 - val_loss: 2.3192 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3081\n",
      "Epoch 1725/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7444 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.7343 - val_loss: 2.3787 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.3629\n",
      "Epoch 1726/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6458 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6349 - val_loss: 2.0272 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.0155\n",
      "Epoch 1727/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6471 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.6350 - val_loss: 2.0633 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.0515\n",
      "Epoch 1728/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6453 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6349 - val_loss: 1.9186 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 1.9023\n",
      "Epoch 1729/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6856 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6751 - val_loss: 1.9851 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 1.9743\n",
      "Epoch 1730/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7749 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7645 - val_loss: 1.8724 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 1.8574\n",
      "Epoch 1731/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6277 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6163 - val_loss: 2.3796 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3690\n",
      "Epoch 1732/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6591 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6488 - val_loss: 2.4919 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4820\n",
      "Epoch 1733/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6489 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6379 - val_loss: 2.3843 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.3748\n",
      "Epoch 1734/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6178 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6069 - val_loss: 2.2099 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.1981\n",
      "Epoch 1735/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6532 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6422 - val_loss: 2.2932 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2827\n",
      "Epoch 1736/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.6650 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6550 - val_loss: 2.3170 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3060\n",
      "Epoch 1737/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6807 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6701 - val_loss: 2.1201 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.1095\n",
      "Epoch 1738/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6775 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6668 - val_loss: 2.6005 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.5907\n",
      "Epoch 1739/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6811 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6704 - val_loss: 2.0116 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.0001\n",
      "Epoch 1740/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6667 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6560 - val_loss: 1.9290 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 1.9171\n",
      "Epoch 1741/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6607 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6496 - val_loss: 2.0795 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 2.0641\n",
      "Epoch 1742/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6363 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6258 - val_loss: 2.3166 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3061\n",
      "Epoch 1743/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6864 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6758 - val_loss: 2.2014 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.1915\n",
      "Epoch 1744/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6875 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6763 - val_loss: 2.2381 - val_output_headline_vector_loss: 0.0163 - val_headline_token_classes_loss: 2.2218\n",
      "Epoch 1745/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8517 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8410 - val_loss: 2.1183 - val_output_headline_vector_loss: 0.0149 - val_headline_token_classes_loss: 2.1035\n",
      "Epoch 1746/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7135 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7031 - val_loss: 2.2806 - val_output_headline_vector_loss: 0.2429 - val_headline_token_classes_loss: 2.0377\n",
      "Epoch 1747/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7872 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7763 - val_loss: 2.3660 - val_output_headline_vector_loss: 0.0934 - val_headline_token_classes_loss: 2.2726\n",
      "Epoch 1748/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7756 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.7641 - val_loss: 2.3773 - val_output_headline_vector_loss: 0.0364 - val_headline_token_classes_loss: 2.3409\n",
      "Epoch 1749/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8046 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7944 - val_loss: 2.6131 - val_output_headline_vector_loss: 0.1662 - val_headline_token_classes_loss: 2.4468\n",
      "Epoch 1750/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7636 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7532 - val_loss: 2.3382 - val_output_headline_vector_loss: 0.0677 - val_headline_token_classes_loss: 2.2705\n",
      "Epoch 1751/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7742 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7636 - val_loss: 2.3973 - val_output_headline_vector_loss: 0.0491 - val_headline_token_classes_loss: 2.3482\n",
      "Epoch 1752/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6857 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6751 - val_loss: 2.0970 - val_output_headline_vector_loss: 0.0276 - val_headline_token_classes_loss: 2.0695\n",
      "Epoch 1753/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8975 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.8862 - val_loss: 2.0716 - val_output_headline_vector_loss: 0.0283 - val_headline_token_classes_loss: 2.0432\n",
      "Epoch 1754/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7426 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7323 - val_loss: 2.2604 - val_output_headline_vector_loss: 0.0197 - val_headline_token_classes_loss: 2.2406\n",
      "Epoch 1755/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.8864 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.8753 - val_loss: 2.2022 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.1891\n",
      "Epoch 1756/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7442 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7334 - val_loss: 2.1033 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.0882\n",
      "Epoch 1757/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.8060 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7958 - val_loss: 2.4487 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.4357\n",
      "Epoch 1758/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.5992 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.5881 - val_loss: 2.0548 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.0433\n",
      "Epoch 1759/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6345 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6237 - val_loss: 2.2028 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.1906\n",
      "Epoch 1760/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.6249 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6139 - val_loss: 1.9270 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 1.9146\n",
      "Epoch 1761/2000\n",
      "4/4 [==============================] - 17s 4s/step - loss: 1.7157 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7053 - val_loss: 2.3480 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.3339\n",
      "Epoch 1762/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.6657 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6552 - val_loss: 2.5253 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.5153\n",
      "Epoch 1763/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6477 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6366 - val_loss: 2.1855 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.1724\n",
      "Epoch 1764/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7278 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.7162 - val_loss: 2.3210 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.3101\n",
      "Epoch 1765/2000\n",
      "4/4 [==============================] - 16s 4s/step - loss: 1.7879 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7776 - val_loss: 2.5590 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5497\n",
      "Epoch 1766/2000\n",
      "4/4 [==============================] - 15s 4s/step - loss: 1.7715 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7611 - val_loss: 2.1238 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.1136\n",
      "Epoch 1767/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7068 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.6953 - val_loss: 2.4234 - val_output_headline_vector_loss: 0.0085 - val_headline_token_classes_loss: 2.4149\n",
      "Epoch 1768/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6831 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6722 - val_loss: 2.1100 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.0972\n",
      "Epoch 1769/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6797 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6689 - val_loss: 2.0762 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.0655\n",
      "Epoch 1770/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 3s/step - loss: 1.7903 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.7794 - val_loss: 2.1954 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1846\n",
      "Epoch 1771/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6052 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.5940 - val_loss: 2.1278 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.1152\n",
      "Epoch 1772/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7305 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7200 - val_loss: 2.0953 - val_output_headline_vector_loss: 0.0162 - val_headline_token_classes_loss: 2.0790\n",
      "Epoch 1773/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7127 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.7009 - val_loss: 1.9915 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 1.9785\n",
      "Epoch 1774/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7220 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7120 - val_loss: 2.1646 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.1535\n",
      "Epoch 1775/2000\n",
      "4/4 [==============================] - 14s 4s/step - loss: 1.7260 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7156 - val_loss: 2.3233 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.3093\n",
      "Epoch 1776/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6384 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6275 - val_loss: 2.3063 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.2961\n",
      "Epoch 1777/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8276 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.8176 - val_loss: 2.1506 - val_output_headline_vector_loss: 0.0147 - val_headline_token_classes_loss: 2.1359\n",
      "Epoch 1778/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8203 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8097 - val_loss: 2.2897 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.2800\n",
      "Epoch 1779/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.9257 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.9149 - val_loss: 2.1738 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.1599\n",
      "Epoch 1780/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6617 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6501 - val_loss: 2.2571 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2457\n",
      "Epoch 1781/2000\n",
      "4/4 [==============================] - 14s 3s/step - loss: 1.6679 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6567 - val_loss: 2.2136 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2015\n",
      "Epoch 1782/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6727 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6624 - val_loss: 2.1718 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1608\n",
      "Epoch 1783/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6919 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6814 - val_loss: 2.6447 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.6344\n",
      "Epoch 1784/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8167 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.8070 - val_loss: 2.3677 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3570\n",
      "Epoch 1785/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7535 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.7431 - val_loss: 2.1737 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.1614\n",
      "Epoch 1786/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6137 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6028 - val_loss: 2.5468 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5360\n",
      "Epoch 1787/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6677 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6575 - val_loss: 2.0432 - val_output_headline_vector_loss: 0.0151 - val_headline_token_classes_loss: 2.0281\n",
      "Epoch 1788/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7193 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7083 - val_loss: 2.3399 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3293\n",
      "Epoch 1789/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6843 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6735 - val_loss: 2.3742 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.3626\n",
      "Epoch 1790/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7435 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7338 - val_loss: 2.2448 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2341\n",
      "Epoch 1791/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7286 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7186 - val_loss: 2.0096 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 1.9941\n",
      "Epoch 1792/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.5680 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.5572 - val_loss: 2.5643 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5544\n",
      "Epoch 1793/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7362 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.7265 - val_loss: 2.2566 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2460\n",
      "Epoch 1794/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6610 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6496 - val_loss: 2.3937 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3822\n",
      "Epoch 1795/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6639 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6527 - val_loss: 2.5258 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.5121\n",
      "Epoch 1796/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6579 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6477 - val_loss: 2.2908 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 2.2732\n",
      "Epoch 1797/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6587 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6480 - val_loss: 2.1365 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1257\n",
      "Epoch 1798/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6375 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6259 - val_loss: 2.2264 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2143\n",
      "Epoch 1799/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6624 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.6525 - val_loss: 2.3838 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3737\n",
      "Epoch 1800/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6721 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6615 - val_loss: 2.1697 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.1600\n",
      "Epoch 1801/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.5920 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.5817 - val_loss: 2.3100 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.2992\n",
      "Epoch 1802/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7473 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7375 - val_loss: 2.0497 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.0361\n",
      "Epoch 1803/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6611 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6503 - val_loss: 2.2917 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.2818\n",
      "Epoch 1804/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6304 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6192 - val_loss: 2.2654 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.2536\n",
      "Epoch 1805/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6388 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6279 - val_loss: 2.6874 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.6775\n",
      "Epoch 1806/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7557 - output_headline_vector_loss: 0.0094 - headline_token_classes_loss: 1.7462 - val_loss: 2.1040 - val_output_headline_vector_loss: 0.0155 - val_headline_token_classes_loss: 2.0885\n",
      "Epoch 1807/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6600 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6483 - val_loss: 2.3575 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3462\n",
      "Epoch 1808/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7360 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.7250 - val_loss: 2.5289 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.5180\n",
      "Epoch 1809/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6559 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.6446 - val_loss: 2.1518 - val_output_headline_vector_loss: 0.0181 - val_headline_token_classes_loss: 2.1337\n",
      "Epoch 1810/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6624 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6517 - val_loss: 2.1244 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1130\n",
      "Epoch 1811/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6475 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6365 - val_loss: 2.2376 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2264\n",
      "Epoch 1812/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7483 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.7369 - val_loss: 2.4418 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4309\n",
      "Epoch 1813/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6776 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6673 - val_loss: 2.0534 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.0407\n",
      "Epoch 1814/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6298 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.6196 - val_loss: 2.1219 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1104\n",
      "Epoch 1815/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.5746 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.5626 - val_loss: 2.4851 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.4760\n",
      "Epoch 1816/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7093 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6992 - val_loss: 2.1756 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1649\n",
      "Epoch 1817/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7679 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.7577 - val_loss: 2.2232 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.2118\n",
      "Epoch 1818/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7114 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 1.7018 - val_loss: 2.2318 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.2222\n",
      "Epoch 1819/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6595 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6486 - val_loss: 2.1579 - val_output_headline_vector_loss: 0.0143 - val_headline_token_classes_loss: 2.1436\n",
      "Epoch 1820/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6689 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6586 - val_loss: 2.3682 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3571\n",
      "Epoch 1821/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7309 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7211 - val_loss: 2.0757 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.0637\n",
      "Epoch 1822/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.8310 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.8205 - val_loss: 2.3944 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.3831\n",
      "Epoch 1823/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6445 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6341 - val_loss: 2.5126 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.5022\n",
      "Epoch 1824/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6531 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6426 - val_loss: 2.0631 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.0518\n",
      "Epoch 1825/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6187 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6072 - val_loss: 2.2667 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.2538\n",
      "Epoch 1826/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6738 - output_headline_vector_loss: 0.0120 - headline_token_classes_loss: 1.6618 - val_loss: 2.2475 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.2339\n",
      "Epoch 1827/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6291 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.6177 - val_loss: 2.1673 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.1566\n",
      "Epoch 1828/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6720 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6612 - val_loss: 2.4943 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.4807\n",
      "Epoch 1829/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6884 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6781 - val_loss: 2.3497 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3395\n",
      "Epoch 1830/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.7178 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.7084 - val_loss: 2.0409 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.0297\n",
      "Epoch 1831/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6104 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.5994 - val_loss: 2.4209 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4102\n",
      "Epoch 1832/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 12s 3s/step - loss: 1.6139 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6033 - val_loss: 2.5014 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.4914\n",
      "Epoch 1833/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.8128 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.8011 - val_loss: 2.4496 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.4385\n",
      "Epoch 1834/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6632 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6524 - val_loss: 2.2082 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.1948\n",
      "Epoch 1835/2000\n",
      "4/4 [==============================] - 13s 3s/step - loss: 1.6988 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6888 - val_loss: 2.0943 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.0803\n",
      "Epoch 1836/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6613 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6509 - val_loss: 2.2957 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2846\n",
      "Epoch 1837/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6862 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.6763 - val_loss: 2.2436 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2331\n",
      "Epoch 1838/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6567 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6462 - val_loss: 2.3556 - val_output_headline_vector_loss: 0.0136 - val_headline_token_classes_loss: 2.3420\n",
      "Epoch 1839/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6172 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6061 - val_loss: 2.3172 - val_output_headline_vector_loss: 0.0176 - val_headline_token_classes_loss: 2.2996\n",
      "Epoch 1840/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6062 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.5957 - val_loss: 2.3725 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3618\n",
      "Epoch 1841/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.7218 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7114 - val_loss: 2.5476 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5373\n",
      "Epoch 1842/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6680 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6576 - val_loss: 2.4028 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3919\n",
      "Epoch 1843/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6584 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6473 - val_loss: 2.2191 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2079\n",
      "Epoch 1844/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6136 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6026 - val_loss: 2.1822 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.1714\n",
      "Epoch 1845/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.5916 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.5813 - val_loss: 2.2170 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2066\n",
      "Epoch 1846/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.5433 - output_headline_vector_loss: 0.0122 - headline_token_classes_loss: 1.5311 - val_loss: 2.4971 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4871\n",
      "Epoch 1847/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6875 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6770 - val_loss: 2.2559 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.2439\n",
      "Epoch 1848/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6286 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6180 - val_loss: 2.2200 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2092\n",
      "Epoch 1849/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7911 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.7804 - val_loss: 1.9983 - val_output_headline_vector_loss: 0.0170 - val_headline_token_classes_loss: 1.9814\n",
      "Epoch 1850/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6687 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6574 - val_loss: 2.1269 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.1152\n",
      "Epoch 1851/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6457 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6347 - val_loss: 2.4000 - val_output_headline_vector_loss: 0.0087 - val_headline_token_classes_loss: 2.3913\n",
      "Epoch 1852/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.7060 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.6947 - val_loss: 2.2852 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.2735\n",
      "Epoch 1853/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.5958 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.5851 - val_loss: 2.1556 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.1414\n",
      "Epoch 1854/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6691 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6581 - val_loss: 2.3068 - val_output_headline_vector_loss: 0.0142 - val_headline_token_classes_loss: 2.2926\n",
      "Epoch 1855/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6252 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6143 - val_loss: 2.1705 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.1587\n",
      "Epoch 1856/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.5788 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.5677 - val_loss: 2.3803 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 2.3676\n",
      "Epoch 1857/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.5902 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.5791 - val_loss: 2.4636 - val_output_headline_vector_loss: 0.0126 - val_headline_token_classes_loss: 2.4510\n",
      "Epoch 1858/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6967 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6859 - val_loss: 2.2752 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.2650\n",
      "Epoch 1859/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6578 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.6480 - val_loss: 2.3592 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3478\n",
      "Epoch 1860/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5503 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.5389 - val_loss: 2.2036 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.1918\n",
      "Epoch 1861/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7602 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.7495 - val_loss: 2.5121 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.5026\n",
      "Epoch 1862/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7871 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7771 - val_loss: 2.3771 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3671\n",
      "Epoch 1863/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6168 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6059 - val_loss: 2.2382 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2274\n",
      "Epoch 1864/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6430 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6327 - val_loss: 2.2508 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.2397\n",
      "Epoch 1865/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.5311 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.5198 - val_loss: 2.3515 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3401\n",
      "Epoch 1866/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6666 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6566 - val_loss: 2.2443 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2331\n",
      "Epoch 1867/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.5787 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.5674 - val_loss: 4.9908 - val_output_headline_vector_loss: 0.0128 - val_headline_token_classes_loss: 4.9780\n",
      "Epoch 1868/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.7263 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7159 - val_loss: 2.5183 - val_output_headline_vector_loss: 0.0146 - val_headline_token_classes_loss: 2.5037\n",
      "Epoch 1869/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.5984 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.5871 - val_loss: 3.9646 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 3.9532\n",
      "Epoch 1870/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.6698 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6597 - val_loss: 2.4697 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4588\n",
      "Epoch 1871/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7222 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.7125 - val_loss: 2.3832 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3723\n",
      "Epoch 1872/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6224 - output_headline_vector_loss: 0.0116 - headline_token_classes_loss: 1.6108 - val_loss: 2.5666 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5555\n",
      "Epoch 1873/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6672 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6570 - val_loss: 2.3228 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3127\n",
      "Epoch 1874/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6655 - output_headline_vector_loss: 0.0092 - headline_token_classes_loss: 1.6563 - val_loss: 2.1601 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.1490\n",
      "Epoch 1875/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6755 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6649 - val_loss: 2.2196 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.2051\n",
      "Epoch 1876/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6142 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6034 - val_loss: 2.2751 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2640\n",
      "Epoch 1877/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6942 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6832 - val_loss: 2.3233 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.3131\n",
      "Epoch 1878/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6361 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6252 - val_loss: 2.3712 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.3601\n",
      "Epoch 1879/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.5716 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.5608 - val_loss: 2.5074 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.4984\n",
      "Epoch 1880/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6525 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.6415 - val_loss: 2.2849 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.2744\n",
      "Epoch 1881/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5861 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.5747 - val_loss: 2.2814 - val_output_headline_vector_loss: 0.0133 - val_headline_token_classes_loss: 2.2681\n",
      "Epoch 1882/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6281 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6176 - val_loss: 2.5682 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.5579\n",
      "Epoch 1883/2000\n",
      "4/4 [==============================] - 12s 3s/step - loss: 1.6602 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6498 - val_loss: 2.5259 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.5150\n",
      "Epoch 1884/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6426 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.6324 - val_loss: 2.4114 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.4015\n",
      "Epoch 1885/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6139 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6036 - val_loss: 2.4495 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4386\n",
      "Epoch 1886/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.5970 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.5856 - val_loss: 2.1212 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.1109\n",
      "Epoch 1887/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.7615 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.7508 - val_loss: 1.9901 - val_output_headline_vector_loss: 0.0132 - val_headline_token_classes_loss: 1.9769\n",
      "Epoch 1888/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6482 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.6380 - val_loss: 2.3823 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.3720\n",
      "Epoch 1889/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.5811 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.5699 - val_loss: 2.1019 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.0897\n",
      "Epoch 1890/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6269 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6163 - val_loss: 2.8068 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.7974\n",
      "Epoch 1891/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6218 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6112 - val_loss: 2.5054 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.4955\n",
      "Epoch 1892/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6072 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.5959 - val_loss: 2.6582 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.6486\n",
      "Epoch 1893/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6443 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6334 - val_loss: 2.3667 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.3558\n",
      "Epoch 1894/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 11s 3s/step - loss: 1.6243 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6136 - val_loss: 2.3821 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.3703\n",
      "Epoch 1895/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.7177 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.7078 - val_loss: 2.1412 - val_output_headline_vector_loss: 0.0110 - val_headline_token_classes_loss: 2.1302\n",
      "Epoch 1896/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6075 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.5970 - val_loss: 2.1480 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.1358\n",
      "Epoch 1897/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6466 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.6368 - val_loss: 1.9193 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 1.9044\n",
      "Epoch 1898/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.6522 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6411 - val_loss: 2.4928 - val_output_headline_vector_loss: 0.0091 - val_headline_token_classes_loss: 2.4837\n",
      "Epoch 1899/2000\n",
      "4/4 [==============================] - 11s 3s/step - loss: 1.6376 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6269 - val_loss: 2.3979 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.3868\n",
      "Epoch 1900/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6758 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.6659 - val_loss: 2.0388 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.0269\n",
      "Epoch 1901/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7624 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.7524 - val_loss: 2.0685 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.0573\n",
      "Epoch 1902/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.6360 - output_headline_vector_loss: 0.0093 - headline_token_classes_loss: 1.6267 - val_loss: 2.4069 - val_output_headline_vector_loss: 0.0098 - val_headline_token_classes_loss: 2.3971\n",
      "Epoch 1903/2000\n",
      "4/4 [==============================] - 10s 3s/step - loss: 1.5976 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.5861 - val_loss: 2.3444 - val_output_headline_vector_loss: 0.0113 - val_headline_token_classes_loss: 2.3332\n",
      "Epoch 1904/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.6981 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6880 - val_loss: 2.3139 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3039\n",
      "Epoch 1905/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6312 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6203 - val_loss: 2.2608 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.2504\n",
      "Epoch 1906/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.5986 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.5878 - val_loss: 2.4824 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.4729\n",
      "Epoch 1907/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6509 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6400 - val_loss: 2.3345 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.3248\n",
      "Epoch 1908/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5745 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.5640 - val_loss: 2.4523 - val_output_headline_vector_loss: 0.0094 - val_headline_token_classes_loss: 2.4429\n",
      "Epoch 1909/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6234 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6129 - val_loss: 2.2186 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2083\n",
      "Epoch 1910/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6935 - output_headline_vector_loss: 0.0092 - headline_token_classes_loss: 1.6843 - val_loss: 2.7443 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.7320\n",
      "Epoch 1911/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.6668 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6563 - val_loss: 2.1921 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.1816\n",
      "Epoch 1912/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.6828 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6722 - val_loss: 2.0257 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.0150\n",
      "Epoch 1913/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.7129 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7026 - val_loss: 2.2011 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.1914\n",
      "Epoch 1914/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6383 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6280 - val_loss: 2.1841 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.1727\n",
      "Epoch 1915/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6355 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6249 - val_loss: 2.5708 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.5603\n",
      "Epoch 1916/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.5445 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.5337 - val_loss: 2.4743 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.4640\n",
      "Epoch 1917/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6779 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.6673 - val_loss: 2.2111 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.2009\n",
      "Epoch 1918/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6728 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6625 - val_loss: 2.2136 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2033\n",
      "Epoch 1919/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6086 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.5976 - val_loss: 2.5034 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4934\n",
      "Epoch 1920/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.7614 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7510 - val_loss: 2.2369 - val_output_headline_vector_loss: 0.0118 - val_headline_token_classes_loss: 2.2252\n",
      "Epoch 1921/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6525 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6423 - val_loss: 2.4923 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.4824\n",
      "Epoch 1922/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.5601 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.5488 - val_loss: 2.3415 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.3271\n",
      "Epoch 1923/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5645 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.5541 - val_loss: 2.6307 - val_output_headline_vector_loss: 0.0090 - val_headline_token_classes_loss: 2.6217\n",
      "Epoch 1924/2000\n",
      "4/4 [==============================] - 10s 2s/step - loss: 1.6271 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6166 - val_loss: 2.3098 - val_output_headline_vector_loss: 0.0112 - val_headline_token_classes_loss: 2.2987\n",
      "Epoch 1925/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6203 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6095 - val_loss: 2.2745 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.2650\n",
      "Epoch 1926/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6137 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6033 - val_loss: 2.3468 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3368\n",
      "Epoch 1927/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5573 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.5470 - val_loss: 2.2293 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.2186\n",
      "Epoch 1928/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.5429 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.5326 - val_loss: 2.1760 - val_output_headline_vector_loss: 0.0139 - val_headline_token_classes_loss: 2.1621\n",
      "Epoch 1929/2000\n",
      "4/4 [==============================] - 9s 2s/step - loss: 1.6703 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.6608 - val_loss: 2.1751 - val_output_headline_vector_loss: 0.0124 - val_headline_token_classes_loss: 2.1628\n",
      "Epoch 1930/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.5308 - output_headline_vector_loss: 0.0115 - headline_token_classes_loss: 1.5193 - val_loss: 2.6089 - val_output_headline_vector_loss: 0.0127 - val_headline_token_classes_loss: 2.5962\n",
      "Epoch 1931/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6600 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.6491 - val_loss: 2.2297 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.2192\n",
      "Epoch 1932/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6102 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.5996 - val_loss: 2.3346 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.3248\n",
      "Epoch 1933/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.6854 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6750 - val_loss: 2.2762 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.2625\n",
      "Epoch 1934/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.6565 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6454 - val_loss: 2.0737 - val_output_headline_vector_loss: 0.0117 - val_headline_token_classes_loss: 2.0620\n",
      "Epoch 1935/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.6063 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.5958 - val_loss: 2.3354 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.3205\n",
      "Epoch 1936/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.6735 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.6636 - val_loss: 2.5049 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.4957\n",
      "Epoch 1937/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.7451 - output_headline_vector_loss: 0.0098 - headline_token_classes_loss: 1.7353 - val_loss: 2.3488 - val_output_headline_vector_loss: 0.0105 - val_headline_token_classes_loss: 2.3383\n",
      "Epoch 1938/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.5790 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.5686 - val_loss: 2.2879 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.2758\n",
      "Epoch 1939/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.5944 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.5839 - val_loss: 2.1959 - val_output_headline_vector_loss: 0.0153 - val_headline_token_classes_loss: 2.1806\n",
      "Epoch 1940/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.6842 - output_headline_vector_loss: 0.0095 - headline_token_classes_loss: 1.6746 - val_loss: 2.1528 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.1413\n",
      "Epoch 1941/2000\n",
      "4/4 [==============================] - 8s 2s/step - loss: 1.5699 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.5591 - val_loss: 2.2913 - val_output_headline_vector_loss: 0.0140 - val_headline_token_classes_loss: 2.2772\n",
      "Epoch 1942/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.5306 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.5193 - val_loss: 2.9006 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.8905\n",
      "Epoch 1943/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6361 - output_headline_vector_loss: 0.0108 - headline_token_classes_loss: 1.6252 - val_loss: 2.4134 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.4025\n",
      "Epoch 1944/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.5539 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.5431 - val_loss: 2.4930 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.4822\n",
      "Epoch 1945/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.5774 - output_headline_vector_loss: 0.0109 - headline_token_classes_loss: 1.5665 - val_loss: 2.3416 - val_output_headline_vector_loss: 0.0137 - val_headline_token_classes_loss: 2.3279\n",
      "Epoch 1946/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.5468 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.5361 - val_loss: 2.3052 - val_output_headline_vector_loss: 0.0129 - val_headline_token_classes_loss: 2.2923\n",
      "Epoch 1947/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6169 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6069 - val_loss: 2.1948 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.1839\n",
      "Epoch 1948/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.6052 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.5948 - val_loss: 2.5605 - val_output_headline_vector_loss: 0.0095 - val_headline_token_classes_loss: 2.5509\n",
      "Epoch 1949/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.6897 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6792 - val_loss: 2.3165 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.3059\n",
      "Epoch 1950/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.5382 - output_headline_vector_loss: 0.0118 - headline_token_classes_loss: 1.5264 - val_loss: 2.5204 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.5105\n",
      "Epoch 1951/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.5273 - output_headline_vector_loss: 0.0114 - headline_token_classes_loss: 1.5159 - val_loss: 2.4423 - val_output_headline_vector_loss: 0.0106 - val_headline_token_classes_loss: 2.4317\n",
      "Epoch 1952/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.5741 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.5636 - val_loss: 2.2139 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.2023\n",
      "Epoch 1953/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6667 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6562 - val_loss: 2.0685 - val_output_headline_vector_loss: 0.0158 - val_headline_token_classes_loss: 2.0528\n",
      "Epoch 1954/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.5702 - output_headline_vector_loss: 0.0110 - headline_token_classes_loss: 1.5592 - val_loss: 2.2517 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.2398\n",
      "Epoch 1955/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5031 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.4920 - val_loss: 1.9972 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 1.9857\n",
      "Epoch 1956/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 6s 1s/step - loss: 1.6787 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6687 - val_loss: 2.3267 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.3147\n",
      "Epoch 1957/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6043 - output_headline_vector_loss: 0.0119 - headline_token_classes_loss: 1.5924 - val_loss: 2.2702 - val_output_headline_vector_loss: 0.0103 - val_headline_token_classes_loss: 2.2598\n",
      "Epoch 1958/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.7482 - output_headline_vector_loss: 0.0097 - headline_token_classes_loss: 1.7385 - val_loss: 2.2281 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.2166\n",
      "Epoch 1959/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6474 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.6375 - val_loss: 2.3810 - val_output_headline_vector_loss: 0.0099 - val_headline_token_classes_loss: 2.3711\n",
      "Epoch 1960/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6864 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6762 - val_loss: 2.1639 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.1520\n",
      "Epoch 1961/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.7224 - output_headline_vector_loss: 0.0094 - headline_token_classes_loss: 1.7129 - val_loss: 1.9356 - val_output_headline_vector_loss: 0.0150 - val_headline_token_classes_loss: 1.9207\n",
      "Epoch 1962/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6592 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6491 - val_loss: 2.4409 - val_output_headline_vector_loss: 0.0104 - val_headline_token_classes_loss: 2.4305\n",
      "Epoch 1963/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.5883 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.5782 - val_loss: 2.0821 - val_output_headline_vector_loss: 0.0202 - val_headline_token_classes_loss: 2.0619\n",
      "Epoch 1964/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5437 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.5331 - val_loss: 2.0664 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.0545\n",
      "Epoch 1965/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5370 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.5265 - val_loss: 2.3251 - val_output_headline_vector_loss: 0.0130 - val_headline_token_classes_loss: 2.3121\n",
      "Epoch 1966/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6484 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6384 - val_loss: 2.1330 - val_output_headline_vector_loss: 0.0120 - val_headline_token_classes_loss: 2.1210\n",
      "Epoch 1967/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6479 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.6368 - val_loss: 2.3371 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.3270\n",
      "Epoch 1968/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.6447 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6343 - val_loss: 2.3111 - val_output_headline_vector_loss: 0.0144 - val_headline_token_classes_loss: 2.2967\n",
      "Epoch 1969/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.5950 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.5843 - val_loss: 2.3984 - val_output_headline_vector_loss: 0.0093 - val_headline_token_classes_loss: 2.3891\n",
      "Epoch 1970/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6062 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.5956 - val_loss: 2.2365 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.2245\n",
      "Epoch 1971/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6141 - output_headline_vector_loss: 0.0099 - headline_token_classes_loss: 1.6042 - val_loss: 2.1635 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.1513\n",
      "Epoch 1972/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6164 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6063 - val_loss: 2.3180 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3079\n",
      "Epoch 1973/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5234 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.5121 - val_loss: 2.0906 - val_output_headline_vector_loss: 0.0145 - val_headline_token_classes_loss: 2.0761\n",
      "Epoch 1974/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6238 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.6133 - val_loss: 2.2990 - val_output_headline_vector_loss: 0.0102 - val_headline_token_classes_loss: 2.2889\n",
      "Epoch 1975/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.5681 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.5577 - val_loss: 2.7081 - val_output_headline_vector_loss: 0.0097 - val_headline_token_classes_loss: 2.6984\n",
      "Epoch 1976/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.6376 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6271 - val_loss: 2.1957 - val_output_headline_vector_loss: 0.0109 - val_headline_token_classes_loss: 2.1849\n",
      "Epoch 1977/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.6213 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 1.6113 - val_loss: 2.1873 - val_output_headline_vector_loss: 0.0116 - val_headline_token_classes_loss: 2.1757\n",
      "Epoch 1978/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.6313 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.6206 - val_loss: 2.3848 - val_output_headline_vector_loss: 0.0101 - val_headline_token_classes_loss: 2.3747\n",
      "Epoch 1979/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.5016 - output_headline_vector_loss: 0.0112 - headline_token_classes_loss: 1.4903 - val_loss: 2.3726 - val_output_headline_vector_loss: 0.0096 - val_headline_token_classes_loss: 2.3629\n",
      "Epoch 1980/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.6129 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.6025 - val_loss: 2.5564 - val_output_headline_vector_loss: 0.0092 - val_headline_token_classes_loss: 2.5471\n",
      "Epoch 1981/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6362 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.6261 - val_loss: 2.2059 - val_output_headline_vector_loss: 0.0123 - val_headline_token_classes_loss: 2.1936\n",
      "Epoch 1982/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.4940 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.4829 - val_loss: 2.0203 - val_output_headline_vector_loss: 0.0121 - val_headline_token_classes_loss: 2.0081\n",
      "Epoch 1983/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.6635 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.6530 - val_loss: 2.3779 - val_output_headline_vector_loss: 0.0108 - val_headline_token_classes_loss: 2.3671\n",
      "Epoch 1984/2000\n",
      "4/4 [==============================] - 4s 1s/step - loss: 1.5848 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.5746 - val_loss: 2.1045 - val_output_headline_vector_loss: 0.0100 - val_headline_token_classes_loss: 2.0944\n",
      "Epoch 1985/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.5700 - output_headline_vector_loss: 0.0113 - headline_token_classes_loss: 1.5588 - val_loss: 2.7528 - val_output_headline_vector_loss: 0.0156 - val_headline_token_classes_loss: 2.7372\n",
      "Epoch 1986/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.8894 - output_headline_vector_loss: 0.0102 - headline_token_classes_loss: 1.8792 - val_loss: 2.6985 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.6864\n",
      "Epoch 1987/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.0919 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 2.0816 - val_loss: 2.3655 - val_output_headline_vector_loss: 0.0156 - val_headline_token_classes_loss: 2.3499\n",
      "Epoch 1988/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 2.0369 - output_headline_vector_loss: 0.0096 - headline_token_classes_loss: 2.0273 - val_loss: 2.1351 - val_output_headline_vector_loss: 0.0148 - val_headline_token_classes_loss: 2.1203\n",
      "Epoch 1989/2000\n",
      "4/4 [==============================] - 6s 2s/step - loss: 1.7609 - output_headline_vector_loss: 0.0117 - headline_token_classes_loss: 1.7492 - val_loss: 2.2116 - val_output_headline_vector_loss: 0.0125 - val_headline_token_classes_loss: 2.1990\n",
      "Epoch 1990/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.7247 - output_headline_vector_loss: 0.0111 - headline_token_classes_loss: 1.7136 - val_loss: 2.3311 - val_output_headline_vector_loss: 0.0141 - val_headline_token_classes_loss: 2.3170\n",
      "Epoch 1991/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.8696 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8590 - val_loss: 2.4471 - val_output_headline_vector_loss: 0.0107 - val_headline_token_classes_loss: 2.4364\n",
      "Epoch 1992/2000\n",
      "4/4 [==============================] - 7s 2s/step - loss: 1.9397 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.9291 - val_loss: 2.5433 - val_output_headline_vector_loss: 0.0111 - val_headline_token_classes_loss: 2.5322\n",
      "Epoch 1993/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.8724 - output_headline_vector_loss: 0.0107 - headline_token_classes_loss: 1.8617 - val_loss: 2.1646 - val_output_headline_vector_loss: 0.0134 - val_headline_token_classes_loss: 2.1512\n",
      "Epoch 1994/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.8570 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8464 - val_loss: 2.1899 - val_output_headline_vector_loss: 0.0184 - val_headline_token_classes_loss: 2.1715\n",
      "Epoch 1995/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 2.0159 - output_headline_vector_loss: 0.0100 - headline_token_classes_loss: 2.0059 - val_loss: 2.0731 - val_output_headline_vector_loss: 0.0131 - val_headline_token_classes_loss: 2.0600\n",
      "Epoch 1996/2000\n",
      "4/4 [==============================] - 6s 1s/step - loss: 1.9317 - output_headline_vector_loss: 0.0105 - headline_token_classes_loss: 1.9211 - val_loss: 2.4059 - val_output_headline_vector_loss: 0.0114 - val_headline_token_classes_loss: 2.3944\n",
      "Epoch 1997/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.9145 - output_headline_vector_loss: 0.0101 - headline_token_classes_loss: 1.9044 - val_loss: 2.0947 - val_output_headline_vector_loss: 0.0171 - val_headline_token_classes_loss: 2.0775\n",
      "Epoch 1998/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.7210 - output_headline_vector_loss: 0.0104 - headline_token_classes_loss: 1.7106 - val_loss: 2.1221 - val_output_headline_vector_loss: 0.0119 - val_headline_token_classes_loss: 2.1102\n",
      "Epoch 1999/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.8630 - output_headline_vector_loss: 0.0106 - headline_token_classes_loss: 1.8525 - val_loss: 2.1062 - val_output_headline_vector_loss: 0.0122 - val_headline_token_classes_loss: 2.0940\n",
      "Epoch 2000/2000\n",
      "4/4 [==============================] - 5s 1s/step - loss: 1.7889 - output_headline_vector_loss: 0.0103 - headline_token_classes_loss: 1.7786 - val_loss: 2.4031 - val_output_headline_vector_loss: 0.0115 - val_headline_token_classes_loss: 2.3916\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(tdg, callbacks=[mc,tb], initial_epoch=0\n",
    "                           ,steps_per_epoch=train_steps_per_epoch\n",
    "                           ,validation_data=vdg\n",
    "                           ,validation_steps=val_steps_per_epoch\n",
    "                           ,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from matplotlib import pyplot as plt\n",
    "# acc = hist.history['acc']\n",
    "# loss = hist.history['loss']\n",
    "\n",
    "# # Create count of the number of epochs\n",
    "# epoch_count = range(1, len(acc) + 1)\n",
    "\n",
    "# # Visualize loss history\n",
    "# # plt.plot(epoch_count, acc, 'b-')\n",
    "# fig, ax = plt.subplots(ncols=2,sharex=True)\n",
    "# ax[0].plot(epoch_count, loss, 'r--')\n",
    "# ax[0].legend(['Loss'])\n",
    "# ax[0].set_xlabel('Epoch')\n",
    "# ax[0].set_ylabel('Loss')\n",
    "# ax[1].plot(epoch_count, acc, 'b-')\n",
    "# ax[1].legend(['Accuracy'])\n",
    "# ax[1].set_xlabel('Epoch')\n",
    "# ax[1].set_xlabel('Accuracy')\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res = pd.DataFrame(hist.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_res[['loss','val_loss']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # df_res[['acc','val_acc']].plot()\n",
    "# hd_nlp = nlp(\"What is you name my name is Anthony Gonsalves What is you name my name is Anthony GonsalvesWhat is you name my name is Anthony GonsalvesWhat is you name my name is Anthony GonsalvesWhat is you name my name is Anthony GonsalvesWhat is you name my name is Anthony Gonsalves!\".lower())\n",
    "# len(hd_nlp[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evalutate SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mshaikh2/anaconda3/envs/tf-gpu/lib/python3.5/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `evaluate_generator` call to the Keras 2 API: `evaluate_generator(<generator..., steps=5, use_multiprocessing=True)`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.2396193504333497, 0.011775833927094937, 2.2278435707092283]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('weights/dnf700_sa_sent_hd_vector_word_gl.hdf5')\n",
    "model.evaluate_generator(test_dg,steps=5,pickle_safe = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(test_dg)\n",
    "pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['us officials try to scare voters with terror threat',\n",
       "       'obama declares his family will move to canada if trump is elected',\n",
       "       'hillary clinton used hand signals to rig debate?',\n",
       "       'hillary’s (islamic) america is already here where ‘muslim no-go zones’ are popping up all over michiganistan',\n",
       "       'former nato chief: we need us as ‘world’s policeman’',\n",
       "       'trump accuses obama, hillary clinton of founding daesh',\n",
       "       'top aide: hillary ‘still not perfect in her head’, wikileaks',\n",
       "       \"fantastic! trump's 7 point plan to reform healthcare begins with a bombshell! » 100percentfedup.com\",\n",
       "       'us officials try to scare voters with terror threat',\n",
       "       '(video) female college students protesting because ‘trump is a rapist’',\n",
       "       'hillary friend bribed fbi agent and his wife',\n",
       "       'fbi director received millions from clinton foundation, his brother’s law firm does clinton’s taxes',\n",
       "       \"physician confirms hillary clinton has parkinson's disease\",\n",
       "       'kremlin: putin congratulates trump, hopes to work together major issues',\n",
       "       'jill stein endorsed donald trump',\n",
       "       'kremlin: putin congratulates trump, hopes to work together major issues',\n",
       "       \"george soros: trump will win popular vote by a landslide but clinton victory a 'done deal'\",\n",
       "       'us officials try to scare voters with terror threat',\n",
       "       'jill stein endorsed donald trump',\n",
       "       'former nato chief: we need us as ‘world’s policeman’',\n",
       "       'fbi agent suspected in hillary email leaks found dead in apparent murder-suicide',\n",
       "       'trump accuses obama, hillary clinton of founding daesh',\n",
       "       'fbi agent suspected in hillary email leaks found dead in apparent murder-suicide',\n",
       "       'president obama confirms he will refuse to leave office if trump is elected',\n",
       "       'hillary’s (islamic) america is already here where ‘muslim no-go zones’ are popping up all over michiganistan',\n",
       "       'hillary sold weapons to isis, wikileaks confirms',\n",
       "       'us officials try to scare voters with terror threat',\n",
       "       'president obama confirms he will refuse to leave office if trump is elected',\n",
       "       'hillary friend bribed fbi agent and his wife',\n",
       "       'breaking: fraudulent clinton votes discovered by the tens of thousands',\n",
       "       'erdoğan: us, the founder of isis',\n",
       "       \"fantastic! trump's 7 point plan to reform healthcare begins with a bombshell! » 100percentfedup.com\",\n",
       "       'hillary clinton used hand signals to rig debate?',\n",
       "       \"hillary clinton wore 'secret earpiece' during commander-in-chief forum\",\n",
       "       'former nato chief: we need us as ‘world’s policeman’',\n",
       "       'the clinton foundation has purchased over $137 million of illegal arms and ammunition',\n",
       "       'wikileaks: hillary got $12 million for clinton charity as quid pro quo for morocco meeting',\n",
       "       \"hillary clinton cut her tax bill by 'donating' $1 million to herself via the clinton foundation?\",\n",
       "       'us officials see no link between trump and russia',\n",
       "       'us threatens military hacks on russia’s electric, communications grids over election',\n",
       "       'reddit users declare war on hillary’s paid internet trolls',\n",
       "       'department of homeland security chairman officially indicts hillary clinton of treason',\n",
       "       'department of homeland security chairman officially indicts hillary clinton of treason',\n",
       "       'hillary clinton’s sudden move of $1.8 billion to qatar central bank stuns financial world',\n",
       "       \"fantastic! trump's 7 point plan to reform healthcare begins with a bombshell! » 100percentfedup.com\",\n",
       "       'hillary clinton used hand signals to rig debate?',\n",
       "       'us officials see no link between trump and russia',\n",
       "       'developing: obama wh admits that hillary gave isis $400 million on accident',\n",
       "       'erdoğan: us, the founder of isis',\n",
       "       \"doj's loretta lynch tried to squash comey's letter to congress\"],\n",
       "      dtype='<U108')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['headline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hillary clinton used hand signals to rig debate?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx = np.random.randint(0,50)\n",
    "display(x['headline'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hillary Clinton is not above cheating, lying or stealing to get what she wants.',\n",
       " 'So it shouldn’t be any surprise that she is being accused of cheating during Monday’s 1st Presidential debate.',\n",
       " 'Clinton was accused of cheating by sending hand signals to the moderator Lester Holt.',\n",
       " 'During the debate when Clinton wanted to signal Holt whent she wanted the floor, she rubbed her face in a manner similar to a baseball manager.',\n",
       " 'According to True Pundit she has not done this in any other debates during her career supporting the accusation that these were signals.',\n",
       " 'Author and journalist Mike Cernovich reached out to poker pros to see if Hillary was signalling Lester Holt with hand gestures during Monday’s debate.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['sentences'][test_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca1 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca2 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca3 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "sentence_vectors (InputLayer)   (None, 500, 300)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 16)      14416       sentence_vectors[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 500, 16)      0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 500, 32)      1568        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 500, 32)      0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 32)      128         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sa1 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa2 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa3 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "sa4 (SelfAttention)             [(None, 500, 32), (5 2377        batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "input_headline_vector (InputLay (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 128)     0           sa1[0][0]                        \n",
      "                                                                 sa2[0][0]                        \n",
      "                                                                 sa3[0][0]                        \n",
      "                                                                 sa4[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          77056       input_headline_vector[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 500, 256)     98560       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1, 256)       0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 500, 256)     0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 1, 256)       1024        lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 256)     1024        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "ca4 (CrossAttention)            [(None, 500, 256), ( 148033      batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 351,317\n",
      "Trainable params: 350,229\n",
      "Non-trainable params: 1,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = Model(model.inputs,model.get_layer(name='ca1').output)\n",
    "model_2 = Model(model.inputs,model.get_layer(name='ca2').output)\n",
    "model_3 = Model(model.inputs,model.get_layer(name='ca3').output)\n",
    "model_4 = Model(model.inputs,model.get_layer(name='ca4').output)\n",
    "model_1.summary()\n",
    "model_2.summary()\n",
    "model_3.summary()\n",
    "model_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, b1, g1 = model_1.predict(x)\n",
    "_, b2, g2 = model_2.predict(x)\n",
    "_, b3, g3 = model_3.predict(x)\n",
    "_, b4, g4 = model_4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b1+b2+b3+b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 5, 2, 1])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_N = 5\n",
    "t = b[test_idx][0][:len(x['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "146.41356"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "b[test_idx][0][:len(x['sentences'][test_idx])].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hillary clinton used hand signals to rig debate?'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['So it shouldn’t be any surprise that she is being accused of cheating during Monday’s 1st Presidential debate.',\n",
       " 'Clinton was accused of cheating by sending hand signals to the moderator Lester Holt.',\n",
       " 'During the debate when Clinton wanted to signal Holt whent she wanted the floor, she rubbed her face in a manner similar to a baseball manager.']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(x['headline'][test_idx])\n",
    "display(x['claims'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 : According to True Pundit she has not done this in any other debates during her career supporting the accusation that these were signals.\n",
      "3 : During the debate when Clinton wanted to signal Holt whent she wanted the floor, she rubbed her face in a manner similar to a baseball manager.\n",
      "5 : Author and journalist Mike Cernovich reached out to poker pros to see if Hillary was signalling Lester Holt with hand gestures during Monday’s debate.\n",
      "2 : Clinton was accused of cheating by sending hand signals to the moderator Lester Holt.\n",
      "1 : So it shouldn’t be any surprise that she is being accused of cheating during Monday’s 1st Presidential debate.\n"
     ]
    }
   ],
   "source": [
    "for s in t:\n",
    "    if s>=len(x['sentences'][test_idx]):continue\n",
    "    print(s,':',x['sentences'][test_idx][s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "146.41356"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(x['sentences'][test_idx]))\n",
    "h_s_attended_vector = b[test_idx][0][:len(x['sentences'][test_idx])]\n",
    "h_s_attended_vector.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h_s_attended_vector = pd.DataFrame(h_s_attended_vector)\n",
    "\n",
    "\n",
    "xw = df_h_s_attended_vector.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "xw_scaled = min_max_scaler.fit_transform(xw)\n",
    "df_h_s_attended_vector = pd.DataFrame(xw_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f7453721358>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 144x504 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(2.0,7.0)})\n",
    "sns.heatmap(df_h_s_attended_vector, annot=True, cmap='YlGnBu', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Between Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa1 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa2 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa3 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "sentence_vectors (InputLayer (None, 500, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 500, 16)           14416     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 500, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 32)           1568      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 32)           128       \n",
      "_________________________________________________________________\n",
      "sa4 (SelfAttention)          [(None, 500, 32), (500, 5 2377      \n",
      "=================================================================\n",
      "Total params: 18,489\n",
      "Trainable params: 18,425\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_s1 = Model(model.inputs,model.get_layer(name='sa1').output)\n",
    "model_s2 = Model(model.inputs,model.get_layer(name='sa2').output)\n",
    "model_s3 = Model(model.inputs,model.get_layer(name='sa3').output)\n",
    "model_s4 = Model(model.inputs,model.get_layer(name='sa4').output)\n",
    "model_s1.summary()\n",
    "model_s2.summary()\n",
    "model_s3.summary()\n",
    "model_s4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sb1, sg1 = model_s1.predict([x['sentence_vectors'],x['input_headline_vector']])\n",
    "_, sb2, sg2 = model_s2.predict(x)\n",
    "_, sb3, sg3 = model_s3.predict(x)\n",
    "_, sb4, sg4 = model_s4.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb = sb1[test_idx]#+sb2[test_idx]+sb3[test_idx]+sb4[test_idx]\n",
    "sb = sb[:len(x['sentences'][test_idx]),:len(x['sentences'][test_idx])]\n",
    "\n",
    "sb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sb = pd.DataFrame(sb)\n",
    "\n",
    "\n",
    "zx = df_sb.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "zx_scaled = min_max_scaler.fit_transform(zx)\n",
    "df_sb = pd.DataFrame(zx_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f74545467b8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x864 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(rc={'figure.figsize':(14.0,12.0)})\n",
    "sns.heatmap(pd.DataFrame(df_sb),annot=True,cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hillary Clinton is not above cheating, lying or stealing to get what she wants.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So it shouldn’t be any surprise that she is being accused of cheating during Monday’s 1st Presidential debate.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clinton was accused of cheating by sending hand signals to the moderator Lester Holt.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>During the debate when Clinton wanted to signal Holt whent she wanted the floor, she rubbed her face in a manner similar to a baseball manager.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>According to True Pundit she has not done this in any other debates during her career supporting the accusation that these were signals.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Author and journalist Mike Cernovich reached out to poker pros to see if Hillary was signalling Lester Holt with hand gestures during Monday’s debate.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                        0\n",
       "0  Hillary Clinton is not above cheating, lying or stealing to get what she wants.                                                                       \n",
       "1  So it shouldn’t be any surprise that she is being accused of cheating during Monday’s 1st Presidential debate.                                        \n",
       "2  Clinton was accused of cheating by sending hand signals to the moderator Lester Holt.                                                                 \n",
       "3  During the debate when Clinton wanted to signal Holt whent she wanted the floor, she rubbed her face in a manner similar to a baseball manager.       \n",
       "4  According to True Pundit she has not done this in any other debates during her career supporting the accusation that these were signals.              \n",
       "5  Author and journalist Mike Cernovich reached out to poker pros to see if Hillary was signalling Lester Holt with hand gestures during Monday’s debate."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(x['sentences'][test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def datagen_dnf_eval():\n",
    "\n",
    "    ar_ids,ar_sents,ar_head_vectors,ar_head_classes,hds,ar_claims, ar_sentences=[],[],[],[],[],[],[]\n",
    "\n",
    "    for idx in dnf_eval.id: \n",
    "        hd = dnf_eval[dnf_eval.id==idx]['headline'].values[0].lower()\n",
    "        ar_id = dnf_eval[dnf_eval.id==idx]['id'].values[0]\n",
    "        cl = dnf_eval[dnf_eval.id==idx]['claim_ids'].values[0]\n",
    "        ar_claims.append(cl)\n",
    "        sentences = articles300[ar_id]\n",
    "        vectors = article_vectors300[ar_id]\n",
    "\n",
    "\n",
    "        hds.append(hd)\n",
    "        ar_sentences.append(sentences)\n",
    "    #         print(len(sentences))\n",
    "        sents = np.zeros((max_sentences,300))\n",
    "\n",
    "        sents[:len(vectors)] = vectors\n",
    "        ar_ids.append(ar_id)\n",
    "        ar_sents.append(sents)\n",
    "        hd_nlp = nlp(hd.lower())\n",
    "        hd_nlp = hd_nlp[:50]\n",
    "        head_classes = np.zeros(50, dtype='int')\n",
    "        for i in range(len(hd_nlp)):\n",
    "            head_classes[i] = hd_nlp[i].rank\n",
    "        ar_head_vectors.append(hd_nlp.vector)\n",
    "        ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "\n",
    "        inputs = {\n",
    "            'article_id': np.array(ar_ids)\n",
    "            ,'headline': np.array(hds)\n",
    "            ,'sentence_vectors' : np.array(ar_sents)\n",
    "            ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "            ,'claims':np.array(ar_claims)\n",
    "            ,'sentences':np.array(ar_sentences)\n",
    "        }\n",
    "        outputs = {\n",
    "            'headline_token_classes': np.array(ar_head_classes)\n",
    "            ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "        }\n",
    "    return inputs,outputs\n",
    "testX,testY = datagen_dnf_eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# display(testX['headline'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for P, R, F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37300000000000005, 0.5006666666666667, 0.4275055322396032)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(testX)\n",
    "_, b2, g2 = model_2.predict(testX)\n",
    "_, b3, g3 = model_3.predict(testX)\n",
    "_, b4, g4 = model_4.predict(testX)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in range(len(testX['headline'])):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(testX['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    pred = b[0][:len(testX['sentences'][test_idx])].argsort()[-best_N:][::-1]\n",
    "    \n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for p in pred:\n",
    "        if p in claims:\n",
    "            tp+=1\n",
    "        else:\n",
    "            fp+=1\n",
    "    for c in claims:\n",
    "        if c not in pred:\n",
    "            fn+=1\n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "#     counter+=1\n",
    "#     if counter==5:\n",
    "#         break\n",
    "#     print(\"----------------------------\")\n",
    "#     for s in t:\n",
    "#         if s>=len(x['sentences'][test_idx]):continue\n",
    "#         x['sentences'][test_idx][s]\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ce4017dc7a4cffa01f8ff24f9f7374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44c0d149896845a6a89dd891773bde01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2808510638297872, 0.11621676196144283, 0.16440315287033902)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hd_tp_cdc = pd.read_csv('evaluation_set/cdc_ibm/headline_topic_mapping.csv')\n",
    "df_ar_cl_cdc = pd.read_csv('evaluation_set/cdc_ibm/article_claim_mapping.csv')\n",
    "df_hd_tp_dnf = pd.read_json('evaluation_set/deepnofakes/Evaluation_Final_50_V4.json')\n",
    "df_hd_tp_dnf.columns = ['authors','claim_ids', 'evidence', 'headline', 'id', 'reason', 'claims', 'type', 'urls']\n",
    "with open('evaluation_set/cdc_ibm/articles.p', 'rb') as fp:\n",
    "    articles = pickle.load(fp)\n",
    "with open('evaluation_set/cdc_ibm/article_vectors.p', 'rb') as fp:\n",
    "    article_vectors = pickle.load(fp)\n",
    "with open('evaluation_set/word_mapping/id_word_mapping.p', 'rb') as fp:\n",
    "    id_word_mapping = pickle.load(fp)\n",
    "df_hd_tp_cdc.keys(),df_ar_cl_cdc.keys(), len(articles.keys()), len(article_vectors.keys()), df_hd_tp_dnf.keys()\n",
    "test_titles = []\n",
    "for ar in df_ar_cl_cdc.Article.unique():\n",
    "    if len(df_ar_cl_cdc[df_ar_cl_cdc.Article==ar]['Claim'].values)>8:\n",
    "        test_titles.append(ar)\n",
    "ar_ids,ar_sents,ar_sentences,ar_head_vectors,ar_head_classes,hds,claims=[],[],[],[],[],[],[]\n",
    "for idx in tqdm_notebook(test_titles):\n",
    "#     print(idx)\n",
    "    hd = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['Headline'].values[0].lower()\n",
    "    hds.append(hd)\n",
    "    ar_id = df_hd_tp_cdc[df_hd_tp_cdc.Title==idx]['article Id'].values[0]\n",
    "    cl = df_ar_cl_cdc[df_ar_cl_cdc.Article==idx]['Claim'].values\n",
    "    claims.append(cl)\n",
    "#     sentences=articles[ar_id]\n",
    "#     ar_sentences.append(ar_sentences)\n",
    "    #         print(len(sentences))\n",
    "    sents = np.zeros((max_sentences,300))\n",
    "    vectors = article_vectors[ar_id]\n",
    "    sents[:len(vectors)] = vectors[:max_sentences]\n",
    "    ar_ids.append(ar_id)\n",
    "    ar_sents.append(sents)\n",
    "    hd_nlp = nlp(hd.lower())\n",
    "    head_classes = np.zeros(50, dtype='int')\n",
    "    for i in range(len(hd_nlp)):\n",
    "        head_classes[i] = hd_nlp[i].rank\n",
    "    ar_head_vectors.append(hd_nlp.vector)\n",
    "    ar_head_classes.append(to_categorical(num_classes=20000,y=head_classes))\n",
    "inputs = {\n",
    "    'article_id': np.array(ar_ids)\n",
    "    ,'headline': np.array(hds)\n",
    "    ,'sentence_vectors' : np.array(ar_sents)\n",
    "#     ,'sentences' : np.array(ar_sentences)\n",
    "    ,'input_headline_vector': np.array(ar_head_vectors)\n",
    "    ,'claims':np.array(claims)\n",
    "}\n",
    "outputs = {\n",
    "    'headline_token_classes': np.array(ar_head_classes)\n",
    "    ,'output_headline_vector': np.array(ar_head_vectors)\n",
    "}\n",
    "threshold = 0.95\n",
    "best_N = 5\n",
    "_, b1, g1 = model_1.predict(inputs)\n",
    "_, b2, g2 = model_2.predict(inputs)\n",
    "_, b3, g3 = model_3.predict(inputs)\n",
    "_, b4, g4 = model_4.predict(inputs)\n",
    "ps, rs = [],[]\n",
    "counter=0\n",
    "for test_idx in tqdm_notebook(range(len(inputs['headline']))):    \n",
    "    tp,fp,fn = 0,0,0\n",
    "    claims = np.array(inputs['claims'][test_idx])\n",
    "#     sentences = list(range(len(articles[test_idx])))\n",
    "    b = b1[test_idx]+b2[test_idx]+b3[test_idx]+b4[test_idx]\n",
    "    ids = b[0][:len(articles[inputs['article_id'][test_idx]])].argsort()[-best_N:][::-1]\n",
    "#     print(ids)\n",
    "    pred = np.array(articles[inputs['article_id'][test_idx]])[ids]\n",
    "#     print('claims:',claims)\n",
    "#     print('pred:',pred)\n",
    "    for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "        t5 = nlp(str(pred[i]))\n",
    "        flag = False\n",
    "        #pred_claim_sent.append(pred[i])\n",
    "    #     print(t5.vector)\n",
    "        for j in range(len(cl)):\n",
    "            _c = nlp(cl[j])\n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                tp+=1\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fp+=1\n",
    "        \n",
    "            \n",
    "   \n",
    "    #     print(t5.vector)\n",
    "    for j in range(len(cl)):\n",
    "        _c = nlp(cl[j])\n",
    "        flag = False\n",
    "        for i in range(len(pred)):\n",
    "    #     print('===========***********',i,'***********============')\n",
    "            t5 = nlp(str(pred[i]))\n",
    "        \n",
    "    #         print(_c.vector)\n",
    "    #         print('top_5:',t5.text)\n",
    "    #         print('-------------------')\n",
    "    #         print('ground_truth:',_c.text)\n",
    "    #         print('t5:{0}, cl:{1}, sim: {2}'.format(i,j,np.around(t5.similarity(_c),4)))\n",
    "    #         print('===================================================================')\n",
    "            if np.around(t5.similarity(_c),4) > threshold:\n",
    "                flag = True\n",
    "                break\n",
    "        if flag is False:\n",
    "            fn+=1\n",
    "         \n",
    "    p = tp/(tp+fp)\n",
    "    r = tp/(tp+fn)\n",
    "#     print()\n",
    "#     tn = sentences - list(set(list(pred)+list(claims)))\n",
    "#     print(test_idx,', article id:',x['article_id'][test_idx], ',# sentences:',len(articles[x['article_id'][test_idx]]),\":\",p,r)\n",
    "    ps.append(p)\n",
    "    rs.append(r)\n",
    "\n",
    "np.average(ps), np.average(rs), 2*np.average(ps)*np.average(rs)/(np.average(ps)+ np.average(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
